{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff8ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的模块和库\n",
    "import os\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor, ops\n",
    "from mindspore.dataset import vision, transforms\n",
    "from mindspore.train import Model\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.dataset import MnistDataset\n",
    "\n",
    "# 定义LeNet5网络结构\n",
    "class LeNet5(nn.Cell):\n",
    "    \"\"\"\n",
    "    LeNet5卷积神经网络模型。\n",
    "    参数:\n",
    "    - num_class (int): 类别数量，默认为10。\n",
    "    - num_channel (int): 输入通道数量，默认为1。\n",
    "    - include_top (bool): 是否包括顶层（全连接层），默认为True。\n",
    "    \"\"\"\n",
    "    def __init__(self, num_class=10, num_channel=1, include_top=True):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 定义网络的卷积层和激活函数\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.include_top = include_top  # 是否包含顶层的标志\n",
    "        # 如果包含顶层，则定义全连接层\n",
    "        if self.include_top:\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.fc1 = nn.Dense(256, 120, weight_init=Normal(0.02))\n",
    "            self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "            self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "\n",
    "    \"\"\"\n",
    "    构造函数，定义网络的前向传播路径。\n",
    "    \"\"\"\n",
    "    def construct(self, x):\n",
    "        # 通过卷积层、激活函数和池化层处理输入\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        # 如果不包含顶层，则在池化层后直接返回\n",
    "        if not self.include_top:\n",
    "            return x\n",
    "        # 如果包含顶层，则将特征图展平并经过全连接层处理\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 创建LeNet5模型实例\n",
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25e5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapipe(path, batch_size):\n",
    "    \"\"\"\n",
    "    创建一个数据管道，用于加载和预处理MNIST数据集。\n",
    "\n",
    "    参数:\n",
    "    path (str): 数据集的路径，分为训练集和测试集。\n",
    "    batch_size (int): 批处理的大小。\n",
    "\n",
    "    返回:\n",
    "    dataset: 经过预处理和批处理后的数据集。\n",
    "    \"\"\"\n",
    "    # 图像预处理变换列表\n",
    "    image_transforms = [\n",
    "        vision.Rescale(1.0 / 255.0, 0),  # 图像缩放到0-1范围\n",
    "        vision.Normalize(mean=(0.1307,), std=(0.3081,)),  # 图像标准化\n",
    "        vision.HWC2CHW()  # 图像通道顺序从HWC转换为CHW\n",
    "    ]\n",
    "    # 标签预处理变换\n",
    "    label_transform = transforms.TypeCast(mindspore.int32)\n",
    "\n",
    "    # 加载MNIST数据集\n",
    "    dataset = MnistDataset(path)\n",
    "    # 应用图像预处理变换\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    # 应用标签预处理变换\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    # 批处理\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_dataset = datapipe('MNIST_Data/train', batch_size=64)\n",
    "test_dataset = datapipe('MNIST_Data/test', batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c309207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化学习率、训练轮数、损失函数和优化器\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = nn.SGD(model.trainable_params(), learning_rate=lr)\n",
    "\n",
    "# 定义前向传播函数，计算损失和激活值\n",
    "def forward_fn(data, label):\n",
    "    logits = model(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss, logits\n",
    "\n",
    "# 编译前向传播函数，以支持梯度计算和参数更新\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
    "\n",
    "# 定义一个训练步骤，包括梯度计算和参数更新\n",
    "def train_step(data, label):\n",
    "    (loss, _), grads = grad_fn(data, label)\n",
    "    optimizer(grads)\n",
    "    return loss\n",
    "\n",
    "# 定义训练循环，遍历数据集并进行训练\n",
    "def train_loop(model, dataset):\n",
    "    size = dataset.get_dataset_size()  # 获取数据集大小\n",
    "    model.set_train()  # 设置模型为训练模式\n",
    "    for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        loss = train_step(data, label)  # 执行一个训练步骤\n",
    "\n",
    "        # 每隔100个批次打印一次当前损失和批次号\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.asnumpy(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")\n",
    "\n",
    "# 定义测试循环，用于评估模型性能\n",
    "def test_loop(model, dataset, loss_fn):\n",
    "    num_batches = dataset.get_dataset_size()  # 获取数据集大小\n",
    "    model.set_train(False)  # 设置模型为评估模式\n",
    "    total, test_loss, correct = 0, 0, 0\n",
    "    for data, label in dataset.create_tuple_iterator():\n",
    "        pred = model(data)  # 做预测\n",
    "        total += len(data)  # 累计样本数\n",
    "        test_loss += loss_fn(pred, label).asnumpy()  # 累计损失\n",
    "        correct += (pred.argmax(1) == label).asnumpy().sum()  # 累计正确预测数\n",
    "    test_loss /= num_batches  # 计算平均损失\n",
    "    correct /= total  # 计算准确率\n",
    "    print(f\"Test: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8c9a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 检查模型文件是否存在，如果存在则加载模型参数，否则训练模型并保存\n",
    "model_path = 'model.ckpt'\n",
    "if os.path.exists(model_path):\n",
    "    # 加载模型参数\n",
    "    param_dict = mindspore.load_checkpoint(model_path)\n",
    "    mindspore.load_param_into_net(model, param_dict)\n",
    "    print('Loaded model from', model_path)\n",
    "else:\n",
    "    # 训练模型\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "        # 获取训练数据集大小\n",
    "        size = train_dataset.get_dataset_size()\n",
    "        model.set_train()\n",
    "        # 迭代训练数据集，并更新模型参数\n",
    "        for batch, (data, label) in enumerate(train_dataset.create_tuple_iterator()):\n",
    "            (loss, _), grads = grad_fn(data, label)\n",
    "            optimizer(grads)\n",
    "\n",
    "            # 每隔100个批次，打印当前损失值\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.asnumpy(), batch\n",
    "                print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")\n",
    "\n",
    "        # 在每个epoch结束时，进行模型测试\n",
    "        num_batches = test_dataset.get_dataset_size()\n",
    "        model.set_train(False)\n",
    "        total, test_loss, correct = 0, 0, 0\n",
    "        # 测试模型性能\n",
    "        for data, label in test_dataset.create_tuple_iterator():\n",
    "            pred = model(data)\n",
    "            total += len(data)\n",
    "            test_loss += loss_fn(pred, label).asnumpy()\n",
    "            correct += (pred.argmax(1) == label).asnumpy().sum()\n",
    "        test_loss /= num_batches\n",
    "        correct /= total\n",
    "        # 打印测试结果\n",
    "        print(f\"Test: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    print(\"Done!\")\n",
    "    # 保存训练好的模型参数\n",
    "    mindspore.save_checkpoint(model, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d9edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1, actual value: 1\n",
      "Predicted class: 1, actual value: 1\n",
      "Predicted class: 3, actual value: 3\n",
      "Predicted class: 0, actual value: 0\n",
      "Predicted class: 2, actual value: 2\n",
      "Predicted class: 5, actual value: 5\n",
      "Predicted class: 4, actual value: 4\n",
      "Predicted class: 2, actual value: 2\n",
      "Predicted class: 0, actual value: 0\n",
      "Predicted class: 7, actual value: 7\n"
     ]
    }
   ],
   "source": [
    "# 遍历测试数据集，并对每个样本进行预测\n",
    "for i in range(10):\n",
    "    # 获取一个测试样本及其标签\n",
    "    img, label = next(iter(test_dataset))\n",
    "    # 将图像样本调整为适合模型输入的格式\n",
    "    img = img[i].unsqueeze(0)\n",
    "    # 将图像数据转换为张量，并指定数据类型\n",
    "    input_data = Tensor(img, mindspore.float32)\n",
    "    # 初始化模型\n",
    "    net = Model(model)\n",
    "    # 使用模型进行预测\n",
    "    result = net.predict(input_data)\n",
    "    # 从预测结果中提取预测类别\n",
    "    pred = ops.argmax(result,dim=1).item()\n",
    "    # 打印预测类别和真实标签\n",
    "    print(f'Predicted class: {pred}, actual value: {label[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98046f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ms]",
   "language": "python",
   "name": "conda-env-ms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
