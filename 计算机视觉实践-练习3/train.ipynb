{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72687cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enable_modelarts': 'Whether training on modelarts, default: False', 'data_url': 'Url for modelarts', 'train_url': 'Url for modelarts', 'data_path': 'The location of the input data.', 'output_path': 'The location of the output file.', 'device_target': 'Device target, support GPU and Ascend.', 'enable_profiling': 'Whether enable profiling while training, default: False'}\n",
      "{'batch_size': 8,\n",
      " 'checkpoint_path': '/cache/checkpoint_path.ckpt',\n",
      " 'ckpt_file': '',\n",
      " 'config_path': 'G:\\\\PythonProject\\\\Peter\\\\model_utils\\\\../config.yaml',\n",
      " 'data_path': 'dataset/mindrecord',\n",
      " 'device_num': 1,\n",
      " 'device_target': 'CPU',\n",
      " 'enable_profiling': False,\n",
      " 'epoch_size': 40,\n",
      " 'file_format': 'MINDIR',\n",
      " 'file_name': 'srcnn',\n",
      " 'filter_weight': False,\n",
      " 'image_height': 512,\n",
      " 'image_path': '',\n",
      " 'image_width': 512,\n",
      " 'keep_checkpoint_max': 20,\n",
      " 'lr': 0.0001,\n",
      " 'output_folder': 'dataset/mindrecord',\n",
      " 'output_path': 'output/train',\n",
      " 'patch_size': 33,\n",
      " 'pre_trained_path': '',\n",
      " 'predict_path': '',\n",
      " 'pretrained_ckpt_path': '/cache/pretrained_ckpt/pretrained.ckpt',\n",
      " 'result_path': '',\n",
      " 'run_distribute': False,\n",
      " 'save_checkpoint': True,\n",
      " 'scale': 2,\n",
      " 'src_folder': 'dataset/train',\n",
      " 'stride': 99,\n",
      " 'test_pic': ''}\n",
      "Please check the above information for the configurations\n",
      "Running on CPU\n",
      "epoch: 1 step: 1, loss is 0.23835161328315735\n",
      "epoch: 1 step: 2, loss is 0.28626784682273865\n",
      "epoch: 1 step: 3, loss is 0.15014387667179108\n",
      "epoch: 1 step: 4, loss is 0.12582316994667053\n",
      "epoch: 1 step: 5, loss is 0.16138797998428345\n",
      "epoch: 1 step: 6, loss is 0.16020610928535461\n",
      "epoch: 1 step: 7, loss is 0.09507246315479279\n",
      "epoch: 1 step: 8, loss is 0.08858449757099152\n",
      "epoch: 1 step: 9, loss is 0.06526146084070206\n",
      "epoch: 1 step: 10, loss is 0.06717602908611298\n",
      "epoch: 1 step: 11, loss is 0.050787653774023056\n",
      "epoch: 1 step: 12, loss is 0.038288116455078125\n",
      "epoch: 1 step: 13, loss is 0.02421553246676922\n",
      "epoch: 1 step: 14, loss is 0.01539225410670042\n",
      "epoch: 1 step: 15, loss is 0.024160725995898247\n",
      "epoch: 1 step: 16, loss is 0.016707448288798332\n",
      "epoch: 1 step: 17, loss is 0.01703035458922386\n",
      "epoch: 1 step: 18, loss is 0.01500284019857645\n",
      "epoch: 1 step: 19, loss is 0.021753551438450813\n",
      "epoch: 1 step: 20, loss is 0.03220929205417633\n",
      "epoch: 1 step: 21, loss is 0.029269902035593987\n",
      "epoch: 1 step: 22, loss is 0.031089846044778824\n",
      "epoch: 1 step: 23, loss is 0.020017463713884354\n",
      "epoch: 1 step: 24, loss is 0.028641756623983383\n",
      "epoch: 1 step: 25, loss is 0.02224360965192318\n",
      "epoch: 1 step: 26, loss is 0.021757906302809715\n",
      "epoch: 1 step: 27, loss is 0.014804486185312271\n",
      "epoch: 1 step: 28, loss is 0.015944065526127815\n",
      "epoch: 1 step: 29, loss is 0.024832293391227722\n",
      "epoch: 1 step: 30, loss is 0.014165080152451992\n",
      "epoch: 1 step: 31, loss is 0.01488326583057642\n",
      "epoch: 1 step: 32, loss is 0.017239583656191826\n",
      "epoch: 1 step: 33, loss is 0.020155908539891243\n",
      "epoch: 1 step: 34, loss is 0.014323652721941471\n",
      "epoch: 1 step: 35, loss is 0.01671878807246685\n",
      "epoch: 1 step: 36, loss is 0.025307590141892433\n",
      "epoch: 1 step: 37, loss is 0.016153233125805855\n",
      "epoch: 1 step: 38, loss is 0.014885881915688515\n",
      "epoch: 1 step: 39, loss is 0.01882251165807247\n",
      "epoch: 1 step: 40, loss is 0.01899440586566925\n",
      "epoch: 1 step: 41, loss is 0.01354388240724802\n",
      "epoch: 1 step: 42, loss is 0.018256282433867455\n",
      "epoch: 1 step: 43, loss is 0.017401548102498055\n",
      "epoch: 1 step: 44, loss is 0.012275554239749908\n",
      "epoch: 1 step: 45, loss is 0.015911288559436798\n",
      "epoch: 1 step: 46, loss is 0.014400331303477287\n",
      "epoch: 1 step: 47, loss is 0.010885536670684814\n",
      "epoch: 1 step: 48, loss is 0.007437978405505419\n",
      "epoch: 1 step: 49, loss is 0.012235408648848534\n",
      "epoch: 1 step: 50, loss is 0.014280363917350769\n",
      "epoch: 1 step: 51, loss is 0.010155451484024525\n",
      "epoch: 1 step: 52, loss is 0.008537686429917812\n",
      "epoch: 1 step: 53, loss is 0.01144258864223957\n",
      "epoch: 1 step: 54, loss is 0.009455258958041668\n",
      "epoch: 1 step: 55, loss is 0.013930382207036018\n",
      "epoch: 1 step: 56, loss is 0.007741242181509733\n",
      "epoch: 1 step: 57, loss is 0.009853078983724117\n",
      "epoch: 1 step: 58, loss is 0.014232656918466091\n",
      "epoch: 1 step: 59, loss is 0.011338923126459122\n",
      "epoch: 1 step: 60, loss is 0.012549405917525291\n",
      "epoch: 1 step: 61, loss is 0.011017251759767532\n",
      "epoch: 1 step: 62, loss is 0.01797889731824398\n",
      "epoch: 1 step: 63, loss is 0.007703193463385105\n",
      "epoch: 1 step: 64, loss is 0.006780114024877548\n",
      "epoch: 1 step: 65, loss is 0.009720764122903347\n",
      "epoch: 1 step: 66, loss is 0.014444955624639988\n",
      "epoch: 1 step: 67, loss is 0.012227710336446762\n",
      "epoch: 1 step: 68, loss is 0.010976225137710571\n",
      "epoch: 1 step: 69, loss is 0.008734765462577343\n",
      "epoch: 1 step: 70, loss is 0.007477265316992998\n",
      "epoch: 1 step: 71, loss is 0.010195259004831314\n",
      "epoch: 1 step: 72, loss is 0.010363521054387093\n",
      "epoch: 1 step: 73, loss is 0.0061496831476688385\n",
      "epoch: 1 step: 74, loss is 0.00878029316663742\n",
      "epoch: 1 step: 75, loss is 0.008741932921111584\n",
      "epoch: 1 step: 76, loss is 0.005559783428907394\n",
      "epoch: 1 step: 77, loss is 0.008764494210481644\n",
      "epoch: 1 step: 78, loss is 0.008260844275355339\n",
      "epoch: 1 step: 79, loss is 0.011404789052903652\n",
      "epoch: 1 step: 80, loss is 0.007836020551621914\n",
      "epoch: 1 step: 81, loss is 0.00791274942457676\n",
      "epoch: 1 step: 82, loss is 0.005841055419296026\n",
      "epoch: 1 step: 83, loss is 0.006582008674740791\n",
      "epoch: 1 step: 84, loss is 0.005706696305423975\n",
      "epoch: 1 step: 85, loss is 0.005915945861488581\n",
      "epoch: 1 step: 86, loss is 0.008157781325280666\n",
      "epoch: 1 step: 87, loss is 0.008568883873522282\n",
      "epoch: 1 step: 88, loss is 0.006450885906815529\n",
      "epoch: 1 step: 89, loss is 0.003050955943763256\n",
      "epoch: 1 step: 90, loss is 0.008275993168354034\n",
      "epoch: 1 step: 91, loss is 0.006157549098134041\n",
      "epoch: 1 step: 92, loss is 0.008664613589644432\n",
      "epoch: 1 step: 93, loss is 0.004621406551450491\n",
      "epoch: 1 step: 94, loss is 0.008653601631522179\n",
      "epoch: 1 step: 95, loss is 0.002795981476083398\n",
      "epoch: 1 step: 96, loss is 0.006722155958414078\n",
      "epoch: 1 step: 97, loss is 0.007299990393221378\n",
      "epoch: 1 step: 98, loss is 0.005538295954465866\n",
      "epoch: 1 step: 99, loss is 0.0038539699744433165\n",
      "epoch: 1 step: 100, loss is 0.00868923682719469\n",
      "epoch: 1 step: 101, loss is 0.005881720222532749\n",
      "epoch: 1 step: 102, loss is 0.004680319223552942\n",
      "epoch: 1 step: 103, loss is 0.004789726808667183\n",
      "epoch: 1 step: 104, loss is 0.003942238166928291\n",
      "epoch: 1 step: 105, loss is 0.004813263658434153\n",
      "epoch: 1 step: 106, loss is 0.01287037692964077\n",
      "epoch: 1 step: 107, loss is 0.0026280153542757034\n",
      "epoch: 1 step: 108, loss is 0.005151025950908661\n",
      "epoch: 1 step: 109, loss is 0.009007235057651997\n",
      "epoch: 1 step: 110, loss is 0.008629761636257172\n",
      "epoch: 1 step: 111, loss is 0.0057117571122944355\n",
      "epoch: 1 step: 112, loss is 0.004154452122747898\n",
      "epoch: 1 step: 113, loss is 0.006856244523078203\n",
      "epoch: 1 step: 114, loss is 0.009614112786948681\n",
      "epoch: 1 step: 115, loss is 0.003998185507953167\n",
      "epoch: 1 step: 116, loss is 0.004218467511236668\n",
      "epoch: 1 step: 117, loss is 0.004110799171030521\n",
      "epoch: 1 step: 118, loss is 0.008465473540127277\n",
      "epoch: 1 step: 119, loss is 0.004258864093571901\n",
      "epoch: 1 step: 120, loss is 0.003020660253241658\n",
      "epoch: 1 step: 121, loss is 0.0035866047255694866\n",
      "epoch: 1 step: 122, loss is 0.00428764708340168\n",
      "epoch: 1 step: 123, loss is 0.0050537316128611565\n",
      "epoch: 1 step: 124, loss is 0.0022177372593432665\n",
      "epoch: 1 step: 125, loss is 0.007684587500989437\n",
      "epoch: 1 step: 126, loss is 0.0077889771200716496\n",
      "epoch: 1 step: 127, loss is 0.0037449821829795837\n",
      "epoch: 1 step: 128, loss is 0.0024040378630161285\n",
      "epoch: 1 step: 129, loss is 0.004715857096016407\n",
      "epoch: 1 step: 130, loss is 0.004732166882604361\n",
      "epoch: 1 step: 131, loss is 0.00556223513558507\n",
      "epoch: 1 step: 132, loss is 0.002560408553108573\n",
      "epoch: 1 step: 133, loss is 0.0075318096205592155\n",
      "epoch: 1 step: 134, loss is 0.003555107628926635\n",
      "epoch: 1 step: 135, loss is 0.007018217816948891\n",
      "epoch: 1 step: 136, loss is 0.004387887194752693\n",
      "epoch: 1 step: 137, loss is 0.002291532466188073\n",
      "epoch: 1 step: 138, loss is 0.004539306741207838\n",
      "epoch: 1 step: 139, loss is 0.00460450816899538\n",
      "epoch: 1 step: 140, loss is 0.004968156572431326\n",
      "epoch: 1 step: 141, loss is 0.005265543237328529\n",
      "epoch: 1 step: 142, loss is 0.004209858365356922\n",
      "epoch: 1 step: 143, loss is 0.005398795008659363\n",
      "epoch: 1 step: 144, loss is 0.0062681217677891254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 145, loss is 0.007453128695487976\n",
      "epoch: 1 step: 146, loss is 0.0031996332108974457\n",
      "epoch: 1 step: 147, loss is 0.0036160338204354048\n",
      "epoch: 1 step: 148, loss is 0.002368620363995433\n",
      "epoch: 1 step: 149, loss is 0.002386759500950575\n",
      "epoch: 1 step: 150, loss is 0.002343876985833049\n",
      "epoch: 1 step: 151, loss is 0.006198520306497812\n",
      "epoch: 1 step: 152, loss is 0.004257000517100096\n",
      "epoch: 1 step: 153, loss is 0.0038512800820171833\n",
      "epoch: 1 step: 154, loss is 0.002820122754201293\n",
      "epoch: 1 step: 155, loss is 0.006789589766412973\n",
      "epoch: 1 step: 156, loss is 0.0023760416079312563\n",
      "epoch: 1 step: 157, loss is 0.004681270103901625\n",
      "epoch: 1 step: 158, loss is 0.0040529766120016575\n",
      "epoch: 1 step: 159, loss is 0.0038051640149205923\n",
      "epoch: 1 step: 160, loss is 0.0018088299548253417\n",
      "epoch: 1 step: 161, loss is 0.001459497376345098\n",
      "epoch: 1 step: 162, loss is 0.004867487587034702\n",
      "epoch: 1 step: 163, loss is 0.0029953056946396828\n",
      "epoch: 1 step: 164, loss is 0.0043536582961678505\n",
      "epoch: 1 step: 165, loss is 0.003187270136550069\n",
      "epoch: 1 step: 166, loss is 0.0048087951727211475\n",
      "epoch: 1 step: 167, loss is 0.0030743286479264498\n",
      "epoch: 1 step: 168, loss is 0.004600785672664642\n",
      "epoch: 1 step: 169, loss is 0.0027966785710304976\n",
      "epoch: 1 step: 170, loss is 0.002877989551052451\n",
      "epoch: 1 step: 171, loss is 0.0024722374510020018\n",
      "epoch: 1 step: 172, loss is 0.0018020030111074448\n",
      "epoch: 1 step: 173, loss is 0.003080127527937293\n",
      "epoch: 1 step: 174, loss is 0.002773798070847988\n",
      "epoch: 1 step: 175, loss is 0.0026061355601996183\n",
      "epoch: 1 step: 176, loss is 0.002093580085784197\n",
      "epoch: 1 step: 177, loss is 0.004199369810521603\n",
      "epoch: 1 step: 178, loss is 0.0022852071560919285\n",
      "epoch: 1 step: 179, loss is 0.0038386941887438297\n",
      "epoch: 1 step: 180, loss is 0.00279283057898283\n",
      "epoch: 1 step: 181, loss is 0.0028047177474945784\n",
      "epoch: 1 step: 182, loss is 0.001739596831612289\n",
      "epoch: 1 step: 183, loss is 0.0024561299942433834\n",
      "epoch: 1 step: 184, loss is 0.0025644367560744286\n",
      "epoch: 1 step: 185, loss is 0.002318671438843012\n",
      "epoch: 1 step: 186, loss is 0.0017890081508085132\n",
      "epoch: 1 step: 187, loss is 0.0016080121276900172\n",
      "epoch: 1 step: 188, loss is 0.002212382620200515\n",
      "epoch: 1 step: 189, loss is 0.0016679608961567283\n",
      "epoch: 1 step: 190, loss is 0.002323295921087265\n",
      "epoch: 1 step: 191, loss is 0.0036471602506935596\n",
      "epoch: 1 step: 192, loss is 0.001414040569216013\n",
      "epoch: 1 step: 193, loss is 0.0014576826943084598\n",
      "epoch: 1 step: 194, loss is 0.002498478163033724\n",
      "epoch: 1 step: 195, loss is 0.0027526752091944218\n",
      "epoch: 1 step: 196, loss is 0.005918142385780811\n",
      "epoch: 1 step: 197, loss is 0.005598618648946285\n",
      "epoch: 1 step: 198, loss is 0.0021247579716145992\n",
      "epoch: 1 step: 199, loss is 0.002205879660323262\n",
      "epoch: 1 step: 200, loss is 0.0025591785088181496\n",
      "epoch: 1 step: 201, loss is 0.0023463305551558733\n",
      "epoch: 1 step: 202, loss is 0.0023199182469397783\n",
      "epoch: 1 step: 203, loss is 0.003921033814549446\n",
      "epoch: 1 step: 204, loss is 0.0016757013509050012\n",
      "epoch: 1 step: 205, loss is 0.0020193038508296013\n",
      "epoch: 1 step: 206, loss is 0.00328461523167789\n",
      "epoch: 1 step: 207, loss is 0.003577206050977111\n",
      "epoch: 1 step: 208, loss is 0.0028499995823949575\n",
      "epoch: 1 step: 209, loss is 0.005519241094589233\n",
      "epoch: 1 step: 210, loss is 0.00207941303960979\n",
      "epoch: 1 step: 211, loss is 0.002847192343324423\n",
      "epoch: 1 step: 212, loss is 0.0019110934808850288\n",
      "epoch: 1 step: 213, loss is 0.0016550018917769194\n",
      "epoch: 1 step: 214, loss is 0.0034047304652631283\n",
      "epoch: 1 step: 215, loss is 0.0023722692858427763\n",
      "epoch: 1 step: 216, loss is 0.0025258976966142654\n",
      "epoch: 1 step: 217, loss is 0.001146157388575375\n",
      "epoch: 1 step: 218, loss is 0.002957108896225691\n",
      "epoch: 1 step: 219, loss is 0.0019143472891300917\n",
      "epoch: 1 step: 220, loss is 0.0026570926420390606\n",
      "epoch: 1 step: 221, loss is 0.002481467556208372\n",
      "epoch: 1 step: 222, loss is 0.0014183190651237965\n",
      "epoch: 1 step: 223, loss is 0.0028411834500730038\n",
      "epoch: 1 step: 224, loss is 0.0020349696278572083\n",
      "epoch: 1 step: 225, loss is 0.002938023069873452\n",
      "epoch: 1 step: 226, loss is 0.0030216819141060114\n",
      "epoch: 1 step: 227, loss is 0.0024453673977404833\n",
      "epoch: 1 step: 228, loss is 0.0014119847910478711\n",
      "epoch: 1 step: 229, loss is 0.0023677879944443703\n",
      "epoch: 1 step: 230, loss is 0.0030688706319779158\n",
      "epoch: 1 step: 231, loss is 0.0006948126247152686\n",
      "epoch: 1 step: 232, loss is 0.0028337938711047173\n",
      "epoch: 1 step: 233, loss is 0.003163797315210104\n",
      "epoch: 1 step: 234, loss is 0.001389597775414586\n",
      "epoch: 1 step: 235, loss is 0.0029153982177376747\n",
      "epoch: 1 step: 236, loss is 0.0021221053320914507\n",
      "epoch: 1 step: 237, loss is 0.0010998453944921494\n",
      "epoch: 1 step: 238, loss is 0.0013214461505413055\n",
      "epoch: 1 step: 239, loss is 0.0022038696333765984\n",
      "epoch: 1 step: 240, loss is 0.002226192969828844\n",
      "epoch: 1 step: 241, loss is 0.002761881100013852\n",
      "epoch: 1 step: 242, loss is 0.0018940989393740892\n",
      "epoch: 1 step: 243, loss is 0.003190217074006796\n",
      "epoch: 1 step: 244, loss is 0.0017873289762064815\n",
      "epoch: 1 step: 245, loss is 0.0024596918374300003\n",
      "epoch: 1 step: 246, loss is 0.0015209052944555879\n",
      "epoch: 1 step: 247, loss is 0.0016080958303064108\n",
      "epoch: 1 step: 248, loss is 0.0013097055489197373\n",
      "epoch: 1 step: 249, loss is 0.0009697213536128402\n",
      "epoch: 1 step: 250, loss is 0.002288497518748045\n",
      "epoch: 1 step: 251, loss is 0.0023428003769367933\n",
      "epoch: 1 step: 252, loss is 0.0031718267127871513\n",
      "epoch: 1 step: 253, loss is 0.001818262622691691\n",
      "epoch: 1 step: 254, loss is 0.0024962592869997025\n",
      "epoch: 1 step: 255, loss is 0.003794277785345912\n",
      "epoch: 1 step: 256, loss is 0.0009273664909414947\n",
      "epoch: 1 step: 257, loss is 0.0019201630493625998\n",
      "epoch: 1 step: 258, loss is 0.001347548677586019\n",
      "epoch: 1 step: 259, loss is 0.0015537376748397946\n",
      "epoch: 1 step: 260, loss is 0.002249485347419977\n",
      "epoch: 1 step: 261, loss is 0.004119222983717918\n",
      "epoch: 1 step: 262, loss is 0.00152364163659513\n",
      "epoch: 1 step: 263, loss is 0.0020710995886474848\n",
      "epoch: 1 step: 264, loss is 0.002488207770511508\n",
      "epoch: 1 step: 265, loss is 0.0010336097329854965\n",
      "epoch: 1 step: 266, loss is 0.002115225652232766\n",
      "epoch: 1 step: 267, loss is 0.002721216529607773\n",
      "epoch: 1 step: 268, loss is 0.0005049679311923683\n",
      "epoch: 1 step: 269, loss is 0.002310703042894602\n",
      "epoch: 1 step: 270, loss is 0.0018460111459717155\n",
      "epoch: 1 step: 271, loss is 0.002206516917794943\n",
      "epoch: 1 step: 272, loss is 0.004614308942109346\n",
      "epoch: 1 step: 273, loss is 0.0009724161354824901\n",
      "epoch: 1 step: 274, loss is 0.0012710727751255035\n",
      "epoch: 1 step: 275, loss is 0.000993179390206933\n",
      "epoch: 1 step: 276, loss is 0.0031083945650607347\n",
      "epoch: 1 step: 277, loss is 0.003986966796219349\n",
      "epoch: 1 step: 278, loss is 0.0015303820837289095\n",
      "epoch: 1 step: 279, loss is 0.004408732522279024\n",
      "epoch: 1 step: 280, loss is 0.0018161318730562925\n",
      "epoch: 1 step: 281, loss is 0.0008138488628901541\n",
      "epoch: 1 step: 282, loss is 0.00228091049939394\n",
      "epoch: 1 step: 283, loss is 0.0007262565195560455\n",
      "epoch: 1 step: 284, loss is 0.001628534635528922\n",
      "epoch: 1 step: 285, loss is 0.0018118558218702674\n",
      "epoch: 1 step: 286, loss is 0.0006695210468024015\n",
      "epoch: 1 step: 287, loss is 0.0018207328394055367\n",
      "epoch: 1 step: 288, loss is 0.0018861786229535937\n",
      "epoch: 1 step: 289, loss is 0.0021160217002034187\n",
      "epoch: 1 step: 290, loss is 0.0014325663214549422\n",
      "epoch: 1 step: 291, loss is 0.0017705218633636832\n",
      "epoch: 1 step: 292, loss is 0.0012561631156131625\n",
      "epoch: 1 step: 293, loss is 0.0010741095757111907\n",
      "epoch: 1 step: 294, loss is 0.003048524959012866\n",
      "epoch: 1 step: 295, loss is 0.0025450645480304956\n",
      "epoch: 1 step: 296, loss is 0.0009995590662583709\n",
      "epoch: 1 step: 297, loss is 0.0017684621270745993\n",
      "epoch: 1 step: 298, loss is 0.0019440042087808251\n",
      "epoch: 1 step: 299, loss is 0.0017331193666905165\n",
      "epoch: 1 step: 300, loss is 0.0013188907178118825\n",
      "epoch: 1 step: 301, loss is 0.001745167886838317\n",
      "epoch: 1 step: 302, loss is 0.0030502930749207735\n",
      "epoch: 1 step: 303, loss is 0.0035871448926627636\n",
      "epoch: 1 step: 304, loss is 0.001938935718499124\n",
      "epoch: 1 step: 305, loss is 0.0023636852856725454\n",
      "epoch: 1 step: 306, loss is 0.0015828682808205485\n",
      "epoch: 1 step: 307, loss is 0.0010245407465845346\n",
      "epoch: 1 step: 308, loss is 0.0011626072227954865\n",
      "epoch: 1 step: 309, loss is 0.0011281950864940882\n",
      "epoch: 1 step: 310, loss is 0.0034434148110449314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 311, loss is 0.003285511862486601\n",
      "epoch: 1 step: 312, loss is 0.0022621904499828815\n",
      "epoch: 1 step: 313, loss is 0.0017937386874109507\n",
      "epoch: 1 step: 314, loss is 0.002254137070849538\n",
      "epoch: 1 step: 315, loss is 0.0034013206604868174\n",
      "epoch: 1 step: 316, loss is 0.0017923510167747736\n",
      "epoch: 1 step: 317, loss is 0.0015948433429002762\n",
      "epoch: 1 step: 318, loss is 0.0013446728698909283\n",
      "epoch: 1 step: 319, loss is 0.0016964789247140288\n",
      "epoch: 1 step: 320, loss is 0.0010923987720161676\n",
      "epoch: 1 step: 321, loss is 0.0032983100973069668\n",
      "epoch: 1 step: 322, loss is 0.003750690259039402\n",
      "epoch: 1 step: 323, loss is 0.0011346094543114305\n",
      "epoch: 1 step: 324, loss is 0.002638805890455842\n",
      "epoch: 1 step: 325, loss is 0.0024413757491856813\n",
      "epoch: 1 step: 326, loss is 0.0016538111958652735\n",
      "epoch: 1 step: 327, loss is 0.0010264447191730142\n",
      "epoch: 1 step: 328, loss is 0.0015991705004125834\n",
      "epoch: 1 step: 329, loss is 0.0019310836214572191\n",
      "epoch: 1 step: 330, loss is 0.0026087630540132523\n",
      "epoch: 1 step: 331, loss is 0.0017374659655615687\n",
      "epoch: 1 step: 332, loss is 0.0029417562764137983\n",
      "epoch: 1 step: 333, loss is 0.001205038046464324\n",
      "epoch: 1 step: 334, loss is 0.0009446822805330157\n",
      "epoch: 1 step: 335, loss is 0.0017154394881799817\n",
      "epoch: 1 step: 336, loss is 0.0018341662362217903\n",
      "epoch: 1 step: 337, loss is 0.0031005560886114836\n",
      "epoch: 1 step: 338, loss is 0.001613709842786193\n",
      "epoch: 1 step: 339, loss is 0.0034247750882059336\n",
      "epoch: 1 step: 340, loss is 0.0017696752911433578\n",
      "epoch: 1 step: 341, loss is 0.0011532618664205074\n",
      "epoch: 1 step: 342, loss is 0.0007486481918022037\n",
      "epoch: 1 step: 343, loss is 0.0019867378287017345\n",
      "epoch: 1 step: 344, loss is 0.0007085470133461058\n",
      "epoch: 1 step: 345, loss is 0.001186314388178289\n",
      "epoch: 1 step: 346, loss is 0.0016402769833803177\n",
      "epoch: 1 step: 347, loss is 0.0012595978332683444\n",
      "epoch: 1 step: 348, loss is 0.0012915392871946096\n",
      "epoch: 1 step: 349, loss is 0.0020430840086191893\n",
      "epoch: 1 step: 350, loss is 0.0022820932790637016\n",
      "epoch: 1 step: 351, loss is 0.0012742531253024936\n",
      "epoch: 1 step: 352, loss is 0.0008605907787568867\n",
      "epoch: 1 step: 353, loss is 0.00088225252693519\n",
      "epoch: 1 step: 354, loss is 0.0007667823228985071\n",
      "epoch: 1 step: 355, loss is 0.0007788146031089127\n",
      "epoch: 1 step: 356, loss is 0.0018462943844497204\n",
      "epoch: 1 step: 357, loss is 0.0017444072291254997\n",
      "epoch: 1 step: 358, loss is 0.0012831506319344044\n",
      "epoch: 1 step: 359, loss is 0.0010957738850265741\n",
      "epoch: 1 step: 360, loss is 0.0015184228541329503\n",
      "epoch: 1 step: 361, loss is 0.0034636149648576975\n",
      "epoch: 1 step: 362, loss is 0.001714461948722601\n",
      "epoch: 1 step: 363, loss is 0.00154954195022583\n",
      "epoch: 1 step: 364, loss is 0.00094246567459777\n",
      "epoch: 1 step: 365, loss is 0.0013445188524201512\n",
      "epoch: 1 step: 366, loss is 0.0022822180762887\n",
      "epoch: 1 step: 367, loss is 0.0017151589272543788\n",
      "epoch: 1 step: 368, loss is 0.0019082839135080576\n",
      "epoch: 1 step: 369, loss is 0.0008547796751372516\n",
      "epoch: 1 step: 370, loss is 0.0011709143873304129\n",
      "epoch: 1 step: 371, loss is 0.0014474834315478802\n",
      "epoch: 1 step: 372, loss is 0.0012353135971352458\n",
      "epoch: 1 step: 373, loss is 0.0018001800635829568\n",
      "epoch: 1 step: 374, loss is 0.001134197460487485\n",
      "epoch: 1 step: 375, loss is 0.0017982781864702702\n",
      "Train epoch time: 12392.733 ms, per step time: 33.047 ms\n",
      "epoch: 2 step: 1, loss is 0.0014003043761476874\n",
      "epoch: 2 step: 2, loss is 0.0013567659771069884\n",
      "epoch: 2 step: 3, loss is 0.0021497320849448442\n",
      "epoch: 2 step: 4, loss is 0.001307327183894813\n",
      "epoch: 2 step: 5, loss is 0.004357441794127226\n",
      "epoch: 2 step: 6, loss is 0.001303551485762\n",
      "epoch: 2 step: 7, loss is 0.0015810620971024036\n",
      "epoch: 2 step: 8, loss is 0.0007775758276693523\n",
      "epoch: 2 step: 9, loss is 0.0023648194037377834\n",
      "epoch: 2 step: 10, loss is 0.0012297307839617133\n",
      "epoch: 2 step: 11, loss is 0.0015769366873428226\n",
      "epoch: 2 step: 12, loss is 0.0006830401252955198\n",
      "epoch: 2 step: 13, loss is 0.0019415464485064149\n",
      "epoch: 2 step: 14, loss is 0.0015387238236144185\n",
      "epoch: 2 step: 15, loss is 0.0009098530281335115\n",
      "epoch: 2 step: 16, loss is 0.0016177828656509519\n",
      "epoch: 2 step: 17, loss is 0.001105448231101036\n",
      "epoch: 2 step: 18, loss is 0.0011896596988663077\n",
      "epoch: 2 step: 19, loss is 0.0005560878780670464\n",
      "epoch: 2 step: 20, loss is 0.0010778100695461035\n",
      "epoch: 2 step: 21, loss is 0.0009864609455689788\n",
      "epoch: 2 step: 22, loss is 0.0015394138172268867\n",
      "epoch: 2 step: 23, loss is 0.0018731210147961974\n",
      "epoch: 2 step: 24, loss is 0.000995720038190484\n",
      "epoch: 2 step: 25, loss is 0.001392546808347106\n",
      "epoch: 2 step: 26, loss is 0.0018080254085361958\n",
      "epoch: 2 step: 27, loss is 0.001114089391194284\n",
      "epoch: 2 step: 28, loss is 0.0013871908886358142\n",
      "epoch: 2 step: 29, loss is 0.001298728515394032\n",
      "epoch: 2 step: 30, loss is 0.0026074950583279133\n",
      "epoch: 2 step: 31, loss is 0.0008658358710817993\n",
      "epoch: 2 step: 32, loss is 0.0008357291226275265\n",
      "epoch: 2 step: 33, loss is 0.0014497162774205208\n",
      "epoch: 2 step: 34, loss is 0.000573109311517328\n",
      "epoch: 2 step: 35, loss is 0.0008088533068075776\n",
      "epoch: 2 step: 36, loss is 0.0012477284763008356\n",
      "epoch: 2 step: 37, loss is 0.000935288262553513\n",
      "epoch: 2 step: 38, loss is 0.0019648561719805002\n",
      "epoch: 2 step: 39, loss is 0.0011124876327812672\n",
      "epoch: 2 step: 40, loss is 0.001071261242032051\n",
      "epoch: 2 step: 41, loss is 0.0012412373907864094\n",
      "epoch: 2 step: 42, loss is 0.001205068314447999\n",
      "epoch: 2 step: 43, loss is 0.0011623891768977046\n",
      "epoch: 2 step: 44, loss is 0.0013183325063437223\n",
      "epoch: 2 step: 45, loss is 0.0010188245214521885\n",
      "epoch: 2 step: 46, loss is 0.0010215335059911013\n",
      "epoch: 2 step: 47, loss is 0.0006100645405240357\n",
      "epoch: 2 step: 48, loss is 0.0035662499722093344\n",
      "epoch: 2 step: 49, loss is 0.00234595057554543\n",
      "epoch: 2 step: 50, loss is 0.0020163152366876602\n",
      "epoch: 2 step: 51, loss is 0.0006984094507060945\n",
      "epoch: 2 step: 52, loss is 0.0016322523588314652\n",
      "epoch: 2 step: 53, loss is 0.0008197681163437665\n",
      "epoch: 2 step: 54, loss is 0.0015213033184409142\n",
      "epoch: 2 step: 55, loss is 0.0003988537355326116\n",
      "epoch: 2 step: 56, loss is 0.001027455204166472\n",
      "epoch: 2 step: 57, loss is 0.0019755084067583084\n",
      "epoch: 2 step: 58, loss is 0.0012988360831514\n",
      "epoch: 2 step: 59, loss is 0.0005802807863801718\n",
      "epoch: 2 step: 60, loss is 0.0017203177558258176\n",
      "epoch: 2 step: 61, loss is 0.0020199373830109835\n",
      "epoch: 2 step: 62, loss is 0.0011304017389193177\n",
      "epoch: 2 step: 63, loss is 0.00042054703226312995\n",
      "epoch: 2 step: 64, loss is 0.001326827215962112\n",
      "epoch: 2 step: 65, loss is 0.0011264883214607835\n",
      "epoch: 2 step: 66, loss is 0.0007067522383295\n",
      "epoch: 2 step: 67, loss is 0.0022025604266673326\n",
      "epoch: 2 step: 68, loss is 0.0007776095881126821\n",
      "epoch: 2 step: 69, loss is 0.0005082176649011672\n",
      "epoch: 2 step: 70, loss is 0.0021519423462450504\n",
      "epoch: 2 step: 71, loss is 0.0010802496690303087\n",
      "epoch: 2 step: 72, loss is 0.0010850178077816963\n",
      "epoch: 2 step: 73, loss is 0.0015462738228961825\n",
      "epoch: 2 step: 74, loss is 0.0008024848648346961\n",
      "epoch: 2 step: 75, loss is 0.001307571423240006\n",
      "epoch: 2 step: 76, loss is 0.0006987328524701297\n",
      "epoch: 2 step: 77, loss is 0.0011270298855379224\n",
      "epoch: 2 step: 78, loss is 0.0017120616976171732\n",
      "epoch: 2 step: 79, loss is 0.0009486717754043639\n",
      "epoch: 2 step: 80, loss is 0.0030445721931755543\n",
      "epoch: 2 step: 81, loss is 0.0017679681768640876\n",
      "epoch: 2 step: 82, loss is 0.0013989870203658938\n",
      "epoch: 2 step: 83, loss is 0.0011018310906365514\n",
      "epoch: 2 step: 84, loss is 0.0017198568675667048\n",
      "epoch: 2 step: 85, loss is 0.002328584436327219\n",
      "epoch: 2 step: 86, loss is 0.0005886078579351306\n",
      "epoch: 2 step: 87, loss is 0.0005918638198636472\n",
      "epoch: 2 step: 88, loss is 0.00099884660448879\n",
      "epoch: 2 step: 89, loss is 0.001169506344012916\n",
      "epoch: 2 step: 90, loss is 0.0010901604546234012\n",
      "epoch: 2 step: 91, loss is 0.001484667300246656\n",
      "epoch: 2 step: 92, loss is 0.0007003765786066651\n",
      "epoch: 2 step: 93, loss is 0.0015726226847618818\n",
      "epoch: 2 step: 94, loss is 0.0013082686346024275\n",
      "epoch: 2 step: 95, loss is 0.0006107229855842888\n",
      "epoch: 2 step: 96, loss is 0.0011938087409362197\n",
      "epoch: 2 step: 97, loss is 0.0020798637997359037\n",
      "epoch: 2 step: 98, loss is 0.0010369396768510342\n",
      "epoch: 2 step: 99, loss is 0.0010108440183103085\n",
      "epoch: 2 step: 100, loss is 0.0011757289757952094\n",
      "epoch: 2 step: 101, loss is 0.001004523946903646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 102, loss is 0.001379743916913867\n",
      "epoch: 2 step: 103, loss is 0.0009414719534106553\n",
      "epoch: 2 step: 104, loss is 0.002698000753298402\n",
      "epoch: 2 step: 105, loss is 0.0021875936072319746\n",
      "epoch: 2 step: 106, loss is 0.0021468179766088724\n",
      "epoch: 2 step: 107, loss is 0.0015071795787662268\n",
      "epoch: 2 step: 108, loss is 0.0013053730363026261\n",
      "epoch: 2 step: 109, loss is 0.00038927618879824877\n",
      "epoch: 2 step: 110, loss is 0.0010850675171241164\n",
      "epoch: 2 step: 111, loss is 0.0009068789076991379\n",
      "epoch: 2 step: 112, loss is 0.0017049222951754928\n",
      "epoch: 2 step: 113, loss is 0.00034177687484771013\n",
      "epoch: 2 step: 114, loss is 0.001077385968528688\n",
      "epoch: 2 step: 115, loss is 0.001534982118755579\n",
      "epoch: 2 step: 116, loss is 0.0013157689245417714\n",
      "epoch: 2 step: 117, loss is 0.0017168825725093484\n",
      "epoch: 2 step: 118, loss is 0.001645573996938765\n",
      "epoch: 2 step: 119, loss is 0.0017343725776299834\n",
      "epoch: 2 step: 120, loss is 0.0013433349085971713\n",
      "epoch: 2 step: 121, loss is 0.000996672548353672\n",
      "epoch: 2 step: 122, loss is 0.001134427497163415\n",
      "epoch: 2 step: 123, loss is 0.0015352896880358458\n",
      "epoch: 2 step: 124, loss is 0.0009000744903460145\n",
      "epoch: 2 step: 125, loss is 0.0008233435219153762\n",
      "epoch: 2 step: 126, loss is 0.0004299585707485676\n",
      "epoch: 2 step: 127, loss is 0.0018912045052275062\n",
      "epoch: 2 step: 128, loss is 0.0018740195082500577\n",
      "epoch: 2 step: 129, loss is 0.0015275460900738835\n",
      "epoch: 2 step: 130, loss is 0.0009163236827589571\n",
      "epoch: 2 step: 131, loss is 0.0017228538636118174\n",
      "epoch: 2 step: 132, loss is 0.0008099059923551977\n",
      "epoch: 2 step: 133, loss is 0.0027792283799499273\n",
      "epoch: 2 step: 134, loss is 0.0027013965882360935\n",
      "epoch: 2 step: 135, loss is 0.000741427531465888\n",
      "epoch: 2 step: 136, loss is 0.001493403222411871\n",
      "epoch: 2 step: 137, loss is 0.00111170276068151\n",
      "epoch: 2 step: 138, loss is 0.000412408058764413\n",
      "epoch: 2 step: 139, loss is 0.0022034572903066874\n",
      "epoch: 2 step: 140, loss is 0.001435613725334406\n",
      "epoch: 2 step: 141, loss is 0.0005985994357615709\n",
      "epoch: 2 step: 142, loss is 0.000859171967022121\n",
      "epoch: 2 step: 143, loss is 0.0013353865360841155\n",
      "epoch: 2 step: 144, loss is 0.0005783195374533534\n",
      "epoch: 2 step: 145, loss is 0.0006708760047331452\n",
      "epoch: 2 step: 146, loss is 0.0008546853205189109\n",
      "epoch: 2 step: 147, loss is 0.0015874344389885664\n",
      "epoch: 2 step: 148, loss is 0.0016706975875422359\n",
      "epoch: 2 step: 149, loss is 0.00099729816429317\n",
      "epoch: 2 step: 150, loss is 0.0013408262748271227\n",
      "epoch: 2 step: 151, loss is 0.0006014012615196407\n",
      "epoch: 2 step: 152, loss is 0.0005941704730503261\n",
      "epoch: 2 step: 153, loss is 0.0023681658785790205\n",
      "epoch: 2 step: 154, loss is 0.0005361296352930367\n",
      "epoch: 2 step: 155, loss is 0.0014133815420791507\n",
      "epoch: 2 step: 156, loss is 0.0008993632509373128\n",
      "epoch: 2 step: 157, loss is 0.00043407868361100554\n",
      "epoch: 2 step: 158, loss is 0.0014057245571166277\n",
      "epoch: 2 step: 159, loss is 0.0009187186369672418\n",
      "epoch: 2 step: 160, loss is 0.0021341152023524046\n",
      "epoch: 2 step: 161, loss is 0.001970921875908971\n",
      "epoch: 2 step: 162, loss is 0.0010899266926571727\n",
      "epoch: 2 step: 163, loss is 0.0021536406129598618\n",
      "epoch: 2 step: 164, loss is 0.0012568336678668857\n",
      "epoch: 2 step: 165, loss is 0.0018864324083551764\n",
      "epoch: 2 step: 166, loss is 0.0018537051510065794\n",
      "epoch: 2 step: 167, loss is 0.001471832045353949\n",
      "epoch: 2 step: 168, loss is 0.0014580980641767383\n",
      "epoch: 2 step: 169, loss is 0.0013879651669412851\n",
      "epoch: 2 step: 170, loss is 0.0013175713829696178\n",
      "epoch: 2 step: 171, loss is 0.0006499987794086337\n",
      "epoch: 2 step: 172, loss is 0.0008970021735876799\n",
      "epoch: 2 step: 173, loss is 0.0010409383103251457\n",
      "epoch: 2 step: 174, loss is 0.0009604874067008495\n",
      "epoch: 2 step: 175, loss is 0.0009896097471937537\n",
      "epoch: 2 step: 176, loss is 0.0015713297761976719\n",
      "epoch: 2 step: 177, loss is 0.0008052984485402703\n",
      "epoch: 2 step: 178, loss is 0.0010507873957976699\n",
      "epoch: 2 step: 179, loss is 0.0013500695349648595\n",
      "epoch: 2 step: 180, loss is 0.0006052484386600554\n",
      "epoch: 2 step: 181, loss is 0.0006828024052083492\n",
      "epoch: 2 step: 182, loss is 0.0011809351854026318\n",
      "epoch: 2 step: 183, loss is 0.001529716537334025\n",
      "epoch: 2 step: 184, loss is 0.0013799985172227025\n",
      "epoch: 2 step: 185, loss is 0.000763758725952357\n",
      "epoch: 2 step: 186, loss is 0.0011909573804587126\n",
      "epoch: 2 step: 187, loss is 0.0008892772602848709\n",
      "epoch: 2 step: 188, loss is 0.0006031348602846265\n",
      "epoch: 2 step: 189, loss is 0.00110060500446707\n",
      "epoch: 2 step: 190, loss is 0.0005239777383394539\n",
      "epoch: 2 step: 191, loss is 0.0011836193734779954\n",
      "epoch: 2 step: 192, loss is 0.0009087991784326732\n",
      "epoch: 2 step: 193, loss is 0.0019285032758489251\n",
      "epoch: 2 step: 194, loss is 0.0004811965045519173\n",
      "epoch: 2 step: 195, loss is 0.0011158729903399944\n",
      "epoch: 2 step: 196, loss is 0.0010799263836815953\n",
      "epoch: 2 step: 197, loss is 0.0009203700465150177\n",
      "epoch: 2 step: 198, loss is 0.000756643945351243\n",
      "epoch: 2 step: 199, loss is 0.0013156132772564888\n",
      "epoch: 2 step: 200, loss is 0.002903452143073082\n",
      "epoch: 2 step: 201, loss is 0.0025283268187195063\n",
      "epoch: 2 step: 202, loss is 0.0007218423415906727\n",
      "epoch: 2 step: 203, loss is 0.0005628906656056643\n",
      "epoch: 2 step: 204, loss is 0.0010252627544105053\n",
      "epoch: 2 step: 205, loss is 0.0010663357097655535\n",
      "epoch: 2 step: 206, loss is 0.0021713580936193466\n",
      "epoch: 2 step: 207, loss is 0.0008489422034472227\n",
      "epoch: 2 step: 208, loss is 0.00040062592597678304\n",
      "epoch: 2 step: 209, loss is 0.0012428127229213715\n",
      "epoch: 2 step: 210, loss is 0.0020146346651017666\n",
      "epoch: 2 step: 211, loss is 0.0009217231418006122\n",
      "epoch: 2 step: 212, loss is 0.0009198908228427172\n",
      "epoch: 2 step: 213, loss is 0.0016492444556206465\n",
      "epoch: 2 step: 214, loss is 0.002435831818729639\n",
      "epoch: 2 step: 215, loss is 0.0006985421059653163\n",
      "epoch: 2 step: 216, loss is 0.0013503754744306207\n",
      "epoch: 2 step: 217, loss is 0.000576673774048686\n",
      "epoch: 2 step: 218, loss is 0.002194478642195463\n",
      "epoch: 2 step: 219, loss is 0.0006959540769457817\n",
      "epoch: 2 step: 220, loss is 0.0007696899119764566\n",
      "epoch: 2 step: 221, loss is 0.002160022035241127\n",
      "epoch: 2 step: 222, loss is 0.0012153754942119122\n",
      "epoch: 2 step: 223, loss is 0.0010775710688903928\n",
      "epoch: 2 step: 224, loss is 0.0009865366155281663\n",
      "epoch: 2 step: 225, loss is 0.0011074327630922198\n",
      "epoch: 2 step: 226, loss is 0.0022035816218703985\n",
      "epoch: 2 step: 227, loss is 0.0011999747948721051\n",
      "epoch: 2 step: 228, loss is 0.0009596529416739941\n",
      "epoch: 2 step: 229, loss is 0.0009572393028065562\n",
      "epoch: 2 step: 230, loss is 0.0009081590687856078\n",
      "epoch: 2 step: 231, loss is 0.0008871349273249507\n",
      "epoch: 2 step: 232, loss is 0.0006522011244669557\n",
      "epoch: 2 step: 233, loss is 0.0011625555343925953\n",
      "epoch: 2 step: 234, loss is 0.001143604633398354\n",
      "epoch: 2 step: 235, loss is 0.0017321216873824596\n",
      "epoch: 2 step: 236, loss is 0.0014814205933362246\n",
      "epoch: 2 step: 237, loss is 0.0007834596326574683\n",
      "epoch: 2 step: 238, loss is 0.001267292071133852\n",
      "epoch: 2 step: 239, loss is 0.0004745079786516726\n",
      "epoch: 2 step: 240, loss is 0.0004932619049213827\n",
      "epoch: 2 step: 241, loss is 0.0008448694134131074\n",
      "epoch: 2 step: 242, loss is 0.0005054394132457674\n",
      "epoch: 2 step: 243, loss is 0.0006845441530458629\n",
      "epoch: 2 step: 244, loss is 0.0019223135896027088\n",
      "epoch: 2 step: 245, loss is 0.0012219002237543464\n",
      "epoch: 2 step: 246, loss is 0.0008804718963801861\n",
      "epoch: 2 step: 247, loss is 0.0013777734711766243\n",
      "epoch: 2 step: 248, loss is 0.0009961534524336457\n",
      "epoch: 2 step: 249, loss is 0.0014739829348400235\n",
      "epoch: 2 step: 250, loss is 0.000577153405174613\n",
      "epoch: 2 step: 251, loss is 0.0009694626205600798\n",
      "epoch: 2 step: 252, loss is 0.0007424289942719042\n",
      "epoch: 2 step: 253, loss is 0.00135276117362082\n",
      "epoch: 2 step: 254, loss is 0.0006753430352546275\n",
      "epoch: 2 step: 255, loss is 0.0005606288905255497\n",
      "epoch: 2 step: 256, loss is 0.0014147608308121562\n",
      "epoch: 2 step: 257, loss is 0.0003547643718775362\n",
      "epoch: 2 step: 258, loss is 0.0010476981988176703\n",
      "epoch: 2 step: 259, loss is 0.00034967201645486057\n",
      "epoch: 2 step: 260, loss is 0.0005661946488544345\n",
      "epoch: 2 step: 261, loss is 0.0008812765008769929\n",
      "epoch: 2 step: 262, loss is 0.0002002543187700212\n",
      "epoch: 2 step: 263, loss is 0.0012162800412625074\n",
      "epoch: 2 step: 264, loss is 0.0009452694794163108\n",
      "epoch: 2 step: 265, loss is 0.00021968425426166505\n",
      "epoch: 2 step: 266, loss is 0.0015189178520813584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 267, loss is 0.0012189419940114021\n",
      "epoch: 2 step: 268, loss is 0.0005740377237088978\n",
      "epoch: 2 step: 269, loss is 0.0011942500714212656\n",
      "epoch: 2 step: 270, loss is 0.001340020215138793\n",
      "epoch: 2 step: 271, loss is 0.001871513552032411\n",
      "epoch: 2 step: 272, loss is 0.0014229284133762121\n",
      "epoch: 2 step: 273, loss is 0.0012804941507056355\n",
      "epoch: 2 step: 274, loss is 0.001413974561728537\n",
      "epoch: 2 step: 275, loss is 0.0010745954932644963\n",
      "epoch: 2 step: 276, loss is 0.0008105825399979949\n",
      "epoch: 2 step: 277, loss is 0.0005032553453929722\n",
      "epoch: 2 step: 278, loss is 0.0008722117054276168\n",
      "epoch: 2 step: 279, loss is 0.0008864098344929516\n",
      "epoch: 2 step: 280, loss is 0.001196652534417808\n",
      "epoch: 2 step: 281, loss is 0.0017174968961626291\n",
      "epoch: 2 step: 282, loss is 0.0009581856429576874\n",
      "epoch: 2 step: 283, loss is 0.0017402766970917583\n",
      "epoch: 2 step: 284, loss is 0.0007569561130367219\n",
      "epoch: 2 step: 285, loss is 0.0008139471174217761\n",
      "epoch: 2 step: 286, loss is 0.0005760536296293139\n",
      "epoch: 2 step: 287, loss is 0.000839830085169524\n",
      "epoch: 2 step: 288, loss is 0.0008178473217412829\n",
      "epoch: 2 step: 289, loss is 0.002496337052434683\n",
      "epoch: 2 step: 290, loss is 0.000946615356951952\n",
      "epoch: 2 step: 291, loss is 0.0018582401098683476\n",
      "epoch: 2 step: 292, loss is 0.001061178045347333\n",
      "epoch: 2 step: 293, loss is 0.0004974622279405594\n",
      "epoch: 2 step: 294, loss is 0.0010770588414743543\n",
      "epoch: 2 step: 295, loss is 0.001371894613839686\n",
      "epoch: 2 step: 296, loss is 0.0011394466273486614\n",
      "epoch: 2 step: 297, loss is 0.0013028868706896901\n",
      "epoch: 2 step: 298, loss is 0.0003664192045107484\n",
      "epoch: 2 step: 299, loss is 0.00028236760408617556\n",
      "epoch: 2 step: 300, loss is 0.001183773041702807\n",
      "epoch: 2 step: 301, loss is 0.0008428277797065675\n",
      "epoch: 2 step: 302, loss is 0.0012063836911693215\n",
      "epoch: 2 step: 303, loss is 0.0007181132095865905\n",
      "epoch: 2 step: 304, loss is 0.0006128563545644283\n",
      "epoch: 2 step: 305, loss is 0.000798793276771903\n",
      "epoch: 2 step: 306, loss is 0.0013520624488592148\n",
      "epoch: 2 step: 307, loss is 0.0008377639460377395\n",
      "epoch: 2 step: 308, loss is 0.00044766266364604235\n",
      "epoch: 2 step: 309, loss is 0.0020861364901065826\n",
      "epoch: 2 step: 310, loss is 0.001383155002258718\n",
      "epoch: 2 step: 311, loss is 0.0008950144401751459\n",
      "epoch: 2 step: 312, loss is 0.0006197019829414785\n",
      "epoch: 2 step: 313, loss is 0.0010745780309662223\n",
      "epoch: 2 step: 314, loss is 0.0005258676246739924\n",
      "epoch: 2 step: 315, loss is 0.0005930335028097034\n",
      "epoch: 2 step: 316, loss is 0.0008667397196404636\n",
      "epoch: 2 step: 317, loss is 0.002537216292694211\n",
      "epoch: 2 step: 318, loss is 0.0013443623902276158\n",
      "epoch: 2 step: 319, loss is 0.0018031790386885405\n",
      "epoch: 2 step: 320, loss is 0.000860215921420604\n",
      "epoch: 2 step: 321, loss is 0.0006310233729891479\n",
      "epoch: 2 step: 322, loss is 0.0015405346639454365\n",
      "epoch: 2 step: 323, loss is 0.002588478848338127\n",
      "epoch: 2 step: 324, loss is 0.0009820535778999329\n",
      "epoch: 2 step: 325, loss is 0.0010360067244619131\n",
      "epoch: 2 step: 326, loss is 0.0007788543007336557\n",
      "epoch: 2 step: 327, loss is 0.0012541848700493574\n",
      "epoch: 2 step: 328, loss is 0.0010375265264883637\n",
      "epoch: 2 step: 329, loss is 0.0007028606487438083\n",
      "epoch: 2 step: 330, loss is 0.0009994730353355408\n",
      "epoch: 2 step: 331, loss is 0.0005640334566123784\n",
      "epoch: 2 step: 332, loss is 0.0005443226546049118\n",
      "epoch: 2 step: 333, loss is 0.0010639755055308342\n",
      "epoch: 2 step: 334, loss is 0.0010438804747536778\n",
      "epoch: 2 step: 335, loss is 0.001193733187392354\n",
      "epoch: 2 step: 336, loss is 0.0007912561413832009\n",
      "epoch: 2 step: 337, loss is 0.0023154106456786394\n",
      "epoch: 2 step: 338, loss is 0.0007500593783333898\n",
      "epoch: 2 step: 339, loss is 0.0002823702816385776\n",
      "epoch: 2 step: 340, loss is 0.0005065269651822746\n",
      "epoch: 2 step: 341, loss is 0.0016735789831727743\n",
      "epoch: 2 step: 342, loss is 0.0012337624793872237\n",
      "epoch: 2 step: 343, loss is 0.0007432109559886158\n",
      "epoch: 2 step: 344, loss is 0.001348400255665183\n",
      "epoch: 2 step: 345, loss is 0.0008651165408082306\n",
      "epoch: 2 step: 346, loss is 0.001682456349954009\n",
      "epoch: 2 step: 347, loss is 0.002178656402975321\n",
      "epoch: 2 step: 348, loss is 0.0005700244219042361\n",
      "epoch: 2 step: 349, loss is 0.0011726689990609884\n",
      "epoch: 2 step: 350, loss is 0.001176941441372037\n",
      "epoch: 2 step: 351, loss is 0.0005714822909794748\n",
      "epoch: 2 step: 352, loss is 0.0010883960640057921\n",
      "epoch: 2 step: 353, loss is 0.0004125999112147838\n",
      "epoch: 2 step: 354, loss is 0.0006828468758612871\n",
      "epoch: 2 step: 355, loss is 0.000782323011662811\n",
      "epoch: 2 step: 356, loss is 0.0008565267198719084\n",
      "epoch: 2 step: 357, loss is 0.0007512189331464469\n",
      "epoch: 2 step: 358, loss is 0.00234119757078588\n",
      "epoch: 2 step: 359, loss is 0.0010591832688078284\n",
      "epoch: 2 step: 360, loss is 0.0007901902426965535\n",
      "epoch: 2 step: 361, loss is 0.0016291391802951694\n",
      "epoch: 2 step: 362, loss is 0.0012013048399239779\n",
      "epoch: 2 step: 363, loss is 0.00038859728374518454\n",
      "epoch: 2 step: 364, loss is 0.0007473689038306475\n",
      "epoch: 2 step: 365, loss is 0.0020331472624093294\n",
      "epoch: 2 step: 366, loss is 0.00044775259448215365\n",
      "epoch: 2 step: 367, loss is 0.0011586785549297929\n",
      "epoch: 2 step: 368, loss is 0.0018066775519400835\n",
      "epoch: 2 step: 369, loss is 0.001035012654028833\n",
      "epoch: 2 step: 370, loss is 0.001833671354688704\n",
      "epoch: 2 step: 371, loss is 0.0007363488548435271\n",
      "epoch: 2 step: 372, loss is 0.0006882501766085625\n",
      "epoch: 2 step: 373, loss is 0.0019457066664472222\n",
      "epoch: 2 step: 374, loss is 0.0007607778534293175\n",
      "epoch: 2 step: 375, loss is 0.0011098819086328149\n",
      "Train epoch time: 12210.851 ms, per step time: 32.562 ms\n",
      "epoch: 3 step: 1, loss is 0.001368221826851368\n",
      "epoch: 3 step: 2, loss is 0.0006143001955933869\n",
      "epoch: 3 step: 3, loss is 0.0012252849992364645\n",
      "epoch: 3 step: 4, loss is 0.0006682891398668289\n",
      "epoch: 3 step: 5, loss is 0.0007988806464709342\n",
      "epoch: 3 step: 6, loss is 0.00036791880847886205\n",
      "epoch: 3 step: 7, loss is 0.000367101893061772\n",
      "epoch: 3 step: 8, loss is 0.0008279711473733187\n",
      "epoch: 3 step: 9, loss is 0.0010516047477722168\n",
      "epoch: 3 step: 10, loss is 0.0009221070795319974\n",
      "epoch: 3 step: 11, loss is 0.001355769345536828\n",
      "epoch: 3 step: 12, loss is 0.001522104605101049\n",
      "epoch: 3 step: 13, loss is 0.0012564993230625987\n",
      "epoch: 3 step: 14, loss is 0.0024154798593372107\n",
      "epoch: 3 step: 15, loss is 0.00110483611933887\n",
      "epoch: 3 step: 16, loss is 0.0011794994352385402\n",
      "epoch: 3 step: 17, loss is 0.000812011188827455\n",
      "epoch: 3 step: 18, loss is 0.002564633497968316\n",
      "epoch: 3 step: 19, loss is 0.0021901142317801714\n",
      "epoch: 3 step: 20, loss is 0.0006896929698996246\n",
      "epoch: 3 step: 21, loss is 0.0014526279410347342\n",
      "epoch: 3 step: 22, loss is 0.0010607433505356312\n",
      "epoch: 3 step: 23, loss is 0.0011933023342862725\n",
      "epoch: 3 step: 24, loss is 0.0011784691596403718\n",
      "epoch: 3 step: 25, loss is 0.001807329012081027\n",
      "epoch: 3 step: 26, loss is 0.0008445439161732793\n",
      "epoch: 3 step: 27, loss is 0.0013074253220111132\n",
      "epoch: 3 step: 28, loss is 0.0005291739944368601\n",
      "epoch: 3 step: 29, loss is 0.001743977190926671\n",
      "epoch: 3 step: 30, loss is 0.0018655236344784498\n",
      "epoch: 3 step: 31, loss is 0.0005092236679047346\n",
      "epoch: 3 step: 32, loss is 0.0015557118458673358\n",
      "epoch: 3 step: 33, loss is 0.0018306236015632749\n",
      "epoch: 3 step: 34, loss is 0.0008445253479294479\n",
      "epoch: 3 step: 35, loss is 0.0014006339479237795\n",
      "epoch: 3 step: 36, loss is 0.0022896858863532543\n",
      "epoch: 3 step: 37, loss is 0.0008938090759329498\n",
      "epoch: 3 step: 38, loss is 0.001212735311128199\n",
      "epoch: 3 step: 39, loss is 0.0005497249658219516\n",
      "epoch: 3 step: 40, loss is 0.0008937806123867631\n",
      "epoch: 3 step: 41, loss is 0.0007306696497835219\n",
      "epoch: 3 step: 42, loss is 0.0006293098558671772\n",
      "epoch: 3 step: 43, loss is 0.00041572583722881973\n",
      "epoch: 3 step: 44, loss is 0.0011334071168676019\n",
      "epoch: 3 step: 45, loss is 0.0007565636769868433\n",
      "epoch: 3 step: 46, loss is 0.0016443650238215923\n",
      "epoch: 3 step: 47, loss is 0.0004923975793644786\n",
      "epoch: 3 step: 48, loss is 0.0008010902674868703\n",
      "epoch: 3 step: 49, loss is 0.0005256157019175589\n",
      "epoch: 3 step: 50, loss is 0.00041250287904404104\n",
      "epoch: 3 step: 51, loss is 0.0009745206334628165\n",
      "epoch: 3 step: 52, loss is 0.001226561376824975\n",
      "epoch: 3 step: 53, loss is 0.0012464752653613687\n",
      "epoch: 3 step: 54, loss is 0.0012479518773034215\n",
      "epoch: 3 step: 55, loss is 0.0011855406919494271\n",
      "epoch: 3 step: 56, loss is 0.0009541543549858034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 57, loss is 0.0007669849437661469\n",
      "epoch: 3 step: 58, loss is 0.0008439889643341303\n",
      "epoch: 3 step: 59, loss is 0.0005838499637320638\n",
      "epoch: 3 step: 60, loss is 0.0006865396280772984\n",
      "epoch: 3 step: 61, loss is 0.0008675203425809741\n",
      "epoch: 3 step: 62, loss is 0.0007605541031807661\n",
      "epoch: 3 step: 63, loss is 0.0007870087865740061\n",
      "epoch: 3 step: 64, loss is 0.0005591199151240289\n",
      "epoch: 3 step: 65, loss is 0.00026499523664824665\n",
      "epoch: 3 step: 66, loss is 0.0011074799112975597\n",
      "epoch: 3 step: 67, loss is 0.0008291801204904914\n",
      "epoch: 3 step: 68, loss is 0.0006621495704166591\n",
      "epoch: 3 step: 69, loss is 0.001011424232274294\n",
      "epoch: 3 step: 70, loss is 0.0009221809450536966\n",
      "epoch: 3 step: 71, loss is 0.0009314905619248748\n",
      "epoch: 3 step: 72, loss is 0.00037498751771636307\n",
      "epoch: 3 step: 73, loss is 0.0006562200142070651\n",
      "epoch: 3 step: 74, loss is 0.000970172812230885\n",
      "epoch: 3 step: 75, loss is 0.0013855623546987772\n",
      "epoch: 3 step: 76, loss is 0.0008108046022243798\n",
      "epoch: 3 step: 77, loss is 0.0006355244549922645\n",
      "epoch: 3 step: 78, loss is 0.0009834623197093606\n",
      "epoch: 3 step: 79, loss is 0.0005961763672530651\n",
      "epoch: 3 step: 80, loss is 0.0010781995952129364\n",
      "epoch: 3 step: 81, loss is 0.0008695604046806693\n",
      "epoch: 3 step: 82, loss is 0.000489286205265671\n",
      "epoch: 3 step: 83, loss is 0.001870752195827663\n",
      "epoch: 3 step: 84, loss is 0.0017871540039777756\n",
      "epoch: 3 step: 85, loss is 0.0015250855358317494\n",
      "epoch: 3 step: 86, loss is 0.00027396174846217036\n",
      "epoch: 3 step: 87, loss is 0.0005324605153873563\n",
      "epoch: 3 step: 88, loss is 0.0013821006286889315\n",
      "epoch: 3 step: 89, loss is 0.0019043986685574055\n",
      "epoch: 3 step: 90, loss is 0.00045651281834580004\n",
      "epoch: 3 step: 91, loss is 0.0009002345032058656\n",
      "epoch: 3 step: 92, loss is 0.0015809881733730435\n",
      "epoch: 3 step: 93, loss is 0.0005866519641131163\n",
      "epoch: 3 step: 94, loss is 0.0012288391590118408\n",
      "epoch: 3 step: 95, loss is 0.0008732398855499923\n",
      "epoch: 3 step: 96, loss is 0.0007054476300254464\n",
      "epoch: 3 step: 97, loss is 0.0006930807721801102\n",
      "epoch: 3 step: 98, loss is 0.000980452517978847\n",
      "epoch: 3 step: 99, loss is 0.0006443609017878771\n",
      "epoch: 3 step: 100, loss is 0.0015104931080713868\n",
      "epoch: 3 step: 101, loss is 0.0005326797836460173\n",
      "epoch: 3 step: 102, loss is 0.0012645982205867767\n",
      "epoch: 3 step: 103, loss is 0.0010944986715912819\n",
      "epoch: 3 step: 104, loss is 0.0009993149433284998\n",
      "epoch: 3 step: 105, loss is 0.002077400218695402\n",
      "epoch: 3 step: 106, loss is 0.00044497387716546655\n",
      "epoch: 3 step: 107, loss is 0.0007669193437322974\n",
      "epoch: 3 step: 108, loss is 0.0008395710028707981\n",
      "epoch: 3 step: 109, loss is 0.0007851831032894552\n",
      "epoch: 3 step: 110, loss is 0.0016017197631299496\n",
      "epoch: 3 step: 111, loss is 0.0014915558276697993\n",
      "epoch: 3 step: 112, loss is 0.0006614708108827472\n",
      "epoch: 3 step: 113, loss is 0.0008980706916190684\n",
      "epoch: 3 step: 114, loss is 0.0007188559393398464\n",
      "epoch: 3 step: 115, loss is 0.0012259037466719747\n",
      "epoch: 3 step: 116, loss is 0.0005512132775038481\n",
      "epoch: 3 step: 117, loss is 0.0011858519865199924\n",
      "epoch: 3 step: 118, loss is 0.0006930304225534201\n",
      "epoch: 3 step: 119, loss is 0.00036947024636901915\n",
      "epoch: 3 step: 120, loss is 0.0006831697537563741\n",
      "epoch: 3 step: 121, loss is 0.0019910724367946386\n",
      "epoch: 3 step: 122, loss is 0.0034220435190945864\n",
      "epoch: 3 step: 123, loss is 0.0007386284996755421\n",
      "epoch: 3 step: 124, loss is 0.0012693241005763412\n",
      "epoch: 3 step: 125, loss is 0.0011221064487472177\n",
      "epoch: 3 step: 126, loss is 0.0008421342936344445\n",
      "epoch: 3 step: 127, loss is 0.0013772258535027504\n",
      "epoch: 3 step: 128, loss is 0.0004651595663744956\n",
      "epoch: 3 step: 129, loss is 0.001094201346859336\n",
      "epoch: 3 step: 130, loss is 0.0007281149155460298\n",
      "epoch: 3 step: 131, loss is 0.0005590852815657854\n",
      "epoch: 3 step: 132, loss is 0.00038407251122407615\n",
      "epoch: 3 step: 133, loss is 0.001273260684683919\n",
      "epoch: 3 step: 134, loss is 0.0008457046933472157\n",
      "epoch: 3 step: 135, loss is 0.000821945141069591\n",
      "epoch: 3 step: 136, loss is 0.0007638277020305395\n",
      "epoch: 3 step: 137, loss is 0.0011082927230745554\n",
      "epoch: 3 step: 138, loss is 0.0012171247508376837\n",
      "epoch: 3 step: 139, loss is 0.0010149661684408784\n",
      "epoch: 3 step: 140, loss is 0.0010603313567116857\n",
      "epoch: 3 step: 141, loss is 0.0005807186244055629\n",
      "epoch: 3 step: 142, loss is 0.0016030037077143788\n",
      "epoch: 3 step: 143, loss is 0.0011573743540793657\n",
      "epoch: 3 step: 144, loss is 0.0009650577558204532\n",
      "epoch: 3 step: 145, loss is 0.00044462838559411466\n",
      "epoch: 3 step: 146, loss is 0.0006912792450748384\n",
      "epoch: 3 step: 147, loss is 0.0014942759880796075\n",
      "epoch: 3 step: 148, loss is 0.0005109464982524514\n",
      "epoch: 3 step: 149, loss is 0.0007936559268273413\n",
      "epoch: 3 step: 150, loss is 0.0005904827266931534\n",
      "epoch: 3 step: 151, loss is 0.0016367052448913455\n",
      "epoch: 3 step: 152, loss is 0.000493813247885555\n",
      "epoch: 3 step: 153, loss is 0.0012016230029985309\n",
      "epoch: 3 step: 154, loss is 0.0008044554269872606\n",
      "epoch: 3 step: 155, loss is 0.0009761031833477318\n",
      "epoch: 3 step: 156, loss is 0.0012037937995046377\n",
      "epoch: 3 step: 157, loss is 0.0007157710497267544\n",
      "epoch: 3 step: 158, loss is 0.0006080387975089252\n",
      "epoch: 3 step: 159, loss is 0.0007830178365111351\n",
      "epoch: 3 step: 160, loss is 0.0006590309203602374\n",
      "epoch: 3 step: 161, loss is 0.0010075713507831097\n",
      "epoch: 3 step: 162, loss is 0.0011051178444176912\n",
      "epoch: 3 step: 163, loss is 0.002545856172218919\n",
      "epoch: 3 step: 164, loss is 0.00033802964026108384\n",
      "epoch: 3 step: 165, loss is 0.00031586538534611464\n",
      "epoch: 3 step: 166, loss is 0.0008147196494974196\n",
      "epoch: 3 step: 167, loss is 0.0025748717598617077\n",
      "epoch: 3 step: 168, loss is 0.0013326117768883705\n",
      "epoch: 3 step: 169, loss is 0.0009206169052049518\n",
      "epoch: 3 step: 170, loss is 0.0014318880857899785\n",
      "epoch: 3 step: 171, loss is 0.0005329261184670031\n",
      "epoch: 3 step: 172, loss is 0.000965253624599427\n",
      "epoch: 3 step: 173, loss is 0.001640342641621828\n",
      "epoch: 3 step: 174, loss is 0.0013004443608224392\n",
      "epoch: 3 step: 175, loss is 0.0007650894112884998\n",
      "epoch: 3 step: 176, loss is 0.0016054699663072824\n",
      "epoch: 3 step: 177, loss is 0.0008089557522907853\n",
      "epoch: 3 step: 178, loss is 0.0010768403299152851\n",
      "epoch: 3 step: 179, loss is 0.000642979983240366\n",
      "epoch: 3 step: 180, loss is 0.0009507574723102152\n",
      "epoch: 3 step: 181, loss is 0.0004229695477988571\n",
      "epoch: 3 step: 182, loss is 0.000791100668720901\n",
      "epoch: 3 step: 183, loss is 0.0006378655089065433\n",
      "epoch: 3 step: 184, loss is 0.0004607937589753419\n",
      "epoch: 3 step: 185, loss is 0.000909850699827075\n",
      "epoch: 3 step: 186, loss is 0.0018830709159374237\n",
      "epoch: 3 step: 187, loss is 0.0015416564419865608\n",
      "epoch: 3 step: 188, loss is 0.000722645316272974\n",
      "epoch: 3 step: 189, loss is 0.0004051268915645778\n",
      "epoch: 3 step: 190, loss is 0.0008238297305069864\n",
      "epoch: 3 step: 191, loss is 0.0013273193035274744\n",
      "epoch: 3 step: 192, loss is 0.000595293880905956\n",
      "epoch: 3 step: 193, loss is 0.0007593384943902493\n",
      "epoch: 3 step: 194, loss is 0.001857301569543779\n",
      "epoch: 3 step: 195, loss is 0.0010192664340138435\n",
      "epoch: 3 step: 196, loss is 0.0011926746228709817\n",
      "epoch: 3 step: 197, loss is 0.0005587638006545603\n",
      "epoch: 3 step: 198, loss is 0.0009876593248918653\n",
      "epoch: 3 step: 199, loss is 0.0012271589366719127\n",
      "epoch: 3 step: 200, loss is 0.002187761478126049\n",
      "epoch: 3 step: 201, loss is 0.002020695246756077\n",
      "epoch: 3 step: 202, loss is 0.0012953634141013026\n",
      "epoch: 3 step: 203, loss is 0.0007896398892626166\n",
      "epoch: 3 step: 204, loss is 0.000902728526853025\n",
      "epoch: 3 step: 205, loss is 0.0002446724975015968\n",
      "epoch: 3 step: 206, loss is 0.0011008536675944924\n",
      "epoch: 3 step: 207, loss is 0.0010319699067622423\n",
      "epoch: 3 step: 208, loss is 0.00036550292861647904\n",
      "epoch: 3 step: 209, loss is 0.0010376994032412767\n",
      "epoch: 3 step: 210, loss is 0.0015683562960475683\n",
      "epoch: 3 step: 211, loss is 0.0011123453732579947\n",
      "epoch: 3 step: 212, loss is 0.0012573795393109322\n",
      "epoch: 3 step: 213, loss is 0.0004915422759950161\n",
      "epoch: 3 step: 214, loss is 0.001642019720748067\n",
      "epoch: 3 step: 215, loss is 0.000679786957334727\n",
      "epoch: 3 step: 216, loss is 0.00155469065066427\n",
      "epoch: 3 step: 217, loss is 0.0008948000613600016\n",
      "epoch: 3 step: 218, loss is 0.0007593177724629641\n",
      "epoch: 3 step: 219, loss is 0.0003849445201922208\n",
      "epoch: 3 step: 220, loss is 0.0007957235793583095\n",
      "epoch: 3 step: 221, loss is 0.0002492704661563039\n",
      "epoch: 3 step: 222, loss is 0.0006206847028806806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 223, loss is 0.0009571275440976024\n",
      "epoch: 3 step: 224, loss is 0.00115282426122576\n",
      "epoch: 3 step: 225, loss is 0.001197332632727921\n",
      "epoch: 3 step: 226, loss is 0.0004744254983961582\n",
      "epoch: 3 step: 227, loss is 0.0009926182683557272\n",
      "epoch: 3 step: 228, loss is 0.0005519737605936825\n",
      "epoch: 3 step: 229, loss is 0.0006400698330253363\n",
      "epoch: 3 step: 230, loss is 0.0011204691836610436\n",
      "epoch: 3 step: 231, loss is 0.0005686219083145261\n",
      "epoch: 3 step: 232, loss is 0.0009392749634571373\n",
      "epoch: 3 step: 233, loss is 0.0007089058053679764\n",
      "epoch: 3 step: 234, loss is 0.001341800088994205\n",
      "epoch: 3 step: 235, loss is 0.001320661511272192\n",
      "epoch: 3 step: 236, loss is 0.0013695396482944489\n",
      "epoch: 3 step: 237, loss is 0.0006341544212773442\n",
      "epoch: 3 step: 238, loss is 0.0008231435786001384\n",
      "epoch: 3 step: 239, loss is 0.0019047085661441088\n",
      "epoch: 3 step: 240, loss is 0.0009017471456900239\n",
      "epoch: 3 step: 241, loss is 0.0007463552756235003\n",
      "epoch: 3 step: 242, loss is 0.0014450125163421035\n",
      "epoch: 3 step: 243, loss is 0.0003762850246857852\n",
      "epoch: 3 step: 244, loss is 0.001226493390277028\n",
      "epoch: 3 step: 245, loss is 0.0004125175182707608\n",
      "epoch: 3 step: 246, loss is 0.00020152860088273883\n",
      "epoch: 3 step: 247, loss is 0.0012687176931649446\n",
      "epoch: 3 step: 248, loss is 0.000500554102472961\n",
      "epoch: 3 step: 249, loss is 0.0005141247529536486\n",
      "epoch: 3 step: 250, loss is 0.0010111459996551275\n",
      "epoch: 3 step: 251, loss is 0.0006628472474403679\n",
      "epoch: 3 step: 252, loss is 0.0009841929422691464\n",
      "epoch: 3 step: 253, loss is 0.0008182080346159637\n",
      "epoch: 3 step: 254, loss is 0.0011153777595609426\n",
      "epoch: 3 step: 255, loss is 0.0011772598372772336\n",
      "epoch: 3 step: 256, loss is 0.0004145855491515249\n",
      "epoch: 3 step: 257, loss is 0.0012932125246152282\n",
      "epoch: 3 step: 258, loss is 0.0005626857746392488\n",
      "epoch: 3 step: 259, loss is 0.0007800179882906377\n",
      "epoch: 3 step: 260, loss is 0.0010946444235742092\n",
      "epoch: 3 step: 261, loss is 0.0006591108976863325\n",
      "epoch: 3 step: 262, loss is 0.0006982536870054901\n",
      "epoch: 3 step: 263, loss is 0.000597508973442018\n",
      "epoch: 3 step: 264, loss is 0.0013722435105592012\n",
      "epoch: 3 step: 265, loss is 0.0009307282161898911\n",
      "epoch: 3 step: 266, loss is 0.0006711691385135055\n",
      "epoch: 3 step: 267, loss is 0.0010857549495995045\n",
      "epoch: 3 step: 268, loss is 0.0003700130619108677\n",
      "epoch: 3 step: 269, loss is 0.002138432115316391\n",
      "epoch: 3 step: 270, loss is 0.0012314686318859458\n",
      "epoch: 3 step: 271, loss is 0.0006874577375128865\n",
      "epoch: 3 step: 272, loss is 0.0001900690549518913\n",
      "epoch: 3 step: 273, loss is 0.0005315079470165074\n",
      "epoch: 3 step: 274, loss is 0.0008798675262369215\n",
      "epoch: 3 step: 275, loss is 0.001121206791140139\n",
      "epoch: 3 step: 276, loss is 0.0005629739025607705\n",
      "epoch: 3 step: 277, loss is 0.0008731414563953876\n",
      "epoch: 3 step: 278, loss is 0.001136043225415051\n",
      "epoch: 3 step: 279, loss is 0.0004519080393947661\n",
      "epoch: 3 step: 280, loss is 0.0012261198135092854\n",
      "epoch: 3 step: 281, loss is 0.0006029977230355144\n",
      "epoch: 3 step: 282, loss is 0.0004291967779863626\n",
      "epoch: 3 step: 283, loss is 0.0009435043903067708\n",
      "epoch: 3 step: 284, loss is 0.0014142208965495229\n",
      "epoch: 3 step: 285, loss is 0.0007767564384266734\n",
      "epoch: 3 step: 286, loss is 0.0009468858479522169\n",
      "epoch: 3 step: 287, loss is 0.001565849524922669\n",
      "epoch: 3 step: 288, loss is 0.0010219861287623644\n",
      "epoch: 3 step: 289, loss is 0.0008230139501392841\n",
      "epoch: 3 step: 290, loss is 0.0006905858172103763\n",
      "epoch: 3 step: 291, loss is 0.000731572974473238\n",
      "epoch: 3 step: 292, loss is 0.0006257324712350965\n",
      "epoch: 3 step: 293, loss is 0.0006621913053095341\n",
      "epoch: 3 step: 294, loss is 0.0002637665602378547\n",
      "epoch: 3 step: 295, loss is 0.0024422663263976574\n",
      "epoch: 3 step: 296, loss is 0.00030497810803353786\n",
      "epoch: 3 step: 297, loss is 0.0003359713591635227\n",
      "epoch: 3 step: 298, loss is 0.0014532428467646241\n",
      "epoch: 3 step: 299, loss is 0.00026261553284712136\n",
      "epoch: 3 step: 300, loss is 0.0009279341902583838\n",
      "epoch: 3 step: 301, loss is 0.0006652393494732678\n",
      "epoch: 3 step: 302, loss is 0.0002271318662678823\n",
      "epoch: 3 step: 303, loss is 0.0005289166583679616\n",
      "epoch: 3 step: 304, loss is 0.0013895787997171283\n",
      "epoch: 3 step: 305, loss is 0.0007716183317825198\n",
      "epoch: 3 step: 306, loss is 0.0005272716516628861\n",
      "epoch: 3 step: 307, loss is 0.0007963457610458136\n",
      "epoch: 3 step: 308, loss is 0.0012823499273508787\n",
      "epoch: 3 step: 309, loss is 0.00042287478572688997\n",
      "epoch: 3 step: 310, loss is 0.00044562810217030346\n",
      "epoch: 3 step: 311, loss is 0.0006919648731127381\n",
      "epoch: 3 step: 312, loss is 0.0007571644964627922\n",
      "epoch: 3 step: 313, loss is 0.000856556638609618\n",
      "epoch: 3 step: 314, loss is 0.0014372857986018062\n",
      "epoch: 3 step: 315, loss is 0.0003014174581039697\n",
      "epoch: 3 step: 316, loss is 0.0019349032081663609\n",
      "epoch: 3 step: 317, loss is 0.001019926741719246\n",
      "epoch: 3 step: 318, loss is 0.001163171837106347\n",
      "epoch: 3 step: 319, loss is 0.00022402088507078588\n",
      "epoch: 3 step: 320, loss is 0.0007449633558280766\n",
      "epoch: 3 step: 321, loss is 0.0010283344890922308\n",
      "epoch: 3 step: 322, loss is 0.0010448984103277326\n",
      "epoch: 3 step: 323, loss is 0.003185782814398408\n",
      "epoch: 3 step: 324, loss is 0.0014937379164621234\n",
      "epoch: 3 step: 325, loss is 0.0005916121881455183\n",
      "epoch: 3 step: 326, loss is 0.0008804205572232604\n",
      "epoch: 3 step: 327, loss is 0.0007348198560066521\n",
      "epoch: 3 step: 328, loss is 0.0011758884647861123\n",
      "epoch: 3 step: 329, loss is 0.0007092786836437881\n",
      "epoch: 3 step: 330, loss is 0.001036391593515873\n",
      "epoch: 3 step: 331, loss is 0.0011180007131770253\n",
      "epoch: 3 step: 332, loss is 0.00036023632856085896\n",
      "epoch: 3 step: 333, loss is 0.0005980511195957661\n",
      "epoch: 3 step: 334, loss is 0.0005397863569669425\n",
      "epoch: 3 step: 335, loss is 0.00019598499056883156\n",
      "epoch: 3 step: 336, loss is 0.0011049432214349508\n",
      "epoch: 3 step: 337, loss is 0.0008993263472802937\n",
      "epoch: 3 step: 338, loss is 0.0005417178035713732\n",
      "epoch: 3 step: 339, loss is 0.0004225212032906711\n",
      "epoch: 3 step: 340, loss is 0.0007049427949823439\n",
      "epoch: 3 step: 341, loss is 0.0009684872347861528\n",
      "epoch: 3 step: 342, loss is 0.0006792127969674766\n",
      "epoch: 3 step: 343, loss is 0.0015945897903293371\n",
      "epoch: 3 step: 344, loss is 0.0024366434663534164\n",
      "epoch: 3 step: 345, loss is 0.0006144628277979791\n",
      "epoch: 3 step: 346, loss is 0.0005200502346269786\n",
      "epoch: 3 step: 347, loss is 0.0009056405397132039\n",
      "epoch: 3 step: 348, loss is 0.0012889554491266608\n",
      "epoch: 3 step: 349, loss is 0.0013530111173167825\n",
      "epoch: 3 step: 350, loss is 0.0011082745622843504\n",
      "epoch: 3 step: 351, loss is 0.0006352786440402269\n",
      "epoch: 3 step: 352, loss is 0.0010755091207101941\n",
      "epoch: 3 step: 353, loss is 0.0008193558314815164\n",
      "epoch: 3 step: 354, loss is 0.0008472028421238065\n",
      "epoch: 3 step: 355, loss is 0.0007935176254250109\n",
      "epoch: 3 step: 356, loss is 0.001609801547601819\n",
      "epoch: 3 step: 357, loss is 0.0011401104275137186\n",
      "epoch: 3 step: 358, loss is 0.00045719812624156475\n",
      "epoch: 3 step: 359, loss is 0.001091589918360114\n",
      "epoch: 3 step: 360, loss is 0.0006130269612185657\n",
      "epoch: 3 step: 361, loss is 0.0007995197083801031\n",
      "epoch: 3 step: 362, loss is 0.00021510654187295586\n",
      "epoch: 3 step: 363, loss is 0.0006912682438269258\n",
      "epoch: 3 step: 364, loss is 0.0008816315676085651\n",
      "epoch: 3 step: 365, loss is 0.000316682766424492\n",
      "epoch: 3 step: 366, loss is 0.0005775653407908976\n",
      "epoch: 3 step: 367, loss is 0.00069601641735062\n",
      "epoch: 3 step: 368, loss is 0.0005921727861277759\n",
      "epoch: 3 step: 369, loss is 0.001558396965265274\n",
      "epoch: 3 step: 370, loss is 0.0011335014132782817\n",
      "epoch: 3 step: 371, loss is 0.0012485639890655875\n",
      "epoch: 3 step: 372, loss is 0.0008359618950635195\n",
      "epoch: 3 step: 373, loss is 0.0012261789524927735\n",
      "epoch: 3 step: 374, loss is 0.0008740125340409577\n",
      "epoch: 3 step: 375, loss is 0.00020351099374238402\n",
      "Train epoch time: 11604.956 ms, per step time: 30.947 ms\n",
      "epoch: 4 step: 1, loss is 0.00028201550594531\n",
      "epoch: 4 step: 2, loss is 0.0006217843620106578\n",
      "epoch: 4 step: 3, loss is 0.001157405786216259\n",
      "epoch: 4 step: 4, loss is 0.0020610117353498936\n",
      "epoch: 4 step: 5, loss is 0.0004770905652549118\n",
      "epoch: 4 step: 6, loss is 0.0006396662211045623\n",
      "epoch: 4 step: 7, loss is 0.0004909948911517859\n",
      "epoch: 4 step: 8, loss is 0.0006428453489206731\n",
      "epoch: 4 step: 9, loss is 0.0012372327037155628\n",
      "epoch: 4 step: 10, loss is 0.0009346335427835584\n",
      "epoch: 4 step: 11, loss is 0.0005170037038624287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 12, loss is 0.00031813024543225765\n",
      "epoch: 4 step: 13, loss is 0.0011708734091371298\n",
      "epoch: 4 step: 14, loss is 0.0008179001160897315\n",
      "epoch: 4 step: 15, loss is 0.001490280032157898\n",
      "epoch: 4 step: 16, loss is 0.0008186839404515922\n",
      "epoch: 4 step: 17, loss is 0.000824321701657027\n",
      "epoch: 4 step: 18, loss is 0.0006340870750136673\n",
      "epoch: 4 step: 19, loss is 0.0005167744820937514\n",
      "epoch: 4 step: 20, loss is 0.0010325752664357424\n",
      "epoch: 4 step: 21, loss is 0.0005632712855003774\n",
      "epoch: 4 step: 22, loss is 0.0006612932193093002\n",
      "epoch: 4 step: 23, loss is 0.0009517551516182721\n",
      "epoch: 4 step: 24, loss is 0.00052306754514575\n",
      "epoch: 4 step: 25, loss is 0.0003521856269799173\n",
      "epoch: 4 step: 26, loss is 0.0005606724298559129\n",
      "epoch: 4 step: 27, loss is 0.00044918112689629197\n",
      "epoch: 4 step: 28, loss is 0.0009601539932191372\n",
      "epoch: 4 step: 29, loss is 0.0012103645130991936\n",
      "epoch: 4 step: 30, loss is 0.0006441856385208666\n",
      "epoch: 4 step: 31, loss is 0.0002909391187131405\n",
      "epoch: 4 step: 32, loss is 0.0008651153766550124\n",
      "epoch: 4 step: 33, loss is 0.0005958079709671438\n",
      "epoch: 4 step: 34, loss is 0.0008280342444777489\n",
      "epoch: 4 step: 35, loss is 0.0006952973199076951\n",
      "epoch: 4 step: 36, loss is 0.0012121221516281366\n",
      "epoch: 4 step: 37, loss is 0.0012758554657921195\n",
      "epoch: 4 step: 38, loss is 0.00045815904741175473\n",
      "epoch: 4 step: 39, loss is 0.0008304624352604151\n",
      "epoch: 4 step: 40, loss is 0.0009088530205190182\n",
      "epoch: 4 step: 41, loss is 0.0011974899098277092\n",
      "epoch: 4 step: 42, loss is 0.0010505245300009847\n",
      "epoch: 4 step: 43, loss is 0.0011823606910184026\n",
      "epoch: 4 step: 44, loss is 0.0005312706925906241\n",
      "epoch: 4 step: 45, loss is 0.0009553980780765414\n",
      "epoch: 4 step: 46, loss is 0.0013058457989245653\n",
      "epoch: 4 step: 47, loss is 0.00043808319605886936\n",
      "epoch: 4 step: 48, loss is 0.000938307261094451\n",
      "epoch: 4 step: 49, loss is 0.0006201158394105732\n",
      "epoch: 4 step: 50, loss is 0.0003505096537992358\n",
      "epoch: 4 step: 51, loss is 0.001404356211423874\n",
      "epoch: 4 step: 52, loss is 0.0008152613881975412\n",
      "epoch: 4 step: 53, loss is 0.0007310184300877154\n",
      "epoch: 4 step: 54, loss is 0.0014329432742670178\n",
      "epoch: 4 step: 55, loss is 0.0009222663356922567\n",
      "epoch: 4 step: 56, loss is 0.000551209319382906\n",
      "epoch: 4 step: 57, loss is 0.0006012172671034932\n",
      "epoch: 4 step: 58, loss is 0.0008378083002753556\n",
      "epoch: 4 step: 59, loss is 0.0007651033229194582\n",
      "epoch: 4 step: 60, loss is 0.00031872137333266437\n",
      "epoch: 4 step: 61, loss is 0.0018728775903582573\n",
      "epoch: 4 step: 62, loss is 0.0005513685173355043\n",
      "epoch: 4 step: 63, loss is 0.000883143104147166\n",
      "epoch: 4 step: 64, loss is 0.0008402493549510837\n",
      "epoch: 4 step: 65, loss is 0.0017160521820187569\n",
      "epoch: 4 step: 66, loss is 0.001297995913773775\n",
      "epoch: 4 step: 67, loss is 0.0013207419542595744\n",
      "epoch: 4 step: 68, loss is 0.002492360072210431\n",
      "epoch: 4 step: 69, loss is 0.0008075584773905575\n",
      "epoch: 4 step: 70, loss is 0.000561499793548137\n",
      "epoch: 4 step: 71, loss is 0.0011082931887358427\n",
      "epoch: 4 step: 72, loss is 0.0013407910009846091\n",
      "epoch: 4 step: 73, loss is 0.0009255004115402699\n",
      "epoch: 4 step: 74, loss is 0.000863009481690824\n",
      "epoch: 4 step: 75, loss is 0.0011717606103047729\n",
      "epoch: 4 step: 76, loss is 0.0008831999730318785\n",
      "epoch: 4 step: 77, loss is 0.0009225897956639528\n",
      "epoch: 4 step: 78, loss is 0.0005751777207478881\n",
      "epoch: 4 step: 79, loss is 0.000271408207481727\n",
      "epoch: 4 step: 80, loss is 0.00028232220211066306\n",
      "epoch: 4 step: 81, loss is 0.0006838181870989501\n",
      "epoch: 4 step: 82, loss is 0.0011993199586868286\n",
      "epoch: 4 step: 83, loss is 0.0005202151369303465\n",
      "epoch: 4 step: 84, loss is 0.001065321615897119\n",
      "epoch: 4 step: 85, loss is 0.0011357825715094805\n",
      "epoch: 4 step: 86, loss is 0.0007214309298433363\n",
      "epoch: 4 step: 87, loss is 0.0014067989541217685\n",
      "epoch: 4 step: 88, loss is 0.0005681219627149403\n",
      "epoch: 4 step: 89, loss is 0.0005000436794944108\n",
      "epoch: 4 step: 90, loss is 0.001214548829011619\n",
      "epoch: 4 step: 91, loss is 0.000496746797580272\n",
      "epoch: 4 step: 92, loss is 0.0003449246287345886\n",
      "epoch: 4 step: 93, loss is 0.0010294071398675442\n",
      "epoch: 4 step: 94, loss is 0.000614688906352967\n",
      "epoch: 4 step: 95, loss is 0.0003202265652362257\n",
      "epoch: 4 step: 96, loss is 0.000659611658193171\n",
      "epoch: 4 step: 97, loss is 0.0006508788210339844\n",
      "epoch: 4 step: 98, loss is 0.0009317354415543377\n",
      "epoch: 4 step: 99, loss is 0.0006585925002582371\n",
      "epoch: 4 step: 100, loss is 0.0007525818073190749\n",
      "epoch: 4 step: 101, loss is 0.0011126920580863953\n",
      "epoch: 4 step: 102, loss is 0.0004687407345045358\n",
      "epoch: 4 step: 103, loss is 0.0011956364614889026\n",
      "epoch: 4 step: 104, loss is 0.0005850819288752973\n",
      "epoch: 4 step: 105, loss is 0.0008546991157345474\n",
      "epoch: 4 step: 106, loss is 0.000798118591774255\n",
      "epoch: 4 step: 107, loss is 0.0008834907785058022\n",
      "epoch: 4 step: 108, loss is 0.0009313129703514278\n",
      "epoch: 4 step: 109, loss is 0.0006668159039691091\n",
      "epoch: 4 step: 110, loss is 0.0014512742636725307\n",
      "epoch: 4 step: 111, loss is 0.0007427220116369426\n",
      "epoch: 4 step: 112, loss is 0.001439357758499682\n",
      "epoch: 4 step: 113, loss is 0.0013790854718536139\n",
      "epoch: 4 step: 114, loss is 0.0008295742445625365\n",
      "epoch: 4 step: 115, loss is 0.001249204040504992\n",
      "epoch: 4 step: 116, loss is 0.0010883727809414268\n",
      "epoch: 4 step: 117, loss is 0.001198302605189383\n",
      "epoch: 4 step: 118, loss is 0.0009373393841087818\n",
      "epoch: 4 step: 119, loss is 0.0005407171556726098\n",
      "epoch: 4 step: 120, loss is 0.000977978459559381\n",
      "epoch: 4 step: 121, loss is 0.0011254864512011409\n",
      "epoch: 4 step: 122, loss is 0.0008350995485670865\n",
      "epoch: 4 step: 123, loss is 0.0008943112916313112\n",
      "epoch: 4 step: 124, loss is 0.0009044365142472088\n",
      "epoch: 4 step: 125, loss is 0.0017131557688117027\n",
      "epoch: 4 step: 126, loss is 0.001294876798056066\n",
      "epoch: 4 step: 127, loss is 0.00020066762226633728\n",
      "epoch: 4 step: 128, loss is 0.0003983227361459285\n",
      "epoch: 4 step: 129, loss is 0.00034653180046007037\n",
      "epoch: 4 step: 130, loss is 0.0019031575648114085\n",
      "epoch: 4 step: 131, loss is 0.0014432258903980255\n",
      "epoch: 4 step: 132, loss is 0.0007437446620315313\n",
      "epoch: 4 step: 133, loss is 0.0009020459256134927\n",
      "epoch: 4 step: 134, loss is 0.0006384376902133226\n",
      "epoch: 4 step: 135, loss is 0.0005536586977541447\n",
      "epoch: 4 step: 136, loss is 0.0005267516244202852\n",
      "epoch: 4 step: 137, loss is 0.0008769890409894288\n",
      "epoch: 4 step: 138, loss is 0.0014041323447600007\n",
      "epoch: 4 step: 139, loss is 0.0005346789839677513\n",
      "epoch: 4 step: 140, loss is 0.00047370768152177334\n",
      "epoch: 4 step: 141, loss is 0.0008985351887531579\n",
      "epoch: 4 step: 142, loss is 0.0005476130754686892\n",
      "epoch: 4 step: 143, loss is 0.00048397871432825923\n",
      "epoch: 4 step: 144, loss is 0.0004938369384035468\n",
      "epoch: 4 step: 145, loss is 0.0008147346670739353\n",
      "epoch: 4 step: 146, loss is 0.000963623751886189\n",
      "epoch: 4 step: 147, loss is 0.0011004942934960127\n",
      "epoch: 4 step: 148, loss is 0.0015851870412006974\n",
      "epoch: 4 step: 149, loss is 0.0020939677488058805\n",
      "epoch: 4 step: 150, loss is 0.0007634790963493288\n",
      "epoch: 4 step: 151, loss is 0.0013428981183096766\n",
      "epoch: 4 step: 152, loss is 0.001032708096317947\n",
      "epoch: 4 step: 153, loss is 0.0012226931285113096\n",
      "epoch: 4 step: 154, loss is 0.0010342561872676015\n",
      "epoch: 4 step: 155, loss is 0.0003764037974178791\n",
      "epoch: 4 step: 156, loss is 0.0015010714996606112\n",
      "epoch: 4 step: 157, loss is 0.0009833230869844556\n",
      "epoch: 4 step: 158, loss is 0.00037880195304751396\n",
      "epoch: 4 step: 159, loss is 0.0015648741973564029\n",
      "epoch: 4 step: 160, loss is 0.0009124896605499089\n",
      "epoch: 4 step: 161, loss is 0.0011719618923962116\n",
      "epoch: 4 step: 162, loss is 0.00028006010688841343\n",
      "epoch: 4 step: 163, loss is 0.0010015106527134776\n",
      "epoch: 4 step: 164, loss is 0.000740852439776063\n",
      "epoch: 4 step: 165, loss is 0.0006473833345808089\n",
      "epoch: 4 step: 166, loss is 0.0012529735686257482\n",
      "epoch: 4 step: 167, loss is 0.0005205580382607877\n",
      "epoch: 4 step: 168, loss is 0.0003110151446890086\n",
      "epoch: 4 step: 169, loss is 0.0006465695332735777\n",
      "epoch: 4 step: 170, loss is 0.0007986209820955992\n",
      "epoch: 4 step: 171, loss is 0.0007158122607506812\n",
      "epoch: 4 step: 172, loss is 0.002334818011149764\n",
      "epoch: 4 step: 173, loss is 0.001780803082510829\n",
      "epoch: 4 step: 174, loss is 0.0007177626830525696\n",
      "epoch: 4 step: 175, loss is 0.0005959668196737766\n",
      "epoch: 4 step: 176, loss is 0.0008029004675336182\n",
      "epoch: 4 step: 177, loss is 0.0013573139440268278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 178, loss is 0.001063534407876432\n",
      "epoch: 4 step: 179, loss is 0.00023467501159757376\n",
      "epoch: 4 step: 180, loss is 0.0011151543585583568\n",
      "epoch: 4 step: 181, loss is 0.002196949440985918\n",
      "epoch: 4 step: 182, loss is 0.0009122196934185922\n",
      "epoch: 4 step: 183, loss is 0.00044753006659448147\n",
      "epoch: 4 step: 184, loss is 0.0006980735342949629\n",
      "epoch: 4 step: 185, loss is 0.0006841451395303011\n",
      "epoch: 4 step: 186, loss is 0.0006340655381791294\n",
      "epoch: 4 step: 187, loss is 0.0007251444621942937\n",
      "epoch: 4 step: 188, loss is 0.0012894442770630121\n",
      "epoch: 4 step: 189, loss is 0.0017431846354156733\n",
      "epoch: 4 step: 190, loss is 0.0009062725584954023\n",
      "epoch: 4 step: 191, loss is 0.0010607915464788675\n",
      "epoch: 4 step: 192, loss is 0.0011528214672580361\n",
      "epoch: 4 step: 193, loss is 0.0006571984849870205\n",
      "epoch: 4 step: 194, loss is 0.0003855241520795971\n",
      "epoch: 4 step: 195, loss is 0.0008846038253977895\n",
      "epoch: 4 step: 196, loss is 0.001843500998802483\n",
      "epoch: 4 step: 197, loss is 0.002006377326324582\n",
      "epoch: 4 step: 198, loss is 0.00017667243082541972\n",
      "epoch: 4 step: 199, loss is 0.0010004256619140506\n",
      "epoch: 4 step: 200, loss is 0.000538768945261836\n",
      "epoch: 4 step: 201, loss is 0.000535544182639569\n",
      "epoch: 4 step: 202, loss is 0.0005490707117132843\n",
      "epoch: 4 step: 203, loss is 0.0002281904744450003\n",
      "epoch: 4 step: 204, loss is 0.0009153808350674808\n",
      "epoch: 4 step: 205, loss is 0.001055563916452229\n",
      "epoch: 4 step: 206, loss is 0.0023114150390028954\n",
      "epoch: 4 step: 207, loss is 0.0015430827625095844\n",
      "epoch: 4 step: 208, loss is 0.0003007618070114404\n",
      "epoch: 4 step: 209, loss is 0.0007782125612720847\n",
      "epoch: 4 step: 210, loss is 0.0007762134191580117\n",
      "epoch: 4 step: 211, loss is 0.0006043623434379697\n",
      "epoch: 4 step: 212, loss is 0.0010859075700864196\n",
      "epoch: 4 step: 213, loss is 0.0007565156556665897\n",
      "epoch: 4 step: 214, loss is 0.0008626707131043077\n",
      "epoch: 4 step: 215, loss is 0.001052160863764584\n",
      "epoch: 4 step: 216, loss is 0.0002668470551725477\n",
      "epoch: 4 step: 217, loss is 0.0010628653690218925\n",
      "epoch: 4 step: 218, loss is 0.001556960865855217\n",
      "epoch: 4 step: 219, loss is 0.0006943514454178512\n",
      "epoch: 4 step: 220, loss is 0.0006917232531122863\n",
      "epoch: 4 step: 221, loss is 0.0007543782703578472\n",
      "epoch: 4 step: 222, loss is 0.00044727177009917796\n",
      "epoch: 4 step: 223, loss is 0.001447100774385035\n",
      "epoch: 4 step: 224, loss is 0.0008960317936725914\n",
      "epoch: 4 step: 225, loss is 0.0010052717989310622\n",
      "epoch: 4 step: 226, loss is 0.0006306890863925219\n",
      "epoch: 4 step: 227, loss is 0.000688419968355447\n",
      "epoch: 4 step: 228, loss is 0.0010825220961123705\n",
      "epoch: 4 step: 229, loss is 0.0008110702619887888\n",
      "epoch: 4 step: 230, loss is 0.0004831019905395806\n",
      "epoch: 4 step: 231, loss is 0.0006655646138824522\n",
      "epoch: 4 step: 232, loss is 0.0011821663938462734\n",
      "epoch: 4 step: 233, loss is 0.001303762081079185\n",
      "epoch: 4 step: 234, loss is 0.0010204227874055505\n",
      "epoch: 4 step: 235, loss is 0.0006292435573413968\n",
      "epoch: 4 step: 236, loss is 0.000687043706420809\n",
      "epoch: 4 step: 237, loss is 0.00045705013326369226\n",
      "epoch: 4 step: 238, loss is 0.000302029395243153\n",
      "epoch: 4 step: 239, loss is 0.00020910931925754994\n",
      "epoch: 4 step: 240, loss is 0.0008258417947217822\n",
      "epoch: 4 step: 241, loss is 0.0006224838434718549\n",
      "epoch: 4 step: 242, loss is 0.0005593208479695022\n",
      "epoch: 4 step: 243, loss is 0.0006836550310254097\n",
      "epoch: 4 step: 244, loss is 0.000530077435541898\n",
      "epoch: 4 step: 245, loss is 0.0008675199351273477\n",
      "epoch: 4 step: 246, loss is 0.0007046655518934131\n",
      "epoch: 4 step: 247, loss is 0.0008749495609663427\n",
      "epoch: 4 step: 248, loss is 0.0006969734677113593\n",
      "epoch: 4 step: 249, loss is 0.0004498678317759186\n",
      "epoch: 4 step: 250, loss is 0.001442132517695427\n",
      "epoch: 4 step: 251, loss is 0.00033461840939708054\n",
      "epoch: 4 step: 252, loss is 0.0013926838291808963\n",
      "epoch: 4 step: 253, loss is 0.0006056278361938894\n",
      "epoch: 4 step: 254, loss is 0.0005854691844433546\n",
      "epoch: 4 step: 255, loss is 0.00016221791156567633\n",
      "epoch: 4 step: 256, loss is 0.0004455961170606315\n",
      "epoch: 4 step: 257, loss is 0.0008643229957669973\n",
      "epoch: 4 step: 258, loss is 0.00134411605540663\n",
      "epoch: 4 step: 259, loss is 0.0013778642751276493\n",
      "epoch: 4 step: 260, loss is 0.00033298524795100093\n",
      "epoch: 4 step: 261, loss is 0.0009316594805568457\n",
      "epoch: 4 step: 262, loss is 0.001183976186439395\n",
      "epoch: 4 step: 263, loss is 0.0008369238930754364\n",
      "epoch: 4 step: 264, loss is 0.0003255319898016751\n",
      "epoch: 4 step: 265, loss is 0.0006965071079321206\n",
      "epoch: 4 step: 266, loss is 0.0004757033020723611\n",
      "epoch: 4 step: 267, loss is 0.0019746196921914816\n",
      "epoch: 4 step: 268, loss is 0.0007841422921046615\n",
      "epoch: 4 step: 269, loss is 0.0010663772700354457\n",
      "epoch: 4 step: 270, loss is 0.0008458831580355763\n",
      "epoch: 4 step: 271, loss is 0.0005147174815647304\n",
      "epoch: 4 step: 272, loss is 0.0005666569923050702\n",
      "epoch: 4 step: 273, loss is 0.0003306241997051984\n",
      "epoch: 4 step: 274, loss is 0.0008549145422875881\n",
      "epoch: 4 step: 275, loss is 0.0002521407150197774\n",
      "epoch: 4 step: 276, loss is 0.0011595089454203844\n",
      "epoch: 4 step: 277, loss is 0.001811813679523766\n",
      "epoch: 4 step: 278, loss is 0.0004859186301473528\n",
      "epoch: 4 step: 279, loss is 0.0012238475028425455\n",
      "epoch: 4 step: 280, loss is 0.0008576345280744135\n",
      "epoch: 4 step: 281, loss is 0.00046342212590388954\n",
      "epoch: 4 step: 282, loss is 0.0007532424060627818\n",
      "epoch: 4 step: 283, loss is 0.000790994381532073\n",
      "epoch: 4 step: 284, loss is 0.000533775077201426\n",
      "epoch: 4 step: 285, loss is 0.0004627513117156923\n",
      "epoch: 4 step: 286, loss is 0.000647927459795028\n",
      "epoch: 4 step: 287, loss is 0.0008095012162812054\n",
      "epoch: 4 step: 288, loss is 0.001025809091515839\n",
      "epoch: 4 step: 289, loss is 0.0008282099734060466\n",
      "epoch: 4 step: 290, loss is 0.0004134454356972128\n",
      "epoch: 4 step: 291, loss is 0.0009071152890101075\n",
      "epoch: 4 step: 292, loss is 0.00042467558523640037\n",
      "epoch: 4 step: 293, loss is 0.0005517361569218338\n",
      "epoch: 4 step: 294, loss is 0.0007352678221650422\n",
      "epoch: 4 step: 295, loss is 0.000813191756606102\n",
      "epoch: 4 step: 296, loss is 0.0009757348452694714\n",
      "epoch: 4 step: 297, loss is 0.0010013231076300144\n",
      "epoch: 4 step: 298, loss is 0.0008138652774505317\n",
      "epoch: 4 step: 299, loss is 0.00031456604483537376\n",
      "epoch: 4 step: 300, loss is 0.0007382423500530422\n",
      "epoch: 4 step: 301, loss is 0.0008305878727696836\n",
      "epoch: 4 step: 302, loss is 0.00024776498321443796\n",
      "epoch: 4 step: 303, loss is 0.0008148504421114922\n",
      "epoch: 4 step: 304, loss is 0.0009632415021769702\n",
      "epoch: 4 step: 305, loss is 0.0011201116722077131\n",
      "epoch: 4 step: 306, loss is 0.0004895967431366444\n",
      "epoch: 4 step: 307, loss is 0.0006753277266398072\n",
      "epoch: 4 step: 308, loss is 0.0008425540290772915\n",
      "epoch: 4 step: 309, loss is 0.0005413916078396142\n",
      "epoch: 4 step: 310, loss is 0.00097935413941741\n",
      "epoch: 4 step: 311, loss is 0.0007340494776144624\n",
      "epoch: 4 step: 312, loss is 0.0005209222435951233\n",
      "epoch: 4 step: 313, loss is 0.0006595070590265095\n",
      "epoch: 4 step: 314, loss is 0.000525193230714649\n",
      "epoch: 4 step: 315, loss is 0.00044695872929878533\n",
      "epoch: 4 step: 316, loss is 0.0006523015908896923\n",
      "epoch: 4 step: 317, loss is 0.00044327747309580445\n",
      "epoch: 4 step: 318, loss is 0.0015877955593168736\n",
      "epoch: 4 step: 319, loss is 0.0025799497961997986\n",
      "epoch: 4 step: 320, loss is 0.0006866439362056553\n",
      "epoch: 4 step: 321, loss is 0.0005817055352963507\n",
      "epoch: 4 step: 322, loss is 0.0008650270756334066\n",
      "epoch: 4 step: 323, loss is 0.00016645407595206052\n",
      "epoch: 4 step: 324, loss is 0.0010184112470597029\n",
      "epoch: 4 step: 325, loss is 0.0006568991229869425\n",
      "epoch: 4 step: 326, loss is 0.0009231983567588031\n",
      "epoch: 4 step: 327, loss is 0.0002799903159029782\n",
      "epoch: 4 step: 328, loss is 0.0013425607467070222\n",
      "epoch: 4 step: 329, loss is 0.0011354363523423672\n",
      "epoch: 4 step: 330, loss is 0.0008100628037936985\n",
      "epoch: 4 step: 331, loss is 0.0005686180666089058\n",
      "epoch: 4 step: 332, loss is 0.0005140893626958132\n",
      "epoch: 4 step: 333, loss is 0.0014467256842181087\n",
      "epoch: 4 step: 334, loss is 0.0012695301556959748\n",
      "epoch: 4 step: 335, loss is 0.0005419019144028425\n",
      "epoch: 4 step: 336, loss is 0.0011693146079778671\n",
      "epoch: 4 step: 337, loss is 0.0013504887465387583\n",
      "epoch: 4 step: 338, loss is 0.0008632251992821693\n",
      "epoch: 4 step: 339, loss is 0.000812569516710937\n",
      "epoch: 4 step: 340, loss is 0.0010908108670264482\n",
      "epoch: 4 step: 341, loss is 0.0017847749404609203\n",
      "epoch: 4 step: 342, loss is 0.0012723369291052222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 343, loss is 0.0009503825567662716\n",
      "epoch: 4 step: 344, loss is 0.0009580072364769876\n",
      "epoch: 4 step: 345, loss is 0.0012210558634251356\n",
      "epoch: 4 step: 346, loss is 0.0006472645909525454\n",
      "epoch: 4 step: 347, loss is 0.0006210437859408557\n",
      "epoch: 4 step: 348, loss is 0.0012152818962931633\n",
      "epoch: 4 step: 349, loss is 0.00046749867033213377\n",
      "epoch: 4 step: 350, loss is 0.0011342957150191069\n",
      "epoch: 4 step: 351, loss is 0.0008069005561992526\n",
      "epoch: 4 step: 352, loss is 0.0012006373144686222\n",
      "epoch: 4 step: 353, loss is 0.0006409629131667316\n",
      "epoch: 4 step: 354, loss is 0.00040526691009290516\n",
      "epoch: 4 step: 355, loss is 0.0008070129551924765\n",
      "epoch: 4 step: 356, loss is 0.0002963965816888958\n",
      "epoch: 4 step: 357, loss is 0.0005755788297392428\n",
      "epoch: 4 step: 358, loss is 0.002604864304885268\n",
      "epoch: 4 step: 359, loss is 0.0013298587873578072\n",
      "epoch: 4 step: 360, loss is 0.0008650000672787428\n",
      "epoch: 4 step: 361, loss is 0.0010438589379191399\n",
      "epoch: 4 step: 362, loss is 0.0010443688370287418\n",
      "epoch: 4 step: 363, loss is 0.0007776312413625419\n",
      "epoch: 4 step: 364, loss is 0.0009665144607424736\n",
      "epoch: 4 step: 365, loss is 0.0007794912671670318\n",
      "epoch: 4 step: 366, loss is 0.0008977462421171367\n",
      "epoch: 4 step: 367, loss is 0.0005426967400126159\n",
      "epoch: 4 step: 368, loss is 0.0016337474808096886\n",
      "epoch: 4 step: 369, loss is 0.0010861408663913608\n",
      "epoch: 4 step: 370, loss is 0.001054976019077003\n",
      "epoch: 4 step: 371, loss is 0.000532857608050108\n",
      "epoch: 4 step: 372, loss is 0.0015343179693445563\n",
      "epoch: 4 step: 373, loss is 0.0012654197635129094\n",
      "epoch: 4 step: 374, loss is 0.0014050209429115057\n",
      "epoch: 4 step: 375, loss is 0.0015679839998483658\n",
      "Train epoch time: 12045.911 ms, per step time: 32.122 ms\n",
      "epoch: 5 step: 1, loss is 0.0003475994453765452\n",
      "epoch: 5 step: 2, loss is 0.0003172618744429201\n",
      "epoch: 5 step: 3, loss is 0.0003174841986037791\n",
      "epoch: 5 step: 4, loss is 0.001006357604637742\n",
      "epoch: 5 step: 5, loss is 0.0010054395534098148\n",
      "epoch: 5 step: 6, loss is 0.0007254412630572915\n",
      "epoch: 5 step: 7, loss is 0.00043645084952004254\n",
      "epoch: 5 step: 8, loss is 0.0007249907939694822\n",
      "epoch: 5 step: 9, loss is 0.0007119679357856512\n",
      "epoch: 5 step: 10, loss is 0.0006256632041186094\n",
      "epoch: 5 step: 11, loss is 0.0010972073068842292\n",
      "epoch: 5 step: 12, loss is 0.000818943721242249\n",
      "epoch: 5 step: 13, loss is 0.000975007307715714\n",
      "epoch: 5 step: 14, loss is 0.0009193764417432249\n",
      "epoch: 5 step: 15, loss is 0.000710657041054219\n",
      "epoch: 5 step: 16, loss is 0.0015398620162159204\n",
      "epoch: 5 step: 17, loss is 0.00037979509215801954\n",
      "epoch: 5 step: 18, loss is 0.0006081447936594486\n",
      "epoch: 5 step: 19, loss is 0.0004452511784620583\n",
      "epoch: 5 step: 20, loss is 0.0003288702282588929\n",
      "epoch: 5 step: 21, loss is 0.0004110221052542329\n",
      "epoch: 5 step: 22, loss is 0.0012407720787450671\n",
      "epoch: 5 step: 23, loss is 0.0009323600679636002\n",
      "epoch: 5 step: 24, loss is 0.00108437635935843\n",
      "epoch: 5 step: 25, loss is 0.0015290516894310713\n",
      "epoch: 5 step: 26, loss is 0.0005985590978525579\n",
      "epoch: 5 step: 27, loss is 0.0006898686406202614\n",
      "epoch: 5 step: 28, loss is 0.0005122920265421271\n",
      "epoch: 5 step: 29, loss is 0.0006166021339595318\n",
      "epoch: 5 step: 30, loss is 0.0017238369910046458\n",
      "epoch: 5 step: 31, loss is 0.0009830938652157784\n",
      "epoch: 5 step: 32, loss is 0.000986746628768742\n",
      "epoch: 5 step: 33, loss is 0.00054178386926651\n",
      "epoch: 5 step: 34, loss is 0.0007821580511517823\n",
      "epoch: 5 step: 35, loss is 0.0008294768631458282\n",
      "epoch: 5 step: 36, loss is 0.0009031594963744283\n",
      "epoch: 5 step: 37, loss is 0.0008169844513759017\n",
      "epoch: 5 step: 38, loss is 0.0007376907160505652\n",
      "epoch: 5 step: 39, loss is 0.0009996916633099318\n",
      "epoch: 5 step: 40, loss is 0.0004104608960915357\n",
      "epoch: 5 step: 41, loss is 0.0007057798211462796\n",
      "epoch: 5 step: 42, loss is 0.00031865350320003927\n",
      "epoch: 5 step: 43, loss is 0.0006291520548984408\n",
      "epoch: 5 step: 44, loss is 0.0012477252166718245\n",
      "epoch: 5 step: 45, loss is 0.0002663973136804998\n",
      "epoch: 5 step: 46, loss is 0.0014897385844960809\n",
      "epoch: 5 step: 47, loss is 0.0007206464069895446\n",
      "epoch: 5 step: 48, loss is 0.0009178970358334482\n",
      "epoch: 5 step: 49, loss is 0.0008575040264986455\n",
      "epoch: 5 step: 50, loss is 0.0015371772460639477\n",
      "epoch: 5 step: 51, loss is 0.001248062471859157\n",
      "epoch: 5 step: 52, loss is 0.0009780032560229301\n",
      "epoch: 5 step: 53, loss is 0.0015337462536990643\n",
      "epoch: 5 step: 54, loss is 0.0003762458509299904\n",
      "epoch: 5 step: 55, loss is 0.0005012654582969844\n",
      "epoch: 5 step: 56, loss is 0.0008587908814661205\n",
      "epoch: 5 step: 57, loss is 0.000986667932011187\n",
      "epoch: 5 step: 58, loss is 0.0007217262173071504\n",
      "epoch: 5 step: 59, loss is 0.0005137427942827344\n",
      "epoch: 5 step: 60, loss is 0.0007570019806735218\n",
      "epoch: 5 step: 61, loss is 0.0007419651956297457\n",
      "epoch: 5 step: 62, loss is 0.0006623798399232328\n",
      "epoch: 5 step: 63, loss is 0.00047941296361386776\n",
      "epoch: 5 step: 64, loss is 0.0008725658990442753\n",
      "epoch: 5 step: 65, loss is 0.0010126790730282664\n",
      "epoch: 5 step: 66, loss is 0.0016963125672191381\n",
      "epoch: 5 step: 67, loss is 0.001431290409527719\n",
      "epoch: 5 step: 68, loss is 0.0014104745350778103\n",
      "epoch: 5 step: 69, loss is 0.0009390658815391362\n",
      "epoch: 5 step: 70, loss is 0.0006840428104624152\n",
      "epoch: 5 step: 71, loss is 0.00036768129211850464\n",
      "epoch: 5 step: 72, loss is 0.0005479608662426472\n",
      "epoch: 5 step: 73, loss is 0.0006032814271748066\n",
      "epoch: 5 step: 74, loss is 0.000776548171415925\n",
      "epoch: 5 step: 75, loss is 0.0008573320228606462\n",
      "epoch: 5 step: 76, loss is 0.00039494872908107936\n",
      "epoch: 5 step: 77, loss is 0.0013901077909395099\n",
      "epoch: 5 step: 78, loss is 0.0011397706111893058\n",
      "epoch: 5 step: 79, loss is 0.0014040055684745312\n",
      "epoch: 5 step: 80, loss is 0.0019008261151611805\n",
      "epoch: 5 step: 81, loss is 0.0008830335573293269\n",
      "epoch: 5 step: 82, loss is 0.000417174567701295\n",
      "epoch: 5 step: 83, loss is 0.0006988533423282206\n",
      "epoch: 5 step: 84, loss is 0.001447959803044796\n",
      "epoch: 5 step: 85, loss is 0.0004900437779724598\n",
      "epoch: 5 step: 86, loss is 0.00040445078047923744\n",
      "epoch: 5 step: 87, loss is 0.0006217234767973423\n",
      "epoch: 5 step: 88, loss is 0.0006104135536588728\n",
      "epoch: 5 step: 89, loss is 0.0010275746462866664\n",
      "epoch: 5 step: 90, loss is 0.000524277682416141\n",
      "epoch: 5 step: 91, loss is 0.00030339296790771186\n",
      "epoch: 5 step: 92, loss is 0.0009490613592788577\n",
      "epoch: 5 step: 93, loss is 0.0008996969554573298\n",
      "epoch: 5 step: 94, loss is 0.0010722342412918806\n",
      "epoch: 5 step: 95, loss is 0.0006299478700384498\n",
      "epoch: 5 step: 96, loss is 0.0002748622791841626\n",
      "epoch: 5 step: 97, loss is 0.0004872096178587526\n",
      "epoch: 5 step: 98, loss is 0.000643672130536288\n",
      "epoch: 5 step: 99, loss is 0.00036813702899962664\n",
      "epoch: 5 step: 100, loss is 0.000656775024253875\n",
      "epoch: 5 step: 101, loss is 0.0010884081711992621\n",
      "epoch: 5 step: 102, loss is 0.0016689538024365902\n",
      "epoch: 5 step: 103, loss is 0.00041317634168080986\n",
      "epoch: 5 step: 104, loss is 0.000814596307463944\n",
      "epoch: 5 step: 105, loss is 0.0011577151017263532\n",
      "epoch: 5 step: 106, loss is 0.0016517852200195193\n",
      "epoch: 5 step: 107, loss is 0.00044597237138077617\n",
      "epoch: 5 step: 108, loss is 0.0006567550590261817\n",
      "epoch: 5 step: 109, loss is 0.0009767308365553617\n",
      "epoch: 5 step: 110, loss is 0.0018084211042150855\n",
      "epoch: 5 step: 111, loss is 0.0003941640316043049\n",
      "epoch: 5 step: 112, loss is 0.0005228194058872759\n",
      "epoch: 5 step: 113, loss is 0.0011616387637332082\n",
      "epoch: 5 step: 114, loss is 0.0010637094965204597\n",
      "epoch: 5 step: 115, loss is 0.0003256457275711\n",
      "epoch: 5 step: 116, loss is 0.0004965745029039681\n",
      "epoch: 5 step: 117, loss is 0.00017987236788030714\n",
      "epoch: 5 step: 118, loss is 0.0014541642740368843\n",
      "epoch: 5 step: 119, loss is 0.0008666273206472397\n",
      "epoch: 5 step: 120, loss is 0.0005005241255275905\n",
      "epoch: 5 step: 121, loss is 0.0017232461832463741\n",
      "epoch: 5 step: 122, loss is 0.0017797085456550121\n",
      "epoch: 5 step: 123, loss is 0.001436689984984696\n",
      "epoch: 5 step: 124, loss is 0.0004605131398420781\n",
      "epoch: 5 step: 125, loss is 0.00096321344608441\n",
      "epoch: 5 step: 126, loss is 0.00048485674778930843\n",
      "epoch: 5 step: 127, loss is 0.0007650073384866118\n",
      "epoch: 5 step: 128, loss is 0.0008827467681840062\n",
      "epoch: 5 step: 129, loss is 0.0013065346283838153\n",
      "epoch: 5 step: 130, loss is 0.0002789171994663775\n",
      "epoch: 5 step: 131, loss is 0.0004153403569944203\n",
      "epoch: 5 step: 132, loss is 0.001338096335530281\n",
      "epoch: 5 step: 133, loss is 0.0007222603890113533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 134, loss is 0.0022009534295648336\n",
      "epoch: 5 step: 135, loss is 0.0009344023419544101\n",
      "epoch: 5 step: 136, loss is 0.000440265896031633\n",
      "epoch: 5 step: 137, loss is 0.0013945158571004868\n",
      "epoch: 5 step: 138, loss is 0.0009521658648736775\n",
      "epoch: 5 step: 139, loss is 0.0006899299914948642\n",
      "epoch: 5 step: 140, loss is 0.0017626662738621235\n",
      "epoch: 5 step: 141, loss is 0.00031776668038219213\n",
      "epoch: 5 step: 142, loss is 0.00038689965731464326\n",
      "epoch: 5 step: 143, loss is 0.0009758261148817837\n",
      "epoch: 5 step: 144, loss is 0.0007981954258866608\n",
      "epoch: 5 step: 145, loss is 0.0005386474658735096\n",
      "epoch: 5 step: 146, loss is 0.0005217205034568906\n",
      "epoch: 5 step: 147, loss is 0.0004672580398619175\n",
      "epoch: 5 step: 148, loss is 0.00042812927858904004\n",
      "epoch: 5 step: 149, loss is 0.0006672623567283154\n",
      "epoch: 5 step: 150, loss is 0.0005579988355748355\n",
      "epoch: 5 step: 151, loss is 0.0008769180858507752\n",
      "epoch: 5 step: 152, loss is 0.0004224265576340258\n",
      "epoch: 5 step: 153, loss is 0.001447299961000681\n",
      "epoch: 5 step: 154, loss is 0.00044872696162201464\n",
      "epoch: 5 step: 155, loss is 0.0006942928303033113\n",
      "epoch: 5 step: 156, loss is 0.0008652893593534827\n",
      "epoch: 5 step: 157, loss is 0.0007335558766499162\n",
      "epoch: 5 step: 158, loss is 0.0016053578583523631\n",
      "epoch: 5 step: 159, loss is 0.0013364385813474655\n",
      "epoch: 5 step: 160, loss is 0.0006333369528874755\n",
      "epoch: 5 step: 161, loss is 0.0008889457094483078\n",
      "epoch: 5 step: 162, loss is 0.0011698516318574548\n",
      "epoch: 5 step: 163, loss is 0.000592555501498282\n",
      "epoch: 5 step: 164, loss is 0.0007336300332099199\n",
      "epoch: 5 step: 165, loss is 0.0010932921431958675\n",
      "epoch: 5 step: 166, loss is 0.0007198245148174465\n",
      "epoch: 5 step: 167, loss is 0.0004843998758587986\n",
      "epoch: 5 step: 168, loss is 0.0003403101291041821\n",
      "epoch: 5 step: 169, loss is 0.0013047871179878712\n",
      "epoch: 5 step: 170, loss is 0.0003836264950223267\n",
      "epoch: 5 step: 171, loss is 0.0007850847323425114\n",
      "epoch: 5 step: 172, loss is 0.0009860896971076727\n",
      "epoch: 5 step: 173, loss is 0.0008915875223465264\n",
      "epoch: 5 step: 174, loss is 0.00105220265686512\n",
      "epoch: 5 step: 175, loss is 0.0004541240050457418\n",
      "epoch: 5 step: 176, loss is 0.0006563799106515944\n",
      "epoch: 5 step: 177, loss is 0.0014293751446530223\n",
      "epoch: 5 step: 178, loss is 0.0009343635174445808\n",
      "epoch: 5 step: 179, loss is 0.0002541471039876342\n",
      "epoch: 5 step: 180, loss is 0.00020100448455195874\n",
      "epoch: 5 step: 181, loss is 0.0007821190520189703\n",
      "epoch: 5 step: 182, loss is 0.0003962776972912252\n",
      "epoch: 5 step: 183, loss is 0.0010479289339855313\n",
      "epoch: 5 step: 184, loss is 0.0008983497391454875\n",
      "epoch: 5 step: 185, loss is 0.0011739055626094341\n",
      "epoch: 5 step: 186, loss is 0.0006374007207341492\n",
      "epoch: 5 step: 187, loss is 0.0006670135771855712\n",
      "epoch: 5 step: 188, loss is 0.0009506936185061932\n",
      "epoch: 5 step: 189, loss is 0.0006853530067019165\n",
      "epoch: 5 step: 190, loss is 0.000693551788572222\n",
      "epoch: 5 step: 191, loss is 0.0016649659955874085\n",
      "epoch: 5 step: 192, loss is 0.0005019968957640231\n",
      "epoch: 5 step: 193, loss is 0.0006870264187455177\n",
      "epoch: 5 step: 194, loss is 0.0015731564490124583\n",
      "epoch: 5 step: 195, loss is 0.0006016018451191485\n",
      "epoch: 5 step: 196, loss is 0.0005297749303281307\n",
      "epoch: 5 step: 197, loss is 0.0003569226828403771\n",
      "epoch: 5 step: 198, loss is 0.0007306835032068193\n",
      "epoch: 5 step: 199, loss is 0.002253009704872966\n",
      "epoch: 5 step: 200, loss is 0.0007146680727601051\n",
      "epoch: 5 step: 201, loss is 0.0019050828414037824\n",
      "epoch: 5 step: 202, loss is 0.0008897635852918029\n",
      "epoch: 5 step: 203, loss is 0.00042917169048450887\n",
      "epoch: 5 step: 204, loss is 0.0003592963912524283\n",
      "epoch: 5 step: 205, loss is 0.0003525886277202517\n",
      "epoch: 5 step: 206, loss is 0.0004043153894599527\n",
      "epoch: 5 step: 207, loss is 0.0008912812336347997\n",
      "epoch: 5 step: 208, loss is 0.0009695769986137748\n",
      "epoch: 5 step: 209, loss is 0.0009400972630828619\n",
      "epoch: 5 step: 210, loss is 0.0010491677094250917\n",
      "epoch: 5 step: 211, loss is 0.000982455094344914\n",
      "epoch: 5 step: 212, loss is 0.0019468751270323992\n",
      "epoch: 5 step: 213, loss is 0.0006013180245645344\n",
      "epoch: 5 step: 214, loss is 0.0012515773996710777\n",
      "epoch: 5 step: 215, loss is 0.0005997446714900434\n",
      "epoch: 5 step: 216, loss is 0.0006687564891763031\n",
      "epoch: 5 step: 217, loss is 0.0006292677717283368\n",
      "epoch: 5 step: 218, loss is 0.0005760528147220612\n",
      "epoch: 5 step: 219, loss is 0.0014951631892472506\n",
      "epoch: 5 step: 220, loss is 0.0006611673161387444\n",
      "epoch: 5 step: 221, loss is 0.0007095990586094558\n",
      "epoch: 5 step: 222, loss is 0.0009252353920601308\n",
      "epoch: 5 step: 223, loss is 0.000589358969591558\n",
      "epoch: 5 step: 224, loss is 0.0007391588878817856\n",
      "epoch: 5 step: 225, loss is 0.0010744567262008786\n",
      "epoch: 5 step: 226, loss is 0.0009434904204681516\n",
      "epoch: 5 step: 227, loss is 0.0004108610737603158\n",
      "epoch: 5 step: 228, loss is 0.0003817934193648398\n",
      "epoch: 5 step: 229, loss is 0.0003423461166676134\n",
      "epoch: 5 step: 230, loss is 0.0006792189669795334\n",
      "epoch: 5 step: 231, loss is 0.0007651444175280631\n",
      "epoch: 5 step: 232, loss is 0.0007212140480987728\n",
      "epoch: 5 step: 233, loss is 0.0007930219871923327\n",
      "epoch: 5 step: 234, loss is 0.0007285551400855184\n",
      "epoch: 5 step: 235, loss is 0.001455259625799954\n",
      "epoch: 5 step: 236, loss is 0.0007449589320458472\n",
      "epoch: 5 step: 237, loss is 0.0008148717461153865\n",
      "epoch: 5 step: 238, loss is 0.0007951445295475423\n",
      "epoch: 5 step: 239, loss is 0.0010710973292589188\n",
      "epoch: 5 step: 240, loss is 0.0011370457941666245\n",
      "epoch: 5 step: 241, loss is 0.0008188007050193846\n",
      "epoch: 5 step: 242, loss is 0.0005724246148020029\n",
      "epoch: 5 step: 243, loss is 0.001980873290449381\n",
      "epoch: 5 step: 244, loss is 0.0013322550803422928\n",
      "epoch: 5 step: 245, loss is 0.0009953583357855678\n",
      "epoch: 5 step: 246, loss is 0.00040317088132724166\n",
      "epoch: 5 step: 247, loss is 0.0013183406554162502\n",
      "epoch: 5 step: 248, loss is 0.0009725652053020895\n",
      "epoch: 5 step: 249, loss is 0.000557360821403563\n",
      "epoch: 5 step: 250, loss is 0.0005268887034617364\n",
      "epoch: 5 step: 251, loss is 0.0012507957872003317\n",
      "epoch: 5 step: 252, loss is 0.0003361661802046001\n",
      "epoch: 5 step: 253, loss is 0.0010443992214277387\n",
      "epoch: 5 step: 254, loss is 0.0008924750727601349\n",
      "epoch: 5 step: 255, loss is 0.0002838478540070355\n",
      "epoch: 5 step: 256, loss is 0.000683906429912895\n",
      "epoch: 5 step: 257, loss is 0.0009652955341152847\n",
      "epoch: 5 step: 258, loss is 0.0016691156197339296\n",
      "epoch: 5 step: 259, loss is 0.0009401738061569631\n",
      "epoch: 5 step: 260, loss is 0.0011790826683863997\n",
      "epoch: 5 step: 261, loss is 0.0006098546436987817\n",
      "epoch: 5 step: 262, loss is 0.0005754301091656089\n",
      "epoch: 5 step: 263, loss is 0.0004985943669453263\n",
      "epoch: 5 step: 264, loss is 0.0007569064036943018\n",
      "epoch: 5 step: 265, loss is 0.0008941064006648958\n",
      "epoch: 5 step: 266, loss is 0.0015076444251462817\n",
      "epoch: 5 step: 267, loss is 0.0007412679260596633\n",
      "epoch: 5 step: 268, loss is 0.00024687848053872585\n",
      "epoch: 5 step: 269, loss is 0.0016592219471931458\n",
      "epoch: 5 step: 270, loss is 0.0013590765884146094\n",
      "epoch: 5 step: 271, loss is 0.001075119012966752\n",
      "epoch: 5 step: 272, loss is 0.0006427777698263526\n",
      "epoch: 5 step: 273, loss is 0.0007734134560450912\n",
      "epoch: 5 step: 274, loss is 0.0009153621504083276\n",
      "epoch: 5 step: 275, loss is 0.0007134935585781932\n",
      "epoch: 5 step: 276, loss is 0.0007195321377366781\n",
      "epoch: 5 step: 277, loss is 0.0005396606284193695\n",
      "epoch: 5 step: 278, loss is 0.0010075237369164824\n",
      "epoch: 5 step: 279, loss is 0.000524133734870702\n",
      "epoch: 5 step: 280, loss is 0.0031317470129579306\n",
      "epoch: 5 step: 281, loss is 0.00047337941941805184\n",
      "epoch: 5 step: 282, loss is 0.001184101332910359\n",
      "epoch: 5 step: 283, loss is 0.0003000664000865072\n",
      "epoch: 5 step: 284, loss is 0.00033216862357221544\n",
      "epoch: 5 step: 285, loss is 0.0005241599283181131\n",
      "epoch: 5 step: 286, loss is 0.00036792081664316356\n",
      "epoch: 5 step: 287, loss is 0.000963376893196255\n",
      "epoch: 5 step: 288, loss is 0.001899305498227477\n",
      "epoch: 5 step: 289, loss is 0.0010246381862089038\n",
      "epoch: 5 step: 290, loss is 0.0015831519849598408\n",
      "epoch: 5 step: 291, loss is 0.0005909665487706661\n",
      "epoch: 5 step: 292, loss is 0.0006989957764744759\n",
      "epoch: 5 step: 293, loss is 0.000989613588899374\n",
      "epoch: 5 step: 294, loss is 0.0011723244097083807\n",
      "epoch: 5 step: 295, loss is 0.00032066076528280973\n",
      "epoch: 5 step: 296, loss is 0.00041591955232433975\n",
      "epoch: 5 step: 297, loss is 0.00044002317008562386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 298, loss is 0.0005637358408421278\n",
      "epoch: 5 step: 299, loss is 0.000988287734799087\n",
      "epoch: 5 step: 300, loss is 0.0006699078949168324\n",
      "epoch: 5 step: 301, loss is 0.001352091901935637\n",
      "epoch: 5 step: 302, loss is 0.0012838063994422555\n",
      "epoch: 5 step: 303, loss is 0.0005201580934226513\n",
      "epoch: 5 step: 304, loss is 0.0013256222009658813\n",
      "epoch: 5 step: 305, loss is 0.0009018172277137637\n",
      "epoch: 5 step: 306, loss is 0.000490053091198206\n",
      "epoch: 5 step: 307, loss is 0.0026080289389938116\n",
      "epoch: 5 step: 308, loss is 0.0004292538214940578\n",
      "epoch: 5 step: 309, loss is 0.0008616319391876459\n",
      "epoch: 5 step: 310, loss is 0.0003081229224335402\n",
      "epoch: 5 step: 311, loss is 0.0009134173742495477\n",
      "epoch: 5 step: 312, loss is 0.0004615889920387417\n",
      "epoch: 5 step: 313, loss is 0.0008351286523975432\n",
      "epoch: 5 step: 314, loss is 0.0007558243232779205\n",
      "epoch: 5 step: 315, loss is 0.0005893952329643071\n",
      "epoch: 5 step: 316, loss is 0.000974536407738924\n",
      "epoch: 5 step: 317, loss is 0.00038179827970452607\n",
      "epoch: 5 step: 318, loss is 0.000421786040533334\n",
      "epoch: 5 step: 319, loss is 0.0006383788422681391\n",
      "epoch: 5 step: 320, loss is 0.00045470616896636784\n",
      "epoch: 5 step: 321, loss is 0.0009005251340568066\n",
      "epoch: 5 step: 322, loss is 0.0007839427562430501\n",
      "epoch: 5 step: 323, loss is 0.0007686706376262009\n",
      "epoch: 5 step: 324, loss is 0.0006050305091775954\n",
      "epoch: 5 step: 325, loss is 0.0009614034206606448\n",
      "epoch: 5 step: 326, loss is 0.0011108468752354383\n",
      "epoch: 5 step: 327, loss is 0.001133798505179584\n",
      "epoch: 5 step: 328, loss is 0.0011311513371765614\n",
      "epoch: 5 step: 329, loss is 0.00040141644421964884\n",
      "epoch: 5 step: 330, loss is 0.0004923983360640705\n",
      "epoch: 5 step: 331, loss is 0.00045362766832113266\n",
      "epoch: 5 step: 332, loss is 0.0004206331504974514\n",
      "epoch: 5 step: 333, loss is 0.0009031193912960589\n",
      "epoch: 5 step: 334, loss is 0.0009584768558852375\n",
      "epoch: 5 step: 335, loss is 0.0006817838293500245\n",
      "epoch: 5 step: 336, loss is 0.0006373339565470815\n",
      "epoch: 5 step: 337, loss is 0.0007781664608046412\n",
      "epoch: 5 step: 338, loss is 0.00023332555429078639\n",
      "epoch: 5 step: 339, loss is 0.000717954128049314\n",
      "epoch: 5 step: 340, loss is 0.0013780641602352262\n",
      "epoch: 5 step: 341, loss is 0.0008993844967335463\n",
      "epoch: 5 step: 342, loss is 0.001585735590197146\n",
      "epoch: 5 step: 343, loss is 0.0002818142238538712\n",
      "epoch: 5 step: 344, loss is 0.0005835400079376996\n",
      "epoch: 5 step: 345, loss is 0.0010705527383834124\n",
      "epoch: 5 step: 346, loss is 0.0003595576563384384\n",
      "epoch: 5 step: 347, loss is 0.0012916300911456347\n",
      "epoch: 5 step: 348, loss is 0.0007924232631921768\n",
      "epoch: 5 step: 349, loss is 0.00023936870275065303\n",
      "epoch: 5 step: 350, loss is 0.0010338585125282407\n",
      "epoch: 5 step: 351, loss is 0.0008615911356173456\n",
      "epoch: 5 step: 352, loss is 0.0004380932659842074\n",
      "epoch: 5 step: 353, loss is 0.00026930845342576504\n",
      "epoch: 5 step: 354, loss is 0.0005537725519388914\n",
      "epoch: 5 step: 355, loss is 0.0009507602080702782\n",
      "epoch: 5 step: 356, loss is 0.00027842112467624247\n",
      "epoch: 5 step: 357, loss is 0.0012264418182894588\n",
      "epoch: 5 step: 358, loss is 0.0012901884038001299\n",
      "epoch: 5 step: 359, loss is 0.0013412506086751819\n",
      "epoch: 5 step: 360, loss is 0.0011679792078211904\n",
      "epoch: 5 step: 361, loss is 0.0009706522687338293\n",
      "epoch: 5 step: 362, loss is 0.0008587586344219744\n",
      "epoch: 5 step: 363, loss is 0.0008951363270170987\n",
      "epoch: 5 step: 364, loss is 0.0008296556770801544\n",
      "epoch: 5 step: 365, loss is 0.0006016673287376761\n",
      "epoch: 5 step: 366, loss is 0.00045501187560148537\n",
      "epoch: 5 step: 367, loss is 0.0005160957225598395\n",
      "epoch: 5 step: 368, loss is 0.002119099022820592\n",
      "epoch: 5 step: 369, loss is 0.0006873621605336666\n",
      "epoch: 5 step: 370, loss is 0.001147279399447143\n",
      "epoch: 5 step: 371, loss is 0.0005359465139918029\n",
      "epoch: 5 step: 372, loss is 0.0009414204978384078\n",
      "epoch: 5 step: 373, loss is 0.0002941972925327718\n",
      "epoch: 5 step: 374, loss is 0.00044259498827159405\n",
      "epoch: 5 step: 375, loss is 0.0004920148057863116\n",
      "Train epoch time: 11918.270 ms, per step time: 31.782 ms\n",
      "epoch: 6 step: 1, loss is 0.0021923575550317764\n",
      "epoch: 6 step: 2, loss is 0.0008606764022260904\n",
      "epoch: 6 step: 3, loss is 0.0004212923813611269\n",
      "epoch: 6 step: 4, loss is 0.0010984860127791762\n",
      "epoch: 6 step: 5, loss is 0.0009111510589718819\n",
      "epoch: 6 step: 6, loss is 0.0010097576305270195\n",
      "epoch: 6 step: 7, loss is 0.000671518559101969\n",
      "epoch: 6 step: 8, loss is 0.0008461493416689336\n",
      "epoch: 6 step: 9, loss is 0.001379641005769372\n",
      "epoch: 6 step: 10, loss is 0.001030081300996244\n",
      "epoch: 6 step: 11, loss is 0.00035852371365763247\n",
      "epoch: 6 step: 12, loss is 0.0008649785886518657\n",
      "epoch: 6 step: 13, loss is 0.0009009807836264372\n",
      "epoch: 6 step: 14, loss is 0.0011249888921156526\n",
      "epoch: 6 step: 15, loss is 0.000735618406906724\n",
      "epoch: 6 step: 16, loss is 0.0016582865500822663\n",
      "epoch: 6 step: 17, loss is 0.0008277958258986473\n",
      "epoch: 6 step: 18, loss is 0.0005237781442701817\n",
      "epoch: 6 step: 19, loss is 0.000595131132286042\n",
      "epoch: 6 step: 20, loss is 0.0004324277979321778\n",
      "epoch: 6 step: 21, loss is 0.000550481432583183\n",
      "epoch: 6 step: 22, loss is 0.0008756192401051521\n",
      "epoch: 6 step: 23, loss is 0.0003254144103266299\n",
      "epoch: 6 step: 24, loss is 0.0009735649800859392\n",
      "epoch: 6 step: 25, loss is 0.001084627932868898\n",
      "epoch: 6 step: 26, loss is 0.0006372936186380684\n",
      "epoch: 6 step: 27, loss is 0.000835990475025028\n",
      "epoch: 6 step: 28, loss is 0.0003288581792730838\n",
      "epoch: 6 step: 29, loss is 0.0010228734463453293\n",
      "epoch: 6 step: 30, loss is 0.0007602632977068424\n",
      "epoch: 6 step: 31, loss is 0.0005433244514279068\n",
      "epoch: 6 step: 32, loss is 0.00021706461848225445\n",
      "epoch: 6 step: 33, loss is 0.0003398782282602042\n",
      "epoch: 6 step: 34, loss is 0.0006433859816752374\n",
      "epoch: 6 step: 35, loss is 0.0012588348472490907\n",
      "epoch: 6 step: 36, loss is 0.0007937338086776435\n",
      "epoch: 6 step: 37, loss is 0.0011800368083640933\n",
      "epoch: 6 step: 38, loss is 0.0007249428890645504\n",
      "epoch: 6 step: 39, loss is 0.001168975606560707\n",
      "epoch: 6 step: 40, loss is 0.00015437128604389727\n",
      "epoch: 6 step: 41, loss is 0.001299785333685577\n",
      "epoch: 6 step: 42, loss is 0.0004935357137583196\n",
      "epoch: 6 step: 43, loss is 0.0005088334437459707\n",
      "epoch: 6 step: 44, loss is 0.0006105611100792885\n",
      "epoch: 6 step: 45, loss is 0.0004282084119040519\n",
      "epoch: 6 step: 46, loss is 0.001636819913983345\n",
      "epoch: 6 step: 47, loss is 0.0003763597924262285\n",
      "epoch: 6 step: 48, loss is 0.000516749860253185\n",
      "epoch: 6 step: 49, loss is 0.0005820179940201342\n",
      "epoch: 6 step: 50, loss is 0.0007038813200779259\n",
      "epoch: 6 step: 51, loss is 0.0011384431272745132\n",
      "epoch: 6 step: 52, loss is 0.001003578188829124\n",
      "epoch: 6 step: 53, loss is 0.0005230715614743531\n",
      "epoch: 6 step: 54, loss is 0.00040217905188910663\n",
      "epoch: 6 step: 55, loss is 0.00030190436518751085\n",
      "epoch: 6 step: 56, loss is 0.0006351791671477258\n",
      "epoch: 6 step: 57, loss is 0.0008413782343268394\n",
      "epoch: 6 step: 58, loss is 0.0016555734910070896\n",
      "epoch: 6 step: 59, loss is 0.0013566394336521626\n",
      "epoch: 6 step: 60, loss is 0.0010872333077713847\n",
      "epoch: 6 step: 61, loss is 0.0006993376300670207\n",
      "epoch: 6 step: 62, loss is 0.00025094536249525845\n",
      "epoch: 6 step: 63, loss is 0.0018422655994072556\n",
      "epoch: 6 step: 64, loss is 0.0002442396362312138\n",
      "epoch: 6 step: 65, loss is 0.0005313482834026217\n",
      "epoch: 6 step: 66, loss is 0.0007194372010417283\n",
      "epoch: 6 step: 67, loss is 0.0007140429806895554\n",
      "epoch: 6 step: 68, loss is 0.0010151289170607924\n",
      "epoch: 6 step: 69, loss is 0.00136253098025918\n",
      "epoch: 6 step: 70, loss is 0.0005005631246604025\n",
      "epoch: 6 step: 71, loss is 0.0008319498156197369\n",
      "epoch: 6 step: 72, loss is 0.0004225757729727775\n",
      "epoch: 6 step: 73, loss is 0.0002433729387121275\n",
      "epoch: 6 step: 74, loss is 0.0006534603890031576\n",
      "epoch: 6 step: 75, loss is 0.0008730855770409107\n",
      "epoch: 6 step: 76, loss is 0.0009086963254958391\n",
      "epoch: 6 step: 77, loss is 0.0005638931761495769\n",
      "epoch: 6 step: 78, loss is 0.0005947048775851727\n",
      "epoch: 6 step: 79, loss is 0.0003632736043073237\n",
      "epoch: 6 step: 80, loss is 0.0002394952462054789\n",
      "epoch: 6 step: 81, loss is 0.0013724110322073102\n",
      "epoch: 6 step: 82, loss is 0.0007268658955581486\n",
      "epoch: 6 step: 83, loss is 0.0002996804832946509\n",
      "epoch: 6 step: 84, loss is 0.00032427633414044976\n",
      "epoch: 6 step: 85, loss is 0.0006544730858877301\n",
      "epoch: 6 step: 86, loss is 0.0007025310187600553\n",
      "epoch: 6 step: 87, loss is 0.0015817946987226605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 88, loss is 0.0009459904977120459\n",
      "epoch: 6 step: 89, loss is 0.0008379060309380293\n",
      "epoch: 6 step: 90, loss is 0.00019891586271114647\n",
      "epoch: 6 step: 91, loss is 0.001323858741670847\n",
      "epoch: 6 step: 92, loss is 0.0005852311151102185\n",
      "epoch: 6 step: 93, loss is 0.001427898765541613\n",
      "epoch: 6 step: 94, loss is 0.0007559539517387748\n",
      "epoch: 6 step: 95, loss is 0.0007576332427561283\n",
      "epoch: 6 step: 96, loss is 0.00042651002877391875\n",
      "epoch: 6 step: 97, loss is 0.0011393362656235695\n",
      "epoch: 6 step: 98, loss is 0.001194553915411234\n",
      "epoch: 6 step: 99, loss is 0.0006584211369045079\n",
      "epoch: 6 step: 100, loss is 0.0004964870167896152\n",
      "epoch: 6 step: 101, loss is 0.0011994504602625966\n",
      "epoch: 6 step: 102, loss is 0.000813269114587456\n",
      "epoch: 6 step: 103, loss is 0.0007723207818344235\n",
      "epoch: 6 step: 104, loss is 0.0007293340167962015\n",
      "epoch: 6 step: 105, loss is 0.0010752227390184999\n",
      "epoch: 6 step: 106, loss is 0.0005647551734000444\n",
      "epoch: 6 step: 107, loss is 0.00036046290188096464\n",
      "epoch: 6 step: 108, loss is 0.001174547360278666\n",
      "epoch: 6 step: 109, loss is 0.0006176488823257387\n",
      "epoch: 6 step: 110, loss is 0.0007154218037612736\n",
      "epoch: 6 step: 111, loss is 0.0003342570853419602\n",
      "epoch: 6 step: 112, loss is 0.0006049428484402597\n",
      "epoch: 6 step: 113, loss is 0.0011143687879666686\n",
      "epoch: 6 step: 114, loss is 0.001500552287325263\n",
      "epoch: 6 step: 115, loss is 0.0009735783096402884\n",
      "epoch: 6 step: 116, loss is 0.0008137368131428957\n",
      "epoch: 6 step: 117, loss is 0.0006124520441517234\n",
      "epoch: 6 step: 118, loss is 0.0007473255391232669\n",
      "epoch: 6 step: 119, loss is 0.00042300959466956556\n",
      "epoch: 6 step: 120, loss is 0.0003507300862111151\n",
      "epoch: 6 step: 121, loss is 0.0007805320783518255\n",
      "epoch: 6 step: 122, loss is 0.0006063258042559028\n",
      "epoch: 6 step: 123, loss is 0.0007937425980344415\n",
      "epoch: 6 step: 124, loss is 0.0006874008686281741\n",
      "epoch: 6 step: 125, loss is 0.0006649192073382437\n",
      "epoch: 6 step: 126, loss is 0.0009653661400079727\n",
      "epoch: 6 step: 127, loss is 0.0007969600846990943\n",
      "epoch: 6 step: 128, loss is 0.0008871854515746236\n",
      "epoch: 6 step: 129, loss is 0.001209221431054175\n",
      "epoch: 6 step: 130, loss is 0.0004838802560698241\n",
      "epoch: 6 step: 131, loss is 0.00028511605341918766\n",
      "epoch: 6 step: 132, loss is 0.0004903175286017358\n",
      "epoch: 6 step: 133, loss is 0.0005073905340395868\n",
      "epoch: 6 step: 134, loss is 0.0013892388669773936\n",
      "epoch: 6 step: 135, loss is 0.001271202345378697\n",
      "epoch: 6 step: 136, loss is 0.0006610059062950313\n",
      "epoch: 6 step: 137, loss is 0.0007343416218645871\n",
      "epoch: 6 step: 138, loss is 0.0009197735344059765\n",
      "epoch: 6 step: 139, loss is 0.0007910078857094049\n",
      "epoch: 6 step: 140, loss is 0.0015046705957502127\n",
      "epoch: 6 step: 141, loss is 0.001569617772474885\n",
      "epoch: 6 step: 142, loss is 0.0006971374386921525\n",
      "epoch: 6 step: 143, loss is 0.000519237422849983\n",
      "epoch: 6 step: 144, loss is 0.0008843075484037399\n",
      "epoch: 6 step: 145, loss is 0.0005589387146756053\n",
      "epoch: 6 step: 146, loss is 0.0013083425583317876\n",
      "epoch: 6 step: 147, loss is 0.0005270811379887164\n",
      "epoch: 6 step: 148, loss is 0.0015710153384134173\n",
      "epoch: 6 step: 149, loss is 0.0005930809420533478\n",
      "epoch: 6 step: 150, loss is 0.0004919538623653352\n",
      "epoch: 6 step: 151, loss is 0.0004601789405569434\n",
      "epoch: 6 step: 152, loss is 0.0013807815266773105\n",
      "epoch: 6 step: 153, loss is 0.0004952508606947958\n",
      "epoch: 6 step: 154, loss is 0.0003488839720375836\n",
      "epoch: 6 step: 155, loss is 0.001493843737989664\n",
      "epoch: 6 step: 156, loss is 0.000892398995347321\n",
      "epoch: 6 step: 157, loss is 0.0005066848825663328\n",
      "epoch: 6 step: 158, loss is 0.0003187104593962431\n",
      "epoch: 6 step: 159, loss is 0.0004974196781404316\n",
      "epoch: 6 step: 160, loss is 0.00042098286212421954\n",
      "epoch: 6 step: 161, loss is 0.0010642120614647865\n",
      "epoch: 6 step: 162, loss is 0.00030366203282028437\n",
      "epoch: 6 step: 163, loss is 0.0003921148891095072\n",
      "epoch: 6 step: 164, loss is 0.0006670579314231873\n",
      "epoch: 6 step: 165, loss is 0.0007599480450153351\n",
      "epoch: 6 step: 166, loss is 0.0008361455984413624\n",
      "epoch: 6 step: 167, loss is 0.0012435262324288487\n",
      "epoch: 6 step: 168, loss is 0.001024927943944931\n",
      "epoch: 6 step: 169, loss is 0.0006788135506212711\n",
      "epoch: 6 step: 170, loss is 0.0002766558318398893\n",
      "epoch: 6 step: 171, loss is 0.0007514047320000827\n",
      "epoch: 6 step: 172, loss is 0.0005822507664561272\n",
      "epoch: 6 step: 173, loss is 0.0005126796313561499\n",
      "epoch: 6 step: 174, loss is 0.0012400957057252526\n",
      "epoch: 6 step: 175, loss is 0.0004832818522118032\n",
      "epoch: 6 step: 176, loss is 0.0006833979277871549\n",
      "epoch: 6 step: 177, loss is 0.0003654790634755045\n",
      "epoch: 6 step: 178, loss is 0.00028835071134380996\n",
      "epoch: 6 step: 179, loss is 0.00025907595409080386\n",
      "epoch: 6 step: 180, loss is 0.0012255581095814705\n",
      "epoch: 6 step: 181, loss is 0.0008488449384458363\n",
      "epoch: 6 step: 182, loss is 0.0005721842753700912\n",
      "epoch: 6 step: 183, loss is 0.000804210954811424\n",
      "epoch: 6 step: 184, loss is 0.00020245814812369645\n",
      "epoch: 6 step: 185, loss is 0.000623362953774631\n",
      "epoch: 6 step: 186, loss is 0.0008768540574237704\n",
      "epoch: 6 step: 187, loss is 0.0014141867868602276\n",
      "epoch: 6 step: 188, loss is 0.000925048952922225\n",
      "epoch: 6 step: 189, loss is 0.0007127982680685818\n",
      "epoch: 6 step: 190, loss is 0.0005652011604979634\n",
      "epoch: 6 step: 191, loss is 0.0005371122388169169\n",
      "epoch: 6 step: 192, loss is 0.0008462205878458917\n",
      "epoch: 6 step: 193, loss is 0.0008839896181598306\n",
      "epoch: 6 step: 194, loss is 0.0005802742671221495\n",
      "epoch: 6 step: 195, loss is 0.0008802436641417444\n",
      "epoch: 6 step: 196, loss is 0.0006748419837094843\n",
      "epoch: 6 step: 197, loss is 0.0009424113668501377\n",
      "epoch: 6 step: 198, loss is 0.0003198364865966141\n",
      "epoch: 6 step: 199, loss is 0.0010514697059988976\n",
      "epoch: 6 step: 200, loss is 0.0007974233012646437\n",
      "epoch: 6 step: 201, loss is 0.0005382198723964393\n",
      "epoch: 6 step: 202, loss is 0.0004275649262126535\n",
      "epoch: 6 step: 203, loss is 0.00104019814170897\n",
      "epoch: 6 step: 204, loss is 0.0009645105456002057\n",
      "epoch: 6 step: 205, loss is 0.00145379186142236\n",
      "epoch: 6 step: 206, loss is 0.0004663454892579466\n",
      "epoch: 6 step: 207, loss is 0.000797388784121722\n",
      "epoch: 6 step: 208, loss is 0.0006488675135187805\n",
      "epoch: 6 step: 209, loss is 0.0008727619424462318\n",
      "epoch: 6 step: 210, loss is 0.00109771394636482\n",
      "epoch: 6 step: 211, loss is 0.0004782628093380481\n",
      "epoch: 6 step: 212, loss is 0.0009141972986981273\n",
      "epoch: 6 step: 213, loss is 0.0004498833150137216\n",
      "epoch: 6 step: 214, loss is 0.0001060184949892573\n",
      "epoch: 6 step: 215, loss is 0.0015871475916355848\n",
      "epoch: 6 step: 216, loss is 0.0007020375924184918\n",
      "epoch: 6 step: 217, loss is 0.00047082267701625824\n",
      "epoch: 6 step: 218, loss is 0.000668079184833914\n",
      "epoch: 6 step: 219, loss is 0.0009465738548897207\n",
      "epoch: 6 step: 220, loss is 0.000402339908760041\n",
      "epoch: 6 step: 221, loss is 0.0008755417657084763\n",
      "epoch: 6 step: 222, loss is 0.0005543226725421846\n",
      "epoch: 6 step: 223, loss is 0.0004112446040380746\n",
      "epoch: 6 step: 224, loss is 0.0004604149144142866\n",
      "epoch: 6 step: 225, loss is 0.0005611659144051373\n",
      "epoch: 6 step: 226, loss is 0.0007671883213333786\n",
      "epoch: 6 step: 227, loss is 0.0015317689394578338\n",
      "epoch: 6 step: 228, loss is 0.0018894510576501489\n",
      "epoch: 6 step: 229, loss is 0.0019050136907026172\n",
      "epoch: 6 step: 230, loss is 0.0005311266286298633\n",
      "epoch: 6 step: 231, loss is 0.0002642393810674548\n",
      "epoch: 6 step: 232, loss is 0.0005071722553111613\n",
      "epoch: 6 step: 233, loss is 0.0011396935442462564\n",
      "epoch: 6 step: 234, loss is 0.0008146156324073672\n",
      "epoch: 6 step: 235, loss is 0.0006470310618169606\n",
      "epoch: 6 step: 236, loss is 0.0018673967570066452\n",
      "epoch: 6 step: 237, loss is 0.0009093188564293087\n",
      "epoch: 6 step: 238, loss is 0.0007594579365104437\n",
      "epoch: 6 step: 239, loss is 0.0007914367015473545\n",
      "epoch: 6 step: 240, loss is 0.0013516796752810478\n",
      "epoch: 6 step: 241, loss is 0.0005705929943360388\n",
      "epoch: 6 step: 242, loss is 0.0022178650833666325\n",
      "epoch: 6 step: 243, loss is 6.186136306496337e-05\n",
      "epoch: 6 step: 244, loss is 0.0006897064158692956\n",
      "epoch: 6 step: 245, loss is 0.0005461994442157447\n",
      "epoch: 6 step: 246, loss is 0.0006007414776831865\n",
      "epoch: 6 step: 247, loss is 0.00047176156658679247\n",
      "epoch: 6 step: 248, loss is 0.000681562814861536\n",
      "epoch: 6 step: 249, loss is 0.0007676146924495697\n",
      "epoch: 6 step: 250, loss is 0.0014526258455589414\n",
      "epoch: 6 step: 251, loss is 0.0004172524204477668\n",
      "epoch: 6 step: 252, loss is 0.00048275385051965714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 253, loss is 0.0020239034201949835\n",
      "epoch: 6 step: 254, loss is 0.0001880540221463889\n",
      "epoch: 6 step: 255, loss is 0.00044298014836385846\n",
      "epoch: 6 step: 256, loss is 0.0005068728351034224\n",
      "epoch: 6 step: 257, loss is 0.0006460638251155615\n",
      "epoch: 6 step: 258, loss is 0.000534584280103445\n",
      "epoch: 6 step: 259, loss is 0.000586490030400455\n",
      "epoch: 6 step: 260, loss is 0.000530555727891624\n",
      "epoch: 6 step: 261, loss is 0.0007747755735181272\n",
      "epoch: 6 step: 262, loss is 0.0019936359021812677\n",
      "epoch: 6 step: 263, loss is 0.0003396039828658104\n",
      "epoch: 6 step: 264, loss is 0.0008971120696514845\n",
      "epoch: 6 step: 265, loss is 0.00048165314365178347\n",
      "epoch: 6 step: 266, loss is 0.0007189991301856935\n",
      "epoch: 6 step: 267, loss is 0.000643101753666997\n",
      "epoch: 6 step: 268, loss is 0.0005171576049178839\n",
      "epoch: 6 step: 269, loss is 0.0004999684751965106\n",
      "epoch: 6 step: 270, loss is 0.0013353016693145037\n",
      "epoch: 6 step: 271, loss is 0.0008024795679375529\n",
      "epoch: 6 step: 272, loss is 0.0003183844091836363\n",
      "epoch: 6 step: 273, loss is 0.0012916763080284\n",
      "epoch: 6 step: 274, loss is 0.0006045224727131426\n",
      "epoch: 6 step: 275, loss is 0.0010627956362441182\n",
      "epoch: 6 step: 276, loss is 0.0008998658158816397\n",
      "epoch: 6 step: 277, loss is 0.0009321293910034001\n",
      "epoch: 6 step: 278, loss is 0.00039132998790591955\n",
      "epoch: 6 step: 279, loss is 0.00048368042916990817\n",
      "epoch: 6 step: 280, loss is 0.0012032995000481606\n",
      "epoch: 6 step: 281, loss is 0.00028832568204961717\n",
      "epoch: 6 step: 282, loss is 0.0007707502227276564\n",
      "epoch: 6 step: 283, loss is 0.0005874784546904266\n",
      "epoch: 6 step: 284, loss is 0.0008470735629089177\n",
      "epoch: 6 step: 285, loss is 0.0005218074657022953\n",
      "epoch: 6 step: 286, loss is 0.0006526561919599771\n",
      "epoch: 6 step: 287, loss is 0.0002784132957458496\n",
      "epoch: 6 step: 288, loss is 0.0004755045520141721\n",
      "epoch: 6 step: 289, loss is 0.0006908511277288198\n",
      "epoch: 6 step: 290, loss is 0.0004108879074919969\n",
      "epoch: 6 step: 291, loss is 0.0004635591758415103\n",
      "epoch: 6 step: 292, loss is 0.0007689028279855847\n",
      "epoch: 6 step: 293, loss is 0.0005749453557655215\n",
      "epoch: 6 step: 294, loss is 0.0004141779791098088\n",
      "epoch: 6 step: 295, loss is 0.0006674535688944161\n",
      "epoch: 6 step: 296, loss is 0.0012134957360103726\n",
      "epoch: 6 step: 297, loss is 0.0022980310022830963\n",
      "epoch: 6 step: 298, loss is 0.00017241448222193867\n",
      "epoch: 6 step: 299, loss is 0.0006769726751372218\n",
      "epoch: 6 step: 300, loss is 0.0005239826859906316\n",
      "epoch: 6 step: 301, loss is 0.0009863160084933043\n",
      "epoch: 6 step: 302, loss is 0.0003735409409273416\n",
      "epoch: 6 step: 303, loss is 0.0011953333159908652\n",
      "epoch: 6 step: 304, loss is 0.0008564603049308062\n",
      "epoch: 6 step: 305, loss is 0.0005619339644908905\n",
      "epoch: 6 step: 306, loss is 0.0013115709880366921\n",
      "epoch: 6 step: 307, loss is 0.0003366541350260377\n",
      "epoch: 6 step: 308, loss is 0.001420519663952291\n",
      "epoch: 6 step: 309, loss is 0.0008070710464380682\n",
      "epoch: 6 step: 310, loss is 0.0003162904758937657\n",
      "epoch: 6 step: 311, loss is 0.0005038012750446796\n",
      "epoch: 6 step: 312, loss is 0.0009036782430484891\n",
      "epoch: 6 step: 313, loss is 0.00162642658688128\n",
      "epoch: 6 step: 314, loss is 0.0005618164432235062\n",
      "epoch: 6 step: 315, loss is 0.0008876768406480551\n",
      "epoch: 6 step: 316, loss is 0.0006555645377375185\n",
      "epoch: 6 step: 317, loss is 0.0006142811034806073\n",
      "epoch: 6 step: 318, loss is 0.0018086415948346257\n",
      "epoch: 6 step: 319, loss is 0.0018825483275577426\n",
      "epoch: 6 step: 320, loss is 0.0002269241667818278\n",
      "epoch: 6 step: 321, loss is 0.0009616625611670315\n",
      "epoch: 6 step: 322, loss is 0.0012752482434734702\n",
      "epoch: 6 step: 323, loss is 0.00115028431173414\n",
      "epoch: 6 step: 324, loss is 0.0008005500421859324\n",
      "epoch: 6 step: 325, loss is 0.001203550840727985\n",
      "epoch: 6 step: 326, loss is 0.0004973937175236642\n",
      "epoch: 6 step: 327, loss is 0.0004894628073088825\n",
      "epoch: 6 step: 328, loss is 0.0021657419856637716\n",
      "epoch: 6 step: 329, loss is 0.0009698698413558304\n",
      "epoch: 6 step: 330, loss is 0.001121667679399252\n",
      "epoch: 6 step: 331, loss is 0.0006926478818058968\n",
      "epoch: 6 step: 332, loss is 0.0025607841089367867\n",
      "epoch: 6 step: 333, loss is 0.0012267628917470574\n",
      "epoch: 6 step: 334, loss is 0.0007917949114926159\n",
      "epoch: 6 step: 335, loss is 0.0015711981104686856\n",
      "epoch: 6 step: 336, loss is 0.0006038630963303149\n",
      "epoch: 6 step: 337, loss is 0.0006925974739715457\n",
      "epoch: 6 step: 338, loss is 0.00026442811940796673\n",
      "epoch: 6 step: 339, loss is 0.0012262732489034534\n",
      "epoch: 6 step: 340, loss is 0.00035544534330256283\n",
      "epoch: 6 step: 341, loss is 0.000604392436798662\n",
      "epoch: 6 step: 342, loss is 0.00047475515748374164\n",
      "epoch: 6 step: 343, loss is 0.0012359169777482748\n",
      "epoch: 6 step: 344, loss is 0.0006251716986298561\n",
      "epoch: 6 step: 345, loss is 0.000297916354611516\n",
      "epoch: 6 step: 346, loss is 0.00041564006824046373\n",
      "epoch: 6 step: 347, loss is 0.0013041904894635081\n",
      "epoch: 6 step: 348, loss is 0.0008800807991065085\n",
      "epoch: 6 step: 349, loss is 0.00030903881997801363\n",
      "epoch: 6 step: 350, loss is 0.0006034760153852403\n",
      "epoch: 6 step: 351, loss is 0.00036540484870783985\n",
      "epoch: 6 step: 352, loss is 0.0006397477118298411\n",
      "epoch: 6 step: 353, loss is 0.0009361961856484413\n",
      "epoch: 6 step: 354, loss is 0.0008143352461047471\n",
      "epoch: 6 step: 355, loss is 0.0005743032088503242\n",
      "epoch: 6 step: 356, loss is 0.0009357209200970829\n",
      "epoch: 6 step: 357, loss is 0.00023562577553093433\n",
      "epoch: 6 step: 358, loss is 0.0005390011356212199\n",
      "epoch: 6 step: 359, loss is 0.0002912598429247737\n",
      "epoch: 6 step: 360, loss is 0.0009596833842806518\n",
      "epoch: 6 step: 361, loss is 0.0008487544837407768\n",
      "epoch: 6 step: 362, loss is 0.002240309491753578\n",
      "epoch: 6 step: 363, loss is 0.0008188316714949906\n",
      "epoch: 6 step: 364, loss is 0.0005816347547806799\n",
      "epoch: 6 step: 365, loss is 0.0010869428515434265\n",
      "epoch: 6 step: 366, loss is 0.0019318341510370374\n",
      "epoch: 6 step: 367, loss is 0.0005685556097887456\n",
      "epoch: 6 step: 368, loss is 0.0012908957432955503\n",
      "epoch: 6 step: 369, loss is 0.001117217936553061\n",
      "epoch: 6 step: 370, loss is 0.0007764828042127192\n",
      "epoch: 6 step: 371, loss is 0.0007226899033412337\n",
      "epoch: 6 step: 372, loss is 0.0014096091035753489\n",
      "epoch: 6 step: 373, loss is 0.0014018653891980648\n",
      "epoch: 6 step: 374, loss is 0.0002555504906922579\n",
      "epoch: 6 step: 375, loss is 0.0007221158593893051\n",
      "Train epoch time: 12076.730 ms, per step time: 32.205 ms\n",
      "epoch: 7 step: 1, loss is 0.0007067144033499062\n",
      "epoch: 7 step: 2, loss is 0.0009527590591460466\n",
      "epoch: 7 step: 3, loss is 0.0011602990562096238\n",
      "epoch: 7 step: 4, loss is 0.0005570495268329978\n",
      "epoch: 7 step: 5, loss is 0.0006803717697039247\n",
      "epoch: 7 step: 6, loss is 0.001165366847999394\n",
      "epoch: 7 step: 7, loss is 0.0017136981477960944\n",
      "epoch: 7 step: 8, loss is 0.000340857106493786\n",
      "epoch: 7 step: 9, loss is 0.0015463934978470206\n",
      "epoch: 7 step: 10, loss is 0.00043987861135974526\n",
      "epoch: 7 step: 11, loss is 0.0018970598466694355\n",
      "epoch: 7 step: 12, loss is 0.0004775984853040427\n",
      "epoch: 7 step: 13, loss is 0.0009027087944559753\n",
      "epoch: 7 step: 14, loss is 0.0006348834722302854\n",
      "epoch: 7 step: 15, loss is 0.00039599917363375425\n",
      "epoch: 7 step: 16, loss is 0.0019912109710276127\n",
      "epoch: 7 step: 17, loss is 0.0007526944391429424\n",
      "epoch: 7 step: 18, loss is 0.0007491515716537833\n",
      "epoch: 7 step: 19, loss is 0.0007971106097102165\n",
      "epoch: 7 step: 20, loss is 0.0008263106574304402\n",
      "epoch: 7 step: 21, loss is 0.0007021160563454032\n",
      "epoch: 7 step: 22, loss is 0.00068822962930426\n",
      "epoch: 7 step: 23, loss is 0.0011183226015418768\n",
      "epoch: 7 step: 24, loss is 0.00036273853038437665\n",
      "epoch: 7 step: 25, loss is 0.0007909590494818985\n",
      "epoch: 7 step: 26, loss is 0.0008918762323446572\n",
      "epoch: 7 step: 27, loss is 0.00046014977851882577\n",
      "epoch: 7 step: 28, loss is 0.0004749191284645349\n",
      "epoch: 7 step: 29, loss is 0.001069695339538157\n",
      "epoch: 7 step: 30, loss is 0.0008758183103054762\n",
      "epoch: 7 step: 31, loss is 0.0012097579892724752\n",
      "epoch: 7 step: 32, loss is 0.00130711798556149\n",
      "epoch: 7 step: 33, loss is 0.0008679146412760019\n",
      "epoch: 7 step: 34, loss is 0.0009384156437590718\n",
      "epoch: 7 step: 35, loss is 0.0004901228239759803\n",
      "epoch: 7 step: 36, loss is 0.0014404283137992024\n",
      "epoch: 7 step: 37, loss is 0.0009539942839182913\n",
      "epoch: 7 step: 38, loss is 0.0007950125727802515\n",
      "epoch: 7 step: 39, loss is 0.0009096249705180526\n",
      "epoch: 7 step: 40, loss is 0.00028144498355686665\n",
      "epoch: 7 step: 41, loss is 0.000974173191934824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 42, loss is 0.0008199174772016704\n",
      "epoch: 7 step: 43, loss is 0.0004928776761516929\n",
      "epoch: 7 step: 44, loss is 0.0014393801102414727\n",
      "epoch: 7 step: 45, loss is 0.002108139917254448\n",
      "epoch: 7 step: 46, loss is 0.0001777295838110149\n",
      "epoch: 7 step: 47, loss is 0.0004432611458469182\n",
      "epoch: 7 step: 48, loss is 0.00047402450582012534\n",
      "epoch: 7 step: 49, loss is 0.0005825452390126884\n",
      "epoch: 7 step: 50, loss is 0.0002996256807819009\n",
      "epoch: 7 step: 51, loss is 0.0010385398054495454\n",
      "epoch: 7 step: 52, loss is 0.0006882695597596467\n",
      "epoch: 7 step: 53, loss is 0.0005284390645101666\n",
      "epoch: 7 step: 54, loss is 0.000706860504578799\n",
      "epoch: 7 step: 55, loss is 0.0005609327927231789\n",
      "epoch: 7 step: 56, loss is 0.00047710322542116046\n",
      "epoch: 7 step: 57, loss is 0.0003428444324526936\n",
      "epoch: 7 step: 58, loss is 0.00045862793922424316\n",
      "epoch: 7 step: 59, loss is 0.0008150044013746083\n",
      "epoch: 7 step: 60, loss is 0.0006019605789333582\n",
      "epoch: 7 step: 61, loss is 0.00036119844298809767\n",
      "epoch: 7 step: 62, loss is 0.00041896066977642477\n",
      "epoch: 7 step: 63, loss is 0.0002501640992704779\n",
      "epoch: 7 step: 64, loss is 0.00047693579108454287\n",
      "epoch: 7 step: 65, loss is 0.0005499992985278368\n",
      "epoch: 7 step: 66, loss is 0.0005352949956431985\n",
      "epoch: 7 step: 67, loss is 0.0009218468330800533\n",
      "epoch: 7 step: 68, loss is 0.0003024672041647136\n",
      "epoch: 7 step: 69, loss is 0.0003422198642510921\n",
      "epoch: 7 step: 70, loss is 0.0003643656673375517\n",
      "epoch: 7 step: 71, loss is 0.0007201152038760483\n",
      "epoch: 7 step: 72, loss is 0.0008028811425901949\n",
      "epoch: 7 step: 73, loss is 0.00021902401931583881\n",
      "epoch: 7 step: 74, loss is 0.0013288146583363414\n",
      "epoch: 7 step: 75, loss is 0.0006916819256730378\n",
      "epoch: 7 step: 76, loss is 0.00047063143574632704\n",
      "epoch: 7 step: 77, loss is 0.0025740533601492643\n",
      "epoch: 7 step: 78, loss is 0.0008727242820896208\n",
      "epoch: 7 step: 79, loss is 0.00037424147012643516\n",
      "epoch: 7 step: 80, loss is 0.001776563236489892\n",
      "epoch: 7 step: 81, loss is 0.0004418655298650265\n",
      "epoch: 7 step: 82, loss is 0.001644579111598432\n",
      "epoch: 7 step: 83, loss is 0.0008871674654074013\n",
      "epoch: 7 step: 84, loss is 0.0002997434639837593\n",
      "epoch: 7 step: 85, loss is 0.00046233090688474476\n",
      "epoch: 7 step: 86, loss is 0.0010692871874198318\n",
      "epoch: 7 step: 87, loss is 0.001009347615763545\n",
      "epoch: 7 step: 88, loss is 0.0016698876861482859\n",
      "epoch: 7 step: 89, loss is 0.0010894456645473838\n",
      "epoch: 7 step: 90, loss is 0.0005834694020450115\n",
      "epoch: 7 step: 91, loss is 0.000509571866132319\n",
      "epoch: 7 step: 92, loss is 0.0007207058952189982\n",
      "epoch: 7 step: 93, loss is 0.0008996998076327145\n",
      "epoch: 7 step: 94, loss is 0.00045727609540335834\n",
      "epoch: 7 step: 95, loss is 0.0006339639076031744\n",
      "epoch: 7 step: 96, loss is 0.0006676205666735768\n",
      "epoch: 7 step: 97, loss is 0.0004965750849805772\n",
      "epoch: 7 step: 98, loss is 0.001345439930446446\n",
      "epoch: 7 step: 99, loss is 0.0009993701241910458\n",
      "epoch: 7 step: 100, loss is 0.00045878742821514606\n",
      "epoch: 7 step: 101, loss is 0.0011228786315768957\n",
      "epoch: 7 step: 102, loss is 0.0013755697291344404\n",
      "epoch: 7 step: 103, loss is 0.001741344458423555\n",
      "epoch: 7 step: 104, loss is 0.0007480065687559545\n",
      "epoch: 7 step: 105, loss is 0.0006493825931102037\n",
      "epoch: 7 step: 106, loss is 0.00036479992559179664\n",
      "epoch: 7 step: 107, loss is 0.0006124419742263854\n",
      "epoch: 7 step: 108, loss is 0.0008202391909435391\n",
      "epoch: 7 step: 109, loss is 0.0014403006061911583\n",
      "epoch: 7 step: 110, loss is 0.0017705061472952366\n",
      "epoch: 7 step: 111, loss is 0.00039435713551938534\n",
      "epoch: 7 step: 112, loss is 0.0004479495983105153\n",
      "epoch: 7 step: 113, loss is 0.000802632246632129\n",
      "epoch: 7 step: 114, loss is 0.001039208029396832\n",
      "epoch: 7 step: 115, loss is 0.000690791814122349\n",
      "epoch: 7 step: 116, loss is 0.0006885351031087339\n",
      "epoch: 7 step: 117, loss is 0.000604343949817121\n",
      "epoch: 7 step: 118, loss is 0.0008970495546236634\n",
      "epoch: 7 step: 119, loss is 0.0008084626169875264\n",
      "epoch: 7 step: 120, loss is 0.00036273864679969847\n",
      "epoch: 7 step: 121, loss is 0.000997604220174253\n",
      "epoch: 7 step: 122, loss is 0.001013437402434647\n",
      "epoch: 7 step: 123, loss is 0.0008354673627763987\n",
      "epoch: 7 step: 124, loss is 0.00022610505402553827\n",
      "epoch: 7 step: 125, loss is 0.0009746243013069034\n",
      "epoch: 7 step: 126, loss is 0.0008418204379267991\n",
      "epoch: 7 step: 127, loss is 0.0005568201886489987\n",
      "epoch: 7 step: 128, loss is 0.0005792225711047649\n",
      "epoch: 7 step: 129, loss is 0.0005827962886542082\n",
      "epoch: 7 step: 130, loss is 0.00048428226727992296\n",
      "epoch: 7 step: 131, loss is 0.0005162457819096744\n",
      "epoch: 7 step: 132, loss is 0.0006294722552411258\n",
      "epoch: 7 step: 133, loss is 0.0009351686458103359\n",
      "epoch: 7 step: 134, loss is 0.00030416777008213103\n",
      "epoch: 7 step: 135, loss is 0.0008154783863574266\n",
      "epoch: 7 step: 136, loss is 0.0013227262534201145\n",
      "epoch: 7 step: 137, loss is 0.0007379316375590861\n",
      "epoch: 7 step: 138, loss is 0.0005406822310760617\n",
      "epoch: 7 step: 139, loss is 0.0009198787738569081\n",
      "epoch: 7 step: 140, loss is 0.0006373075302690268\n",
      "epoch: 7 step: 141, loss is 0.0006271065212786198\n",
      "epoch: 7 step: 142, loss is 0.0010246956953778863\n",
      "epoch: 7 step: 143, loss is 0.0016296219546347857\n",
      "epoch: 7 step: 144, loss is 0.0005619735457003117\n",
      "epoch: 7 step: 145, loss is 0.000954240676946938\n",
      "epoch: 7 step: 146, loss is 0.0004160149837844074\n",
      "epoch: 7 step: 147, loss is 0.0003928808437194675\n",
      "epoch: 7 step: 148, loss is 0.00029465113766491413\n",
      "epoch: 7 step: 149, loss is 0.00036245613591745496\n",
      "epoch: 7 step: 150, loss is 0.0010212537599727511\n",
      "epoch: 7 step: 151, loss is 0.000854220415931195\n",
      "epoch: 7 step: 152, loss is 0.0006884212489239872\n",
      "epoch: 7 step: 153, loss is 0.001019515679217875\n",
      "epoch: 7 step: 154, loss is 0.0005181221640668809\n",
      "epoch: 7 step: 155, loss is 0.00043971609557047486\n",
      "epoch: 7 step: 156, loss is 0.0007105989498086274\n",
      "epoch: 7 step: 157, loss is 0.0007826618384569883\n",
      "epoch: 7 step: 158, loss is 0.0007962819654494524\n",
      "epoch: 7 step: 159, loss is 0.0004305327602196485\n",
      "epoch: 7 step: 160, loss is 0.0003793523064814508\n",
      "epoch: 7 step: 161, loss is 0.00032674981048330665\n",
      "epoch: 7 step: 162, loss is 0.0008167908526957035\n",
      "epoch: 7 step: 163, loss is 0.00019659980898723006\n",
      "epoch: 7 step: 164, loss is 0.0005021301913075149\n",
      "epoch: 7 step: 165, loss is 0.0003567081002984196\n",
      "epoch: 7 step: 166, loss is 0.0006139139295555651\n",
      "epoch: 7 step: 167, loss is 0.0005920720286667347\n",
      "epoch: 7 step: 168, loss is 0.0004433835856616497\n",
      "epoch: 7 step: 169, loss is 0.0009471865487284958\n",
      "epoch: 7 step: 170, loss is 0.00013624472194351256\n",
      "epoch: 7 step: 171, loss is 0.0017592315562069416\n",
      "epoch: 7 step: 172, loss is 0.0004692460352089256\n",
      "epoch: 7 step: 173, loss is 0.0003996828163508326\n",
      "epoch: 7 step: 174, loss is 0.0009551196126267314\n",
      "epoch: 7 step: 175, loss is 0.0008301367633976042\n",
      "epoch: 7 step: 176, loss is 0.0004660026461351663\n",
      "epoch: 7 step: 177, loss is 0.00036186460056342185\n",
      "epoch: 7 step: 178, loss is 0.0010926949325948954\n",
      "epoch: 7 step: 179, loss is 0.0010314143728464842\n",
      "epoch: 7 step: 180, loss is 0.0018646672833710909\n",
      "epoch: 7 step: 181, loss is 0.000583408516831696\n",
      "epoch: 7 step: 182, loss is 0.0003321180120110512\n",
      "epoch: 7 step: 183, loss is 0.0014197295531630516\n",
      "epoch: 7 step: 184, loss is 0.001124982489272952\n",
      "epoch: 7 step: 185, loss is 0.0007038524490781128\n",
      "epoch: 7 step: 186, loss is 0.00032061783713288605\n",
      "epoch: 7 step: 187, loss is 0.00025848174118436873\n",
      "epoch: 7 step: 188, loss is 0.0002875580103136599\n",
      "epoch: 7 step: 189, loss is 0.0005727782263420522\n",
      "epoch: 7 step: 190, loss is 0.0009608369437046349\n",
      "epoch: 7 step: 191, loss is 0.0006054063560441136\n",
      "epoch: 7 step: 192, loss is 0.0006454921676777303\n",
      "epoch: 7 step: 193, loss is 0.0006070570088922977\n",
      "epoch: 7 step: 194, loss is 0.0006325406138785183\n",
      "epoch: 7 step: 195, loss is 0.0015290721785277128\n",
      "epoch: 7 step: 196, loss is 0.0008677805308252573\n",
      "epoch: 7 step: 197, loss is 0.0003214175521861762\n",
      "epoch: 7 step: 198, loss is 0.0002841249806806445\n",
      "epoch: 7 step: 199, loss is 0.0003549985121935606\n",
      "epoch: 7 step: 200, loss is 0.0009091465617530048\n",
      "epoch: 7 step: 201, loss is 0.0005965647869743407\n",
      "epoch: 7 step: 202, loss is 0.001091943122446537\n",
      "epoch: 7 step: 203, loss is 0.00048512499779462814\n",
      "epoch: 7 step: 204, loss is 0.0006088576046749949\n",
      "epoch: 7 step: 205, loss is 0.001567614614032209\n",
      "epoch: 7 step: 206, loss is 0.0007640501135028899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 207, loss is 0.0003772105264943093\n",
      "epoch: 7 step: 208, loss is 0.0004813327395822853\n",
      "epoch: 7 step: 209, loss is 0.0005910163163207471\n",
      "epoch: 7 step: 210, loss is 0.0007215174846351147\n",
      "epoch: 7 step: 211, loss is 0.0006137434393167496\n",
      "epoch: 7 step: 212, loss is 0.0006843801238574088\n",
      "epoch: 7 step: 213, loss is 0.0003482457541394979\n",
      "epoch: 7 step: 214, loss is 0.0003688513534143567\n",
      "epoch: 7 step: 215, loss is 0.0007495140307582915\n",
      "epoch: 7 step: 216, loss is 0.000569439958781004\n",
      "epoch: 7 step: 217, loss is 0.0009133469429798424\n",
      "epoch: 7 step: 218, loss is 0.0004772180982399732\n",
      "epoch: 7 step: 219, loss is 0.000602610525675118\n",
      "epoch: 7 step: 220, loss is 0.0016476953169330955\n",
      "epoch: 7 step: 221, loss is 0.00031953543657436967\n",
      "epoch: 7 step: 222, loss is 0.000765129632782191\n",
      "epoch: 7 step: 223, loss is 0.0003477242134977132\n",
      "epoch: 7 step: 224, loss is 0.001047087600454688\n",
      "epoch: 7 step: 225, loss is 0.002414928749203682\n",
      "epoch: 7 step: 226, loss is 0.001335123903118074\n",
      "epoch: 7 step: 227, loss is 0.0005631726235151291\n",
      "epoch: 7 step: 228, loss is 0.0007225825684145093\n",
      "epoch: 7 step: 229, loss is 0.0009781222324818373\n",
      "epoch: 7 step: 230, loss is 0.0009911319939419627\n",
      "epoch: 7 step: 231, loss is 0.0009457873529754579\n",
      "epoch: 7 step: 232, loss is 0.000845678907353431\n",
      "epoch: 7 step: 233, loss is 0.00048781646182760596\n",
      "epoch: 7 step: 234, loss is 0.0008531492785550654\n",
      "epoch: 7 step: 235, loss is 0.000997561146505177\n",
      "epoch: 7 step: 236, loss is 0.0006106151267886162\n",
      "epoch: 7 step: 237, loss is 0.00044196535600349307\n",
      "epoch: 7 step: 238, loss is 0.0012804241850972176\n",
      "epoch: 7 step: 239, loss is 0.00040886408532969654\n",
      "epoch: 7 step: 240, loss is 0.0013856121804565191\n",
      "epoch: 7 step: 241, loss is 0.0010679985862225294\n",
      "epoch: 7 step: 242, loss is 0.0009184489026665688\n",
      "epoch: 7 step: 243, loss is 0.0007512994925491512\n",
      "epoch: 7 step: 244, loss is 0.0006077598663978279\n",
      "epoch: 7 step: 245, loss is 0.0009202071814797819\n",
      "epoch: 7 step: 246, loss is 0.0001953733153641224\n",
      "epoch: 7 step: 247, loss is 0.00045463821152225137\n",
      "epoch: 7 step: 248, loss is 0.0005940747796557844\n",
      "epoch: 7 step: 249, loss is 0.0010045442031696439\n",
      "epoch: 7 step: 250, loss is 0.000343593506840989\n",
      "epoch: 7 step: 251, loss is 0.0008152923546731472\n",
      "epoch: 7 step: 252, loss is 0.001105141476728022\n",
      "epoch: 7 step: 253, loss is 0.001775893964804709\n",
      "epoch: 7 step: 254, loss is 0.0005902080447413027\n",
      "epoch: 7 step: 255, loss is 0.00040259689558297396\n",
      "epoch: 7 step: 256, loss is 0.0005156254628673196\n",
      "epoch: 7 step: 257, loss is 0.0012315557105466723\n",
      "epoch: 7 step: 258, loss is 0.00047022596118040383\n",
      "epoch: 7 step: 259, loss is 0.0014138635015115142\n",
      "epoch: 7 step: 260, loss is 0.0005451239994727075\n",
      "epoch: 7 step: 261, loss is 0.0014019185910001397\n",
      "epoch: 7 step: 262, loss is 0.000543009489774704\n",
      "epoch: 7 step: 263, loss is 0.0011480588000267744\n",
      "epoch: 7 step: 264, loss is 0.0004262206784915179\n",
      "epoch: 7 step: 265, loss is 0.0009625190286897123\n",
      "epoch: 7 step: 266, loss is 0.0015753181651234627\n",
      "epoch: 7 step: 267, loss is 0.0007010659901425242\n",
      "epoch: 7 step: 268, loss is 0.00043964441283605993\n",
      "epoch: 7 step: 269, loss is 0.0005982798174954951\n",
      "epoch: 7 step: 270, loss is 0.0009148610988631845\n",
      "epoch: 7 step: 271, loss is 0.00036762410309165716\n",
      "epoch: 7 step: 272, loss is 0.0009722203831188381\n",
      "epoch: 7 step: 273, loss is 0.000997274531982839\n",
      "epoch: 7 step: 274, loss is 0.001019655610434711\n",
      "epoch: 7 step: 275, loss is 0.0008508258615620434\n",
      "epoch: 7 step: 276, loss is 0.0008560772403143346\n",
      "epoch: 7 step: 277, loss is 0.0008267685188911855\n",
      "epoch: 7 step: 278, loss is 0.0006468104547820985\n",
      "epoch: 7 step: 279, loss is 0.0007329678628593683\n",
      "epoch: 7 step: 280, loss is 0.00016298415721394122\n",
      "epoch: 7 step: 281, loss is 0.0006089879316277802\n",
      "epoch: 7 step: 282, loss is 0.0004654069198295474\n",
      "epoch: 7 step: 283, loss is 0.0005531363422051072\n",
      "epoch: 7 step: 284, loss is 0.0011331533314660192\n",
      "epoch: 7 step: 285, loss is 0.0011372289154678583\n",
      "epoch: 7 step: 286, loss is 0.0006098511512391269\n",
      "epoch: 7 step: 287, loss is 0.00040944042848423123\n",
      "epoch: 7 step: 288, loss is 0.0009830509079620242\n",
      "epoch: 7 step: 289, loss is 0.0006079510785639286\n",
      "epoch: 7 step: 290, loss is 0.0012985720532014966\n",
      "epoch: 7 step: 291, loss is 0.0008806849946267903\n",
      "epoch: 7 step: 292, loss is 0.0005127481417730451\n",
      "epoch: 7 step: 293, loss is 0.0007239887490868568\n",
      "epoch: 7 step: 294, loss is 0.0012570236576721072\n",
      "epoch: 7 step: 295, loss is 0.0011321842903271317\n",
      "epoch: 7 step: 296, loss is 0.0009405474993400276\n",
      "epoch: 7 step: 297, loss is 0.0003342987038195133\n",
      "epoch: 7 step: 298, loss is 0.001129798241890967\n",
      "epoch: 7 step: 299, loss is 0.0008887172443792224\n",
      "epoch: 7 step: 300, loss is 0.000400820019422099\n",
      "epoch: 7 step: 301, loss is 0.0004715181712526828\n",
      "epoch: 7 step: 302, loss is 0.0010022271890193224\n",
      "epoch: 7 step: 303, loss is 0.0007284103776328266\n",
      "epoch: 7 step: 304, loss is 0.0006772115593776107\n",
      "epoch: 7 step: 305, loss is 0.00036160845775157213\n",
      "epoch: 7 step: 306, loss is 0.0005486973677761853\n",
      "epoch: 7 step: 307, loss is 0.0005992423975840211\n",
      "epoch: 7 step: 308, loss is 0.0005437860963866115\n",
      "epoch: 7 step: 309, loss is 0.0004152833134867251\n",
      "epoch: 7 step: 310, loss is 0.0008704153588041663\n",
      "epoch: 7 step: 311, loss is 0.0004780243325512856\n",
      "epoch: 7 step: 312, loss is 0.0005833983304910362\n",
      "epoch: 7 step: 313, loss is 0.0002925729495473206\n",
      "epoch: 7 step: 314, loss is 0.0007800103048793972\n",
      "epoch: 7 step: 315, loss is 0.0006933737895451486\n",
      "epoch: 7 step: 316, loss is 0.001800898346118629\n",
      "epoch: 7 step: 317, loss is 0.0013843015767633915\n",
      "epoch: 7 step: 318, loss is 0.0005707869422622025\n",
      "epoch: 7 step: 319, loss is 0.0015746933640912175\n",
      "epoch: 7 step: 320, loss is 0.0008087152964435518\n",
      "epoch: 7 step: 321, loss is 0.0006038611754775047\n",
      "epoch: 7 step: 322, loss is 0.000525261159054935\n",
      "epoch: 7 step: 323, loss is 0.0011296352604404092\n",
      "epoch: 7 step: 324, loss is 0.0006043483153916895\n",
      "epoch: 7 step: 325, loss is 0.0004924795357510448\n",
      "epoch: 7 step: 326, loss is 0.0011545591987669468\n",
      "epoch: 7 step: 327, loss is 0.00039245092193596065\n",
      "epoch: 7 step: 328, loss is 0.0005370950093492866\n",
      "epoch: 7 step: 329, loss is 0.00080608029384166\n",
      "epoch: 7 step: 330, loss is 0.0013405258068814874\n",
      "epoch: 7 step: 331, loss is 0.00034377272822894156\n",
      "epoch: 7 step: 332, loss is 0.0017718934686854482\n",
      "epoch: 7 step: 333, loss is 0.00025576193002052605\n",
      "epoch: 7 step: 334, loss is 0.0004624808789230883\n",
      "epoch: 7 step: 335, loss is 0.0012664520181715488\n",
      "epoch: 7 step: 336, loss is 0.0005451958277262747\n",
      "epoch: 7 step: 337, loss is 0.0005116953398101032\n",
      "epoch: 7 step: 338, loss is 0.0009658143972046673\n",
      "epoch: 7 step: 339, loss is 0.0003276944044046104\n",
      "epoch: 7 step: 340, loss is 0.0006069675437174737\n",
      "epoch: 7 step: 341, loss is 0.0005045115831308067\n",
      "epoch: 7 step: 342, loss is 0.0003507764486130327\n",
      "epoch: 7 step: 343, loss is 0.0005245573702268302\n",
      "epoch: 7 step: 344, loss is 0.00037357196561060846\n",
      "epoch: 7 step: 345, loss is 0.0005127283511683345\n",
      "epoch: 7 step: 346, loss is 0.0009184203227050602\n",
      "epoch: 7 step: 347, loss is 0.0005146132316440344\n",
      "epoch: 7 step: 348, loss is 0.0005586647312156856\n",
      "epoch: 7 step: 349, loss is 0.0005552847869694233\n",
      "epoch: 7 step: 350, loss is 0.0014698620652779937\n",
      "epoch: 7 step: 351, loss is 0.0008254508720710874\n",
      "epoch: 7 step: 352, loss is 0.0007814935524947941\n",
      "epoch: 7 step: 353, loss is 0.0012426340254023671\n",
      "epoch: 7 step: 354, loss is 0.0014708030503243208\n",
      "epoch: 7 step: 355, loss is 0.0009928925428539515\n",
      "epoch: 7 step: 356, loss is 0.0005680861650034785\n",
      "epoch: 7 step: 357, loss is 0.0022429258096963167\n",
      "epoch: 7 step: 358, loss is 0.001500551006756723\n",
      "epoch: 7 step: 359, loss is 0.0002750618732534349\n",
      "epoch: 7 step: 360, loss is 0.0017055310308933258\n",
      "epoch: 7 step: 361, loss is 0.0007376292487606406\n",
      "epoch: 7 step: 362, loss is 0.0009830017806962132\n",
      "epoch: 7 step: 363, loss is 0.0007951569277793169\n",
      "epoch: 7 step: 364, loss is 0.00038750749081373215\n",
      "epoch: 7 step: 365, loss is 0.0010669847251847386\n",
      "epoch: 7 step: 366, loss is 0.0003687247808557004\n",
      "epoch: 7 step: 367, loss is 0.0017971827182918787\n",
      "epoch: 7 step: 368, loss is 0.0005480229738168418\n",
      "epoch: 7 step: 369, loss is 0.00075979606481269\n",
      "epoch: 7 step: 370, loss is 0.0007075344328768551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 371, loss is 0.0009372778586111963\n",
      "epoch: 7 step: 372, loss is 0.001076610991731286\n",
      "epoch: 7 step: 373, loss is 0.0006697136559523642\n",
      "epoch: 7 step: 374, loss is 0.001457472681067884\n",
      "epoch: 7 step: 375, loss is 0.0005812907475046813\n",
      "Train epoch time: 12032.062 ms, per step time: 32.085 ms\n",
      "epoch: 8 step: 1, loss is 0.0005921753472648561\n",
      "epoch: 8 step: 2, loss is 0.00042656317236833274\n",
      "epoch: 8 step: 3, loss is 0.00141599599737674\n",
      "epoch: 8 step: 4, loss is 0.0008500842959620059\n",
      "epoch: 8 step: 5, loss is 0.0006032446981407702\n",
      "epoch: 8 step: 6, loss is 0.002006768947467208\n",
      "epoch: 8 step: 7, loss is 0.0006211571744643152\n",
      "epoch: 8 step: 8, loss is 0.0003701478708535433\n",
      "epoch: 8 step: 9, loss is 0.0006770370528101921\n",
      "epoch: 8 step: 10, loss is 0.00047353454283438623\n",
      "epoch: 8 step: 11, loss is 0.0005065243458375335\n",
      "epoch: 8 step: 12, loss is 0.00031130138086155057\n",
      "epoch: 8 step: 13, loss is 0.0006017282721586525\n",
      "epoch: 8 step: 14, loss is 0.0009374992805533111\n",
      "epoch: 8 step: 15, loss is 0.0006444788305088878\n",
      "epoch: 8 step: 16, loss is 0.0003934230771847069\n",
      "epoch: 8 step: 17, loss is 0.0006919758743606508\n",
      "epoch: 8 step: 18, loss is 0.0014156417455524206\n",
      "epoch: 8 step: 19, loss is 0.00039582522003911436\n",
      "epoch: 8 step: 20, loss is 0.0014533748617395759\n",
      "epoch: 8 step: 21, loss is 0.0005517363897524774\n",
      "epoch: 8 step: 22, loss is 0.0014626475749537349\n",
      "epoch: 8 step: 23, loss is 0.0010954480385407805\n",
      "epoch: 8 step: 24, loss is 0.0006887865602038801\n",
      "epoch: 8 step: 25, loss is 0.0006191681604832411\n",
      "epoch: 8 step: 26, loss is 0.0005205817287787795\n",
      "epoch: 8 step: 27, loss is 0.0004411929112393409\n",
      "epoch: 8 step: 28, loss is 0.0008973993244580925\n",
      "epoch: 8 step: 29, loss is 0.0007316594128496945\n",
      "epoch: 8 step: 30, loss is 0.0003119181783404201\n",
      "epoch: 8 step: 31, loss is 0.0014256230788305402\n",
      "epoch: 8 step: 32, loss is 0.000616351084318012\n",
      "epoch: 8 step: 33, loss is 0.0023389195557683706\n",
      "epoch: 8 step: 34, loss is 0.001998147927224636\n",
      "epoch: 8 step: 35, loss is 0.00043810263741761446\n",
      "epoch: 8 step: 36, loss is 0.0009422326111234725\n",
      "epoch: 8 step: 37, loss is 0.0013784380862489343\n",
      "epoch: 8 step: 38, loss is 0.0014482024125754833\n",
      "epoch: 8 step: 39, loss is 0.0006981796468608081\n",
      "epoch: 8 step: 40, loss is 0.0012202027719467878\n",
      "epoch: 8 step: 41, loss is 0.0016139318468049169\n",
      "epoch: 8 step: 42, loss is 0.0012468630447983742\n",
      "epoch: 8 step: 43, loss is 0.0005095226806588471\n",
      "epoch: 8 step: 44, loss is 0.0021359040401875973\n",
      "epoch: 8 step: 45, loss is 0.0007865992956794798\n",
      "epoch: 8 step: 46, loss is 0.0024608143139630556\n",
      "epoch: 8 step: 47, loss is 0.0015248650452122092\n",
      "epoch: 8 step: 48, loss is 0.0015237948391586542\n",
      "epoch: 8 step: 49, loss is 0.0008970330818556249\n",
      "epoch: 8 step: 50, loss is 0.0006574231665581465\n",
      "epoch: 8 step: 51, loss is 0.0010913553414866328\n",
      "epoch: 8 step: 52, loss is 0.0009776940569281578\n",
      "epoch: 8 step: 53, loss is 0.0010456626769155264\n",
      "epoch: 8 step: 54, loss is 0.0009057847200892866\n",
      "epoch: 8 step: 55, loss is 0.0006801115232519805\n",
      "epoch: 8 step: 56, loss is 0.0011833778116852045\n",
      "epoch: 8 step: 57, loss is 0.001158067723736167\n",
      "epoch: 8 step: 58, loss is 0.0007427140371873975\n",
      "epoch: 8 step: 59, loss is 0.0010972386226058006\n",
      "epoch: 8 step: 60, loss is 0.0012832138454541564\n",
      "epoch: 8 step: 61, loss is 0.0017135533271357417\n",
      "epoch: 8 step: 62, loss is 0.0006606836686842144\n",
      "epoch: 8 step: 63, loss is 0.0008551113423891366\n",
      "epoch: 8 step: 64, loss is 0.0010552298044785857\n",
      "epoch: 8 step: 65, loss is 0.0020330664701759815\n",
      "epoch: 8 step: 66, loss is 0.0011198498541489244\n",
      "epoch: 8 step: 67, loss is 0.0010073480661958456\n",
      "epoch: 8 step: 68, loss is 0.0005330215208232403\n",
      "epoch: 8 step: 69, loss is 0.0012293036561459303\n",
      "epoch: 8 step: 70, loss is 0.0010512792505323887\n",
      "epoch: 8 step: 71, loss is 0.0006194303859956563\n",
      "epoch: 8 step: 72, loss is 0.001028649159707129\n",
      "epoch: 8 step: 73, loss is 0.0007028282852843404\n",
      "epoch: 8 step: 74, loss is 0.0008317941101267934\n",
      "epoch: 8 step: 75, loss is 0.0002496062661521137\n",
      "epoch: 8 step: 76, loss is 0.0009151362464763224\n",
      "epoch: 8 step: 77, loss is 0.0007961161900311708\n",
      "epoch: 8 step: 78, loss is 0.00042691812268458307\n",
      "epoch: 8 step: 79, loss is 0.000534447783138603\n",
      "epoch: 8 step: 80, loss is 0.0007878058822825551\n",
      "epoch: 8 step: 81, loss is 0.0010397969745099545\n",
      "epoch: 8 step: 82, loss is 0.00038634444354102015\n",
      "epoch: 8 step: 83, loss is 0.0013370926026254892\n",
      "epoch: 8 step: 84, loss is 0.00014687702059745789\n",
      "epoch: 8 step: 85, loss is 0.0004982269019819796\n",
      "epoch: 8 step: 86, loss is 0.00022545648971572518\n",
      "epoch: 8 step: 87, loss is 0.0008207830251194537\n",
      "epoch: 8 step: 88, loss is 0.0006377301760949194\n",
      "epoch: 8 step: 89, loss is 0.0011123648146167397\n",
      "epoch: 8 step: 90, loss is 0.001153761986643076\n",
      "epoch: 8 step: 91, loss is 0.0004576431820169091\n",
      "epoch: 8 step: 92, loss is 0.0006384351872839034\n",
      "epoch: 8 step: 93, loss is 0.0019004170317202806\n",
      "epoch: 8 step: 94, loss is 0.0015743918484076858\n",
      "epoch: 8 step: 95, loss is 0.00045374466571956873\n",
      "epoch: 8 step: 96, loss is 0.0012274396140128374\n",
      "epoch: 8 step: 97, loss is 0.0004513954045251012\n",
      "epoch: 8 step: 98, loss is 0.000515165738761425\n",
      "epoch: 8 step: 99, loss is 0.0005889930762350559\n",
      "epoch: 8 step: 100, loss is 0.000494783220347017\n",
      "epoch: 8 step: 101, loss is 0.0015772844199091196\n",
      "epoch: 8 step: 102, loss is 0.00046205552644096315\n",
      "epoch: 8 step: 103, loss is 0.0013251624768599868\n",
      "epoch: 8 step: 104, loss is 0.0004247162723913789\n",
      "epoch: 8 step: 105, loss is 0.0009048189385794103\n",
      "epoch: 8 step: 106, loss is 0.0008102987194433808\n",
      "epoch: 8 step: 107, loss is 0.0005964093725197017\n",
      "epoch: 8 step: 108, loss is 0.0002756804460659623\n",
      "epoch: 8 step: 109, loss is 0.00029252131935209036\n",
      "epoch: 8 step: 110, loss is 0.0001677152031334117\n",
      "epoch: 8 step: 111, loss is 0.000616172794252634\n",
      "epoch: 8 step: 112, loss is 0.0010953089222311974\n",
      "epoch: 8 step: 113, loss is 0.000583140819799155\n",
      "epoch: 8 step: 114, loss is 0.0007009104010649025\n",
      "epoch: 8 step: 115, loss is 0.0004477980255614966\n",
      "epoch: 8 step: 116, loss is 0.0007500640931539237\n",
      "epoch: 8 step: 117, loss is 0.0004352624237071723\n",
      "epoch: 8 step: 118, loss is 0.0010717854602262378\n",
      "epoch: 8 step: 119, loss is 0.002056398894637823\n",
      "epoch: 8 step: 120, loss is 0.0005678266170434654\n",
      "epoch: 8 step: 121, loss is 0.0012008575722575188\n",
      "epoch: 8 step: 122, loss is 0.0009038338321261108\n",
      "epoch: 8 step: 123, loss is 0.0006593925063498318\n",
      "epoch: 8 step: 124, loss is 0.0009817713871598244\n",
      "epoch: 8 step: 125, loss is 0.00043257043580524623\n",
      "epoch: 8 step: 126, loss is 0.000153052867972292\n",
      "epoch: 8 step: 127, loss is 0.0006456074770539999\n",
      "epoch: 8 step: 128, loss is 0.0005798258353024721\n",
      "epoch: 8 step: 129, loss is 0.0006887575727887452\n",
      "epoch: 8 step: 130, loss is 0.0003664188552647829\n",
      "epoch: 8 step: 131, loss is 0.0011618705466389656\n",
      "epoch: 8 step: 132, loss is 0.0005642510368488729\n",
      "epoch: 8 step: 133, loss is 0.0008739597979001701\n",
      "epoch: 8 step: 134, loss is 0.0007802558247931302\n",
      "epoch: 8 step: 135, loss is 0.0004945372347719967\n",
      "epoch: 8 step: 136, loss is 0.001172669231891632\n",
      "epoch: 8 step: 137, loss is 0.0004016942111775279\n",
      "epoch: 8 step: 138, loss is 0.0006664812681265175\n",
      "epoch: 8 step: 139, loss is 0.000496969441883266\n",
      "epoch: 8 step: 140, loss is 0.0002990757639054209\n",
      "epoch: 8 step: 141, loss is 0.0009797130478546023\n",
      "epoch: 8 step: 142, loss is 0.001278216135688126\n",
      "epoch: 8 step: 143, loss is 0.000375006755348295\n",
      "epoch: 8 step: 144, loss is 0.0004995061317458749\n",
      "epoch: 8 step: 145, loss is 0.00039906089659780264\n",
      "epoch: 8 step: 146, loss is 0.00046656615450046957\n",
      "epoch: 8 step: 147, loss is 0.0008741460042074323\n",
      "epoch: 8 step: 148, loss is 0.00023876091290730983\n",
      "epoch: 8 step: 149, loss is 0.0009412902290932834\n",
      "epoch: 8 step: 150, loss is 0.0006595798768103123\n",
      "epoch: 8 step: 151, loss is 0.0006637023179791868\n",
      "epoch: 8 step: 152, loss is 0.0008629898075014353\n",
      "epoch: 8 step: 153, loss is 0.00039308215491473675\n",
      "epoch: 8 step: 154, loss is 0.000377814460080117\n",
      "epoch: 8 step: 155, loss is 0.0006888579810038209\n",
      "epoch: 8 step: 156, loss is 0.00037452828837558627\n",
      "epoch: 8 step: 157, loss is 0.0007728670025244355\n",
      "epoch: 8 step: 158, loss is 0.001011075684800744\n",
      "epoch: 8 step: 159, loss is 0.00045336762559600174\n",
      "epoch: 8 step: 160, loss is 0.002223275601863861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 161, loss is 0.0015889810165390372\n",
      "epoch: 8 step: 162, loss is 0.0008641469175927341\n",
      "epoch: 8 step: 163, loss is 0.0006312202312983572\n",
      "epoch: 8 step: 164, loss is 0.0004405799263622612\n",
      "epoch: 8 step: 165, loss is 0.00043800321873277426\n",
      "epoch: 8 step: 166, loss is 0.001214961288496852\n",
      "epoch: 8 step: 167, loss is 0.0004773761611431837\n",
      "epoch: 8 step: 168, loss is 0.0007283821469172835\n",
      "epoch: 8 step: 169, loss is 0.0002586965565569699\n",
      "epoch: 8 step: 170, loss is 0.0008260747999884188\n",
      "epoch: 8 step: 171, loss is 0.0004341480671428144\n",
      "epoch: 8 step: 172, loss is 0.0009447951451875269\n",
      "epoch: 8 step: 173, loss is 0.00037451530806720257\n",
      "epoch: 8 step: 174, loss is 0.0004444977093953639\n",
      "epoch: 8 step: 175, loss is 0.00036395704955793917\n",
      "epoch: 8 step: 176, loss is 0.00017178764392156154\n",
      "epoch: 8 step: 177, loss is 0.0006128362147137523\n",
      "epoch: 8 step: 178, loss is 0.0002983307058457285\n",
      "epoch: 8 step: 179, loss is 0.0006037181592546403\n",
      "epoch: 8 step: 180, loss is 0.0007622200064361095\n",
      "epoch: 8 step: 181, loss is 0.0004228452162351459\n",
      "epoch: 8 step: 182, loss is 0.000500645546708256\n",
      "epoch: 8 step: 183, loss is 0.0008396098273806274\n",
      "epoch: 8 step: 184, loss is 0.0013949715066701174\n",
      "epoch: 8 step: 185, loss is 0.0002920530969277024\n",
      "epoch: 8 step: 186, loss is 0.0006340203108265996\n",
      "epoch: 8 step: 187, loss is 0.00048076827079057693\n",
      "epoch: 8 step: 188, loss is 0.0007131880847737193\n",
      "epoch: 8 step: 189, loss is 0.000525861163623631\n",
      "epoch: 8 step: 190, loss is 0.00022446413640864193\n",
      "epoch: 8 step: 191, loss is 0.0007536077173426747\n",
      "epoch: 8 step: 192, loss is 0.0006102395709604025\n",
      "epoch: 8 step: 193, loss is 0.0012899753637611866\n",
      "epoch: 8 step: 194, loss is 0.0008250758983194828\n",
      "epoch: 8 step: 195, loss is 0.00046781994751654565\n",
      "epoch: 8 step: 196, loss is 0.0005020803073421121\n",
      "epoch: 8 step: 197, loss is 0.0007803430780768394\n",
      "epoch: 8 step: 198, loss is 0.0007176160579547286\n",
      "epoch: 8 step: 199, loss is 0.0011503748828545213\n",
      "epoch: 8 step: 200, loss is 0.0009547116351313889\n",
      "epoch: 8 step: 201, loss is 0.0004601213731803\n",
      "epoch: 8 step: 202, loss is 0.0011199318105354905\n",
      "epoch: 8 step: 203, loss is 0.00045094601227901876\n",
      "epoch: 8 step: 204, loss is 0.00047234405064955354\n",
      "epoch: 8 step: 205, loss is 0.0007476292666979134\n",
      "epoch: 8 step: 206, loss is 0.0016819941811263561\n",
      "epoch: 8 step: 207, loss is 0.00016860250616446137\n",
      "epoch: 8 step: 208, loss is 0.00041716214036569\n",
      "epoch: 8 step: 209, loss is 0.0012974092969670892\n",
      "epoch: 8 step: 210, loss is 0.0007732957019470632\n",
      "epoch: 8 step: 211, loss is 0.0011533824726939201\n",
      "epoch: 8 step: 212, loss is 0.0004410036199260503\n",
      "epoch: 8 step: 213, loss is 0.00040739416726864874\n",
      "epoch: 8 step: 214, loss is 0.0004932701704092324\n",
      "epoch: 8 step: 215, loss is 0.0018621209310367703\n",
      "epoch: 8 step: 216, loss is 0.001220682286657393\n",
      "epoch: 8 step: 217, loss is 0.0002433781628496945\n",
      "epoch: 8 step: 218, loss is 0.001311265048570931\n",
      "epoch: 8 step: 219, loss is 0.0002652648836374283\n",
      "epoch: 8 step: 220, loss is 0.000516353000421077\n",
      "epoch: 8 step: 221, loss is 0.0005986399482935667\n",
      "epoch: 8 step: 222, loss is 0.0002907635935116559\n",
      "epoch: 8 step: 223, loss is 0.0006454829126596451\n",
      "epoch: 8 step: 224, loss is 0.0004077136400155723\n",
      "epoch: 8 step: 225, loss is 0.0006795749650336802\n",
      "epoch: 8 step: 226, loss is 0.0007869991241022944\n",
      "epoch: 8 step: 227, loss is 0.0006944273482076824\n",
      "epoch: 8 step: 228, loss is 0.0010766590712592006\n",
      "epoch: 8 step: 229, loss is 0.0005639196024276316\n",
      "epoch: 8 step: 230, loss is 0.0016227734740823507\n",
      "epoch: 8 step: 231, loss is 0.0009037235868163407\n",
      "epoch: 8 step: 232, loss is 0.00042535405373200774\n",
      "epoch: 8 step: 233, loss is 0.0007961257942952216\n",
      "epoch: 8 step: 234, loss is 0.0007246459135785699\n",
      "epoch: 8 step: 235, loss is 0.0006184196099638939\n",
      "epoch: 8 step: 236, loss is 0.00038335580029524863\n",
      "epoch: 8 step: 237, loss is 0.00033914647065103054\n",
      "epoch: 8 step: 238, loss is 0.0008971394854597747\n",
      "epoch: 8 step: 239, loss is 0.0003860692377202213\n",
      "epoch: 8 step: 240, loss is 0.0014773498987779021\n",
      "epoch: 8 step: 241, loss is 0.0005371934967115521\n",
      "epoch: 8 step: 242, loss is 0.0013494850136339664\n",
      "epoch: 8 step: 243, loss is 0.0011066817678511143\n",
      "epoch: 8 step: 244, loss is 0.0020598622504621744\n",
      "epoch: 8 step: 245, loss is 0.002161777578294277\n",
      "epoch: 8 step: 246, loss is 0.0007557241478934884\n",
      "epoch: 8 step: 247, loss is 0.0006326813600026071\n",
      "epoch: 8 step: 248, loss is 0.0010686771711334586\n",
      "epoch: 8 step: 249, loss is 0.0012519500451162457\n",
      "epoch: 8 step: 250, loss is 0.00064316630596295\n",
      "epoch: 8 step: 251, loss is 0.0004941390361636877\n",
      "epoch: 8 step: 252, loss is 0.0005221502506174147\n",
      "epoch: 8 step: 253, loss is 0.00042012534686364233\n",
      "epoch: 8 step: 254, loss is 0.0007421714253723621\n",
      "epoch: 8 step: 255, loss is 0.0008925580186769366\n",
      "epoch: 8 step: 256, loss is 0.0005188145441934466\n",
      "epoch: 8 step: 257, loss is 0.00044698244892060757\n",
      "epoch: 8 step: 258, loss is 0.0010149982990697026\n",
      "epoch: 8 step: 259, loss is 0.0009686811245046556\n",
      "epoch: 8 step: 260, loss is 0.00040531763806939125\n",
      "epoch: 8 step: 261, loss is 0.0005148841300979257\n",
      "epoch: 8 step: 262, loss is 0.0009558966848999262\n",
      "epoch: 8 step: 263, loss is 0.0006145369843579829\n",
      "epoch: 8 step: 264, loss is 0.00013805484923068434\n",
      "epoch: 8 step: 265, loss is 0.0005072795320302248\n",
      "epoch: 8 step: 266, loss is 0.0005506246234290302\n",
      "epoch: 8 step: 267, loss is 0.00040325438021682203\n",
      "epoch: 8 step: 268, loss is 0.0006221557850949466\n",
      "epoch: 8 step: 269, loss is 0.0005926835583522916\n",
      "epoch: 8 step: 270, loss is 0.0005044768913649023\n",
      "epoch: 8 step: 271, loss is 0.0010104852262884378\n",
      "epoch: 8 step: 272, loss is 0.00024851487250998616\n",
      "epoch: 8 step: 273, loss is 0.0003927993238903582\n",
      "epoch: 8 step: 274, loss is 0.0008379787905141711\n",
      "epoch: 8 step: 275, loss is 0.0008829207508824766\n",
      "epoch: 8 step: 276, loss is 0.0006490527302958071\n",
      "epoch: 8 step: 277, loss is 0.0017370886635035276\n",
      "epoch: 8 step: 278, loss is 0.0003092121332883835\n",
      "epoch: 8 step: 279, loss is 0.001482179039157927\n",
      "epoch: 8 step: 280, loss is 0.00044273381354287267\n",
      "epoch: 8 step: 281, loss is 0.001160724670626223\n",
      "epoch: 8 step: 282, loss is 0.0006523808697238564\n",
      "epoch: 8 step: 283, loss is 0.0004165202262811363\n",
      "epoch: 8 step: 284, loss is 0.0008750814595259726\n",
      "epoch: 8 step: 285, loss is 0.0012880208669230342\n",
      "epoch: 8 step: 286, loss is 0.0007625464932061732\n",
      "epoch: 8 step: 287, loss is 0.000622983614448458\n",
      "epoch: 8 step: 288, loss is 0.0002979852433782071\n",
      "epoch: 8 step: 289, loss is 0.0006151378038339317\n",
      "epoch: 8 step: 290, loss is 0.00055115477880463\n",
      "epoch: 8 step: 291, loss is 0.0010456671006977558\n",
      "epoch: 8 step: 292, loss is 0.0012848330661654472\n",
      "epoch: 8 step: 293, loss is 0.0005502165295183659\n",
      "epoch: 8 step: 294, loss is 0.0004773247637785971\n",
      "epoch: 8 step: 295, loss is 0.0009133428684435785\n",
      "epoch: 8 step: 296, loss is 0.0010110916336998343\n",
      "epoch: 8 step: 297, loss is 0.000838276173453778\n",
      "epoch: 8 step: 298, loss is 0.0009941163007169962\n",
      "epoch: 8 step: 299, loss is 0.000540451961569488\n",
      "epoch: 8 step: 300, loss is 0.0007955230539664626\n",
      "epoch: 8 step: 301, loss is 0.0012032659724354744\n",
      "epoch: 8 step: 302, loss is 0.0011745973024517298\n",
      "epoch: 8 step: 303, loss is 0.0006516568246297538\n",
      "epoch: 8 step: 304, loss is 0.0002446926664561033\n",
      "epoch: 8 step: 305, loss is 0.0003577389579731971\n",
      "epoch: 8 step: 306, loss is 0.0005980851128697395\n",
      "epoch: 8 step: 307, loss is 0.0003834026283584535\n",
      "epoch: 8 step: 308, loss is 0.0007541702361777425\n",
      "epoch: 8 step: 309, loss is 0.0012658152263611555\n",
      "epoch: 8 step: 310, loss is 0.0004628430469892919\n",
      "epoch: 8 step: 311, loss is 0.0015174089930951595\n",
      "epoch: 8 step: 312, loss is 0.0004840432375203818\n",
      "epoch: 8 step: 313, loss is 0.0001894373563118279\n",
      "epoch: 8 step: 314, loss is 0.0013449101243168116\n",
      "epoch: 8 step: 315, loss is 0.000927226385101676\n",
      "epoch: 8 step: 316, loss is 0.0009016887051984668\n",
      "epoch: 8 step: 317, loss is 0.001142054796218872\n",
      "epoch: 8 step: 318, loss is 0.00054395996266976\n",
      "epoch: 8 step: 319, loss is 0.0006082872278057039\n",
      "epoch: 8 step: 320, loss is 0.0008139245910570025\n",
      "epoch: 8 step: 321, loss is 0.00039083018782548606\n",
      "epoch: 8 step: 322, loss is 0.000867342168930918\n",
      "epoch: 8 step: 323, loss is 0.00172304583247751\n",
      "epoch: 8 step: 324, loss is 0.001631291350349784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 325, loss is 0.0004877307510469109\n",
      "epoch: 8 step: 326, loss is 0.0006685994449071586\n",
      "epoch: 8 step: 327, loss is 0.0004767441132571548\n",
      "epoch: 8 step: 328, loss is 0.0009982828050851822\n",
      "epoch: 8 step: 329, loss is 0.0012194649316370487\n",
      "epoch: 8 step: 330, loss is 0.0003374169173184782\n",
      "epoch: 8 step: 331, loss is 0.00099682598374784\n",
      "epoch: 8 step: 332, loss is 0.0014713931595906615\n",
      "epoch: 8 step: 333, loss is 0.00037477706791833043\n",
      "epoch: 8 step: 334, loss is 0.0003279376542195678\n",
      "epoch: 8 step: 335, loss is 0.0006245095864869654\n",
      "epoch: 8 step: 336, loss is 0.0005258150631561875\n",
      "epoch: 8 step: 337, loss is 0.0009749548626132309\n",
      "epoch: 8 step: 338, loss is 0.0012140189064666629\n",
      "epoch: 8 step: 339, loss is 0.0006524326745420694\n",
      "epoch: 8 step: 340, loss is 0.0014930263860151172\n",
      "epoch: 8 step: 341, loss is 0.0008424604311585426\n",
      "epoch: 8 step: 342, loss is 0.00042081333231180906\n",
      "epoch: 8 step: 343, loss is 0.0011763018555939198\n",
      "epoch: 8 step: 344, loss is 0.0008902513654902577\n",
      "epoch: 8 step: 345, loss is 0.0014691855758428574\n",
      "epoch: 8 step: 346, loss is 0.0009265865664929152\n",
      "epoch: 8 step: 347, loss is 0.00096436298917979\n",
      "epoch: 8 step: 348, loss is 0.00043601420475170016\n",
      "epoch: 8 step: 349, loss is 0.0008296432206407189\n",
      "epoch: 8 step: 350, loss is 0.0006929953233338892\n",
      "epoch: 8 step: 351, loss is 0.0001324306067544967\n",
      "epoch: 8 step: 352, loss is 0.00043039157753810287\n",
      "epoch: 8 step: 353, loss is 0.002017349936068058\n",
      "epoch: 8 step: 354, loss is 0.0008015460916794837\n",
      "epoch: 8 step: 355, loss is 0.0006224013050086796\n",
      "epoch: 8 step: 356, loss is 0.0008860760717652738\n",
      "epoch: 8 step: 357, loss is 0.0010278784902766347\n",
      "epoch: 8 step: 358, loss is 0.0008133613155223429\n",
      "epoch: 8 step: 359, loss is 0.00046656347694806755\n",
      "epoch: 8 step: 360, loss is 0.0007594905910082161\n",
      "epoch: 8 step: 361, loss is 0.0008846287382766604\n",
      "epoch: 8 step: 362, loss is 0.0002490232000127435\n",
      "epoch: 8 step: 363, loss is 0.00044177324161864817\n",
      "epoch: 8 step: 364, loss is 0.0008298061438836157\n",
      "epoch: 8 step: 365, loss is 0.00039165158523246646\n",
      "epoch: 8 step: 366, loss is 0.0004904306842945516\n",
      "epoch: 8 step: 367, loss is 0.0002634454285725951\n",
      "epoch: 8 step: 368, loss is 0.0008071332122199237\n",
      "epoch: 8 step: 369, loss is 0.00042988956556655467\n",
      "epoch: 8 step: 370, loss is 0.0007977892528288066\n",
      "epoch: 8 step: 371, loss is 0.0014880886301398277\n",
      "epoch: 8 step: 372, loss is 0.0011380492942407727\n",
      "epoch: 8 step: 373, loss is 0.00046574280713684857\n",
      "epoch: 8 step: 374, loss is 0.0006563145434483886\n",
      "epoch: 8 step: 375, loss is 0.0005809038993902504\n",
      "Train epoch time: 12014.810 ms, per step time: 32.039 ms\n",
      "epoch: 9 step: 1, loss is 0.0007267107721418142\n",
      "epoch: 9 step: 2, loss is 0.0006350571056827903\n",
      "epoch: 9 step: 3, loss is 0.00046320646652020514\n",
      "epoch: 9 step: 4, loss is 0.00046581472270190716\n",
      "epoch: 9 step: 5, loss is 0.0005455904174596071\n",
      "epoch: 9 step: 6, loss is 0.0014017700450494885\n",
      "epoch: 9 step: 7, loss is 0.0009354626527056098\n",
      "epoch: 9 step: 8, loss is 0.0011033107293769717\n",
      "epoch: 9 step: 9, loss is 0.00021519785514101386\n",
      "epoch: 9 step: 10, loss is 0.0012716075871139765\n",
      "epoch: 9 step: 11, loss is 0.0013322726590558887\n",
      "epoch: 9 step: 12, loss is 0.001163908513262868\n",
      "epoch: 9 step: 13, loss is 0.00047184378490783274\n",
      "epoch: 9 step: 14, loss is 0.00010773400572361425\n",
      "epoch: 9 step: 15, loss is 0.0009271403541788459\n",
      "epoch: 9 step: 16, loss is 0.00025599164655432105\n",
      "epoch: 9 step: 17, loss is 0.0009273317991755903\n",
      "epoch: 9 step: 18, loss is 0.0007411059341393411\n",
      "epoch: 9 step: 19, loss is 0.0012637648032978177\n",
      "epoch: 9 step: 20, loss is 0.0010331273078918457\n",
      "epoch: 9 step: 21, loss is 0.0013652105117216706\n",
      "epoch: 9 step: 22, loss is 0.0005679947789758444\n",
      "epoch: 9 step: 23, loss is 0.0011127640027552843\n",
      "epoch: 9 step: 24, loss is 0.0007269029156304896\n",
      "epoch: 9 step: 25, loss is 0.0008045677095651627\n",
      "epoch: 9 step: 26, loss is 0.0006584367365576327\n",
      "epoch: 9 step: 27, loss is 0.0008915162761695683\n",
      "epoch: 9 step: 28, loss is 0.0004981103120371699\n",
      "epoch: 9 step: 29, loss is 0.0006881383014842868\n",
      "epoch: 9 step: 30, loss is 0.0021592574194073677\n",
      "epoch: 9 step: 31, loss is 0.00033686490496620536\n",
      "epoch: 9 step: 32, loss is 0.0008365349494852126\n",
      "epoch: 9 step: 33, loss is 0.0008724870276637375\n",
      "epoch: 9 step: 34, loss is 0.0008862800896167755\n",
      "epoch: 9 step: 35, loss is 0.0002575505350250751\n",
      "epoch: 9 step: 36, loss is 0.0005033878842368722\n",
      "epoch: 9 step: 37, loss is 0.0006418661214411259\n",
      "epoch: 9 step: 38, loss is 0.0007339700823649764\n",
      "epoch: 9 step: 39, loss is 0.002102428348734975\n",
      "epoch: 9 step: 40, loss is 0.0008667802903801203\n",
      "epoch: 9 step: 41, loss is 0.0006090823444537818\n",
      "epoch: 9 step: 42, loss is 0.000980311306193471\n",
      "epoch: 9 step: 43, loss is 0.0012737795477733016\n",
      "epoch: 9 step: 44, loss is 0.00048171915113925934\n",
      "epoch: 9 step: 45, loss is 0.0005006387364119291\n",
      "epoch: 9 step: 46, loss is 0.0008917361265048385\n",
      "epoch: 9 step: 47, loss is 0.0010461306665092707\n",
      "epoch: 9 step: 48, loss is 0.00016154661716427654\n",
      "epoch: 9 step: 49, loss is 0.0005413057515397668\n",
      "epoch: 9 step: 50, loss is 0.000542737077921629\n",
      "epoch: 9 step: 51, loss is 0.00029644000460393727\n",
      "epoch: 9 step: 52, loss is 0.0022709323093295097\n",
      "epoch: 9 step: 53, loss is 0.0011270084651187062\n",
      "epoch: 9 step: 54, loss is 0.000686121464241296\n",
      "epoch: 9 step: 55, loss is 0.00039741405635140836\n",
      "epoch: 9 step: 56, loss is 0.0013927083928138018\n",
      "epoch: 9 step: 57, loss is 0.0003231835435144603\n",
      "epoch: 9 step: 58, loss is 0.001393066137097776\n",
      "epoch: 9 step: 59, loss is 0.0003575953305698931\n",
      "epoch: 9 step: 60, loss is 0.0005298269097693264\n",
      "epoch: 9 step: 61, loss is 0.00036640354664996266\n",
      "epoch: 9 step: 62, loss is 0.00021379005920607597\n",
      "epoch: 9 step: 63, loss is 0.0011286450317129493\n",
      "epoch: 9 step: 64, loss is 0.000421253964304924\n",
      "epoch: 9 step: 65, loss is 0.0005987730110064149\n",
      "epoch: 9 step: 66, loss is 0.0006187481922097504\n",
      "epoch: 9 step: 67, loss is 0.0004489476850721985\n",
      "epoch: 9 step: 68, loss is 0.00010476038005435839\n",
      "epoch: 9 step: 69, loss is 0.0004811063699889928\n",
      "epoch: 9 step: 70, loss is 0.0007492171134799719\n",
      "epoch: 9 step: 71, loss is 0.0004433525027707219\n",
      "epoch: 9 step: 72, loss is 0.0005635226843878627\n",
      "epoch: 9 step: 73, loss is 0.0004206323646940291\n",
      "epoch: 9 step: 74, loss is 0.0010227093007415533\n",
      "epoch: 9 step: 75, loss is 0.0005771099240519106\n",
      "epoch: 9 step: 76, loss is 0.0005624592886306345\n",
      "epoch: 9 step: 77, loss is 0.0015344612766057253\n",
      "epoch: 9 step: 78, loss is 0.0005840673111379147\n",
      "epoch: 9 step: 79, loss is 0.0007753477548249066\n",
      "epoch: 9 step: 80, loss is 0.0006024615140631795\n",
      "epoch: 9 step: 81, loss is 0.00013429176760837436\n",
      "epoch: 9 step: 82, loss is 0.0005034334026277065\n",
      "epoch: 9 step: 83, loss is 0.0007861859048716724\n",
      "epoch: 9 step: 84, loss is 0.00046393240336328745\n",
      "epoch: 9 step: 85, loss is 0.0007884720689617097\n",
      "epoch: 9 step: 86, loss is 0.0007703081355430186\n",
      "epoch: 9 step: 87, loss is 0.0004957524361088872\n",
      "epoch: 9 step: 88, loss is 0.000904798333067447\n",
      "epoch: 9 step: 89, loss is 0.0006699188961647451\n",
      "epoch: 9 step: 90, loss is 0.001358344336040318\n",
      "epoch: 9 step: 91, loss is 0.0009338229428976774\n",
      "epoch: 9 step: 92, loss is 0.0007400753092952073\n",
      "epoch: 9 step: 93, loss is 0.0006123818457126617\n",
      "epoch: 9 step: 94, loss is 0.0006922807078808546\n",
      "epoch: 9 step: 95, loss is 0.001044125179760158\n",
      "epoch: 9 step: 96, loss is 0.000835325859952718\n",
      "epoch: 9 step: 97, loss is 0.0005518637481145561\n",
      "epoch: 9 step: 98, loss is 0.0006827160832472146\n",
      "epoch: 9 step: 99, loss is 0.00033328105928376317\n",
      "epoch: 9 step: 100, loss is 0.0011932190973311663\n",
      "epoch: 9 step: 101, loss is 0.00029376946622505784\n",
      "epoch: 9 step: 102, loss is 0.0007195908110588789\n",
      "epoch: 9 step: 103, loss is 0.0012466047191992402\n",
      "epoch: 9 step: 104, loss is 0.00017395989561919123\n",
      "epoch: 9 step: 105, loss is 0.000555673090275377\n",
      "epoch: 9 step: 106, loss is 0.0006935656419955194\n",
      "epoch: 9 step: 107, loss is 0.0007204904686659575\n",
      "epoch: 9 step: 108, loss is 0.0006840831483714283\n",
      "epoch: 9 step: 109, loss is 0.00022397520660888404\n",
      "epoch: 9 step: 110, loss is 0.0013432829873636365\n",
      "epoch: 9 step: 111, loss is 0.001363625400699675\n",
      "epoch: 9 step: 112, loss is 0.0021273894235491753\n",
      "epoch: 9 step: 113, loss is 0.001288483152166009\n",
      "epoch: 9 step: 114, loss is 0.0007610470056533813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 115, loss is 0.0003945273638237268\n",
      "epoch: 9 step: 116, loss is 0.0005791953881271183\n",
      "epoch: 9 step: 117, loss is 0.0007525779074057937\n",
      "epoch: 9 step: 118, loss is 0.0007269324269145727\n",
      "epoch: 9 step: 119, loss is 0.0008238187874667346\n",
      "epoch: 9 step: 120, loss is 0.0010272156214341521\n",
      "epoch: 9 step: 121, loss is 0.000706608931068331\n",
      "epoch: 9 step: 122, loss is 0.0007073991000652313\n",
      "epoch: 9 step: 123, loss is 0.0012224131496623158\n",
      "epoch: 9 step: 124, loss is 0.0010676849633455276\n",
      "epoch: 9 step: 125, loss is 0.0012243875535205007\n",
      "epoch: 9 step: 126, loss is 0.0004500287468545139\n",
      "epoch: 9 step: 127, loss is 0.0002338216290809214\n",
      "epoch: 9 step: 128, loss is 0.0003160676278639585\n",
      "epoch: 9 step: 129, loss is 0.0003535509167704731\n",
      "epoch: 9 step: 130, loss is 0.0008223229087889194\n",
      "epoch: 9 step: 131, loss is 0.0005261203041300178\n",
      "epoch: 9 step: 132, loss is 0.0008817739435471594\n",
      "epoch: 9 step: 133, loss is 0.00043424739851616323\n",
      "epoch: 9 step: 134, loss is 0.0005410800222307444\n",
      "epoch: 9 step: 135, loss is 0.0009912332752719522\n",
      "epoch: 9 step: 136, loss is 9.608107211533934e-05\n",
      "epoch: 9 step: 137, loss is 0.00133856653701514\n",
      "epoch: 9 step: 138, loss is 0.000848046678584069\n",
      "epoch: 9 step: 139, loss is 0.0003539266181178391\n",
      "epoch: 9 step: 140, loss is 0.000857605307828635\n",
      "epoch: 9 step: 141, loss is 0.0018326399149373174\n",
      "epoch: 9 step: 142, loss is 0.0008431057212874293\n",
      "epoch: 9 step: 143, loss is 0.00036062896833755076\n",
      "epoch: 9 step: 144, loss is 0.0016117325285449624\n",
      "epoch: 9 step: 145, loss is 0.0005175776313990355\n",
      "epoch: 9 step: 146, loss is 0.0004924139939248562\n",
      "epoch: 9 step: 147, loss is 0.0006960947066545486\n",
      "epoch: 9 step: 148, loss is 0.0007959477952681482\n",
      "epoch: 9 step: 149, loss is 0.0008640930755063891\n",
      "epoch: 9 step: 150, loss is 0.001193110249005258\n",
      "epoch: 9 step: 151, loss is 0.000377886084606871\n",
      "epoch: 9 step: 152, loss is 0.0006157357129268348\n",
      "epoch: 9 step: 153, loss is 0.000585343164857477\n",
      "epoch: 9 step: 154, loss is 0.0007086751284077764\n",
      "epoch: 9 step: 155, loss is 0.0007093898602761328\n",
      "epoch: 9 step: 156, loss is 0.0007485569221898913\n",
      "epoch: 9 step: 157, loss is 0.0005972536746412516\n",
      "epoch: 9 step: 158, loss is 0.0005349380662664771\n",
      "epoch: 9 step: 159, loss is 0.00032399981864728034\n",
      "epoch: 9 step: 160, loss is 0.00045556301483884454\n",
      "epoch: 9 step: 161, loss is 0.0004983283579349518\n",
      "epoch: 9 step: 162, loss is 0.0006950814859010279\n",
      "epoch: 9 step: 163, loss is 0.0005692447884939611\n",
      "epoch: 9 step: 164, loss is 0.0012977892765775323\n",
      "epoch: 9 step: 165, loss is 0.0012523188488557935\n",
      "epoch: 9 step: 166, loss is 0.0005927180172875524\n",
      "epoch: 9 step: 167, loss is 0.0005119845154695213\n",
      "epoch: 9 step: 168, loss is 0.0005920941475778818\n",
      "epoch: 9 step: 169, loss is 0.0005184377077966928\n",
      "epoch: 9 step: 170, loss is 0.0007101231021806598\n",
      "epoch: 9 step: 171, loss is 0.0005812730523757637\n",
      "epoch: 9 step: 172, loss is 0.0018802718259394169\n",
      "epoch: 9 step: 173, loss is 0.0003293213958386332\n",
      "epoch: 9 step: 174, loss is 0.0004698527918662876\n",
      "epoch: 9 step: 175, loss is 0.000636369688436389\n",
      "epoch: 9 step: 176, loss is 0.0006300785462372005\n",
      "epoch: 9 step: 177, loss is 0.0009638767223805189\n",
      "epoch: 9 step: 178, loss is 0.0008014045306481421\n",
      "epoch: 9 step: 179, loss is 0.000736042158678174\n",
      "epoch: 9 step: 180, loss is 0.0007811295217834413\n",
      "epoch: 9 step: 181, loss is 0.0010951596777886152\n",
      "epoch: 9 step: 182, loss is 0.0004576703649945557\n",
      "epoch: 9 step: 183, loss is 0.0005401921807788312\n",
      "epoch: 9 step: 184, loss is 0.0010380761232227087\n",
      "epoch: 9 step: 185, loss is 0.0005441603716462851\n",
      "epoch: 9 step: 186, loss is 0.00013331994705367833\n",
      "epoch: 9 step: 187, loss is 0.0008792738080956042\n",
      "epoch: 9 step: 188, loss is 0.00026009223074652255\n",
      "epoch: 9 step: 189, loss is 0.00036189312231726944\n",
      "epoch: 9 step: 190, loss is 0.0005904603167437017\n",
      "epoch: 9 step: 191, loss is 0.00020256701100151986\n",
      "epoch: 9 step: 192, loss is 0.001187998102977872\n",
      "epoch: 9 step: 193, loss is 0.000520395755302161\n",
      "epoch: 9 step: 194, loss is 0.0005390251171775162\n",
      "epoch: 9 step: 195, loss is 0.00042009781464003026\n",
      "epoch: 9 step: 196, loss is 0.0007502647349610925\n",
      "epoch: 9 step: 197, loss is 0.0007661788840778172\n",
      "epoch: 9 step: 198, loss is 0.00032459484646096826\n",
      "epoch: 9 step: 199, loss is 0.0004628809110727161\n",
      "epoch: 9 step: 200, loss is 0.000610680493991822\n",
      "epoch: 9 step: 201, loss is 0.0006057697464711964\n",
      "epoch: 9 step: 202, loss is 0.0005325331003405154\n",
      "epoch: 9 step: 203, loss is 0.0008170230430550873\n",
      "epoch: 9 step: 204, loss is 0.001158183324150741\n",
      "epoch: 9 step: 205, loss is 0.0007023568614386022\n",
      "epoch: 9 step: 206, loss is 0.0005678120069205761\n",
      "epoch: 9 step: 207, loss is 0.0006535022985190153\n",
      "epoch: 9 step: 208, loss is 0.0003301546967122704\n",
      "epoch: 9 step: 209, loss is 0.0016075164312496781\n",
      "epoch: 9 step: 210, loss is 0.000638663477730006\n",
      "epoch: 9 step: 211, loss is 0.0008527464233338833\n",
      "epoch: 9 step: 212, loss is 0.0005369000136852264\n",
      "epoch: 9 step: 213, loss is 0.00027832441264763474\n",
      "epoch: 9 step: 214, loss is 0.0012949361698701978\n",
      "epoch: 9 step: 215, loss is 0.0005235276184976101\n",
      "epoch: 9 step: 216, loss is 0.00040610687574371696\n",
      "epoch: 9 step: 217, loss is 0.0008917496888898313\n",
      "epoch: 9 step: 218, loss is 0.00044898694613948464\n",
      "epoch: 9 step: 219, loss is 0.0004913558950647712\n",
      "epoch: 9 step: 220, loss is 0.0006454454851336777\n",
      "epoch: 9 step: 221, loss is 0.0005409153527580202\n",
      "epoch: 9 step: 222, loss is 0.0007098611677065492\n",
      "epoch: 9 step: 223, loss is 0.0008594070095568895\n",
      "epoch: 9 step: 224, loss is 0.0004906475078314543\n",
      "epoch: 9 step: 225, loss is 0.0011725738877430558\n",
      "epoch: 9 step: 226, loss is 0.00041271679219789803\n",
      "epoch: 9 step: 227, loss is 0.0011251962278038263\n",
      "epoch: 9 step: 228, loss is 0.0005815036129206419\n",
      "epoch: 9 step: 229, loss is 0.0004462139622773975\n",
      "epoch: 9 step: 230, loss is 0.0012480324367061257\n",
      "epoch: 9 step: 231, loss is 0.0005078559624962509\n",
      "epoch: 9 step: 232, loss is 0.0006670503062196076\n",
      "epoch: 9 step: 233, loss is 0.0014721461338922381\n",
      "epoch: 9 step: 234, loss is 0.001452671829611063\n",
      "epoch: 9 step: 235, loss is 0.0006597163155674934\n",
      "epoch: 9 step: 236, loss is 0.001698852051049471\n",
      "epoch: 9 step: 237, loss is 0.00022742126020602882\n",
      "epoch: 9 step: 238, loss is 0.00038252733065746725\n",
      "epoch: 9 step: 239, loss is 0.0002575271937530488\n",
      "epoch: 9 step: 240, loss is 0.0007667295867577195\n",
      "epoch: 9 step: 241, loss is 0.00023618263367097825\n",
      "epoch: 9 step: 242, loss is 0.0004240063426550478\n",
      "epoch: 9 step: 243, loss is 0.00016055309970397502\n",
      "epoch: 9 step: 244, loss is 0.0005437152576632798\n",
      "epoch: 9 step: 245, loss is 0.0004399311146698892\n",
      "epoch: 9 step: 246, loss is 0.00040369044290855527\n",
      "epoch: 9 step: 247, loss is 0.0007254558149725199\n",
      "epoch: 9 step: 248, loss is 0.00043073034612461925\n",
      "epoch: 9 step: 249, loss is 0.0008805182878859341\n",
      "epoch: 9 step: 250, loss is 0.0010267250472679734\n",
      "epoch: 9 step: 251, loss is 0.00023366058303508908\n",
      "epoch: 9 step: 252, loss is 0.00020581505668815225\n",
      "epoch: 9 step: 253, loss is 0.0003065433993469924\n",
      "epoch: 9 step: 254, loss is 0.0009833155199885368\n",
      "epoch: 9 step: 255, loss is 0.0003739810490515083\n",
      "epoch: 9 step: 256, loss is 0.0006119502941146493\n",
      "epoch: 9 step: 257, loss is 0.0005214737029746175\n",
      "epoch: 9 step: 258, loss is 0.0011402916861698031\n",
      "epoch: 9 step: 259, loss is 0.0005527114262804389\n",
      "epoch: 9 step: 260, loss is 0.0006167683168314397\n",
      "epoch: 9 step: 261, loss is 0.0014381024520844221\n",
      "epoch: 9 step: 262, loss is 0.0004013665020465851\n",
      "epoch: 9 step: 263, loss is 0.0015216948231682181\n",
      "epoch: 9 step: 264, loss is 0.0003798970428761095\n",
      "epoch: 9 step: 265, loss is 0.0005383851821534336\n",
      "epoch: 9 step: 266, loss is 0.0002233882260043174\n",
      "epoch: 9 step: 267, loss is 0.001081886701285839\n",
      "epoch: 9 step: 268, loss is 0.0003958582819905132\n",
      "epoch: 9 step: 269, loss is 0.0008904255228117108\n",
      "epoch: 9 step: 270, loss is 0.0006695289630442858\n",
      "epoch: 9 step: 271, loss is 0.0008292539278045297\n",
      "epoch: 9 step: 272, loss is 0.00047912276932038367\n",
      "epoch: 9 step: 273, loss is 0.0006530550308525562\n",
      "epoch: 9 step: 274, loss is 0.002152254106476903\n",
      "epoch: 9 step: 275, loss is 0.0014999877894297242\n",
      "epoch: 9 step: 276, loss is 0.0012500948505476117\n",
      "epoch: 9 step: 277, loss is 0.0016507689142599702\n",
      "epoch: 9 step: 278, loss is 0.0007291059591807425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 279, loss is 0.0010189691092818975\n",
      "epoch: 9 step: 280, loss is 0.0014125750167295337\n",
      "epoch: 9 step: 281, loss is 0.0008740160265006125\n",
      "epoch: 9 step: 282, loss is 0.0004056663019582629\n",
      "epoch: 9 step: 283, loss is 0.0006393414223566651\n",
      "epoch: 9 step: 284, loss is 0.0006201255600899458\n",
      "epoch: 9 step: 285, loss is 0.0002963684091810137\n",
      "epoch: 9 step: 286, loss is 0.00036497320979833603\n",
      "epoch: 9 step: 287, loss is 0.0012386247981339693\n",
      "epoch: 9 step: 288, loss is 0.0004794738779310137\n",
      "epoch: 9 step: 289, loss is 0.0005485816509462893\n",
      "epoch: 9 step: 290, loss is 0.0012256387853994966\n",
      "epoch: 9 step: 291, loss is 0.0005711065605282784\n",
      "epoch: 9 step: 292, loss is 0.0008120605489239097\n",
      "epoch: 9 step: 293, loss is 0.000139922063681297\n",
      "epoch: 9 step: 294, loss is 0.0012082590255886316\n",
      "epoch: 9 step: 295, loss is 0.0011629322543740273\n",
      "epoch: 9 step: 296, loss is 0.0005513705546036363\n",
      "epoch: 9 step: 297, loss is 0.0005596618866547942\n",
      "epoch: 9 step: 298, loss is 0.0003898669092450291\n",
      "epoch: 9 step: 299, loss is 0.0008980434504337609\n",
      "epoch: 9 step: 300, loss is 0.0004169123712927103\n",
      "epoch: 9 step: 301, loss is 0.0005722700152546167\n",
      "epoch: 9 step: 302, loss is 0.0005391204613260925\n",
      "epoch: 9 step: 303, loss is 0.0010833045234903693\n",
      "epoch: 9 step: 304, loss is 0.001427228911779821\n",
      "epoch: 9 step: 305, loss is 0.00043472900870256126\n",
      "epoch: 9 step: 306, loss is 0.001775661134161055\n",
      "epoch: 9 step: 307, loss is 0.0008753120782785118\n",
      "epoch: 9 step: 308, loss is 0.0008190399967133999\n",
      "epoch: 9 step: 309, loss is 0.0018401804845780134\n",
      "epoch: 9 step: 310, loss is 0.0005528461188077927\n",
      "epoch: 9 step: 311, loss is 0.0004719279531855136\n",
      "epoch: 9 step: 312, loss is 0.0010196996154263616\n",
      "epoch: 9 step: 313, loss is 0.0006679878570139408\n",
      "epoch: 9 step: 314, loss is 0.0008618443971499801\n",
      "epoch: 9 step: 315, loss is 0.000614686869084835\n",
      "epoch: 9 step: 316, loss is 0.00045106938341632485\n",
      "epoch: 9 step: 317, loss is 0.0003827658365480602\n",
      "epoch: 9 step: 318, loss is 0.0010607156436890364\n",
      "epoch: 9 step: 319, loss is 0.000977257383055985\n",
      "epoch: 9 step: 320, loss is 0.00019850554235745221\n",
      "epoch: 9 step: 321, loss is 0.0010485383681952953\n",
      "epoch: 9 step: 322, loss is 0.0009633144945837557\n",
      "epoch: 9 step: 323, loss is 0.00044908473500981927\n",
      "epoch: 9 step: 324, loss is 0.001065115793608129\n",
      "epoch: 9 step: 325, loss is 0.0011984558077529073\n",
      "epoch: 9 step: 326, loss is 0.0013826418435201049\n",
      "epoch: 9 step: 327, loss is 0.0007889015250839293\n",
      "epoch: 9 step: 328, loss is 0.0006806807359680533\n",
      "epoch: 9 step: 329, loss is 0.0007646371959708631\n",
      "epoch: 9 step: 330, loss is 0.0012175996089354157\n",
      "epoch: 9 step: 331, loss is 0.0004577109357342124\n",
      "epoch: 9 step: 332, loss is 0.0009189731208607554\n",
      "epoch: 9 step: 333, loss is 0.0012750817695632577\n",
      "epoch: 9 step: 334, loss is 0.001054347027093172\n",
      "epoch: 9 step: 335, loss is 0.0006454753456637263\n",
      "epoch: 9 step: 336, loss is 0.00040055258432403207\n",
      "epoch: 9 step: 337, loss is 0.0016777630662545562\n",
      "epoch: 9 step: 338, loss is 0.00043994010775350034\n",
      "epoch: 9 step: 339, loss is 0.000769793230574578\n",
      "epoch: 9 step: 340, loss is 0.0006551541155204177\n",
      "epoch: 9 step: 341, loss is 0.0006017857231199741\n",
      "epoch: 9 step: 342, loss is 0.0003897551796399057\n",
      "epoch: 9 step: 343, loss is 0.0003910541709046811\n",
      "epoch: 9 step: 344, loss is 0.0006572840502485633\n",
      "epoch: 9 step: 345, loss is 0.0008748742402531207\n",
      "epoch: 9 step: 346, loss is 0.0013082540826871991\n",
      "epoch: 9 step: 347, loss is 0.0010457048192620277\n",
      "epoch: 9 step: 348, loss is 0.0004223198920954019\n",
      "epoch: 9 step: 349, loss is 0.0013456674059852958\n",
      "epoch: 9 step: 350, loss is 0.0010924753732979298\n",
      "epoch: 9 step: 351, loss is 0.0007238338002935052\n",
      "epoch: 9 step: 352, loss is 0.0005280397599563003\n",
      "epoch: 9 step: 353, loss is 0.0007942735101096332\n",
      "epoch: 9 step: 354, loss is 0.001078444067388773\n",
      "epoch: 9 step: 355, loss is 0.000747215875890106\n",
      "epoch: 9 step: 356, loss is 0.0005553732044063509\n",
      "epoch: 9 step: 357, loss is 0.000824478454887867\n",
      "epoch: 9 step: 358, loss is 0.0003972795093432069\n",
      "epoch: 9 step: 359, loss is 0.0008930440526455641\n",
      "epoch: 9 step: 360, loss is 0.0007316016126424074\n",
      "epoch: 9 step: 361, loss is 0.0005870205932296813\n",
      "epoch: 9 step: 362, loss is 0.00039679204928688705\n",
      "epoch: 9 step: 363, loss is 0.0019140606746077538\n",
      "epoch: 9 step: 364, loss is 0.00041652057552710176\n",
      "epoch: 9 step: 365, loss is 0.0005299330223351717\n",
      "epoch: 9 step: 366, loss is 0.000748779799323529\n",
      "epoch: 9 step: 367, loss is 0.0006761300610378385\n",
      "epoch: 9 step: 368, loss is 0.0009061249438673258\n",
      "epoch: 9 step: 369, loss is 0.0005954924854449928\n",
      "epoch: 9 step: 370, loss is 0.0005986965261399746\n",
      "epoch: 9 step: 371, loss is 0.0009748002048581839\n",
      "epoch: 9 step: 372, loss is 0.000849480158649385\n",
      "epoch: 9 step: 373, loss is 0.000565654831007123\n",
      "epoch: 9 step: 374, loss is 0.00021331159223336726\n",
      "epoch: 9 step: 375, loss is 0.000705947692040354\n",
      "Train epoch time: 12195.080 ms, per step time: 32.520 ms\n",
      "epoch: 10 step: 1, loss is 0.0009218170889653265\n",
      "epoch: 10 step: 2, loss is 0.0005684110219590366\n",
      "epoch: 10 step: 3, loss is 0.0005401528906077147\n",
      "epoch: 10 step: 4, loss is 0.0009626730461604893\n",
      "epoch: 10 step: 5, loss is 0.0009096534340642393\n",
      "epoch: 10 step: 6, loss is 0.0010395756689831614\n",
      "epoch: 10 step: 7, loss is 0.0005185041227377951\n",
      "epoch: 10 step: 8, loss is 0.0012387661263346672\n",
      "epoch: 10 step: 9, loss is 0.0017366297543048859\n",
      "epoch: 10 step: 10, loss is 0.0008284440846182406\n",
      "epoch: 10 step: 11, loss is 0.0010744238970801234\n",
      "epoch: 10 step: 12, loss is 0.0004794724518433213\n",
      "epoch: 10 step: 13, loss is 0.0005583746242336929\n",
      "epoch: 10 step: 14, loss is 0.0005339689669199288\n",
      "epoch: 10 step: 15, loss is 0.0004997256328351796\n",
      "epoch: 10 step: 16, loss is 0.00048604357289150357\n",
      "epoch: 10 step: 17, loss is 0.0007503582164645195\n",
      "epoch: 10 step: 18, loss is 0.0011959525290876627\n",
      "epoch: 10 step: 19, loss is 0.0010190255707129836\n",
      "epoch: 10 step: 20, loss is 0.0009095564601011574\n",
      "epoch: 10 step: 21, loss is 0.0008613474201411009\n",
      "epoch: 10 step: 22, loss is 0.0007383801275864244\n",
      "epoch: 10 step: 23, loss is 0.0017475893255323172\n",
      "epoch: 10 step: 24, loss is 0.0007700902060605586\n",
      "epoch: 10 step: 25, loss is 0.000613463285844773\n",
      "epoch: 10 step: 26, loss is 0.0007804275956004858\n",
      "epoch: 10 step: 27, loss is 0.0009412695653736591\n",
      "epoch: 10 step: 28, loss is 0.0007278851117007434\n",
      "epoch: 10 step: 29, loss is 0.0009561642655171454\n",
      "epoch: 10 step: 30, loss is 0.0003479830047581345\n",
      "epoch: 10 step: 31, loss is 0.000895721314009279\n",
      "epoch: 10 step: 32, loss is 0.00039772759191691875\n",
      "epoch: 10 step: 33, loss is 0.0008692046976648271\n",
      "epoch: 10 step: 34, loss is 0.0009578797034919262\n",
      "epoch: 10 step: 35, loss is 0.0014123226283118129\n",
      "epoch: 10 step: 36, loss is 0.0009526284993626177\n",
      "epoch: 10 step: 37, loss is 0.0003834657836705446\n",
      "epoch: 10 step: 38, loss is 0.0009784952271729708\n",
      "epoch: 10 step: 39, loss is 0.0010867882519960403\n",
      "epoch: 10 step: 40, loss is 0.0014475886709988117\n",
      "epoch: 10 step: 41, loss is 0.0015904143219813704\n",
      "epoch: 10 step: 42, loss is 0.0011143016163259745\n",
      "epoch: 10 step: 43, loss is 0.000706508057191968\n",
      "epoch: 10 step: 44, loss is 0.0004210784682072699\n",
      "epoch: 10 step: 45, loss is 0.00038489350117743015\n",
      "epoch: 10 step: 46, loss is 0.000741749070584774\n",
      "epoch: 10 step: 47, loss is 0.0009784608846530318\n",
      "epoch: 10 step: 48, loss is 0.0005529004847630858\n",
      "epoch: 10 step: 49, loss is 0.0006295836647041142\n",
      "epoch: 10 step: 50, loss is 0.0011886864667758346\n",
      "epoch: 10 step: 51, loss is 0.0010697877733036876\n",
      "epoch: 10 step: 52, loss is 0.00046730812755413353\n",
      "epoch: 10 step: 53, loss is 0.00082046800525859\n",
      "epoch: 10 step: 54, loss is 0.0004276429826859385\n",
      "epoch: 10 step: 55, loss is 0.0005115472595207393\n",
      "epoch: 10 step: 56, loss is 0.0007681668503209949\n",
      "epoch: 10 step: 57, loss is 0.0008599630673415959\n",
      "epoch: 10 step: 58, loss is 0.0005663780611939728\n",
      "epoch: 10 step: 59, loss is 0.0007885127561166883\n",
      "epoch: 10 step: 60, loss is 0.0005080356495454907\n",
      "epoch: 10 step: 61, loss is 0.00033934367820620537\n",
      "epoch: 10 step: 62, loss is 0.0006304343696683645\n",
      "epoch: 10 step: 63, loss is 0.0007509710849262774\n",
      "epoch: 10 step: 64, loss is 0.0003620756324380636\n",
      "epoch: 10 step: 65, loss is 0.0013725582975894213\n",
      "epoch: 10 step: 66, loss is 0.0011956002563238144\n",
      "epoch: 10 step: 67, loss is 0.00018493234529159963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 68, loss is 0.0007164479466155171\n",
      "epoch: 10 step: 69, loss is 0.0006467512575909495\n",
      "epoch: 10 step: 70, loss is 0.0004428622778505087\n",
      "epoch: 10 step: 71, loss is 0.001028744620271027\n",
      "epoch: 10 step: 72, loss is 0.0007499033818021417\n",
      "epoch: 10 step: 73, loss is 0.0008822567760944366\n",
      "epoch: 10 step: 74, loss is 0.0004506803525146097\n",
      "epoch: 10 step: 75, loss is 0.00048588207573629916\n",
      "epoch: 10 step: 76, loss is 0.0004002771165687591\n",
      "epoch: 10 step: 77, loss is 0.0008370346040464938\n",
      "epoch: 10 step: 78, loss is 0.0003860181022901088\n",
      "epoch: 10 step: 79, loss is 0.0007762887980788946\n",
      "epoch: 10 step: 80, loss is 0.0010904696537181735\n",
      "epoch: 10 step: 81, loss is 0.0003818110271822661\n",
      "epoch: 10 step: 82, loss is 0.00026429130230098963\n",
      "epoch: 10 step: 83, loss is 0.000813948514405638\n",
      "epoch: 10 step: 84, loss is 0.0006663470412604511\n",
      "epoch: 10 step: 85, loss is 0.0014980601845309138\n",
      "epoch: 10 step: 86, loss is 0.000662460457533598\n",
      "epoch: 10 step: 87, loss is 0.0004385334032122046\n",
      "epoch: 10 step: 88, loss is 0.0005375886103138328\n",
      "epoch: 10 step: 89, loss is 0.0006802444695495069\n",
      "epoch: 10 step: 90, loss is 0.00043267488945275545\n",
      "epoch: 10 step: 91, loss is 0.0004042975197080523\n",
      "epoch: 10 step: 92, loss is 0.0004218578105792403\n",
      "epoch: 10 step: 93, loss is 0.0003362612333148718\n",
      "epoch: 10 step: 94, loss is 0.0003069512895308435\n",
      "epoch: 10 step: 95, loss is 0.0008277697488665581\n",
      "epoch: 10 step: 96, loss is 0.0007419229950755835\n",
      "epoch: 10 step: 97, loss is 0.0004362751205917448\n",
      "epoch: 10 step: 98, loss is 0.0004522529197856784\n",
      "epoch: 10 step: 99, loss is 0.0003505389322526753\n",
      "epoch: 10 step: 100, loss is 0.0004662131250370294\n",
      "epoch: 10 step: 101, loss is 0.00046330722398124635\n",
      "epoch: 10 step: 102, loss is 0.0005323060322552919\n",
      "epoch: 10 step: 103, loss is 0.0005566737381741405\n",
      "epoch: 10 step: 104, loss is 0.0006491210660897195\n",
      "epoch: 10 step: 105, loss is 0.0008206114289350808\n",
      "epoch: 10 step: 106, loss is 0.0004922807565890253\n",
      "epoch: 10 step: 107, loss is 0.000990158412605524\n",
      "epoch: 10 step: 108, loss is 0.0009063946781679988\n",
      "epoch: 10 step: 109, loss is 0.0007473883451893926\n",
      "epoch: 10 step: 110, loss is 0.0010081188520416617\n",
      "epoch: 10 step: 111, loss is 0.0004448570834938437\n",
      "epoch: 10 step: 112, loss is 0.0010193479247391224\n",
      "epoch: 10 step: 113, loss is 0.000888215727172792\n",
      "epoch: 10 step: 114, loss is 0.0006643650121986866\n",
      "epoch: 10 step: 115, loss is 0.001696018734946847\n",
      "epoch: 10 step: 116, loss is 0.0004269156779628247\n",
      "epoch: 10 step: 117, loss is 0.0007554281037300825\n",
      "epoch: 10 step: 118, loss is 0.000356199307134375\n",
      "epoch: 10 step: 119, loss is 0.0005955208907835186\n",
      "epoch: 10 step: 120, loss is 0.001009906642138958\n",
      "epoch: 10 step: 121, loss is 0.000995130161754787\n",
      "epoch: 10 step: 122, loss is 0.00207385397516191\n",
      "epoch: 10 step: 123, loss is 0.000572300108615309\n",
      "epoch: 10 step: 124, loss is 0.0008844266412779689\n",
      "epoch: 10 step: 125, loss is 0.0009523555636405945\n",
      "epoch: 10 step: 126, loss is 0.000834022939670831\n",
      "epoch: 10 step: 127, loss is 0.0006553963175974786\n",
      "epoch: 10 step: 128, loss is 0.000454739696579054\n",
      "epoch: 10 step: 129, loss is 0.000587416929192841\n",
      "epoch: 10 step: 130, loss is 0.001494702766649425\n",
      "epoch: 10 step: 131, loss is 0.0006198559422045946\n",
      "epoch: 10 step: 132, loss is 0.001212970819324255\n",
      "epoch: 10 step: 133, loss is 0.0007607228471897542\n",
      "epoch: 10 step: 134, loss is 0.0009234407916665077\n",
      "epoch: 10 step: 135, loss is 0.0012808154569938779\n",
      "epoch: 10 step: 136, loss is 0.0003433874808251858\n",
      "epoch: 10 step: 137, loss is 0.0002423792757326737\n",
      "epoch: 10 step: 138, loss is 0.0007210155599750578\n",
      "epoch: 10 step: 139, loss is 0.0021091136150062084\n",
      "epoch: 10 step: 140, loss is 0.0010066950926557183\n",
      "epoch: 10 step: 141, loss is 0.00041103834519162774\n",
      "epoch: 10 step: 142, loss is 0.0006328001036308706\n",
      "epoch: 10 step: 143, loss is 0.0002827380667440593\n",
      "epoch: 10 step: 144, loss is 0.0009757425868883729\n",
      "epoch: 10 step: 145, loss is 0.0011424367548897862\n",
      "epoch: 10 step: 146, loss is 0.0006631066207773983\n",
      "epoch: 10 step: 147, loss is 0.00023551886260975152\n",
      "epoch: 10 step: 148, loss is 0.000526641437318176\n",
      "epoch: 10 step: 149, loss is 0.000538152118679136\n",
      "epoch: 10 step: 150, loss is 0.000917276949621737\n",
      "epoch: 10 step: 151, loss is 0.0005945515586063266\n",
      "epoch: 10 step: 152, loss is 0.0008394671021960676\n",
      "epoch: 10 step: 153, loss is 0.00020012418099213392\n",
      "epoch: 10 step: 154, loss is 0.0008216056739911437\n",
      "epoch: 10 step: 155, loss is 0.0005137576372362673\n",
      "epoch: 10 step: 156, loss is 0.0005429686279967427\n",
      "epoch: 10 step: 157, loss is 0.0005940587143413723\n",
      "epoch: 10 step: 158, loss is 0.001606050762347877\n",
      "epoch: 10 step: 159, loss is 0.0011226710630580783\n",
      "epoch: 10 step: 160, loss is 0.00019233720377087593\n",
      "epoch: 10 step: 161, loss is 0.0005863360711373389\n",
      "epoch: 10 step: 162, loss is 0.000314943928970024\n",
      "epoch: 10 step: 163, loss is 0.0004966323031112552\n",
      "epoch: 10 step: 164, loss is 0.0016114739701151848\n",
      "epoch: 10 step: 165, loss is 0.0018886906327679753\n",
      "epoch: 10 step: 166, loss is 0.0005732749705202878\n",
      "epoch: 10 step: 167, loss is 0.0009279740625061095\n",
      "epoch: 10 step: 168, loss is 0.000796114036347717\n",
      "epoch: 10 step: 169, loss is 0.00026094066561199725\n",
      "epoch: 10 step: 170, loss is 0.001221950864419341\n",
      "epoch: 10 step: 171, loss is 0.0007672059000469744\n",
      "epoch: 10 step: 172, loss is 0.001214690157212317\n",
      "epoch: 10 step: 173, loss is 0.0004955516778863966\n",
      "epoch: 10 step: 174, loss is 7.449736585840583e-05\n",
      "epoch: 10 step: 175, loss is 0.0005002776742912829\n",
      "epoch: 10 step: 176, loss is 0.0005696399603039026\n",
      "epoch: 10 step: 177, loss is 0.0012787431478500366\n",
      "epoch: 10 step: 178, loss is 0.0012628111289814115\n",
      "epoch: 10 step: 179, loss is 0.0010644816793501377\n",
      "epoch: 10 step: 180, loss is 0.0005454191123135388\n",
      "epoch: 10 step: 181, loss is 0.0003806625318247825\n",
      "epoch: 10 step: 182, loss is 0.0006337382365018129\n",
      "epoch: 10 step: 183, loss is 0.001417547813616693\n",
      "epoch: 10 step: 184, loss is 0.0005536397802643478\n",
      "epoch: 10 step: 185, loss is 0.001450449344702065\n",
      "epoch: 10 step: 186, loss is 0.00037295778747648\n",
      "epoch: 10 step: 187, loss is 0.0002313197182957083\n",
      "epoch: 10 step: 188, loss is 0.0005868853186257184\n",
      "epoch: 10 step: 189, loss is 0.0006160191842354834\n",
      "epoch: 10 step: 190, loss is 0.0007981952512636781\n",
      "epoch: 10 step: 191, loss is 0.00023137893003877252\n",
      "epoch: 10 step: 192, loss is 0.001072937622666359\n",
      "epoch: 10 step: 193, loss is 0.0003400894347578287\n",
      "epoch: 10 step: 194, loss is 0.0011946280719712377\n",
      "epoch: 10 step: 195, loss is 0.0005795784527435899\n",
      "epoch: 10 step: 196, loss is 0.0005862648831680417\n",
      "epoch: 10 step: 197, loss is 0.0005589853972196579\n",
      "epoch: 10 step: 198, loss is 0.00026163188158534467\n",
      "epoch: 10 step: 199, loss is 0.0005513564683496952\n",
      "epoch: 10 step: 200, loss is 0.0007129374425858259\n",
      "epoch: 10 step: 201, loss is 0.0008566399337723851\n",
      "epoch: 10 step: 202, loss is 0.0007071411237120628\n",
      "epoch: 10 step: 203, loss is 0.0006723616388626397\n",
      "epoch: 10 step: 204, loss is 0.0002801869995892048\n",
      "epoch: 10 step: 205, loss is 0.001169910072349012\n",
      "epoch: 10 step: 206, loss is 0.0009463144233450294\n",
      "epoch: 10 step: 207, loss is 0.0009749013697728515\n",
      "epoch: 10 step: 208, loss is 0.0007484731613658369\n",
      "epoch: 10 step: 209, loss is 0.0014029039302840829\n",
      "epoch: 10 step: 210, loss is 0.0008009488810785115\n",
      "epoch: 10 step: 211, loss is 0.0005482081323862076\n",
      "epoch: 10 step: 212, loss is 0.0007698421832174063\n",
      "epoch: 10 step: 213, loss is 0.0005593262030743062\n",
      "epoch: 10 step: 214, loss is 0.0007469099364243448\n",
      "epoch: 10 step: 215, loss is 0.000572656630538404\n",
      "epoch: 10 step: 216, loss is 0.0014866555575281382\n",
      "epoch: 10 step: 217, loss is 0.0006295998464338481\n",
      "epoch: 10 step: 218, loss is 0.001020182971842587\n",
      "epoch: 10 step: 219, loss is 0.00047982324031181633\n",
      "epoch: 10 step: 220, loss is 0.000642989354673773\n",
      "epoch: 10 step: 221, loss is 0.001206816523335874\n",
      "epoch: 10 step: 222, loss is 0.0009827094618231058\n",
      "epoch: 10 step: 223, loss is 0.0003008107887580991\n",
      "epoch: 10 step: 224, loss is 0.0005287649109959602\n",
      "epoch: 10 step: 225, loss is 0.0007632355554960668\n",
      "epoch: 10 step: 226, loss is 0.001598573406226933\n",
      "epoch: 10 step: 227, loss is 0.0009316459763795137\n",
      "epoch: 10 step: 228, loss is 0.0006536213331855834\n",
      "epoch: 10 step: 229, loss is 0.0003705998824443668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 230, loss is 0.0020349291153252125\n",
      "epoch: 10 step: 231, loss is 0.0008284253417514265\n",
      "epoch: 10 step: 232, loss is 0.0006938052247278392\n",
      "epoch: 10 step: 233, loss is 0.0014175039250403643\n",
      "epoch: 10 step: 234, loss is 0.000557255232706666\n",
      "epoch: 10 step: 235, loss is 0.0004057595506310463\n",
      "epoch: 10 step: 236, loss is 0.00043933899723924696\n",
      "epoch: 10 step: 237, loss is 0.0007341743912547827\n",
      "epoch: 10 step: 238, loss is 0.0006539149326272309\n",
      "epoch: 10 step: 239, loss is 0.0013674994697794318\n",
      "epoch: 10 step: 240, loss is 0.0005867042345926166\n",
      "epoch: 10 step: 241, loss is 0.0007992509054020047\n",
      "epoch: 10 step: 242, loss is 0.0009094789857044816\n",
      "epoch: 10 step: 243, loss is 0.0008092438220046461\n",
      "epoch: 10 step: 244, loss is 0.0006863902090117335\n",
      "epoch: 10 step: 245, loss is 0.0007000978803262115\n",
      "epoch: 10 step: 246, loss is 0.000519357796292752\n",
      "epoch: 10 step: 247, loss is 0.00010656110680429265\n",
      "epoch: 10 step: 248, loss is 0.00035379387554712594\n",
      "epoch: 10 step: 249, loss is 0.0004211047780700028\n",
      "epoch: 10 step: 250, loss is 0.00017504363495390862\n",
      "epoch: 10 step: 251, loss is 0.0003811738279182464\n",
      "epoch: 10 step: 252, loss is 0.0008435362251475453\n",
      "epoch: 10 step: 253, loss is 0.0005988681223243475\n",
      "epoch: 10 step: 254, loss is 0.0005281101912260056\n",
      "epoch: 10 step: 255, loss is 0.0006254957406781614\n",
      "epoch: 10 step: 256, loss is 0.00028509501134976745\n",
      "epoch: 10 step: 257, loss is 0.0005693060229532421\n",
      "epoch: 10 step: 258, loss is 0.0013619752135127783\n",
      "epoch: 10 step: 259, loss is 0.0013565442059189081\n",
      "epoch: 10 step: 260, loss is 0.0007056096801534295\n",
      "epoch: 10 step: 261, loss is 0.0001786593784345314\n",
      "epoch: 10 step: 262, loss is 0.0005610687076114118\n",
      "epoch: 10 step: 263, loss is 0.0008081037667579949\n",
      "epoch: 10 step: 264, loss is 0.0005633189575746655\n",
      "epoch: 10 step: 265, loss is 0.0006298789521679282\n",
      "epoch: 10 step: 266, loss is 0.0006531288963742554\n",
      "epoch: 10 step: 267, loss is 0.0005188623326830566\n",
      "epoch: 10 step: 268, loss is 0.0002658693992998451\n",
      "epoch: 10 step: 269, loss is 0.00043007131898775697\n",
      "epoch: 10 step: 270, loss is 0.0012199031189084053\n",
      "epoch: 10 step: 271, loss is 0.00028144539101049304\n",
      "epoch: 10 step: 272, loss is 0.00038480779039673507\n",
      "epoch: 10 step: 273, loss is 0.00020929475431330502\n",
      "epoch: 10 step: 274, loss is 0.0009007403859868646\n",
      "epoch: 10 step: 275, loss is 0.0002010045718634501\n",
      "epoch: 10 step: 276, loss is 0.001204287982545793\n",
      "epoch: 10 step: 277, loss is 0.0002444158890284598\n",
      "epoch: 10 step: 278, loss is 0.00042654015123844147\n",
      "epoch: 10 step: 279, loss is 0.0009618079056963325\n",
      "epoch: 10 step: 280, loss is 0.0009661574731580913\n",
      "epoch: 10 step: 281, loss is 0.0005376555491238832\n",
      "epoch: 10 step: 282, loss is 0.0010060117347165942\n",
      "epoch: 10 step: 283, loss is 0.0010635093785822392\n",
      "epoch: 10 step: 284, loss is 0.0006560199544765055\n",
      "epoch: 10 step: 285, loss is 0.0003281473182141781\n",
      "epoch: 10 step: 286, loss is 0.000842296052724123\n",
      "epoch: 10 step: 287, loss is 0.0007642533746547997\n",
      "epoch: 10 step: 288, loss is 0.00023739211610518396\n",
      "epoch: 10 step: 289, loss is 0.0011412884341552854\n",
      "epoch: 10 step: 290, loss is 0.0003624218516051769\n",
      "epoch: 10 step: 291, loss is 0.0011090657208114862\n",
      "epoch: 10 step: 292, loss is 0.0007194219506345689\n",
      "epoch: 10 step: 293, loss is 0.0008532908977940679\n",
      "epoch: 10 step: 294, loss is 0.00043918585288338363\n",
      "epoch: 10 step: 295, loss is 0.0006105475476942956\n",
      "epoch: 10 step: 296, loss is 0.0009904903126880527\n",
      "epoch: 10 step: 297, loss is 0.0005919623654335737\n",
      "epoch: 10 step: 298, loss is 0.0007421509944833815\n",
      "epoch: 10 step: 299, loss is 0.0006272561731748283\n",
      "epoch: 10 step: 300, loss is 0.0010831075487658381\n",
      "epoch: 10 step: 301, loss is 0.0008732547285035253\n",
      "epoch: 10 step: 302, loss is 0.0020021232776343822\n",
      "epoch: 10 step: 303, loss is 0.00020678700821008533\n",
      "epoch: 10 step: 304, loss is 0.001250653644092381\n",
      "epoch: 10 step: 305, loss is 0.0005159678403288126\n",
      "epoch: 10 step: 306, loss is 0.0006956943543627858\n",
      "epoch: 10 step: 307, loss is 0.0012557607842609286\n",
      "epoch: 10 step: 308, loss is 0.0007024009828455746\n",
      "epoch: 10 step: 309, loss is 0.0003408491029404104\n",
      "epoch: 10 step: 310, loss is 0.001025908743031323\n",
      "epoch: 10 step: 311, loss is 0.00023011038138065487\n",
      "epoch: 10 step: 312, loss is 0.0017553193029016256\n",
      "epoch: 10 step: 313, loss is 0.0007773253018967807\n",
      "epoch: 10 step: 314, loss is 0.00073446542955935\n",
      "epoch: 10 step: 315, loss is 0.0013658342650160193\n",
      "epoch: 10 step: 316, loss is 0.0006181274075061083\n",
      "epoch: 10 step: 317, loss is 0.001136893522925675\n",
      "epoch: 10 step: 318, loss is 0.0005536714452318847\n",
      "epoch: 10 step: 319, loss is 0.00044534014887176454\n",
      "epoch: 10 step: 320, loss is 0.0007896004244685173\n",
      "epoch: 10 step: 321, loss is 0.0005414003971964121\n",
      "epoch: 10 step: 322, loss is 0.00036122891469858587\n",
      "epoch: 10 step: 323, loss is 0.0006581938941963017\n",
      "epoch: 10 step: 324, loss is 0.00027628400130197406\n",
      "epoch: 10 step: 325, loss is 0.0004803600604645908\n",
      "epoch: 10 step: 326, loss is 0.0007269592024385929\n",
      "epoch: 10 step: 327, loss is 0.0006689172005280852\n",
      "epoch: 10 step: 328, loss is 0.0005568558699451387\n",
      "epoch: 10 step: 329, loss is 0.0005352150765247643\n",
      "epoch: 10 step: 330, loss is 0.00046131471754051745\n",
      "epoch: 10 step: 331, loss is 0.00060930015752092\n",
      "epoch: 10 step: 332, loss is 0.0009869985515251756\n",
      "epoch: 10 step: 333, loss is 0.00015216738393064588\n",
      "epoch: 10 step: 334, loss is 0.0008287025266326964\n",
      "epoch: 10 step: 335, loss is 0.0007774962577968836\n",
      "epoch: 10 step: 336, loss is 0.0003037455026060343\n",
      "epoch: 10 step: 337, loss is 0.0005171477678231895\n",
      "epoch: 10 step: 338, loss is 0.0010985556291416287\n",
      "epoch: 10 step: 339, loss is 0.0015390716725960374\n",
      "epoch: 10 step: 340, loss is 0.0003962272312492132\n",
      "epoch: 10 step: 341, loss is 0.0013805447379127145\n",
      "epoch: 10 step: 342, loss is 0.00109384348616004\n",
      "epoch: 10 step: 343, loss is 0.0004705517494585365\n",
      "epoch: 10 step: 344, loss is 0.0013965610414743423\n",
      "epoch: 10 step: 345, loss is 0.001250733621418476\n",
      "epoch: 10 step: 346, loss is 0.0003158941399306059\n",
      "epoch: 10 step: 347, loss is 0.000949254899751395\n",
      "epoch: 10 step: 348, loss is 0.0008711410919204354\n",
      "epoch: 10 step: 349, loss is 0.0007903057849034667\n",
      "epoch: 10 step: 350, loss is 0.0012295303167775273\n",
      "epoch: 10 step: 351, loss is 0.0011208803625777364\n",
      "epoch: 10 step: 352, loss is 0.0002552215300966054\n",
      "epoch: 10 step: 353, loss is 0.0009104625205509365\n",
      "epoch: 10 step: 354, loss is 0.0002038859238382429\n",
      "epoch: 10 step: 355, loss is 0.00019377174612600356\n",
      "epoch: 10 step: 356, loss is 0.001432440709322691\n",
      "epoch: 10 step: 357, loss is 0.0005593904643319547\n",
      "epoch: 10 step: 358, loss is 0.0007118699722923338\n",
      "epoch: 10 step: 359, loss is 0.0004134452319703996\n",
      "epoch: 10 step: 360, loss is 0.0007292827358469367\n",
      "epoch: 10 step: 361, loss is 0.0009732302278280258\n",
      "epoch: 10 step: 362, loss is 0.00031049412791617215\n",
      "epoch: 10 step: 363, loss is 0.0003652472805697471\n",
      "epoch: 10 step: 364, loss is 0.0003638991038314998\n",
      "epoch: 10 step: 365, loss is 0.0004957218188792467\n",
      "epoch: 10 step: 366, loss is 0.0005138926790095866\n",
      "epoch: 10 step: 367, loss is 0.001058630645275116\n",
      "epoch: 10 step: 368, loss is 0.0008773010922595859\n",
      "epoch: 10 step: 369, loss is 0.0012310807360336185\n",
      "epoch: 10 step: 370, loss is 0.0006440228316932917\n",
      "epoch: 10 step: 371, loss is 0.00015036571130622178\n",
      "epoch: 10 step: 372, loss is 0.0005684525822289288\n",
      "epoch: 10 step: 373, loss is 0.0006934305420145392\n",
      "epoch: 10 step: 374, loss is 0.0005902217817492783\n",
      "epoch: 10 step: 375, loss is 0.0005025969003327191\n",
      "Train epoch time: 12016.986 ms, per step time: 32.045 ms\n",
      "epoch: 11 step: 1, loss is 0.00045386137207970023\n",
      "epoch: 11 step: 2, loss is 0.0006150103872641921\n",
      "epoch: 11 step: 3, loss is 0.0011248576920479536\n",
      "epoch: 11 step: 4, loss is 0.0006180405616760254\n",
      "epoch: 11 step: 5, loss is 0.00044194667134433985\n",
      "epoch: 11 step: 6, loss is 0.001032769912853837\n",
      "epoch: 11 step: 7, loss is 0.0009469076176173985\n",
      "epoch: 11 step: 8, loss is 0.0006055632838979363\n",
      "epoch: 11 step: 9, loss is 0.0005677836015820503\n",
      "epoch: 11 step: 10, loss is 0.0002859040687326342\n",
      "epoch: 11 step: 11, loss is 0.0008189031505025923\n",
      "epoch: 11 step: 12, loss is 0.0007316860137507319\n",
      "epoch: 11 step: 13, loss is 0.0005865604034624994\n",
      "epoch: 11 step: 14, loss is 0.00016464607324451208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 15, loss is 0.0006784977158531547\n",
      "epoch: 11 step: 16, loss is 0.0008649548981338739\n",
      "epoch: 11 step: 17, loss is 0.0010993086034432054\n",
      "epoch: 11 step: 18, loss is 0.0008938998798839748\n",
      "epoch: 11 step: 19, loss is 0.0005141185829415917\n",
      "epoch: 11 step: 20, loss is 0.0005031924811191857\n",
      "epoch: 11 step: 21, loss is 0.0003314525820314884\n",
      "epoch: 11 step: 22, loss is 0.0005753438454121351\n",
      "epoch: 11 step: 23, loss is 0.0006773446802981198\n",
      "epoch: 11 step: 24, loss is 0.0006031228112988174\n",
      "epoch: 11 step: 25, loss is 0.000604479864705354\n",
      "epoch: 11 step: 26, loss is 0.0006361859268508852\n",
      "epoch: 11 step: 27, loss is 0.0009167544194497168\n",
      "epoch: 11 step: 28, loss is 0.0005360395298339427\n",
      "epoch: 11 step: 29, loss is 0.00014911741891410202\n",
      "epoch: 11 step: 30, loss is 0.0012188886757940054\n",
      "epoch: 11 step: 31, loss is 0.0011698836460709572\n",
      "epoch: 11 step: 32, loss is 0.0007451842539012432\n",
      "epoch: 11 step: 33, loss is 0.0010274506639689207\n",
      "epoch: 11 step: 34, loss is 0.00126623862888664\n",
      "epoch: 11 step: 35, loss is 0.0006065077614039183\n",
      "epoch: 11 step: 36, loss is 0.0005837925127707422\n",
      "epoch: 11 step: 37, loss is 0.0008869628072716296\n",
      "epoch: 11 step: 38, loss is 0.001593605149537325\n",
      "epoch: 11 step: 39, loss is 0.000683995836880058\n",
      "epoch: 11 step: 40, loss is 0.0005881126853637397\n",
      "epoch: 11 step: 41, loss is 0.0012397654354572296\n",
      "epoch: 11 step: 42, loss is 0.0010858471505343914\n",
      "epoch: 11 step: 43, loss is 0.0018873983062803745\n",
      "epoch: 11 step: 44, loss is 0.00047385008656419814\n",
      "epoch: 11 step: 45, loss is 0.0004019381885882467\n",
      "epoch: 11 step: 46, loss is 0.0008977316902019083\n",
      "epoch: 11 step: 47, loss is 0.0008757467730902135\n",
      "epoch: 11 step: 48, loss is 0.0004174130444880575\n",
      "epoch: 11 step: 49, loss is 0.0013731358340010047\n",
      "epoch: 11 step: 50, loss is 0.00046136995661072433\n",
      "epoch: 11 step: 51, loss is 0.00016851065447553992\n",
      "epoch: 11 step: 52, loss is 0.00018287819693796337\n",
      "epoch: 11 step: 53, loss is 0.0010524960234761238\n",
      "epoch: 11 step: 54, loss is 0.00047389004612341523\n",
      "epoch: 11 step: 55, loss is 0.0009397456306032836\n",
      "epoch: 11 step: 56, loss is 0.0007135242340154946\n",
      "epoch: 11 step: 57, loss is 0.0005176377599127591\n",
      "epoch: 11 step: 58, loss is 0.0013799186563119292\n",
      "epoch: 11 step: 59, loss is 0.0003046056372113526\n",
      "epoch: 11 step: 60, loss is 0.0007477835169993341\n",
      "epoch: 11 step: 61, loss is 0.0005703146453015506\n",
      "epoch: 11 step: 62, loss is 0.0008230032399296761\n",
      "epoch: 11 step: 63, loss is 0.0005968191544525325\n",
      "epoch: 11 step: 64, loss is 0.0005153134115971625\n",
      "epoch: 11 step: 65, loss is 0.0005626558559015393\n",
      "epoch: 11 step: 66, loss is 0.000729787047021091\n",
      "epoch: 11 step: 67, loss is 0.0001177461672341451\n",
      "epoch: 11 step: 68, loss is 0.0008104524458758533\n",
      "epoch: 11 step: 69, loss is 0.001606158446520567\n",
      "epoch: 11 step: 70, loss is 0.0005449935561046004\n",
      "epoch: 11 step: 71, loss is 0.0009402051800861955\n",
      "epoch: 11 step: 72, loss is 0.000664005521684885\n",
      "epoch: 11 step: 73, loss is 0.001889269333332777\n",
      "epoch: 11 step: 74, loss is 0.0008929740870371461\n",
      "epoch: 11 step: 75, loss is 0.000663387996610254\n",
      "epoch: 11 step: 76, loss is 0.0002747330872807652\n",
      "epoch: 11 step: 77, loss is 0.00014307980018202215\n",
      "epoch: 11 step: 78, loss is 0.0001512418530182913\n",
      "epoch: 11 step: 79, loss is 0.0007263632141984999\n",
      "epoch: 11 step: 80, loss is 0.0006721901008859277\n",
      "epoch: 11 step: 81, loss is 0.0004240283160470426\n",
      "epoch: 11 step: 82, loss is 0.0005743823712691665\n",
      "epoch: 11 step: 83, loss is 0.001054567052051425\n",
      "epoch: 11 step: 84, loss is 0.0015466931508854032\n",
      "epoch: 11 step: 85, loss is 0.0018949257209897041\n",
      "epoch: 11 step: 86, loss is 0.0010268077021464705\n",
      "epoch: 11 step: 87, loss is 0.00022966241522226483\n",
      "epoch: 11 step: 88, loss is 0.00145376764703542\n",
      "epoch: 11 step: 89, loss is 0.0009974058484658599\n",
      "epoch: 11 step: 90, loss is 0.0008615200058557093\n",
      "epoch: 11 step: 91, loss is 0.0005172449164092541\n",
      "epoch: 11 step: 92, loss is 0.0004274711536709219\n",
      "epoch: 11 step: 93, loss is 0.0003626936813816428\n",
      "epoch: 11 step: 94, loss is 0.001591000473126769\n",
      "epoch: 11 step: 95, loss is 0.0003542566846590489\n",
      "epoch: 11 step: 96, loss is 0.0009806306334212422\n",
      "epoch: 11 step: 97, loss is 0.001647645141929388\n",
      "epoch: 11 step: 98, loss is 0.0006382546271197498\n",
      "epoch: 11 step: 99, loss is 0.0005998031119816005\n",
      "epoch: 11 step: 100, loss is 0.0005404793773777783\n",
      "epoch: 11 step: 101, loss is 0.0005594086833298206\n",
      "epoch: 11 step: 102, loss is 0.0002444454003125429\n",
      "epoch: 11 step: 103, loss is 0.0009528450900688767\n",
      "epoch: 11 step: 104, loss is 0.0009625655366107821\n",
      "epoch: 11 step: 105, loss is 0.00039349941653199494\n",
      "epoch: 11 step: 106, loss is 0.000534414779394865\n",
      "epoch: 11 step: 107, loss is 0.0008080929983407259\n",
      "epoch: 11 step: 108, loss is 0.0005171445664018393\n",
      "epoch: 11 step: 109, loss is 0.0009428882040083408\n",
      "epoch: 11 step: 110, loss is 0.0013013517018407583\n",
      "epoch: 11 step: 111, loss is 0.0007717604748904705\n",
      "epoch: 11 step: 112, loss is 0.0010615260107442737\n",
      "epoch: 11 step: 113, loss is 0.0003775636141654104\n",
      "epoch: 11 step: 114, loss is 0.0014813863672316074\n",
      "epoch: 11 step: 115, loss is 0.0005213161930441856\n",
      "epoch: 11 step: 116, loss is 0.000786533288192004\n",
      "epoch: 11 step: 117, loss is 0.0009199286578223109\n",
      "epoch: 11 step: 118, loss is 0.0005657824221998453\n",
      "epoch: 11 step: 119, loss is 0.0006471943343058228\n",
      "epoch: 11 step: 120, loss is 0.0010171262547373772\n",
      "epoch: 11 step: 121, loss is 0.0005910572363063693\n",
      "epoch: 11 step: 122, loss is 0.0017028747824952006\n",
      "epoch: 11 step: 123, loss is 0.0006699387449771166\n",
      "epoch: 11 step: 124, loss is 0.0006346860900521278\n",
      "epoch: 11 step: 125, loss is 0.0011529892217367887\n",
      "epoch: 11 step: 126, loss is 0.0013165328418835998\n",
      "epoch: 11 step: 127, loss is 0.001527553889900446\n",
      "epoch: 11 step: 128, loss is 0.001413267687894404\n",
      "epoch: 11 step: 129, loss is 0.0010157049400731921\n",
      "epoch: 11 step: 130, loss is 0.0008902177214622498\n",
      "epoch: 11 step: 131, loss is 0.0005965869640931487\n",
      "epoch: 11 step: 132, loss is 0.0007048565894365311\n",
      "epoch: 11 step: 133, loss is 0.0018854287918657064\n",
      "epoch: 11 step: 134, loss is 0.0005960030248388648\n",
      "epoch: 11 step: 135, loss is 0.00027694468735717237\n",
      "epoch: 11 step: 136, loss is 0.0009740665555000305\n",
      "epoch: 11 step: 137, loss is 0.0007571959285996854\n",
      "epoch: 11 step: 138, loss is 0.0007399984169751406\n",
      "epoch: 11 step: 139, loss is 0.00027739114011637866\n",
      "epoch: 11 step: 140, loss is 0.0008518646354787052\n",
      "epoch: 11 step: 141, loss is 0.0005702728522010148\n",
      "epoch: 11 step: 142, loss is 0.0010102406376972795\n",
      "epoch: 11 step: 143, loss is 0.0007493030861951411\n",
      "epoch: 11 step: 144, loss is 0.0008312090649269521\n",
      "epoch: 11 step: 145, loss is 0.0012983287451788783\n",
      "epoch: 11 step: 146, loss is 0.0006386899040080607\n",
      "epoch: 11 step: 147, loss is 0.0006415307288989425\n",
      "epoch: 11 step: 148, loss is 0.0007441467605531216\n",
      "epoch: 11 step: 149, loss is 0.0001834853319451213\n",
      "epoch: 11 step: 150, loss is 0.0010956927435472608\n",
      "epoch: 11 step: 151, loss is 0.0004553244507405907\n",
      "epoch: 11 step: 152, loss is 0.0012593958526849747\n",
      "epoch: 11 step: 153, loss is 0.0003970738616771996\n",
      "epoch: 11 step: 154, loss is 0.0005477718659676611\n",
      "epoch: 11 step: 155, loss is 0.0007675097440369427\n",
      "epoch: 11 step: 156, loss is 0.0015379819087684155\n",
      "epoch: 11 step: 157, loss is 0.0013533898163586855\n",
      "epoch: 11 step: 158, loss is 0.000519577763043344\n",
      "epoch: 11 step: 159, loss is 0.0009473044192418456\n",
      "epoch: 11 step: 160, loss is 0.00024207093520089984\n",
      "epoch: 11 step: 161, loss is 0.000806736177764833\n",
      "epoch: 11 step: 162, loss is 0.0008380552753806114\n",
      "epoch: 11 step: 163, loss is 0.0004452260909602046\n",
      "epoch: 11 step: 164, loss is 0.0005480438703671098\n",
      "epoch: 11 step: 165, loss is 0.0013559621293097734\n",
      "epoch: 11 step: 166, loss is 0.0004633041098713875\n",
      "epoch: 11 step: 167, loss is 0.00041718242573551834\n",
      "epoch: 11 step: 168, loss is 0.0006864037713967264\n",
      "epoch: 11 step: 169, loss is 0.0008988289046101272\n",
      "epoch: 11 step: 170, loss is 0.0005493138451129198\n",
      "epoch: 11 step: 171, loss is 0.002424571430310607\n",
      "epoch: 11 step: 172, loss is 0.0005865723360329866\n",
      "epoch: 11 step: 173, loss is 0.0005876363138668239\n",
      "epoch: 11 step: 174, loss is 0.00032452953746542335\n",
      "epoch: 11 step: 175, loss is 0.0008449868764728308\n",
      "epoch: 11 step: 176, loss is 0.0003095216234214604\n",
      "epoch: 11 step: 177, loss is 0.00041065324330702424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 178, loss is 0.0007672853535041213\n",
      "epoch: 11 step: 179, loss is 0.000787591387052089\n",
      "epoch: 11 step: 180, loss is 0.00048740862985141575\n",
      "epoch: 11 step: 181, loss is 0.0008624558104202151\n",
      "epoch: 11 step: 182, loss is 0.0005175302503630519\n",
      "epoch: 11 step: 183, loss is 0.0008145986357703805\n",
      "epoch: 11 step: 184, loss is 0.0007232715142890811\n",
      "epoch: 11 step: 185, loss is 0.0007011287962086499\n",
      "epoch: 11 step: 186, loss is 0.000757204950787127\n",
      "epoch: 11 step: 187, loss is 0.0008517587557435036\n",
      "epoch: 11 step: 188, loss is 0.0005735100130550563\n",
      "epoch: 11 step: 189, loss is 0.0014232571702450514\n",
      "epoch: 11 step: 190, loss is 0.0009165622759610415\n",
      "epoch: 11 step: 191, loss is 0.00043630460277199745\n",
      "epoch: 11 step: 192, loss is 0.00014403022942133248\n",
      "epoch: 11 step: 193, loss is 0.001175501151010394\n",
      "epoch: 11 step: 194, loss is 0.00016269519983325154\n",
      "epoch: 11 step: 195, loss is 0.0006557304295711219\n",
      "epoch: 11 step: 196, loss is 0.0008208634681068361\n",
      "epoch: 11 step: 197, loss is 0.0005388818681240082\n",
      "epoch: 11 step: 198, loss is 0.000201839255169034\n",
      "epoch: 11 step: 199, loss is 0.0006135277217254043\n",
      "epoch: 11 step: 200, loss is 0.00040245920536108315\n",
      "epoch: 11 step: 201, loss is 0.0005081716226413846\n",
      "epoch: 11 step: 202, loss is 0.0007048987899906933\n",
      "epoch: 11 step: 203, loss is 0.0007642790442332625\n",
      "epoch: 11 step: 204, loss is 0.0004463306104298681\n",
      "epoch: 11 step: 205, loss is 0.00041952752508223057\n",
      "epoch: 11 step: 206, loss is 0.0007266294560395181\n",
      "epoch: 11 step: 207, loss is 0.0008896125946193933\n",
      "epoch: 11 step: 208, loss is 0.00021536694839596748\n",
      "epoch: 11 step: 209, loss is 9.889482316793874e-05\n",
      "epoch: 11 step: 210, loss is 0.00029683017055504024\n",
      "epoch: 11 step: 211, loss is 0.0004612391348928213\n",
      "epoch: 11 step: 212, loss is 0.0011540129780769348\n",
      "epoch: 11 step: 213, loss is 0.0007789994706399739\n",
      "epoch: 11 step: 214, loss is 0.0004128485743422061\n",
      "epoch: 11 step: 215, loss is 0.0009294439805671573\n",
      "epoch: 11 step: 216, loss is 0.0005108623881824315\n",
      "epoch: 11 step: 217, loss is 0.00037866286584176123\n",
      "epoch: 11 step: 218, loss is 0.00019028944370802492\n",
      "epoch: 11 step: 219, loss is 0.0007053701556287706\n",
      "epoch: 11 step: 220, loss is 0.0009923841571435332\n",
      "epoch: 11 step: 221, loss is 0.0010861426126211882\n",
      "epoch: 11 step: 222, loss is 0.0004921633517369628\n",
      "epoch: 11 step: 223, loss is 0.0005495369550772011\n",
      "epoch: 11 step: 224, loss is 0.0007152342004701495\n",
      "epoch: 11 step: 225, loss is 0.0017759950133040547\n",
      "epoch: 11 step: 226, loss is 0.00033794427872635424\n",
      "epoch: 11 step: 227, loss is 0.0005898643285036087\n",
      "epoch: 11 step: 228, loss is 0.0009189934935420752\n",
      "epoch: 11 step: 229, loss is 0.0008631855016574264\n",
      "epoch: 11 step: 230, loss is 0.001566220191307366\n",
      "epoch: 11 step: 231, loss is 0.0006003367016091943\n",
      "epoch: 11 step: 232, loss is 0.0007245205342769623\n",
      "epoch: 11 step: 233, loss is 0.0004650138725992292\n",
      "epoch: 11 step: 234, loss is 0.0005182632594369352\n",
      "epoch: 11 step: 235, loss is 0.0008186855120584369\n",
      "epoch: 11 step: 236, loss is 0.001024814904667437\n",
      "epoch: 11 step: 237, loss is 0.0009939126903191209\n",
      "epoch: 11 step: 238, loss is 0.00042084092274308205\n",
      "epoch: 11 step: 239, loss is 0.000357667391654104\n",
      "epoch: 11 step: 240, loss is 0.000365100015187636\n",
      "epoch: 11 step: 241, loss is 0.00023395914467982948\n",
      "epoch: 11 step: 242, loss is 0.0007196599035523832\n",
      "epoch: 11 step: 243, loss is 0.000795578642282635\n",
      "epoch: 11 step: 244, loss is 0.0003947385121136904\n",
      "epoch: 11 step: 245, loss is 0.0006220789509825408\n",
      "epoch: 11 step: 246, loss is 0.0013363660546019673\n",
      "epoch: 11 step: 247, loss is 0.0006766434526070952\n",
      "epoch: 11 step: 248, loss is 0.00042897500679828227\n",
      "epoch: 11 step: 249, loss is 0.0010543983662500978\n",
      "epoch: 11 step: 250, loss is 0.00032041192753240466\n",
      "epoch: 11 step: 251, loss is 0.0010367297800257802\n",
      "epoch: 11 step: 252, loss is 0.000577588623855263\n",
      "epoch: 11 step: 253, loss is 0.0005606778431683779\n",
      "epoch: 11 step: 254, loss is 0.0013368551153689623\n",
      "epoch: 11 step: 255, loss is 0.0005341538926586509\n",
      "epoch: 11 step: 256, loss is 0.0002806796401273459\n",
      "epoch: 11 step: 257, loss is 0.0009800655534490943\n",
      "epoch: 11 step: 258, loss is 0.0007877607131376863\n",
      "epoch: 11 step: 259, loss is 0.0005144214956089854\n",
      "epoch: 11 step: 260, loss is 0.0006690316367894411\n",
      "epoch: 11 step: 261, loss is 0.0006722152465954423\n",
      "epoch: 11 step: 262, loss is 8.857828652253374e-05\n",
      "epoch: 11 step: 263, loss is 0.0007673887885175645\n",
      "epoch: 11 step: 264, loss is 0.0004596480866894126\n",
      "epoch: 11 step: 265, loss is 0.0010116592748090625\n",
      "epoch: 11 step: 266, loss is 0.0007181094260886312\n",
      "epoch: 11 step: 267, loss is 0.000560249260161072\n",
      "epoch: 11 step: 268, loss is 0.002712210640311241\n",
      "epoch: 11 step: 269, loss is 0.00027014309307560325\n",
      "epoch: 11 step: 270, loss is 0.0007069373968988657\n",
      "epoch: 11 step: 271, loss is 0.0008752326830290258\n",
      "epoch: 11 step: 272, loss is 0.0003970797697547823\n",
      "epoch: 11 step: 273, loss is 0.0005248698289506137\n",
      "epoch: 11 step: 274, loss is 0.0007829117239452899\n",
      "epoch: 11 step: 275, loss is 0.0005575952818617225\n",
      "epoch: 11 step: 276, loss is 0.000736345537006855\n",
      "epoch: 11 step: 277, loss is 0.00032987858867272735\n",
      "epoch: 11 step: 278, loss is 0.00028756962274201214\n",
      "epoch: 11 step: 279, loss is 0.000523195369169116\n",
      "epoch: 11 step: 280, loss is 0.00016552851593587548\n",
      "epoch: 11 step: 281, loss is 0.0012255706824362278\n",
      "epoch: 11 step: 282, loss is 0.0006766140577383339\n",
      "epoch: 11 step: 283, loss is 0.0006262304959818721\n",
      "epoch: 11 step: 284, loss is 0.00012843323929701\n",
      "epoch: 11 step: 285, loss is 0.00045484237489290535\n",
      "epoch: 11 step: 286, loss is 0.0009162477217614651\n",
      "epoch: 11 step: 287, loss is 0.0009272885508835316\n",
      "epoch: 11 step: 288, loss is 0.0005944695440120995\n",
      "epoch: 11 step: 289, loss is 0.000667919113766402\n",
      "epoch: 11 step: 290, loss is 0.0006844829185865819\n",
      "epoch: 11 step: 291, loss is 0.0005852978792972863\n",
      "epoch: 11 step: 292, loss is 0.0005201607127673924\n",
      "epoch: 11 step: 293, loss is 0.0006192661239765584\n",
      "epoch: 11 step: 294, loss is 0.0005572632071562111\n",
      "epoch: 11 step: 295, loss is 0.0005280848126858473\n",
      "epoch: 11 step: 296, loss is 0.0005756352329626679\n",
      "epoch: 11 step: 297, loss is 0.0006019721040502191\n",
      "epoch: 11 step: 298, loss is 0.0006475602276623249\n",
      "epoch: 11 step: 299, loss is 0.0008514054352417588\n",
      "epoch: 11 step: 300, loss is 0.000675015791784972\n",
      "epoch: 11 step: 301, loss is 0.001199397025629878\n",
      "epoch: 11 step: 302, loss is 0.0007425619987770915\n",
      "epoch: 11 step: 303, loss is 0.00041282139136455953\n",
      "epoch: 11 step: 304, loss is 0.0008364769746549428\n",
      "epoch: 11 step: 305, loss is 0.00036500123678706586\n",
      "epoch: 11 step: 306, loss is 0.0013365488266572356\n",
      "epoch: 11 step: 307, loss is 0.0006029147189110518\n",
      "epoch: 11 step: 308, loss is 0.0006791381747461855\n",
      "epoch: 11 step: 309, loss is 0.00020293232228141278\n",
      "epoch: 11 step: 310, loss is 0.0007136092172004282\n",
      "epoch: 11 step: 311, loss is 0.0005799647769890726\n",
      "epoch: 11 step: 312, loss is 0.0008003097027540207\n",
      "epoch: 11 step: 313, loss is 0.00041653792141005397\n",
      "epoch: 11 step: 314, loss is 0.0005632304237224162\n",
      "epoch: 11 step: 315, loss is 0.0008039727108553052\n",
      "epoch: 11 step: 316, loss is 0.001770487637259066\n",
      "epoch: 11 step: 317, loss is 0.0008764633093960583\n",
      "epoch: 11 step: 318, loss is 0.0006514309206977487\n",
      "epoch: 11 step: 319, loss is 0.001054058433510363\n",
      "epoch: 11 step: 320, loss is 0.001049179583787918\n",
      "epoch: 11 step: 321, loss is 0.0022675651125609875\n",
      "epoch: 11 step: 322, loss is 0.0009451920632272959\n",
      "epoch: 11 step: 323, loss is 0.0004402630729600787\n",
      "epoch: 11 step: 324, loss is 0.0010930775897577405\n",
      "epoch: 11 step: 325, loss is 0.00042091822251677513\n",
      "epoch: 11 step: 326, loss is 0.001346470438875258\n",
      "epoch: 11 step: 327, loss is 0.00020369382400531322\n",
      "epoch: 11 step: 328, loss is 0.0003976175212301314\n",
      "epoch: 11 step: 329, loss is 0.0012813135981559753\n",
      "epoch: 11 step: 330, loss is 0.0006138443714007735\n",
      "epoch: 11 step: 331, loss is 0.0005344851524569094\n",
      "epoch: 11 step: 332, loss is 0.0011150013888254762\n",
      "epoch: 11 step: 333, loss is 0.0004873665457125753\n",
      "epoch: 11 step: 334, loss is 0.0006250250735320151\n",
      "epoch: 11 step: 335, loss is 0.0010591461323201656\n",
      "epoch: 11 step: 336, loss is 0.0002876793732866645\n",
      "epoch: 11 step: 337, loss is 0.0005099010304547846\n",
      "epoch: 11 step: 338, loss is 0.0007293117232620716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 339, loss is 0.0006264543626457453\n",
      "epoch: 11 step: 340, loss is 0.0007793161203153431\n",
      "epoch: 11 step: 341, loss is 0.0005660184542648494\n",
      "epoch: 11 step: 342, loss is 0.0007058182964101434\n",
      "epoch: 11 step: 343, loss is 0.0008608697098679841\n",
      "epoch: 11 step: 344, loss is 0.00025512176216579974\n",
      "epoch: 11 step: 345, loss is 0.00048606592463329434\n",
      "epoch: 11 step: 346, loss is 0.0003301975957583636\n",
      "epoch: 11 step: 347, loss is 0.0008718157769180834\n",
      "epoch: 11 step: 348, loss is 0.0012909142533317208\n",
      "epoch: 11 step: 349, loss is 0.0004112222814001143\n",
      "epoch: 11 step: 350, loss is 0.0009665258112363517\n",
      "epoch: 11 step: 351, loss is 0.0006890539661981165\n",
      "epoch: 11 step: 352, loss is 0.0004991929163224995\n",
      "epoch: 11 step: 353, loss is 0.0008380788494832814\n",
      "epoch: 11 step: 354, loss is 0.00028951969579793513\n",
      "epoch: 11 step: 355, loss is 0.0006955955177545547\n",
      "epoch: 11 step: 356, loss is 0.0015711173182353377\n",
      "epoch: 11 step: 357, loss is 0.0008240574970841408\n",
      "epoch: 11 step: 358, loss is 0.0013927059480920434\n",
      "epoch: 11 step: 359, loss is 0.0009782947599887848\n",
      "epoch: 11 step: 360, loss is 0.0007668635225854814\n",
      "epoch: 11 step: 361, loss is 0.0006489056977443397\n",
      "epoch: 11 step: 362, loss is 0.0009416477405466139\n",
      "epoch: 11 step: 363, loss is 0.00094650371465832\n",
      "epoch: 11 step: 364, loss is 0.0007855532458052039\n",
      "epoch: 11 step: 365, loss is 0.0012030147481709719\n",
      "epoch: 11 step: 366, loss is 0.0008645587950013578\n",
      "epoch: 11 step: 367, loss is 0.00018827637541107833\n",
      "epoch: 11 step: 368, loss is 0.0011424950789660215\n",
      "epoch: 11 step: 369, loss is 0.0004990571178495884\n",
      "epoch: 11 step: 370, loss is 0.0002121762663591653\n",
      "epoch: 11 step: 371, loss is 0.0007170792086981237\n",
      "epoch: 11 step: 372, loss is 0.00034754571970552206\n",
      "epoch: 11 step: 373, loss is 0.00026943307602778077\n",
      "epoch: 11 step: 374, loss is 0.0009744035778567195\n",
      "epoch: 11 step: 375, loss is 0.0005246687796898186\n",
      "Train epoch time: 11939.886 ms, per step time: 31.840 ms\n",
      "epoch: 12 step: 1, loss is 0.0008931790362112224\n",
      "epoch: 12 step: 2, loss is 0.0005069786566309631\n",
      "epoch: 12 step: 3, loss is 0.0009083208860829473\n",
      "epoch: 12 step: 4, loss is 0.0004262438742443919\n",
      "epoch: 12 step: 5, loss is 0.0005834030453115702\n",
      "epoch: 12 step: 6, loss is 0.000789482204709202\n",
      "epoch: 12 step: 7, loss is 0.0008616354898549616\n",
      "epoch: 12 step: 8, loss is 0.0010722067672759295\n",
      "epoch: 12 step: 9, loss is 0.0009344877325929701\n",
      "epoch: 12 step: 10, loss is 0.0024116088170558214\n",
      "epoch: 12 step: 11, loss is 0.0001389959070365876\n",
      "epoch: 12 step: 12, loss is 0.00025484245270490646\n",
      "epoch: 12 step: 13, loss is 0.0006353599019348621\n",
      "epoch: 12 step: 14, loss is 0.000732197193428874\n",
      "epoch: 12 step: 15, loss is 0.0013588321162387729\n",
      "epoch: 12 step: 16, loss is 0.0004829225654248148\n",
      "epoch: 12 step: 17, loss is 0.001150607131421566\n",
      "epoch: 12 step: 18, loss is 0.0004326124908402562\n",
      "epoch: 12 step: 19, loss is 0.0005800123908556998\n",
      "epoch: 12 step: 20, loss is 0.00014386576367542148\n",
      "epoch: 12 step: 21, loss is 0.0008352220174856484\n",
      "epoch: 12 step: 22, loss is 0.00103985785972327\n",
      "epoch: 12 step: 23, loss is 0.0005204463959671557\n",
      "epoch: 12 step: 24, loss is 0.0008741920464672148\n",
      "epoch: 12 step: 25, loss is 0.00036068056942895055\n",
      "epoch: 12 step: 26, loss is 0.00019171216990798712\n",
      "epoch: 12 step: 27, loss is 0.0004259265260770917\n",
      "epoch: 12 step: 28, loss is 0.0009932632092386484\n",
      "epoch: 12 step: 29, loss is 0.0008891680627129972\n",
      "epoch: 12 step: 30, loss is 0.0006192580913193524\n",
      "epoch: 12 step: 31, loss is 0.000712726206984371\n",
      "epoch: 12 step: 32, loss is 0.000495341548230499\n",
      "epoch: 12 step: 33, loss is 0.0013915036106482148\n",
      "epoch: 12 step: 34, loss is 0.0004117648641113192\n",
      "epoch: 12 step: 35, loss is 0.001446340698748827\n",
      "epoch: 12 step: 36, loss is 0.00023783471260685474\n",
      "epoch: 12 step: 37, loss is 0.0004497627669479698\n",
      "epoch: 12 step: 38, loss is 0.0011878537479788065\n",
      "epoch: 12 step: 39, loss is 0.00046668044524267316\n",
      "epoch: 12 step: 40, loss is 0.0009164756629616022\n",
      "epoch: 12 step: 41, loss is 0.0006124454084783792\n",
      "epoch: 12 step: 42, loss is 0.0003404835588298738\n",
      "epoch: 12 step: 43, loss is 0.00031052069971337914\n",
      "epoch: 12 step: 44, loss is 0.0008903347188606858\n",
      "epoch: 12 step: 45, loss is 0.0004687238542828709\n",
      "epoch: 12 step: 46, loss is 0.00026169500779360533\n",
      "epoch: 12 step: 47, loss is 0.0006055515259504318\n",
      "epoch: 12 step: 48, loss is 0.0006372433854267001\n",
      "epoch: 12 step: 49, loss is 0.0004228017060086131\n",
      "epoch: 12 step: 50, loss is 0.0008868516888469458\n",
      "epoch: 12 step: 51, loss is 0.0008377721533179283\n",
      "epoch: 12 step: 52, loss is 0.0007549611618742347\n",
      "epoch: 12 step: 53, loss is 0.0011996214743703604\n",
      "epoch: 12 step: 54, loss is 0.0007028584368526936\n",
      "epoch: 12 step: 55, loss is 0.0009290206362493336\n",
      "epoch: 12 step: 56, loss is 0.0007697045803070068\n",
      "epoch: 12 step: 57, loss is 0.0004794183769263327\n",
      "epoch: 12 step: 58, loss is 0.0007694973610341549\n",
      "epoch: 12 step: 59, loss is 0.0003195816825609654\n",
      "epoch: 12 step: 60, loss is 0.0005803927197121084\n",
      "epoch: 12 step: 61, loss is 0.001061688526533544\n",
      "epoch: 12 step: 62, loss is 0.00047193150385282934\n",
      "epoch: 12 step: 63, loss is 0.0006286233547143638\n",
      "epoch: 12 step: 64, loss is 0.0005479127285070717\n",
      "epoch: 12 step: 65, loss is 0.0004556395288091153\n",
      "epoch: 12 step: 66, loss is 0.0010265936143696308\n",
      "epoch: 12 step: 67, loss is 0.0006817627581767738\n",
      "epoch: 12 step: 68, loss is 0.0017215994885191321\n",
      "epoch: 12 step: 69, loss is 0.00037674905615858734\n",
      "epoch: 12 step: 70, loss is 0.0012221005745232105\n",
      "epoch: 12 step: 71, loss is 0.0006529291276820004\n",
      "epoch: 12 step: 72, loss is 0.0014147708425298333\n",
      "epoch: 12 step: 73, loss is 0.0009859196143224835\n",
      "epoch: 12 step: 74, loss is 0.0005169065552763641\n",
      "epoch: 12 step: 75, loss is 0.0010820486349985003\n",
      "epoch: 12 step: 76, loss is 0.0007628095336258411\n",
      "epoch: 12 step: 77, loss is 0.000357841927325353\n",
      "epoch: 12 step: 78, loss is 0.0007419388857670128\n",
      "epoch: 12 step: 79, loss is 0.0008675734279677272\n",
      "epoch: 12 step: 80, loss is 0.00051734724547714\n",
      "epoch: 12 step: 81, loss is 0.0008473569178022444\n",
      "epoch: 12 step: 82, loss is 0.0010032313875854015\n",
      "epoch: 12 step: 83, loss is 0.0005916485679335892\n",
      "epoch: 12 step: 84, loss is 0.0004271898069418967\n",
      "epoch: 12 step: 85, loss is 0.0012801379198208451\n",
      "epoch: 12 step: 86, loss is 0.0008837798959575593\n",
      "epoch: 12 step: 87, loss is 0.00041161058470606804\n",
      "epoch: 12 step: 88, loss is 0.000909610535018146\n",
      "epoch: 12 step: 89, loss is 0.0002579280990175903\n",
      "epoch: 12 step: 90, loss is 0.0013882219791412354\n",
      "epoch: 12 step: 91, loss is 0.0007592398906126618\n",
      "epoch: 12 step: 92, loss is 0.000531783327460289\n",
      "epoch: 12 step: 93, loss is 0.0006987570086494088\n",
      "epoch: 12 step: 94, loss is 0.0007953765452839434\n",
      "epoch: 12 step: 95, loss is 0.0012924126349389553\n",
      "epoch: 12 step: 96, loss is 0.000623203522991389\n",
      "epoch: 12 step: 97, loss is 0.0009479293948970735\n",
      "epoch: 12 step: 98, loss is 0.0005193366669118404\n",
      "epoch: 12 step: 99, loss is 0.0010721641592681408\n",
      "epoch: 12 step: 100, loss is 0.00041626847814768553\n",
      "epoch: 12 step: 101, loss is 0.00022493026335723698\n",
      "epoch: 12 step: 102, loss is 0.0014683561166748405\n",
      "epoch: 12 step: 103, loss is 0.0005661119357682765\n",
      "epoch: 12 step: 104, loss is 0.0005974735831841826\n",
      "epoch: 12 step: 105, loss is 0.0006009373464621603\n",
      "epoch: 12 step: 106, loss is 0.0004416221927385777\n",
      "epoch: 12 step: 107, loss is 0.0014579746639356017\n",
      "epoch: 12 step: 108, loss is 0.0004484742821659893\n",
      "epoch: 12 step: 109, loss is 0.0013945234240964055\n",
      "epoch: 12 step: 110, loss is 0.000577569124288857\n",
      "epoch: 12 step: 111, loss is 0.0005990200443193316\n",
      "epoch: 12 step: 112, loss is 0.00031512760324403644\n",
      "epoch: 12 step: 113, loss is 0.00031370832584798336\n",
      "epoch: 12 step: 114, loss is 0.0009901558514684439\n",
      "epoch: 12 step: 115, loss is 0.0011309924302622676\n",
      "epoch: 12 step: 116, loss is 0.0012005300959572196\n",
      "epoch: 12 step: 117, loss is 0.00030391538166441023\n",
      "epoch: 12 step: 118, loss is 0.0009103642078116536\n",
      "epoch: 12 step: 119, loss is 0.0019071899587288499\n",
      "epoch: 12 step: 120, loss is 0.0008813866879791021\n",
      "epoch: 12 step: 121, loss is 0.0013529218267649412\n",
      "epoch: 12 step: 122, loss is 0.0005332698347046971\n",
      "epoch: 12 step: 123, loss is 0.0010864305077120662\n",
      "epoch: 12 step: 124, loss is 0.0007329553482122719\n",
      "epoch: 12 step: 125, loss is 0.0005388186546042562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 126, loss is 0.000661620288155973\n",
      "epoch: 12 step: 127, loss is 0.0005496556404978037\n",
      "epoch: 12 step: 128, loss is 0.000566445232834667\n",
      "epoch: 12 step: 129, loss is 0.0005430541350506246\n",
      "epoch: 12 step: 130, loss is 0.00046402725274674594\n",
      "epoch: 12 step: 131, loss is 0.0005570187931880355\n",
      "epoch: 12 step: 132, loss is 0.0009627383551560342\n",
      "epoch: 12 step: 133, loss is 0.0005404843250289559\n",
      "epoch: 12 step: 134, loss is 0.0004617924860212952\n",
      "epoch: 12 step: 135, loss is 0.0003792324278037995\n",
      "epoch: 12 step: 136, loss is 0.0003659637877717614\n",
      "epoch: 12 step: 137, loss is 0.0008375108009204268\n",
      "epoch: 12 step: 138, loss is 0.0004959535435773432\n",
      "epoch: 12 step: 139, loss is 0.00042938199476338923\n",
      "epoch: 12 step: 140, loss is 0.00027644159854389727\n",
      "epoch: 12 step: 141, loss is 0.0006444001337513328\n",
      "epoch: 12 step: 142, loss is 0.0004369655507616699\n",
      "epoch: 12 step: 143, loss is 0.0005189312505535781\n",
      "epoch: 12 step: 144, loss is 0.0010550571605563164\n",
      "epoch: 12 step: 145, loss is 0.001023811288177967\n",
      "epoch: 12 step: 146, loss is 0.0005462435074150562\n",
      "epoch: 12 step: 147, loss is 0.0010497035691514611\n",
      "epoch: 12 step: 148, loss is 0.0008539402042515576\n",
      "epoch: 12 step: 149, loss is 0.000243075453909114\n",
      "epoch: 12 step: 150, loss is 0.001579254399985075\n",
      "epoch: 12 step: 151, loss is 0.00040066431392915547\n",
      "epoch: 12 step: 152, loss is 0.001685924013145268\n",
      "epoch: 12 step: 153, loss is 0.0012121363542973995\n",
      "epoch: 12 step: 154, loss is 0.0013146194396540523\n",
      "epoch: 12 step: 155, loss is 0.000707291008438915\n",
      "epoch: 12 step: 156, loss is 0.0009245709516108036\n",
      "epoch: 12 step: 157, loss is 0.0003594894369598478\n",
      "epoch: 12 step: 158, loss is 0.001126581453718245\n",
      "epoch: 12 step: 159, loss is 0.0003345958248246461\n",
      "epoch: 12 step: 160, loss is 0.0021138833835721016\n",
      "epoch: 12 step: 161, loss is 0.0003968646633438766\n",
      "epoch: 12 step: 162, loss is 0.00036976300179958344\n",
      "epoch: 12 step: 163, loss is 0.0006331941694952548\n",
      "epoch: 12 step: 164, loss is 0.0005945560405962169\n",
      "epoch: 12 step: 165, loss is 0.0004318934225011617\n",
      "epoch: 12 step: 166, loss is 0.0006570515688508749\n",
      "epoch: 12 step: 167, loss is 0.0005349842249415815\n",
      "epoch: 12 step: 168, loss is 0.0006939379381947219\n",
      "epoch: 12 step: 169, loss is 0.00047063137753866613\n",
      "epoch: 12 step: 170, loss is 0.0009456109837628901\n",
      "epoch: 12 step: 171, loss is 0.0009379264083690941\n",
      "epoch: 12 step: 172, loss is 0.0008134521194733679\n",
      "epoch: 12 step: 173, loss is 0.0006014790269546211\n",
      "epoch: 12 step: 174, loss is 0.0005327853141352534\n",
      "epoch: 12 step: 175, loss is 0.00033547577913850546\n",
      "epoch: 12 step: 176, loss is 0.0005608440842479467\n",
      "epoch: 12 step: 177, loss is 0.0002805020776577294\n",
      "epoch: 12 step: 178, loss is 0.00029758995515294373\n",
      "epoch: 12 step: 179, loss is 0.0010872369166463614\n",
      "epoch: 12 step: 180, loss is 0.0003955367428716272\n",
      "epoch: 12 step: 181, loss is 0.0004037003091070801\n",
      "epoch: 12 step: 182, loss is 0.0004911188734695315\n",
      "epoch: 12 step: 183, loss is 0.0005633347318507731\n",
      "epoch: 12 step: 184, loss is 0.0007928122067824006\n",
      "epoch: 12 step: 185, loss is 0.000379474920919165\n",
      "epoch: 12 step: 186, loss is 0.000788031320553273\n",
      "epoch: 12 step: 187, loss is 0.0005303201614879072\n",
      "epoch: 12 step: 188, loss is 0.0009245376568287611\n",
      "epoch: 12 step: 189, loss is 0.00030215649167075753\n",
      "epoch: 12 step: 190, loss is 0.0004242827126290649\n",
      "epoch: 12 step: 191, loss is 0.0021043242886662483\n",
      "epoch: 12 step: 192, loss is 0.0013284350279718637\n",
      "epoch: 12 step: 193, loss is 0.0019150292500853539\n",
      "epoch: 12 step: 194, loss is 0.0006924067856743932\n",
      "epoch: 12 step: 195, loss is 0.0005681123002432287\n",
      "epoch: 12 step: 196, loss is 0.00010339137224946171\n",
      "epoch: 12 step: 197, loss is 0.0005316516617313027\n",
      "epoch: 12 step: 198, loss is 0.0003576622111722827\n",
      "epoch: 12 step: 199, loss is 0.0009373805369250476\n",
      "epoch: 12 step: 200, loss is 0.00046744325663894415\n",
      "epoch: 12 step: 201, loss is 0.0006071286625228822\n",
      "epoch: 12 step: 202, loss is 0.0009467282216064632\n",
      "epoch: 12 step: 203, loss is 0.0014675906859338284\n",
      "epoch: 12 step: 204, loss is 0.001886513433419168\n",
      "epoch: 12 step: 205, loss is 0.0005777893820777535\n",
      "epoch: 12 step: 206, loss is 0.0003224314423277974\n",
      "epoch: 12 step: 207, loss is 0.0006851567886769772\n",
      "epoch: 12 step: 208, loss is 0.000803800649009645\n",
      "epoch: 12 step: 209, loss is 0.0006712321774102747\n",
      "epoch: 12 step: 210, loss is 0.0004471667343750596\n",
      "epoch: 12 step: 211, loss is 0.0005335423047654331\n",
      "epoch: 12 step: 212, loss is 0.0005880374810658395\n",
      "epoch: 12 step: 213, loss is 0.0008608888019807637\n",
      "epoch: 12 step: 214, loss is 0.0006504278862848878\n",
      "epoch: 12 step: 215, loss is 0.0006353670032694936\n",
      "epoch: 12 step: 216, loss is 0.0005135748069733381\n",
      "epoch: 12 step: 217, loss is 0.0009693888132460415\n",
      "epoch: 12 step: 218, loss is 0.0014544283039867878\n",
      "epoch: 12 step: 219, loss is 0.0010194755159318447\n",
      "epoch: 12 step: 220, loss is 0.00046115313307382166\n",
      "epoch: 12 step: 221, loss is 0.0010291672078892589\n",
      "epoch: 12 step: 222, loss is 0.0008453194168396294\n",
      "epoch: 12 step: 223, loss is 0.0005640501040033996\n",
      "epoch: 12 step: 224, loss is 0.0002902028791140765\n",
      "epoch: 12 step: 225, loss is 0.00045924633741378784\n",
      "epoch: 12 step: 226, loss is 0.0008651312091387808\n",
      "epoch: 12 step: 227, loss is 0.0007085886900313199\n",
      "epoch: 12 step: 228, loss is 0.000646580068860203\n",
      "epoch: 12 step: 229, loss is 0.0005584848113358021\n",
      "epoch: 12 step: 230, loss is 0.0007369498489424586\n",
      "epoch: 12 step: 231, loss is 0.0007647641468793154\n",
      "epoch: 12 step: 232, loss is 0.0008548623300157487\n",
      "epoch: 12 step: 233, loss is 0.00027803119155578315\n",
      "epoch: 12 step: 234, loss is 0.0005222702748142183\n",
      "epoch: 12 step: 235, loss is 0.000495949003379792\n",
      "epoch: 12 step: 236, loss is 0.0006180059863254428\n",
      "epoch: 12 step: 237, loss is 0.0004360216553322971\n",
      "epoch: 12 step: 238, loss is 0.0009999906178563833\n",
      "epoch: 12 step: 239, loss is 0.0003703449619933963\n",
      "epoch: 12 step: 240, loss is 0.0006027041235938668\n",
      "epoch: 12 step: 241, loss is 0.0010517118498682976\n",
      "epoch: 12 step: 242, loss is 0.00031591905280947685\n",
      "epoch: 12 step: 243, loss is 0.0005120392306707799\n",
      "epoch: 12 step: 244, loss is 0.0007721296278759837\n",
      "epoch: 12 step: 245, loss is 0.0007254161173477769\n",
      "epoch: 12 step: 246, loss is 0.0009135595173574984\n",
      "epoch: 12 step: 247, loss is 0.000837076804600656\n",
      "epoch: 12 step: 248, loss is 0.0004837092128582299\n",
      "epoch: 12 step: 249, loss is 0.0005888480227440596\n",
      "epoch: 12 step: 250, loss is 0.0004216798988636583\n",
      "epoch: 12 step: 251, loss is 0.0011143576120957732\n",
      "epoch: 12 step: 252, loss is 0.0007759332656860352\n",
      "epoch: 12 step: 253, loss is 0.0006103218183852732\n",
      "epoch: 12 step: 254, loss is 0.0008306435192935169\n",
      "epoch: 12 step: 255, loss is 0.0003236218180973083\n",
      "epoch: 12 step: 256, loss is 0.00046401459258049726\n",
      "epoch: 12 step: 257, loss is 0.0002628520887810737\n",
      "epoch: 12 step: 258, loss is 0.0006505363271571696\n",
      "epoch: 12 step: 259, loss is 0.0012219882337376475\n",
      "epoch: 12 step: 260, loss is 0.0003258932556491345\n",
      "epoch: 12 step: 261, loss is 0.0003020008734893054\n",
      "epoch: 12 step: 262, loss is 0.0008825759869068861\n",
      "epoch: 12 step: 263, loss is 0.00024216667225118726\n",
      "epoch: 12 step: 264, loss is 0.0004452341527212411\n",
      "epoch: 12 step: 265, loss is 0.0010732589289546013\n",
      "epoch: 12 step: 266, loss is 0.0003339581307955086\n",
      "epoch: 12 step: 267, loss is 0.000631216331385076\n",
      "epoch: 12 step: 268, loss is 0.00029044030816294253\n",
      "epoch: 12 step: 269, loss is 0.000646802771370858\n",
      "epoch: 12 step: 270, loss is 0.0010326500050723553\n",
      "epoch: 12 step: 271, loss is 0.00042016032966785133\n",
      "epoch: 12 step: 272, loss is 0.0006884108879603446\n",
      "epoch: 12 step: 273, loss is 0.0011094361543655396\n",
      "epoch: 12 step: 274, loss is 0.0012780879624187946\n",
      "epoch: 12 step: 275, loss is 0.0002786783443298191\n",
      "epoch: 12 step: 276, loss is 0.0014240448363125324\n",
      "epoch: 12 step: 277, loss is 0.0007940179784782231\n",
      "epoch: 12 step: 278, loss is 0.0008153009111993015\n",
      "epoch: 12 step: 279, loss is 0.001924246782436967\n",
      "epoch: 12 step: 280, loss is 0.0011339730117470026\n",
      "epoch: 12 step: 281, loss is 0.0002061347186099738\n",
      "epoch: 12 step: 282, loss is 0.0007214666111394763\n",
      "epoch: 12 step: 283, loss is 0.000663929502479732\n",
      "epoch: 12 step: 284, loss is 0.0006525862263515592\n",
      "epoch: 12 step: 285, loss is 0.0004173946217633784\n",
      "epoch: 12 step: 286, loss is 0.0010959248756989837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 287, loss is 0.0004435582959558815\n",
      "epoch: 12 step: 288, loss is 0.0003083925403188914\n",
      "epoch: 12 step: 289, loss is 0.0007184644928202033\n",
      "epoch: 12 step: 290, loss is 0.0009314336348325014\n",
      "epoch: 12 step: 291, loss is 0.0017522562993690372\n",
      "epoch: 12 step: 292, loss is 0.0014195396797731519\n",
      "epoch: 12 step: 293, loss is 0.0010070294374600053\n",
      "epoch: 12 step: 294, loss is 0.0005061175907030702\n",
      "epoch: 12 step: 295, loss is 0.0012610094854608178\n",
      "epoch: 12 step: 296, loss is 0.00041265232721343637\n",
      "epoch: 12 step: 297, loss is 0.000577724480535835\n",
      "epoch: 12 step: 298, loss is 0.00027601842884905636\n",
      "epoch: 12 step: 299, loss is 0.0005681069451384246\n",
      "epoch: 12 step: 300, loss is 0.00024614357971586287\n",
      "epoch: 12 step: 301, loss is 0.00032757417648099363\n",
      "epoch: 12 step: 302, loss is 0.0014997797552496195\n",
      "epoch: 12 step: 303, loss is 0.0011226508067920804\n",
      "epoch: 12 step: 304, loss is 0.0009515010751783848\n",
      "epoch: 12 step: 305, loss is 0.0008004596456885338\n",
      "epoch: 12 step: 306, loss is 0.0013528545387089252\n",
      "epoch: 12 step: 307, loss is 0.0012375093065202236\n",
      "epoch: 12 step: 308, loss is 0.0009106594370678067\n",
      "epoch: 12 step: 309, loss is 0.000936255615670234\n",
      "epoch: 12 step: 310, loss is 0.0012334028724581003\n",
      "epoch: 12 step: 311, loss is 0.0004663635918404907\n",
      "epoch: 12 step: 312, loss is 0.0005777447950094938\n",
      "epoch: 12 step: 313, loss is 0.001255886279977858\n",
      "epoch: 12 step: 314, loss is 0.00018251074652653188\n",
      "epoch: 12 step: 315, loss is 0.00046815391397103667\n",
      "epoch: 12 step: 316, loss is 0.0008960597333498299\n",
      "epoch: 12 step: 317, loss is 0.0005718157044611871\n",
      "epoch: 12 step: 318, loss is 0.0004543933318927884\n",
      "epoch: 12 step: 319, loss is 0.0003077916626352817\n",
      "epoch: 12 step: 320, loss is 0.000637244840618223\n",
      "epoch: 12 step: 321, loss is 0.0007244592998176813\n",
      "epoch: 12 step: 322, loss is 0.001034173066727817\n",
      "epoch: 12 step: 323, loss is 0.000938188808504492\n",
      "epoch: 12 step: 324, loss is 0.0002544272574596107\n",
      "epoch: 12 step: 325, loss is 0.00078721868339926\n",
      "epoch: 12 step: 326, loss is 0.0005590654327534139\n",
      "epoch: 12 step: 327, loss is 0.0009964952478185296\n",
      "epoch: 12 step: 328, loss is 0.0004531067388597876\n",
      "epoch: 12 step: 329, loss is 0.0005875936476513743\n",
      "epoch: 12 step: 330, loss is 0.0004735784896183759\n",
      "epoch: 12 step: 331, loss is 0.0006628609844483435\n",
      "epoch: 12 step: 332, loss is 0.001825334969907999\n",
      "epoch: 12 step: 333, loss is 0.00035713615943677723\n",
      "epoch: 12 step: 334, loss is 0.0006209320854395628\n",
      "epoch: 12 step: 335, loss is 0.0004800018505193293\n",
      "epoch: 12 step: 336, loss is 0.0008385444525629282\n",
      "epoch: 12 step: 337, loss is 0.00042613697587512434\n",
      "epoch: 12 step: 338, loss is 0.0006412537768483162\n",
      "epoch: 12 step: 339, loss is 0.0009507854701951146\n",
      "epoch: 12 step: 340, loss is 0.00025623603141866624\n",
      "epoch: 12 step: 341, loss is 0.0001911781437229365\n",
      "epoch: 12 step: 342, loss is 0.0013864119537174702\n",
      "epoch: 12 step: 343, loss is 0.00022484036162495613\n",
      "epoch: 12 step: 344, loss is 0.0004502198426052928\n",
      "epoch: 12 step: 345, loss is 0.0007764564361423254\n",
      "epoch: 12 step: 346, loss is 0.001414253725670278\n",
      "epoch: 12 step: 347, loss is 0.00044085888657718897\n",
      "epoch: 12 step: 348, loss is 0.0005395321641117334\n",
      "epoch: 12 step: 349, loss is 0.0002712355926632881\n",
      "epoch: 12 step: 350, loss is 0.0007477703620679677\n",
      "epoch: 12 step: 351, loss is 0.0008474757196381688\n",
      "epoch: 12 step: 352, loss is 0.0011323281796649098\n",
      "epoch: 12 step: 353, loss is 0.0003633031446952373\n",
      "epoch: 12 step: 354, loss is 0.0007136716158129275\n",
      "epoch: 12 step: 355, loss is 0.0012622871436178684\n",
      "epoch: 12 step: 356, loss is 0.000388028915040195\n",
      "epoch: 12 step: 357, loss is 0.0003249658620916307\n",
      "epoch: 12 step: 358, loss is 0.0007904836675152183\n",
      "epoch: 12 step: 359, loss is 0.00026576040545478463\n",
      "epoch: 12 step: 360, loss is 0.0001286949700443074\n",
      "epoch: 12 step: 361, loss is 0.001160593586973846\n",
      "epoch: 12 step: 362, loss is 0.0011645249323919415\n",
      "epoch: 12 step: 363, loss is 0.00119592749979347\n",
      "epoch: 12 step: 364, loss is 0.0012137637240812182\n",
      "epoch: 12 step: 365, loss is 0.0007640968542546034\n",
      "epoch: 12 step: 366, loss is 0.0008995554526336491\n",
      "epoch: 12 step: 367, loss is 0.0010483291698619723\n",
      "epoch: 12 step: 368, loss is 0.0006023584282957017\n",
      "epoch: 12 step: 369, loss is 0.0006114490097388625\n",
      "epoch: 12 step: 370, loss is 0.0006261395756155252\n",
      "epoch: 12 step: 371, loss is 0.00010446745727676898\n",
      "epoch: 12 step: 372, loss is 0.001316405599936843\n",
      "epoch: 12 step: 373, loss is 0.0002668921952135861\n",
      "epoch: 12 step: 374, loss is 0.0004259445413481444\n",
      "epoch: 12 step: 375, loss is 0.0014521866105496883\n",
      "Train epoch time: 11911.182 ms, per step time: 31.763 ms\n",
      "epoch: 13 step: 1, loss is 0.0004139759112149477\n",
      "epoch: 13 step: 2, loss is 0.00020573960500769317\n",
      "epoch: 13 step: 3, loss is 0.0004321386222727597\n",
      "epoch: 13 step: 4, loss is 0.0005624821060337126\n",
      "epoch: 13 step: 5, loss is 0.0010952792363241315\n",
      "epoch: 13 step: 6, loss is 0.0007462462526746094\n",
      "epoch: 13 step: 7, loss is 0.0006923762266524136\n",
      "epoch: 13 step: 8, loss is 0.0005342238582670689\n",
      "epoch: 13 step: 9, loss is 0.0008590264478698373\n",
      "epoch: 13 step: 10, loss is 0.0008281274931505322\n",
      "epoch: 13 step: 11, loss is 0.0005225537461228669\n",
      "epoch: 13 step: 12, loss is 0.001349787344224751\n",
      "epoch: 13 step: 13, loss is 0.00039421446854248643\n",
      "epoch: 13 step: 14, loss is 0.000523253227584064\n",
      "epoch: 13 step: 15, loss is 0.001083899987861514\n",
      "epoch: 13 step: 16, loss is 0.0005204124609008431\n",
      "epoch: 13 step: 17, loss is 0.0006064962362870574\n",
      "epoch: 13 step: 18, loss is 0.000438246235717088\n",
      "epoch: 13 step: 19, loss is 0.00047096575144678354\n",
      "epoch: 13 step: 20, loss is 0.000512733357027173\n",
      "epoch: 13 step: 21, loss is 0.0008893692283891141\n",
      "epoch: 13 step: 22, loss is 0.0003315674257464707\n",
      "epoch: 13 step: 23, loss is 0.0011025449493899941\n",
      "epoch: 13 step: 24, loss is 0.001329712918959558\n",
      "epoch: 13 step: 25, loss is 0.0009183441288769245\n",
      "epoch: 13 step: 26, loss is 0.0003846210311166942\n",
      "epoch: 13 step: 27, loss is 0.0004077545600011945\n",
      "epoch: 13 step: 28, loss is 0.001691198442131281\n",
      "epoch: 13 step: 29, loss is 0.0009672405431047082\n",
      "epoch: 13 step: 30, loss is 0.000479063339298591\n",
      "epoch: 13 step: 31, loss is 0.0004498715861700475\n",
      "epoch: 13 step: 32, loss is 0.0006493217078968883\n",
      "epoch: 13 step: 33, loss is 0.0005487138987518847\n",
      "epoch: 13 step: 34, loss is 0.0005657831788994372\n",
      "epoch: 13 step: 35, loss is 0.0007552123861387372\n",
      "epoch: 13 step: 36, loss is 0.001104541472159326\n",
      "epoch: 13 step: 37, loss is 0.0004676763783209026\n",
      "epoch: 13 step: 38, loss is 0.00044159451499581337\n",
      "epoch: 13 step: 39, loss is 0.0003410231729503721\n",
      "epoch: 13 step: 40, loss is 0.0005970826605334878\n",
      "epoch: 13 step: 41, loss is 0.0007229312905110419\n",
      "epoch: 13 step: 42, loss is 0.0008066411246545613\n",
      "epoch: 13 step: 43, loss is 0.0008679308812133968\n",
      "epoch: 13 step: 44, loss is 0.0018438877305015922\n",
      "epoch: 13 step: 45, loss is 0.0011904551647603512\n",
      "epoch: 13 step: 46, loss is 0.0002964468440040946\n",
      "epoch: 13 step: 47, loss is 0.0004507422272581607\n",
      "epoch: 13 step: 48, loss is 0.0007544277468696237\n",
      "epoch: 13 step: 49, loss is 0.0004929345450364053\n",
      "epoch: 13 step: 50, loss is 0.0006939581944607198\n",
      "epoch: 13 step: 51, loss is 0.0006083432235755026\n",
      "epoch: 13 step: 52, loss is 0.0015812887577340007\n",
      "epoch: 13 step: 53, loss is 0.00109904445707798\n",
      "epoch: 13 step: 54, loss is 0.0009726088610477746\n",
      "epoch: 13 step: 55, loss is 0.0012260061921551824\n",
      "epoch: 13 step: 56, loss is 0.000835334591101855\n",
      "epoch: 13 step: 57, loss is 0.00020828208653256297\n",
      "epoch: 13 step: 58, loss is 0.0011044067796319723\n",
      "epoch: 13 step: 59, loss is 0.00038686415064148605\n",
      "epoch: 13 step: 60, loss is 0.0004833591228816658\n",
      "epoch: 13 step: 61, loss is 0.0009417178225703537\n",
      "epoch: 13 step: 62, loss is 0.00018259962962474674\n",
      "epoch: 13 step: 63, loss is 0.0007062305230647326\n",
      "epoch: 13 step: 64, loss is 0.0007859280449338257\n",
      "epoch: 13 step: 65, loss is 0.0013899082550778985\n",
      "epoch: 13 step: 66, loss is 0.00043081134208478034\n",
      "epoch: 13 step: 67, loss is 0.0007852194830775261\n",
      "epoch: 13 step: 68, loss is 0.00013343477621674538\n",
      "epoch: 13 step: 69, loss is 0.0009821004932746291\n",
      "epoch: 13 step: 70, loss is 0.0005321941571310163\n",
      "epoch: 13 step: 71, loss is 0.0008332941215485334\n",
      "epoch: 13 step: 72, loss is 0.0003250902518630028\n",
      "epoch: 13 step: 73, loss is 0.0010087883565574884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 74, loss is 0.001170898205600679\n",
      "epoch: 13 step: 75, loss is 0.0010415267897769809\n",
      "epoch: 13 step: 76, loss is 0.0003734557831194252\n",
      "epoch: 13 step: 77, loss is 0.0007980710943229496\n",
      "epoch: 13 step: 78, loss is 0.0004405593208502978\n",
      "epoch: 13 step: 79, loss is 0.0008661164320074022\n",
      "epoch: 13 step: 80, loss is 0.0009180675260722637\n",
      "epoch: 13 step: 81, loss is 0.0005315078306011856\n",
      "epoch: 13 step: 82, loss is 0.0005050977342762053\n",
      "epoch: 13 step: 83, loss is 0.0006756779621355236\n",
      "epoch: 13 step: 84, loss is 0.0008598951390013099\n",
      "epoch: 13 step: 85, loss is 0.001146701630204916\n",
      "epoch: 13 step: 86, loss is 0.0007177670486271381\n",
      "epoch: 13 step: 87, loss is 0.0005409431760199368\n",
      "epoch: 13 step: 88, loss is 0.0013787777861580253\n",
      "epoch: 13 step: 89, loss is 0.0010288014309480786\n",
      "epoch: 13 step: 90, loss is 0.0005478716338984668\n",
      "epoch: 13 step: 91, loss is 0.0006342882988974452\n",
      "epoch: 13 step: 92, loss is 0.0006900916923768818\n",
      "epoch: 13 step: 93, loss is 0.0011005459818989038\n",
      "epoch: 13 step: 94, loss is 0.00024926307378336787\n",
      "epoch: 13 step: 95, loss is 0.0006047138595022261\n",
      "epoch: 13 step: 96, loss is 0.0013996866764500737\n",
      "epoch: 13 step: 97, loss is 0.0006713071488775313\n",
      "epoch: 13 step: 98, loss is 0.00047456900938414037\n",
      "epoch: 13 step: 99, loss is 0.0010375723941251636\n",
      "epoch: 13 step: 100, loss is 0.00048193184193223715\n",
      "epoch: 13 step: 101, loss is 0.0004544018884189427\n",
      "epoch: 13 step: 102, loss is 0.0002852494944818318\n",
      "epoch: 13 step: 103, loss is 0.00152862467803061\n",
      "epoch: 13 step: 104, loss is 0.0006092528929002583\n",
      "epoch: 13 step: 105, loss is 0.0010382892796769738\n",
      "epoch: 13 step: 106, loss is 0.00099468685220927\n",
      "epoch: 13 step: 107, loss is 0.00040058422018773854\n",
      "epoch: 13 step: 108, loss is 0.00085596734425053\n",
      "epoch: 13 step: 109, loss is 0.001236089738085866\n",
      "epoch: 13 step: 110, loss is 0.0006380820996128023\n",
      "epoch: 13 step: 111, loss is 0.00047249821363948286\n",
      "epoch: 13 step: 112, loss is 0.0008550281636416912\n",
      "epoch: 13 step: 113, loss is 0.00045040101394988596\n",
      "epoch: 13 step: 114, loss is 0.0008057727827690542\n",
      "epoch: 13 step: 115, loss is 0.0008944490691646934\n",
      "epoch: 13 step: 116, loss is 0.0003127790114376694\n",
      "epoch: 13 step: 117, loss is 0.0004859570472035557\n",
      "epoch: 13 step: 118, loss is 0.0006441731238737702\n",
      "epoch: 13 step: 119, loss is 0.0005482670967467129\n",
      "epoch: 13 step: 120, loss is 0.0011063636047765613\n",
      "epoch: 13 step: 121, loss is 0.0004990872694179416\n",
      "epoch: 13 step: 122, loss is 0.0012169203255325556\n",
      "epoch: 13 step: 123, loss is 0.0004901709617115557\n",
      "epoch: 13 step: 124, loss is 0.0007894728914834559\n",
      "epoch: 13 step: 125, loss is 0.00034057346056215465\n",
      "epoch: 13 step: 126, loss is 0.0003646067634690553\n",
      "epoch: 13 step: 127, loss is 0.0007619959651492536\n",
      "epoch: 13 step: 128, loss is 0.000648076122161001\n",
      "epoch: 13 step: 129, loss is 0.0013236014638096094\n",
      "epoch: 13 step: 130, loss is 0.0008436593343503773\n",
      "epoch: 13 step: 131, loss is 0.002011252334341407\n",
      "epoch: 13 step: 132, loss is 0.0005845176638104022\n",
      "epoch: 13 step: 133, loss is 0.0009380996343679726\n",
      "epoch: 13 step: 134, loss is 0.0003590287233237177\n",
      "epoch: 13 step: 135, loss is 0.0003511031100060791\n",
      "epoch: 13 step: 136, loss is 0.0011300001060590148\n",
      "epoch: 13 step: 137, loss is 0.00042879919055849314\n",
      "epoch: 13 step: 138, loss is 0.0009554167045280337\n",
      "epoch: 13 step: 139, loss is 0.0006970744580030441\n",
      "epoch: 13 step: 140, loss is 0.0004865408409386873\n",
      "epoch: 13 step: 141, loss is 0.0007412913837470114\n",
      "epoch: 13 step: 142, loss is 0.000260088563663885\n",
      "epoch: 13 step: 143, loss is 0.0007417708402499557\n",
      "epoch: 13 step: 144, loss is 0.0011559431441128254\n",
      "epoch: 13 step: 145, loss is 0.00024854883668012917\n",
      "epoch: 13 step: 146, loss is 0.000529036857187748\n",
      "epoch: 13 step: 147, loss is 0.0025060675106942654\n",
      "epoch: 13 step: 148, loss is 0.0003961331385653466\n",
      "epoch: 13 step: 149, loss is 0.001004766090773046\n",
      "epoch: 13 step: 150, loss is 0.00043706875294446945\n",
      "epoch: 13 step: 151, loss is 0.0005287620588205755\n",
      "epoch: 13 step: 152, loss is 0.0006174762384034693\n",
      "epoch: 13 step: 153, loss is 0.0004797075816895813\n",
      "epoch: 13 step: 154, loss is 0.00022306086611934006\n",
      "epoch: 13 step: 155, loss is 0.000431362132076174\n",
      "epoch: 13 step: 156, loss is 0.00028784642927348614\n",
      "epoch: 13 step: 157, loss is 0.00031720404513180256\n",
      "epoch: 13 step: 158, loss is 0.001072784187272191\n",
      "epoch: 13 step: 159, loss is 0.0012255276087671518\n",
      "epoch: 13 step: 160, loss is 0.00031190793379209936\n",
      "epoch: 13 step: 161, loss is 0.0005331861320883036\n",
      "epoch: 13 step: 162, loss is 0.00017317224410362542\n",
      "epoch: 13 step: 163, loss is 0.0005174255347810686\n",
      "epoch: 13 step: 164, loss is 0.0009385846788063645\n",
      "epoch: 13 step: 165, loss is 0.0005276986048556864\n",
      "epoch: 13 step: 166, loss is 0.000742321542929858\n",
      "epoch: 13 step: 167, loss is 0.0005707269883714616\n",
      "epoch: 13 step: 168, loss is 0.00174881296698004\n",
      "epoch: 13 step: 169, loss is 0.00037093833088874817\n",
      "epoch: 13 step: 170, loss is 0.0006104525527916849\n",
      "epoch: 13 step: 171, loss is 0.0003112465492449701\n",
      "epoch: 13 step: 172, loss is 0.0008970689959824085\n",
      "epoch: 13 step: 173, loss is 0.0006809444166719913\n",
      "epoch: 13 step: 174, loss is 0.0010410997783765197\n",
      "epoch: 13 step: 175, loss is 0.00045253708958625793\n",
      "epoch: 13 step: 176, loss is 0.0004112798487767577\n",
      "epoch: 13 step: 177, loss is 0.0005946509772911668\n",
      "epoch: 13 step: 178, loss is 0.0006687997956760228\n",
      "epoch: 13 step: 179, loss is 0.0008334186859428883\n",
      "epoch: 13 step: 180, loss is 0.000917967758141458\n",
      "epoch: 13 step: 181, loss is 0.001390828867442906\n",
      "epoch: 13 step: 182, loss is 0.00043416250264272094\n",
      "epoch: 13 step: 183, loss is 0.0004281551227904856\n",
      "epoch: 13 step: 184, loss is 0.000695846218150109\n",
      "epoch: 13 step: 185, loss is 0.0008150279754772782\n",
      "epoch: 13 step: 186, loss is 0.0019190642051398754\n",
      "epoch: 13 step: 187, loss is 0.0010281478753313422\n",
      "epoch: 13 step: 188, loss is 0.0011607208289206028\n",
      "epoch: 13 step: 189, loss is 0.0014221592573449016\n",
      "epoch: 13 step: 190, loss is 0.00024191079137381166\n",
      "epoch: 13 step: 191, loss is 0.0004561269888654351\n",
      "epoch: 13 step: 192, loss is 0.0006295509519986808\n",
      "epoch: 13 step: 193, loss is 0.001082235830835998\n",
      "epoch: 13 step: 194, loss is 0.00047773326514288783\n",
      "epoch: 13 step: 195, loss is 0.000996718998067081\n",
      "epoch: 13 step: 196, loss is 0.000766714452765882\n",
      "epoch: 13 step: 197, loss is 0.0003838812990579754\n",
      "epoch: 13 step: 198, loss is 0.0004755325790029019\n",
      "epoch: 13 step: 199, loss is 0.0006367585156112909\n",
      "epoch: 13 step: 200, loss is 0.0011822710512205958\n",
      "epoch: 13 step: 201, loss is 0.0007076406618580222\n",
      "epoch: 13 step: 202, loss is 0.0014133076183497906\n",
      "epoch: 13 step: 203, loss is 0.0013390788808465004\n",
      "epoch: 13 step: 204, loss is 0.0015734863700345159\n",
      "epoch: 13 step: 205, loss is 0.00021814140200149268\n",
      "epoch: 13 step: 206, loss is 0.0008888505399227142\n",
      "epoch: 13 step: 207, loss is 0.0006770844338461757\n",
      "epoch: 13 step: 208, loss is 0.0005420361994765699\n",
      "epoch: 13 step: 209, loss is 0.0005178135470487177\n",
      "epoch: 13 step: 210, loss is 0.0009668881539255381\n",
      "epoch: 13 step: 211, loss is 0.0004209513426758349\n",
      "epoch: 13 step: 212, loss is 0.0006573660648427904\n",
      "epoch: 13 step: 213, loss is 0.000822138215880841\n",
      "epoch: 13 step: 214, loss is 0.00043587308027781546\n",
      "epoch: 13 step: 215, loss is 0.0003878663119394332\n",
      "epoch: 13 step: 216, loss is 0.0002760161005426198\n",
      "epoch: 13 step: 217, loss is 0.00016650099132675678\n",
      "epoch: 13 step: 218, loss is 0.0004863879585172981\n",
      "epoch: 13 step: 219, loss is 0.0003102742484770715\n",
      "epoch: 13 step: 220, loss is 0.0006715743220411241\n",
      "epoch: 13 step: 221, loss is 0.0007773336255922914\n",
      "epoch: 13 step: 222, loss is 0.0002554102393332869\n",
      "epoch: 13 step: 223, loss is 0.0008581618312746286\n",
      "epoch: 13 step: 224, loss is 0.0006113160052336752\n",
      "epoch: 13 step: 225, loss is 0.00044129358138889074\n",
      "epoch: 13 step: 226, loss is 0.0004060360661242157\n",
      "epoch: 13 step: 227, loss is 0.0002592116652522236\n",
      "epoch: 13 step: 228, loss is 0.0002928176836576313\n",
      "epoch: 13 step: 229, loss is 0.00017880610539577901\n",
      "epoch: 13 step: 230, loss is 0.0015529714291915298\n",
      "epoch: 13 step: 231, loss is 0.0006490361411124468\n",
      "epoch: 13 step: 232, loss is 0.0012406804598867893\n",
      "epoch: 13 step: 233, loss is 0.0004173509660176933\n",
      "epoch: 13 step: 234, loss is 0.0008173645474016666\n",
      "epoch: 13 step: 235, loss is 0.001271684537641704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 236, loss is 0.0013436998706310987\n",
      "epoch: 13 step: 237, loss is 0.00118415174074471\n",
      "epoch: 13 step: 238, loss is 0.0004591132455971092\n",
      "epoch: 13 step: 239, loss is 0.0014810946304351091\n",
      "epoch: 13 step: 240, loss is 0.0007207871531136334\n",
      "epoch: 13 step: 241, loss is 0.0018159307073801756\n",
      "epoch: 13 step: 242, loss is 0.00011329773406032473\n",
      "epoch: 13 step: 243, loss is 0.0007902865181677043\n",
      "epoch: 13 step: 244, loss is 0.0005401069647632539\n",
      "epoch: 13 step: 245, loss is 0.0003507078217808157\n",
      "epoch: 13 step: 246, loss is 0.0004217782989144325\n",
      "epoch: 13 step: 247, loss is 0.0012281383387744427\n",
      "epoch: 13 step: 248, loss is 0.0005335959140211344\n",
      "epoch: 13 step: 249, loss is 0.0006957952864468098\n",
      "epoch: 13 step: 250, loss is 0.0005925594014115632\n",
      "epoch: 13 step: 251, loss is 0.0010538363130763173\n",
      "epoch: 13 step: 252, loss is 0.0009315602947026491\n",
      "epoch: 13 step: 253, loss is 0.0006301744724623859\n",
      "epoch: 13 step: 254, loss is 0.0003070820530410856\n",
      "epoch: 13 step: 255, loss is 0.0004914479795843363\n",
      "epoch: 13 step: 256, loss is 0.0015471023507416248\n",
      "epoch: 13 step: 257, loss is 0.000578063540160656\n",
      "epoch: 13 step: 258, loss is 0.0010051204590126872\n",
      "epoch: 13 step: 259, loss is 0.0005681927432306111\n",
      "epoch: 13 step: 260, loss is 0.0004937264020554721\n",
      "epoch: 13 step: 261, loss is 0.0006146143423393369\n",
      "epoch: 13 step: 262, loss is 0.0004865313821937889\n",
      "epoch: 13 step: 263, loss is 0.0005104587762616575\n",
      "epoch: 13 step: 264, loss is 0.0013449357356876135\n",
      "epoch: 13 step: 265, loss is 0.0004958934732712805\n",
      "epoch: 13 step: 266, loss is 0.0006633774028159678\n",
      "epoch: 13 step: 267, loss is 0.0012268915306776762\n",
      "epoch: 13 step: 268, loss is 0.0014295283472165465\n",
      "epoch: 13 step: 269, loss is 0.0005991689977236092\n",
      "epoch: 13 step: 270, loss is 0.0009360559633933008\n",
      "epoch: 13 step: 271, loss is 0.0005689066019840539\n",
      "epoch: 13 step: 272, loss is 0.0005797207122668624\n",
      "epoch: 13 step: 273, loss is 0.00028066991944797337\n",
      "epoch: 13 step: 274, loss is 0.0010094947647303343\n",
      "epoch: 13 step: 275, loss is 0.00039822550024837255\n",
      "epoch: 13 step: 276, loss is 0.0006631221040152013\n",
      "epoch: 13 step: 277, loss is 0.000602156447712332\n",
      "epoch: 13 step: 278, loss is 0.0011515383375808597\n",
      "epoch: 13 step: 279, loss is 0.000390204309951514\n",
      "epoch: 13 step: 280, loss is 0.000431136111728847\n",
      "epoch: 13 step: 281, loss is 0.00015771377366036177\n",
      "epoch: 13 step: 282, loss is 0.0007750869262963533\n",
      "epoch: 13 step: 283, loss is 0.0008675807039253414\n",
      "epoch: 13 step: 284, loss is 0.0006021082517690957\n",
      "epoch: 13 step: 285, loss is 0.0005643562762998044\n",
      "epoch: 13 step: 286, loss is 0.0005303685320541263\n",
      "epoch: 13 step: 287, loss is 0.00096754333935678\n",
      "epoch: 13 step: 288, loss is 0.002470688195899129\n",
      "epoch: 13 step: 289, loss is 0.0003816797980107367\n",
      "epoch: 13 step: 290, loss is 0.00020012255117762834\n",
      "epoch: 13 step: 291, loss is 0.0006762640550732613\n",
      "epoch: 13 step: 292, loss is 0.0002676086442079395\n",
      "epoch: 13 step: 293, loss is 0.0016764578176662326\n",
      "epoch: 13 step: 294, loss is 0.00022435472055803984\n",
      "epoch: 13 step: 295, loss is 0.0008330802666023374\n",
      "epoch: 13 step: 296, loss is 0.0010500705102458596\n",
      "epoch: 13 step: 297, loss is 0.0013100211508572102\n",
      "epoch: 13 step: 298, loss is 0.0006531771505251527\n",
      "epoch: 13 step: 299, loss is 0.0014532724162563682\n",
      "epoch: 13 step: 300, loss is 0.0009253316093236208\n",
      "epoch: 13 step: 301, loss is 0.001181098516099155\n",
      "epoch: 13 step: 302, loss is 0.00037518053431995213\n",
      "epoch: 13 step: 303, loss is 0.0001906948018586263\n",
      "epoch: 13 step: 304, loss is 0.0013477032771334052\n",
      "epoch: 13 step: 305, loss is 0.0006366366287693381\n",
      "epoch: 13 step: 306, loss is 0.00011369866842869669\n",
      "epoch: 13 step: 307, loss is 0.00046246653073467314\n",
      "epoch: 13 step: 308, loss is 0.0007942309021018445\n",
      "epoch: 13 step: 309, loss is 0.0004906399990431964\n",
      "epoch: 13 step: 310, loss is 0.0004337019345257431\n",
      "epoch: 13 step: 311, loss is 0.0009274404728785157\n",
      "epoch: 13 step: 312, loss is 0.0006225096294656396\n",
      "epoch: 13 step: 313, loss is 0.000177753550815396\n",
      "epoch: 13 step: 314, loss is 0.00048766660620458424\n",
      "epoch: 13 step: 315, loss is 0.0003576748422347009\n",
      "epoch: 13 step: 316, loss is 0.00019442802295088768\n",
      "epoch: 13 step: 317, loss is 0.0008549129706807435\n",
      "epoch: 13 step: 318, loss is 0.000685028440784663\n",
      "epoch: 13 step: 319, loss is 0.00042548892088234425\n",
      "epoch: 13 step: 320, loss is 0.00036141189048066735\n",
      "epoch: 13 step: 321, loss is 0.00046186053077690303\n",
      "epoch: 13 step: 322, loss is 0.0004758414579555392\n",
      "epoch: 13 step: 323, loss is 0.0013650580076500773\n",
      "epoch: 13 step: 324, loss is 0.0008881940157152712\n",
      "epoch: 13 step: 325, loss is 0.00046445472980849445\n",
      "epoch: 13 step: 326, loss is 0.0008826537523418665\n",
      "epoch: 13 step: 327, loss is 0.0005187746719457209\n",
      "epoch: 13 step: 328, loss is 0.0004827265802305192\n",
      "epoch: 13 step: 329, loss is 0.0006279695662669837\n",
      "epoch: 13 step: 330, loss is 0.0008591085206717253\n",
      "epoch: 13 step: 331, loss is 0.0009096463909372687\n",
      "epoch: 13 step: 332, loss is 0.00082303152885288\n",
      "epoch: 13 step: 333, loss is 0.0005099460831843317\n",
      "epoch: 13 step: 334, loss is 0.0012058578431606293\n",
      "epoch: 13 step: 335, loss is 0.0007876631570979953\n",
      "epoch: 13 step: 336, loss is 0.0007221237756311893\n",
      "epoch: 13 step: 337, loss is 0.0013305768370628357\n",
      "epoch: 13 step: 338, loss is 0.0005616167327389121\n",
      "epoch: 13 step: 339, loss is 0.0012244475074112415\n",
      "epoch: 13 step: 340, loss is 0.0006414962699636817\n",
      "epoch: 13 step: 341, loss is 0.0005185238551348448\n",
      "epoch: 13 step: 342, loss is 0.00017465066048316658\n",
      "epoch: 13 step: 343, loss is 0.0004362173785921186\n",
      "epoch: 13 step: 344, loss is 0.0011990731582045555\n",
      "epoch: 13 step: 345, loss is 0.00022668781457468867\n",
      "epoch: 13 step: 346, loss is 0.001259658019989729\n",
      "epoch: 13 step: 347, loss is 0.000939460820518434\n",
      "epoch: 13 step: 348, loss is 0.0011085448786616325\n",
      "epoch: 13 step: 349, loss is 0.00012222967052366585\n",
      "epoch: 13 step: 350, loss is 0.0007496027392335236\n",
      "epoch: 13 step: 351, loss is 0.0018342535477131605\n",
      "epoch: 13 step: 352, loss is 0.0005971614737063646\n",
      "epoch: 13 step: 353, loss is 0.00034137032344006\n",
      "epoch: 13 step: 354, loss is 0.0003938248264603317\n",
      "epoch: 13 step: 355, loss is 0.00047825934598222375\n",
      "epoch: 13 step: 356, loss is 0.00037615338806062937\n",
      "epoch: 13 step: 357, loss is 0.0005399783840402961\n",
      "epoch: 13 step: 358, loss is 0.0003594926674850285\n",
      "epoch: 13 step: 359, loss is 0.000616205099504441\n",
      "epoch: 13 step: 360, loss is 0.0007788973161950707\n",
      "epoch: 13 step: 361, loss is 0.0006414963281713426\n",
      "epoch: 13 step: 362, loss is 0.0006985370418988168\n",
      "epoch: 13 step: 363, loss is 0.0009468809003010392\n",
      "epoch: 13 step: 364, loss is 0.0004598951491061598\n",
      "epoch: 13 step: 365, loss is 0.0012812906643375754\n",
      "epoch: 13 step: 366, loss is 0.0005217802245169878\n",
      "epoch: 13 step: 367, loss is 0.0007178388186730444\n",
      "epoch: 13 step: 368, loss is 0.0007772256503812969\n",
      "epoch: 13 step: 369, loss is 0.00040943670319393277\n",
      "epoch: 13 step: 370, loss is 0.0007347919163294137\n",
      "epoch: 13 step: 371, loss is 0.000893771240953356\n",
      "epoch: 13 step: 372, loss is 0.0004968563443981111\n",
      "epoch: 13 step: 373, loss is 0.0007705928292125463\n",
      "epoch: 13 step: 374, loss is 0.0004994727205485106\n",
      "epoch: 13 step: 375, loss is 0.0002390747977187857\n",
      "Train epoch time: 11943.979 ms, per step time: 31.851 ms\n",
      "epoch: 14 step: 1, loss is 0.0009719571098685265\n",
      "epoch: 14 step: 2, loss is 0.0007918954943306744\n",
      "epoch: 14 step: 3, loss is 0.0006117300945334136\n",
      "epoch: 14 step: 4, loss is 0.0009032589732669294\n",
      "epoch: 14 step: 5, loss is 0.0004575840139295906\n",
      "epoch: 14 step: 6, loss is 0.00042256174492649734\n",
      "epoch: 14 step: 7, loss is 0.0006914573023095727\n",
      "epoch: 14 step: 8, loss is 0.0008856512722559273\n",
      "epoch: 14 step: 9, loss is 0.0006786267622373998\n",
      "epoch: 14 step: 10, loss is 0.0005856477655470371\n",
      "epoch: 14 step: 11, loss is 0.0006396400858648121\n",
      "epoch: 14 step: 12, loss is 0.0009388262405991554\n",
      "epoch: 14 step: 13, loss is 0.0003865758772008121\n",
      "epoch: 14 step: 14, loss is 0.0005108872428536415\n",
      "epoch: 14 step: 15, loss is 0.0009254885953851044\n",
      "epoch: 14 step: 16, loss is 0.0005503087886609137\n",
      "epoch: 14 step: 17, loss is 0.00032816166640259326\n",
      "epoch: 14 step: 18, loss is 0.0003762229753192514\n",
      "epoch: 14 step: 19, loss is 0.0007100850925780833\n",
      "epoch: 14 step: 20, loss is 0.0008707743836566806\n",
      "epoch: 14 step: 21, loss is 0.000455152039648965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 22, loss is 0.0009016814874485135\n",
      "epoch: 14 step: 23, loss is 0.0003580547927413136\n",
      "epoch: 14 step: 24, loss is 0.0005050702020525932\n",
      "epoch: 14 step: 25, loss is 0.0005269725224934518\n",
      "epoch: 14 step: 26, loss is 0.0010957616614177823\n",
      "epoch: 14 step: 27, loss is 0.0005751686403527856\n",
      "epoch: 14 step: 28, loss is 0.0014737615128979087\n",
      "epoch: 14 step: 29, loss is 0.0008889143355190754\n",
      "epoch: 14 step: 30, loss is 0.0010035036830231547\n",
      "epoch: 14 step: 31, loss is 0.0018961646128445864\n",
      "epoch: 14 step: 32, loss is 0.0010452494025230408\n",
      "epoch: 14 step: 33, loss is 0.00044426077511161566\n",
      "epoch: 14 step: 34, loss is 0.0004875623853877187\n",
      "epoch: 14 step: 35, loss is 0.0006904858164489269\n",
      "epoch: 14 step: 36, loss is 0.0010196423390880227\n",
      "epoch: 14 step: 37, loss is 0.0005584642640314996\n",
      "epoch: 14 step: 38, loss is 0.0009075002162717283\n",
      "epoch: 14 step: 39, loss is 0.0003572722489479929\n",
      "epoch: 14 step: 40, loss is 0.0006446693441830575\n",
      "epoch: 14 step: 41, loss is 0.0006084616761654615\n",
      "epoch: 14 step: 42, loss is 0.0018720057560130954\n",
      "epoch: 14 step: 43, loss is 0.0006880954024381936\n",
      "epoch: 14 step: 44, loss is 0.0005683143390342593\n",
      "epoch: 14 step: 45, loss is 0.0003960519970860332\n",
      "epoch: 14 step: 46, loss is 0.0008117580437101424\n",
      "epoch: 14 step: 47, loss is 0.000591841759160161\n",
      "epoch: 14 step: 48, loss is 0.0003229519643355161\n",
      "epoch: 14 step: 49, loss is 0.0006803401629440486\n",
      "epoch: 14 step: 50, loss is 0.0003674238105304539\n",
      "epoch: 14 step: 51, loss is 0.000690076092723757\n",
      "epoch: 14 step: 52, loss is 0.0004407188971526921\n",
      "epoch: 14 step: 53, loss is 0.0008509167237207294\n",
      "epoch: 14 step: 54, loss is 0.00046553713036701083\n",
      "epoch: 14 step: 55, loss is 0.0004930316936224699\n",
      "epoch: 14 step: 56, loss is 0.0003751687763724476\n",
      "epoch: 14 step: 57, loss is 0.0020223602186888456\n",
      "epoch: 14 step: 58, loss is 0.0010695656528696418\n",
      "epoch: 14 step: 59, loss is 0.0004994493210688233\n",
      "epoch: 14 step: 60, loss is 0.00041298946598544717\n",
      "epoch: 14 step: 61, loss is 0.00048199319280683994\n",
      "epoch: 14 step: 62, loss is 0.0006410359055735171\n",
      "epoch: 14 step: 63, loss is 0.0007159785600379109\n",
      "epoch: 14 step: 64, loss is 0.0005877525545656681\n",
      "epoch: 14 step: 65, loss is 0.0006079983431845903\n",
      "epoch: 14 step: 66, loss is 0.0006657743942923844\n",
      "epoch: 14 step: 67, loss is 0.0004841288027819246\n",
      "epoch: 14 step: 68, loss is 0.00047320773592218757\n",
      "epoch: 14 step: 69, loss is 0.0008457410149276257\n",
      "epoch: 14 step: 70, loss is 0.0004902455257251859\n",
      "epoch: 14 step: 71, loss is 0.0009298555669374764\n",
      "epoch: 14 step: 72, loss is 0.000441956304712221\n",
      "epoch: 14 step: 73, loss is 0.0010023764334619045\n",
      "epoch: 14 step: 74, loss is 0.0012351012555882335\n",
      "epoch: 14 step: 75, loss is 0.0008620644803158939\n",
      "epoch: 14 step: 76, loss is 0.0012896062107756734\n",
      "epoch: 14 step: 77, loss is 0.0007583448896184564\n",
      "epoch: 14 step: 78, loss is 0.0008038544910959899\n",
      "epoch: 14 step: 79, loss is 0.0006631197757087648\n",
      "epoch: 14 step: 80, loss is 0.0009512213873676956\n",
      "epoch: 14 step: 81, loss is 0.000490601931232959\n",
      "epoch: 14 step: 82, loss is 0.0005556942196562886\n",
      "epoch: 14 step: 83, loss is 0.0005173271638341248\n",
      "epoch: 14 step: 84, loss is 0.002713199006393552\n",
      "epoch: 14 step: 85, loss is 0.00046517691225744784\n",
      "epoch: 14 step: 86, loss is 0.0007094711763784289\n",
      "epoch: 14 step: 87, loss is 0.0012012207880616188\n",
      "epoch: 14 step: 88, loss is 0.0005318725015968084\n",
      "epoch: 14 step: 89, loss is 0.000835273414850235\n",
      "epoch: 14 step: 90, loss is 0.0008377116173505783\n",
      "epoch: 14 step: 91, loss is 0.0008121163700707257\n",
      "epoch: 14 step: 92, loss is 0.0008657124126330018\n",
      "epoch: 14 step: 93, loss is 0.0007647994789294899\n",
      "epoch: 14 step: 94, loss is 0.0006598302279599011\n",
      "epoch: 14 step: 95, loss is 0.0003591642598621547\n",
      "epoch: 14 step: 96, loss is 0.0002610158990137279\n",
      "epoch: 14 step: 97, loss is 0.0011520549887791276\n",
      "epoch: 14 step: 98, loss is 0.0004424015060067177\n",
      "epoch: 14 step: 99, loss is 0.0004268157063052058\n",
      "epoch: 14 step: 100, loss is 0.0012631952995434403\n",
      "epoch: 14 step: 101, loss is 0.0006361570558510721\n",
      "epoch: 14 step: 102, loss is 0.001104111084714532\n",
      "epoch: 14 step: 103, loss is 0.0009550409158691764\n",
      "epoch: 14 step: 104, loss is 0.0008118239347822964\n",
      "epoch: 14 step: 105, loss is 0.0012973183766007423\n",
      "epoch: 14 step: 106, loss is 0.002080820733681321\n",
      "epoch: 14 step: 107, loss is 0.00019033343414776027\n",
      "epoch: 14 step: 108, loss is 0.0005952752544544637\n",
      "epoch: 14 step: 109, loss is 0.0011291165137663484\n",
      "epoch: 14 step: 110, loss is 0.0006775579531677067\n",
      "epoch: 14 step: 111, loss is 0.0013407755177468061\n",
      "epoch: 14 step: 112, loss is 0.0008625350892543793\n",
      "epoch: 14 step: 113, loss is 0.0002679894387256354\n",
      "epoch: 14 step: 114, loss is 0.0009478218853473663\n",
      "epoch: 14 step: 115, loss is 0.0008391882292926311\n",
      "epoch: 14 step: 116, loss is 0.0005779601633548737\n",
      "epoch: 14 step: 117, loss is 0.00038837356260046363\n",
      "epoch: 14 step: 118, loss is 0.0016484629595652223\n",
      "epoch: 14 step: 119, loss is 0.0010396352736279368\n",
      "epoch: 14 step: 120, loss is 0.0007126579876057804\n",
      "epoch: 14 step: 121, loss is 0.00016008398961275816\n",
      "epoch: 14 step: 122, loss is 0.0007656987872906029\n",
      "epoch: 14 step: 123, loss is 0.0014910472091287374\n",
      "epoch: 14 step: 124, loss is 0.0005048837047070265\n",
      "epoch: 14 step: 125, loss is 0.00034694946953095496\n",
      "epoch: 14 step: 126, loss is 0.0019706538878381252\n",
      "epoch: 14 step: 127, loss is 0.00030226216767914593\n",
      "epoch: 14 step: 128, loss is 0.0005837653297930956\n",
      "epoch: 14 step: 129, loss is 0.0011545366141945124\n",
      "epoch: 14 step: 130, loss is 9.704536205390468e-05\n",
      "epoch: 14 step: 131, loss is 0.0004102081584278494\n",
      "epoch: 14 step: 132, loss is 0.001147664152085781\n",
      "epoch: 14 step: 133, loss is 0.00048028863966464996\n",
      "epoch: 14 step: 134, loss is 0.0007648914470337331\n",
      "epoch: 14 step: 135, loss is 0.0008047227747738361\n",
      "epoch: 14 step: 136, loss is 0.0008076443336904049\n",
      "epoch: 14 step: 137, loss is 0.00043498643208295107\n",
      "epoch: 14 step: 138, loss is 0.0007543109240941703\n",
      "epoch: 14 step: 139, loss is 0.0003782335843425244\n",
      "epoch: 14 step: 140, loss is 0.0010367733193561435\n",
      "epoch: 14 step: 141, loss is 0.00046015059342607856\n",
      "epoch: 14 step: 142, loss is 0.0003129798569716513\n",
      "epoch: 14 step: 143, loss is 0.0005634783301502466\n",
      "epoch: 14 step: 144, loss is 0.0004959727521054447\n",
      "epoch: 14 step: 145, loss is 0.0001996368810068816\n",
      "epoch: 14 step: 146, loss is 0.001142837223596871\n",
      "epoch: 14 step: 147, loss is 0.0002066954766632989\n",
      "epoch: 14 step: 148, loss is 0.0006442036828957498\n",
      "epoch: 14 step: 149, loss is 0.0008247734513133764\n",
      "epoch: 14 step: 150, loss is 0.00024174789723474532\n",
      "epoch: 14 step: 151, loss is 0.0006664620013907552\n",
      "epoch: 14 step: 152, loss is 0.0014377563493326306\n",
      "epoch: 14 step: 153, loss is 0.00022121303481981158\n",
      "epoch: 14 step: 154, loss is 0.0014831237494945526\n",
      "epoch: 14 step: 155, loss is 0.0005730376578867435\n",
      "epoch: 14 step: 156, loss is 0.0013708032201975584\n",
      "epoch: 14 step: 157, loss is 0.00031065777875483036\n",
      "epoch: 14 step: 158, loss is 0.0012989466777071357\n",
      "epoch: 14 step: 159, loss is 0.00028393699903972447\n",
      "epoch: 14 step: 160, loss is 0.0008065964793786407\n",
      "epoch: 14 step: 161, loss is 0.000890372961293906\n",
      "epoch: 14 step: 162, loss is 0.00030879952828399837\n",
      "epoch: 14 step: 163, loss is 0.000679106218740344\n",
      "epoch: 14 step: 164, loss is 0.00029987544985488057\n",
      "epoch: 14 step: 165, loss is 0.000736227841116488\n",
      "epoch: 14 step: 166, loss is 0.0009477019193582237\n",
      "epoch: 14 step: 167, loss is 0.0005469736643135548\n",
      "epoch: 14 step: 168, loss is 0.0006297891377471387\n",
      "epoch: 14 step: 169, loss is 0.0008471172768622637\n",
      "epoch: 14 step: 170, loss is 0.0008593666134402156\n",
      "epoch: 14 step: 171, loss is 0.0004310470831114799\n",
      "epoch: 14 step: 172, loss is 0.0006390457274392247\n",
      "epoch: 14 step: 173, loss is 0.0008898529340513051\n",
      "epoch: 14 step: 174, loss is 0.0014168012421578169\n",
      "epoch: 14 step: 175, loss is 0.0005556967225857079\n",
      "epoch: 14 step: 176, loss is 0.0003137728199362755\n",
      "epoch: 14 step: 177, loss is 0.0003851325891446322\n",
      "epoch: 14 step: 178, loss is 0.000484009156934917\n",
      "epoch: 14 step: 179, loss is 0.0005243240739218891\n",
      "epoch: 14 step: 180, loss is 0.0009751959005370736\n",
      "epoch: 14 step: 181, loss is 0.0008211858803406358\n",
      "epoch: 14 step: 182, loss is 0.0002615099656395614\n",
      "epoch: 14 step: 183, loss is 0.0004954694304615259\n",
      "epoch: 14 step: 184, loss is 0.0008377551566809416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 185, loss is 0.0004137048381380737\n",
      "epoch: 14 step: 186, loss is 0.0013067452237010002\n",
      "epoch: 14 step: 187, loss is 0.0004732551460620016\n",
      "epoch: 14 step: 188, loss is 0.0016655660001561046\n",
      "epoch: 14 step: 189, loss is 0.000416440045228228\n",
      "epoch: 14 step: 190, loss is 0.0006031975499354303\n",
      "epoch: 14 step: 191, loss is 0.001308046979829669\n",
      "epoch: 14 step: 192, loss is 0.000388092827051878\n",
      "epoch: 14 step: 193, loss is 0.0005108220502734184\n",
      "epoch: 14 step: 194, loss is 0.000632866402156651\n",
      "epoch: 14 step: 195, loss is 0.0005227903020568192\n",
      "epoch: 14 step: 196, loss is 0.000583841057959944\n",
      "epoch: 14 step: 197, loss is 0.0002284110669279471\n",
      "epoch: 14 step: 198, loss is 0.000559766951482743\n",
      "epoch: 14 step: 199, loss is 0.0006122472696006298\n",
      "epoch: 14 step: 200, loss is 6.217916961759329e-05\n",
      "epoch: 14 step: 201, loss is 0.00103742943610996\n",
      "epoch: 14 step: 202, loss is 0.0003492334799375385\n",
      "epoch: 14 step: 203, loss is 0.0010220439871773124\n",
      "epoch: 14 step: 204, loss is 0.0004396947624627501\n",
      "epoch: 14 step: 205, loss is 9.006724576465786e-05\n",
      "epoch: 14 step: 206, loss is 0.0005581242730841041\n",
      "epoch: 14 step: 207, loss is 0.0010161844547837973\n",
      "epoch: 14 step: 208, loss is 0.0005833134637214243\n",
      "epoch: 14 step: 209, loss is 0.00139655452221632\n",
      "epoch: 14 step: 210, loss is 0.0010324823670089245\n",
      "epoch: 14 step: 211, loss is 0.00037012045504525304\n",
      "epoch: 14 step: 212, loss is 0.00052937853615731\n",
      "epoch: 14 step: 213, loss is 0.0005544308805838227\n",
      "epoch: 14 step: 214, loss is 0.0008746261009946465\n",
      "epoch: 14 step: 215, loss is 0.0004959309590049088\n",
      "epoch: 14 step: 216, loss is 0.00040857112617231905\n",
      "epoch: 14 step: 217, loss is 0.0009022460435517132\n",
      "epoch: 14 step: 218, loss is 0.0005830302834510803\n",
      "epoch: 14 step: 219, loss is 0.00034396545379422605\n",
      "epoch: 14 step: 220, loss is 0.0006684993859380484\n",
      "epoch: 14 step: 221, loss is 0.001314394292421639\n",
      "epoch: 14 step: 222, loss is 0.0005382236558943987\n",
      "epoch: 14 step: 223, loss is 0.0006170790875330567\n",
      "epoch: 14 step: 224, loss is 0.0004260049609001726\n",
      "epoch: 14 step: 225, loss is 0.0012368113966658711\n",
      "epoch: 14 step: 226, loss is 0.0011828152928501368\n",
      "epoch: 14 step: 227, loss is 0.0011402955278754234\n",
      "epoch: 14 step: 228, loss is 0.0004260097921360284\n",
      "epoch: 14 step: 229, loss is 0.0005080617847852409\n",
      "epoch: 14 step: 230, loss is 0.00021403258142527193\n",
      "epoch: 14 step: 231, loss is 0.00035274145193398\n",
      "epoch: 14 step: 232, loss is 0.00029565984732471406\n",
      "epoch: 14 step: 233, loss is 0.0007211687043309212\n",
      "epoch: 14 step: 234, loss is 0.0006270721787586808\n",
      "epoch: 14 step: 235, loss is 0.0006932097021490335\n",
      "epoch: 14 step: 236, loss is 0.000603881839197129\n",
      "epoch: 14 step: 237, loss is 0.0011805873364210129\n",
      "epoch: 14 step: 238, loss is 0.0007240419508889318\n",
      "epoch: 14 step: 239, loss is 0.0006304524140432477\n",
      "epoch: 14 step: 240, loss is 0.00034400049480609596\n",
      "epoch: 14 step: 241, loss is 0.0007176775252446532\n",
      "epoch: 14 step: 242, loss is 0.00023911238531582057\n",
      "epoch: 14 step: 243, loss is 0.0006318006198853254\n",
      "epoch: 14 step: 244, loss is 0.0002777965855784714\n",
      "epoch: 14 step: 245, loss is 0.0006742756231687963\n",
      "epoch: 14 step: 246, loss is 0.0003163655346725136\n",
      "epoch: 14 step: 247, loss is 0.00046506451326422393\n",
      "epoch: 14 step: 248, loss is 0.00032721308525651693\n",
      "epoch: 14 step: 249, loss is 0.00034867844078689814\n",
      "epoch: 14 step: 250, loss is 0.00032998036476783454\n",
      "epoch: 14 step: 251, loss is 0.0007227822788991034\n",
      "epoch: 14 step: 252, loss is 0.0008979527046903968\n",
      "epoch: 14 step: 253, loss is 0.0005431562894955277\n",
      "epoch: 14 step: 254, loss is 0.0017886839341372252\n",
      "epoch: 14 step: 255, loss is 0.00033163087209686637\n",
      "epoch: 14 step: 256, loss is 0.0018291475716978312\n",
      "epoch: 14 step: 257, loss is 0.00029922820976935327\n",
      "epoch: 14 step: 258, loss is 0.0005248384550213814\n",
      "epoch: 14 step: 259, loss is 0.0010801588650792837\n",
      "epoch: 14 step: 260, loss is 0.0012622249778360128\n",
      "epoch: 14 step: 261, loss is 0.0005842349492013454\n",
      "epoch: 14 step: 262, loss is 0.0003245142288506031\n",
      "epoch: 14 step: 263, loss is 0.0010386426001787186\n",
      "epoch: 14 step: 264, loss is 0.00023967475863173604\n",
      "epoch: 14 step: 265, loss is 0.00034590731956996024\n",
      "epoch: 14 step: 266, loss is 0.0010430037509649992\n",
      "epoch: 14 step: 267, loss is 0.0002554644306655973\n",
      "epoch: 14 step: 268, loss is 0.00037978088948875666\n",
      "epoch: 14 step: 269, loss is 0.00024362011754419655\n",
      "epoch: 14 step: 270, loss is 0.0007262749131768942\n",
      "epoch: 14 step: 271, loss is 0.000322906271321699\n",
      "epoch: 14 step: 272, loss is 0.0010437349556013942\n",
      "epoch: 14 step: 273, loss is 0.0004749658110085875\n",
      "epoch: 14 step: 274, loss is 0.0018372194608673453\n",
      "epoch: 14 step: 275, loss is 0.0007894535665400326\n",
      "epoch: 14 step: 276, loss is 0.0010037870379164815\n",
      "epoch: 14 step: 277, loss is 0.0007325202459469438\n",
      "epoch: 14 step: 278, loss is 0.0011561269639059901\n",
      "epoch: 14 step: 279, loss is 0.000754660926759243\n",
      "epoch: 14 step: 280, loss is 0.0003563080681487918\n",
      "epoch: 14 step: 281, loss is 0.0008721619378775358\n",
      "epoch: 14 step: 282, loss is 0.00019509090634528548\n",
      "epoch: 14 step: 283, loss is 0.000647218432277441\n",
      "epoch: 14 step: 284, loss is 0.0005461204564198852\n",
      "epoch: 14 step: 285, loss is 0.0009085136698558927\n",
      "epoch: 14 step: 286, loss is 0.0013115820474922657\n",
      "epoch: 14 step: 287, loss is 0.000449510378530249\n",
      "epoch: 14 step: 288, loss is 0.00029944669222459197\n",
      "epoch: 14 step: 289, loss is 0.0005708549870178103\n",
      "epoch: 14 step: 290, loss is 0.000899685372132808\n",
      "epoch: 14 step: 291, loss is 0.0002488619356881827\n",
      "epoch: 14 step: 292, loss is 0.0010780340526252985\n",
      "epoch: 14 step: 293, loss is 0.0010028976248577237\n",
      "epoch: 14 step: 294, loss is 0.0021974067203700542\n",
      "epoch: 14 step: 295, loss is 0.0004987631691619754\n",
      "epoch: 14 step: 296, loss is 0.0009512645192444324\n",
      "epoch: 14 step: 297, loss is 0.000571470707654953\n",
      "epoch: 14 step: 298, loss is 0.0005765625974163413\n",
      "epoch: 14 step: 299, loss is 0.0017256104620173573\n",
      "epoch: 14 step: 300, loss is 0.0007367730722762644\n",
      "epoch: 14 step: 301, loss is 0.0007772863609716296\n",
      "epoch: 14 step: 302, loss is 0.0004823245690204203\n",
      "epoch: 14 step: 303, loss is 0.0006412691436707973\n",
      "epoch: 14 step: 304, loss is 0.0007513994933106005\n",
      "epoch: 14 step: 305, loss is 0.0002870624593924731\n",
      "epoch: 14 step: 306, loss is 0.0007754696998745203\n",
      "epoch: 14 step: 307, loss is 0.0007400173926725984\n",
      "epoch: 14 step: 308, loss is 0.0008886391296982765\n",
      "epoch: 14 step: 309, loss is 0.0005151400691829622\n",
      "epoch: 14 step: 310, loss is 0.0013572809984907508\n",
      "epoch: 14 step: 311, loss is 0.000672528229188174\n",
      "epoch: 14 step: 312, loss is 0.0006714463233947754\n",
      "epoch: 14 step: 313, loss is 0.0010881323833018541\n",
      "epoch: 14 step: 314, loss is 0.0009676513727754354\n",
      "epoch: 14 step: 315, loss is 0.0003852566296700388\n",
      "epoch: 14 step: 316, loss is 0.001152245793491602\n",
      "epoch: 14 step: 317, loss is 0.0006042039021849632\n",
      "epoch: 14 step: 318, loss is 0.0008484031422995031\n",
      "epoch: 14 step: 319, loss is 0.0005396305350586772\n",
      "epoch: 14 step: 320, loss is 0.0004862355999648571\n",
      "epoch: 14 step: 321, loss is 0.00033829917083494365\n",
      "epoch: 14 step: 322, loss is 0.000759678368922323\n",
      "epoch: 14 step: 323, loss is 0.0005973799852654338\n",
      "epoch: 14 step: 324, loss is 0.0014181439764797688\n",
      "epoch: 14 step: 325, loss is 0.0005194012192077935\n",
      "epoch: 14 step: 326, loss is 0.000440381612861529\n",
      "epoch: 14 step: 327, loss is 0.0006304787821136415\n",
      "epoch: 14 step: 328, loss is 0.00036397395888343453\n",
      "epoch: 14 step: 329, loss is 0.0004979444202035666\n",
      "epoch: 14 step: 330, loss is 0.0012168822577223182\n",
      "epoch: 14 step: 331, loss is 0.0005773945013061166\n",
      "epoch: 14 step: 332, loss is 0.0010377723956480622\n",
      "epoch: 14 step: 333, loss is 0.0001622766867512837\n",
      "epoch: 14 step: 334, loss is 0.0006892107776366174\n",
      "epoch: 14 step: 335, loss is 0.0011525340378284454\n",
      "epoch: 14 step: 336, loss is 0.0012147279921919107\n",
      "epoch: 14 step: 337, loss is 0.0005925172590650618\n",
      "epoch: 14 step: 338, loss is 0.0008233647677116096\n",
      "epoch: 14 step: 339, loss is 0.0013479242334142327\n",
      "epoch: 14 step: 340, loss is 0.00048322847578674555\n",
      "epoch: 14 step: 341, loss is 0.0005171949742361903\n",
      "epoch: 14 step: 342, loss is 0.0013779032742604613\n",
      "epoch: 14 step: 343, loss is 0.0005428172298707068\n",
      "epoch: 14 step: 344, loss is 0.0010792691027745605\n",
      "epoch: 14 step: 345, loss is 0.0005265114596113563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 346, loss is 0.0011235823621973395\n",
      "epoch: 14 step: 347, loss is 0.0011851262534037232\n",
      "epoch: 14 step: 348, loss is 0.0008961176499724388\n",
      "epoch: 14 step: 349, loss is 0.0010582016548141837\n",
      "epoch: 14 step: 350, loss is 0.0004599170933943242\n",
      "epoch: 14 step: 351, loss is 0.000545389368198812\n",
      "epoch: 14 step: 352, loss is 0.0005507104797288775\n",
      "epoch: 14 step: 353, loss is 0.0007713344530202448\n",
      "epoch: 14 step: 354, loss is 0.000548544863704592\n",
      "epoch: 14 step: 355, loss is 0.0003440712171141058\n",
      "epoch: 14 step: 356, loss is 0.0003073630796279758\n",
      "epoch: 14 step: 357, loss is 0.0008099757833406329\n",
      "epoch: 14 step: 358, loss is 0.0006299677188508213\n",
      "epoch: 14 step: 359, loss is 0.0004121340753044933\n",
      "epoch: 14 step: 360, loss is 0.0006295921630226076\n",
      "epoch: 14 step: 361, loss is 0.0013680476695299149\n",
      "epoch: 14 step: 362, loss is 0.00019314010569360107\n",
      "epoch: 14 step: 363, loss is 0.0005984383169561625\n",
      "epoch: 14 step: 364, loss is 0.001727813039906323\n",
      "epoch: 14 step: 365, loss is 0.0003541868645697832\n",
      "epoch: 14 step: 366, loss is 0.0012845670571550727\n",
      "epoch: 14 step: 367, loss is 0.0007816102588549256\n",
      "epoch: 14 step: 368, loss is 0.0011240162421017885\n",
      "epoch: 14 step: 369, loss is 0.0005431720637716353\n",
      "epoch: 14 step: 370, loss is 0.000783750438131392\n",
      "epoch: 14 step: 371, loss is 0.001266778097487986\n",
      "epoch: 14 step: 372, loss is 0.000539690547157079\n",
      "epoch: 14 step: 373, loss is 0.0003017789567820728\n",
      "epoch: 14 step: 374, loss is 0.00021987548097968102\n",
      "epoch: 14 step: 375, loss is 0.0005069953040219843\n",
      "Train epoch time: 11927.846 ms, per step time: 31.808 ms\n",
      "epoch: 15 step: 1, loss is 0.00013393857807386667\n",
      "epoch: 15 step: 2, loss is 0.0008093126816675067\n",
      "epoch: 15 step: 3, loss is 0.0006552136037498713\n",
      "epoch: 15 step: 4, loss is 0.0003656772314570844\n",
      "epoch: 15 step: 5, loss is 0.000994604779407382\n",
      "epoch: 15 step: 6, loss is 0.0007058673654682934\n",
      "epoch: 15 step: 7, loss is 0.00045194855192676187\n",
      "epoch: 15 step: 8, loss is 0.0009665089892223477\n",
      "epoch: 15 step: 9, loss is 0.0009454947430640459\n",
      "epoch: 15 step: 10, loss is 0.0017516892403364182\n",
      "epoch: 15 step: 11, loss is 0.0004920943756587803\n",
      "epoch: 15 step: 12, loss is 0.0017038469668477774\n",
      "epoch: 15 step: 13, loss is 0.000679182936437428\n",
      "epoch: 15 step: 14, loss is 0.0006682245875708759\n",
      "epoch: 15 step: 15, loss is 0.002103981329128146\n",
      "epoch: 15 step: 16, loss is 0.0015118182636797428\n",
      "epoch: 15 step: 17, loss is 0.00038405199302360415\n",
      "epoch: 15 step: 18, loss is 0.0003305467253085226\n",
      "epoch: 15 step: 19, loss is 7.68018580856733e-05\n",
      "epoch: 15 step: 20, loss is 0.0007457408937625587\n",
      "epoch: 15 step: 21, loss is 0.0006337406812235713\n",
      "epoch: 15 step: 22, loss is 0.0008997906115837395\n",
      "epoch: 15 step: 23, loss is 0.0010600395034998655\n",
      "epoch: 15 step: 24, loss is 0.0002793033781927079\n",
      "epoch: 15 step: 25, loss is 0.000890978320967406\n",
      "epoch: 15 step: 26, loss is 0.00043056547292508185\n",
      "epoch: 15 step: 27, loss is 0.0006498433067463338\n",
      "epoch: 15 step: 28, loss is 0.0006953757256269455\n",
      "epoch: 15 step: 29, loss is 0.0008682411862537265\n",
      "epoch: 15 step: 30, loss is 0.0008453454938717186\n",
      "epoch: 15 step: 31, loss is 0.000762370356824249\n",
      "epoch: 15 step: 32, loss is 0.00040857907151803374\n",
      "epoch: 15 step: 33, loss is 0.0015024833846837282\n",
      "epoch: 15 step: 34, loss is 0.00034743029391393065\n",
      "epoch: 15 step: 35, loss is 0.001260735560208559\n",
      "epoch: 15 step: 36, loss is 0.0008966622990556061\n",
      "epoch: 15 step: 37, loss is 0.0004624337307177484\n",
      "epoch: 15 step: 38, loss is 0.0005390114965848625\n",
      "epoch: 15 step: 39, loss is 0.001156883081421256\n",
      "epoch: 15 step: 40, loss is 0.0016760529251769185\n",
      "epoch: 15 step: 41, loss is 0.00033568826620467007\n",
      "epoch: 15 step: 42, loss is 0.0017024659318849444\n",
      "epoch: 15 step: 43, loss is 0.0003474737168289721\n",
      "epoch: 15 step: 44, loss is 0.0005779050989076495\n",
      "epoch: 15 step: 45, loss is 0.0002706906816456467\n",
      "epoch: 15 step: 46, loss is 0.0011373269371688366\n",
      "epoch: 15 step: 47, loss is 0.0006091565010137856\n",
      "epoch: 15 step: 48, loss is 0.00043212552554905415\n",
      "epoch: 15 step: 49, loss is 0.0009841832797974348\n",
      "epoch: 15 step: 50, loss is 0.0005874464404769242\n",
      "epoch: 15 step: 51, loss is 0.0011409989092499018\n",
      "epoch: 15 step: 52, loss is 0.0004808841331396252\n",
      "epoch: 15 step: 53, loss is 0.00044005890958942473\n",
      "epoch: 15 step: 54, loss is 0.0003675651387311518\n",
      "epoch: 15 step: 55, loss is 0.000616982695646584\n",
      "epoch: 15 step: 56, loss is 0.0010969116119667888\n",
      "epoch: 15 step: 57, loss is 0.0003174666780978441\n",
      "epoch: 15 step: 58, loss is 0.0012814020738005638\n",
      "epoch: 15 step: 59, loss is 0.0003370295453350991\n",
      "epoch: 15 step: 60, loss is 0.00010085526446346194\n",
      "epoch: 15 step: 61, loss is 0.000674817303661257\n",
      "epoch: 15 step: 62, loss is 0.00032625769381411374\n",
      "epoch: 15 step: 63, loss is 0.0005159744177944958\n",
      "epoch: 15 step: 64, loss is 0.0006793852080591023\n",
      "epoch: 15 step: 65, loss is 0.0004715246905107051\n",
      "epoch: 15 step: 66, loss is 0.0004108355788048357\n",
      "epoch: 15 step: 67, loss is 0.0003559532924555242\n",
      "epoch: 15 step: 68, loss is 0.0018033940577879548\n",
      "epoch: 15 step: 69, loss is 0.001073469640687108\n",
      "epoch: 15 step: 70, loss is 4.060145511175506e-05\n",
      "epoch: 15 step: 71, loss is 0.00042870567995123565\n",
      "epoch: 15 step: 72, loss is 0.000676432391628623\n",
      "epoch: 15 step: 73, loss is 0.0002870428725145757\n",
      "epoch: 15 step: 74, loss is 0.0004370418027974665\n",
      "epoch: 15 step: 75, loss is 0.0006506508216261864\n",
      "epoch: 15 step: 76, loss is 0.0006429151399061084\n",
      "epoch: 15 step: 77, loss is 0.000283791683614254\n",
      "epoch: 15 step: 78, loss is 0.0005134617094881833\n",
      "epoch: 15 step: 79, loss is 0.0007069064886309206\n",
      "epoch: 15 step: 80, loss is 0.0015812122728675604\n",
      "epoch: 15 step: 81, loss is 0.000366590335033834\n",
      "epoch: 15 step: 82, loss is 0.00022952166909817606\n",
      "epoch: 15 step: 83, loss is 0.001203927444294095\n",
      "epoch: 15 step: 84, loss is 0.000517289387062192\n",
      "epoch: 15 step: 85, loss is 0.0005040966789238155\n",
      "epoch: 15 step: 86, loss is 0.000716681475751102\n",
      "epoch: 15 step: 87, loss is 0.0005858007934875786\n",
      "epoch: 15 step: 88, loss is 0.0003641358925960958\n",
      "epoch: 15 step: 89, loss is 0.0012250138679519296\n",
      "epoch: 15 step: 90, loss is 0.00025837606517598033\n",
      "epoch: 15 step: 91, loss is 0.000989123829640448\n",
      "epoch: 15 step: 92, loss is 0.0001640048430999741\n",
      "epoch: 15 step: 93, loss is 0.0006457487470470369\n",
      "epoch: 15 step: 94, loss is 0.0004852565180044621\n",
      "epoch: 15 step: 95, loss is 0.000505240575876087\n",
      "epoch: 15 step: 96, loss is 0.0002001140092033893\n",
      "epoch: 15 step: 97, loss is 0.0007392108673229814\n",
      "epoch: 15 step: 98, loss is 0.0008494405192323029\n",
      "epoch: 15 step: 99, loss is 0.001503710518591106\n",
      "epoch: 15 step: 100, loss is 0.0006604886730201542\n",
      "epoch: 15 step: 101, loss is 0.0007542800158262253\n",
      "epoch: 15 step: 102, loss is 0.0008633466204628348\n",
      "epoch: 15 step: 103, loss is 0.0006458685384131968\n",
      "epoch: 15 step: 104, loss is 0.000958204735070467\n",
      "epoch: 15 step: 105, loss is 0.0006052000098861754\n",
      "epoch: 15 step: 106, loss is 0.00038136326475068927\n",
      "epoch: 15 step: 107, loss is 0.0002877849619835615\n",
      "epoch: 15 step: 108, loss is 0.0004985628183931112\n",
      "epoch: 15 step: 109, loss is 0.0010085701942443848\n",
      "epoch: 15 step: 110, loss is 0.002412158064544201\n",
      "epoch: 15 step: 111, loss is 0.0003631192957982421\n",
      "epoch: 15 step: 112, loss is 0.0005316177848726511\n",
      "epoch: 15 step: 113, loss is 0.0006801767158322036\n",
      "epoch: 15 step: 114, loss is 0.001918744994327426\n",
      "epoch: 15 step: 115, loss is 0.0009933779947459698\n",
      "epoch: 15 step: 116, loss is 0.00043570096022449434\n",
      "epoch: 15 step: 117, loss is 0.00039882087730802596\n",
      "epoch: 15 step: 118, loss is 0.0004351951356511563\n",
      "epoch: 15 step: 119, loss is 0.00022935133893042803\n",
      "epoch: 15 step: 120, loss is 0.000288905983325094\n",
      "epoch: 15 step: 121, loss is 0.0009903365280479193\n",
      "epoch: 15 step: 122, loss is 0.0005987663171254098\n",
      "epoch: 15 step: 123, loss is 0.0017515122890472412\n",
      "epoch: 15 step: 124, loss is 0.0005625190678983927\n",
      "epoch: 15 step: 125, loss is 0.0015305094420909882\n",
      "epoch: 15 step: 126, loss is 0.0006984531064517796\n",
      "epoch: 15 step: 127, loss is 0.0011287771631032228\n",
      "epoch: 15 step: 128, loss is 0.0002765418903436512\n",
      "epoch: 15 step: 129, loss is 0.0005966078024357557\n",
      "epoch: 15 step: 130, loss is 0.0006293482147157192\n",
      "epoch: 15 step: 131, loss is 0.0009741319809108973\n",
      "epoch: 15 step: 132, loss is 0.0004634571960195899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 133, loss is 0.0009956146823242307\n",
      "epoch: 15 step: 134, loss is 0.00036496881511993706\n",
      "epoch: 15 step: 135, loss is 0.0002827933640219271\n",
      "epoch: 15 step: 136, loss is 0.0007277290569618344\n",
      "epoch: 15 step: 137, loss is 0.0006515734130516648\n",
      "epoch: 15 step: 138, loss is 0.0007483798544853926\n",
      "epoch: 15 step: 139, loss is 0.00021458625269588083\n",
      "epoch: 15 step: 140, loss is 0.0020874624606221914\n",
      "epoch: 15 step: 141, loss is 0.0014797440962865949\n",
      "epoch: 15 step: 142, loss is 0.001296789152547717\n",
      "epoch: 15 step: 143, loss is 0.0006385786109603941\n",
      "epoch: 15 step: 144, loss is 0.000650224566925317\n",
      "epoch: 15 step: 145, loss is 0.001572167151607573\n",
      "epoch: 15 step: 146, loss is 0.0002831139718182385\n",
      "epoch: 15 step: 147, loss is 0.0005716753657907248\n",
      "epoch: 15 step: 148, loss is 0.0005904179997742176\n",
      "epoch: 15 step: 149, loss is 0.0006648824200965464\n",
      "epoch: 15 step: 150, loss is 0.000336786441039294\n",
      "epoch: 15 step: 151, loss is 0.0010693800868466496\n",
      "epoch: 15 step: 152, loss is 0.0004615128564182669\n",
      "epoch: 15 step: 153, loss is 0.0005625349003821611\n",
      "epoch: 15 step: 154, loss is 0.00011203876056242734\n",
      "epoch: 15 step: 155, loss is 0.0006513305124826729\n",
      "epoch: 15 step: 156, loss is 0.0008736606105230749\n",
      "epoch: 15 step: 157, loss is 0.0005679128225892782\n",
      "epoch: 15 step: 158, loss is 0.0007306432817131281\n",
      "epoch: 15 step: 159, loss is 0.0003124485956504941\n",
      "epoch: 15 step: 160, loss is 0.0003255931369494647\n",
      "epoch: 15 step: 161, loss is 0.0012237265473231673\n",
      "epoch: 15 step: 162, loss is 0.000857044942677021\n",
      "epoch: 15 step: 163, loss is 0.0007468538242392242\n",
      "epoch: 15 step: 164, loss is 0.0007288769702427089\n",
      "epoch: 15 step: 165, loss is 0.0004564968985505402\n",
      "epoch: 15 step: 166, loss is 0.00043199604260735214\n",
      "epoch: 15 step: 167, loss is 0.0006230220315046608\n",
      "epoch: 15 step: 168, loss is 0.0004433125432115048\n",
      "epoch: 15 step: 169, loss is 0.0004598484665621072\n",
      "epoch: 15 step: 170, loss is 0.0004642042040359229\n",
      "epoch: 15 step: 171, loss is 0.0003001043514814228\n",
      "epoch: 15 step: 172, loss is 0.0006306620198301971\n",
      "epoch: 15 step: 173, loss is 0.0010367477079853415\n",
      "epoch: 15 step: 174, loss is 0.0009113227715715766\n",
      "epoch: 15 step: 175, loss is 0.000902849598787725\n",
      "epoch: 15 step: 176, loss is 0.0009948592633008957\n",
      "epoch: 15 step: 177, loss is 0.0010371992830187082\n",
      "epoch: 15 step: 178, loss is 0.0006182033685036004\n",
      "epoch: 15 step: 179, loss is 0.000822155037894845\n",
      "epoch: 15 step: 180, loss is 0.00043114484287798405\n",
      "epoch: 15 step: 181, loss is 0.0006376896053552628\n",
      "epoch: 15 step: 182, loss is 0.0008473554626107216\n",
      "epoch: 15 step: 183, loss is 0.0008514643413946033\n",
      "epoch: 15 step: 184, loss is 0.000400189048377797\n",
      "epoch: 15 step: 185, loss is 0.00015104966587387025\n",
      "epoch: 15 step: 186, loss is 0.00040077604353427887\n",
      "epoch: 15 step: 187, loss is 0.0005144693423062563\n",
      "epoch: 15 step: 188, loss is 0.0006450400687754154\n",
      "epoch: 15 step: 189, loss is 0.0006892549572512507\n",
      "epoch: 15 step: 190, loss is 0.0006687406566925347\n",
      "epoch: 15 step: 191, loss is 0.0007002138299867511\n",
      "epoch: 15 step: 192, loss is 0.00017956417286768556\n",
      "epoch: 15 step: 193, loss is 0.00048146492918021977\n",
      "epoch: 15 step: 194, loss is 0.0010956223122775555\n",
      "epoch: 15 step: 195, loss is 0.00043168742558918893\n",
      "epoch: 15 step: 196, loss is 0.00031980325002223253\n",
      "epoch: 15 step: 197, loss is 0.0008315318846143782\n",
      "epoch: 15 step: 198, loss is 0.0008666208595968783\n",
      "epoch: 15 step: 199, loss is 0.0004500116629060358\n",
      "epoch: 15 step: 200, loss is 0.0009424351737834513\n",
      "epoch: 15 step: 201, loss is 0.00014671827375423163\n",
      "epoch: 15 step: 202, loss is 0.0004153101472184062\n",
      "epoch: 15 step: 203, loss is 0.000632666633464396\n",
      "epoch: 15 step: 204, loss is 0.0004280434222891927\n",
      "epoch: 15 step: 205, loss is 0.0009509396040812135\n",
      "epoch: 15 step: 206, loss is 0.0013954496243968606\n",
      "epoch: 15 step: 207, loss is 0.00017897467478178442\n",
      "epoch: 15 step: 208, loss is 0.0014895065687596798\n",
      "epoch: 15 step: 209, loss is 0.0004458444891497493\n",
      "epoch: 15 step: 210, loss is 0.00039861953700892627\n",
      "epoch: 15 step: 211, loss is 0.0016402645269408822\n",
      "epoch: 15 step: 212, loss is 0.0003516828583087772\n",
      "epoch: 15 step: 213, loss is 0.0006087883375585079\n",
      "epoch: 15 step: 214, loss is 0.00022303794685285538\n",
      "epoch: 15 step: 215, loss is 0.0008471239707432687\n",
      "epoch: 15 step: 216, loss is 0.00040779271512292325\n",
      "epoch: 15 step: 217, loss is 0.0006793224019929767\n",
      "epoch: 15 step: 218, loss is 0.00039018350071273744\n",
      "epoch: 15 step: 219, loss is 0.0004630788753274828\n",
      "epoch: 15 step: 220, loss is 0.0005378982750698924\n",
      "epoch: 15 step: 221, loss is 0.00037870797677896917\n",
      "epoch: 15 step: 222, loss is 0.0005643654731102288\n",
      "epoch: 15 step: 223, loss is 0.0013738289708271623\n",
      "epoch: 15 step: 224, loss is 0.0004662425199057907\n",
      "epoch: 15 step: 225, loss is 0.00046643780660815537\n",
      "epoch: 15 step: 226, loss is 0.0008987163892015815\n",
      "epoch: 15 step: 227, loss is 0.0007041344651952386\n",
      "epoch: 15 step: 228, loss is 0.001122038229368627\n",
      "epoch: 15 step: 229, loss is 0.0005741373170167208\n",
      "epoch: 15 step: 230, loss is 0.0003854061651509255\n",
      "epoch: 15 step: 231, loss is 0.002053395612165332\n",
      "epoch: 15 step: 232, loss is 0.0007046249229460955\n",
      "epoch: 15 step: 233, loss is 0.0007277206750586629\n",
      "epoch: 15 step: 234, loss is 0.0006637030164711177\n",
      "epoch: 15 step: 235, loss is 0.0012420929269865155\n",
      "epoch: 15 step: 236, loss is 0.00027552185929380357\n",
      "epoch: 15 step: 237, loss is 0.001708576804958284\n",
      "epoch: 15 step: 238, loss is 0.0005616432172246277\n",
      "epoch: 15 step: 239, loss is 0.0007409113459289074\n",
      "epoch: 15 step: 240, loss is 0.0003379241097718477\n",
      "epoch: 15 step: 241, loss is 0.0005411046440713108\n",
      "epoch: 15 step: 242, loss is 0.0009841786231845617\n",
      "epoch: 15 step: 243, loss is 0.0002839018125087023\n",
      "epoch: 15 step: 244, loss is 0.0007226612651720643\n",
      "epoch: 15 step: 245, loss is 0.0004866959643550217\n",
      "epoch: 15 step: 246, loss is 0.0002972746442537755\n",
      "epoch: 15 step: 247, loss is 0.0009988683741539717\n",
      "epoch: 15 step: 248, loss is 0.001168701914139092\n",
      "epoch: 15 step: 249, loss is 0.0015172063140198588\n",
      "epoch: 15 step: 250, loss is 0.00013403159391600639\n",
      "epoch: 15 step: 251, loss is 0.00038496541674248874\n",
      "epoch: 15 step: 252, loss is 0.0014765505911782384\n",
      "epoch: 15 step: 253, loss is 0.00029753398848697543\n",
      "epoch: 15 step: 254, loss is 0.0008477834053337574\n",
      "epoch: 15 step: 255, loss is 0.0005318964831531048\n",
      "epoch: 15 step: 256, loss is 0.001273012487217784\n",
      "epoch: 15 step: 257, loss is 0.0017785148229449987\n",
      "epoch: 15 step: 258, loss is 0.0014308658428490162\n",
      "epoch: 15 step: 259, loss is 0.0006408586050383747\n",
      "epoch: 15 step: 260, loss is 0.0004220704722683877\n",
      "epoch: 15 step: 261, loss is 0.0005340530769899487\n",
      "epoch: 15 step: 262, loss is 0.0006594526930712163\n",
      "epoch: 15 step: 263, loss is 0.0005886090802960098\n",
      "epoch: 15 step: 264, loss is 0.0004879404732491821\n",
      "epoch: 15 step: 265, loss is 0.0006354464567266405\n",
      "epoch: 15 step: 266, loss is 0.0008361111977137625\n",
      "epoch: 15 step: 267, loss is 0.0016648415476083755\n",
      "epoch: 15 step: 268, loss is 0.0008310347329825163\n",
      "epoch: 15 step: 269, loss is 0.0009493795223534107\n",
      "epoch: 15 step: 270, loss is 0.0005424530245363712\n",
      "epoch: 15 step: 271, loss is 0.0005679284804500639\n",
      "epoch: 15 step: 272, loss is 0.0006487414357252419\n",
      "epoch: 15 step: 273, loss is 0.0006776583613827825\n",
      "epoch: 15 step: 274, loss is 0.0006338389357551932\n",
      "epoch: 15 step: 275, loss is 0.0007331959786824882\n",
      "epoch: 15 step: 276, loss is 0.00035855433088727295\n",
      "epoch: 15 step: 277, loss is 0.0005214492557570338\n",
      "epoch: 15 step: 278, loss is 0.000981788500212133\n",
      "epoch: 15 step: 279, loss is 0.00016574304027017206\n",
      "epoch: 15 step: 280, loss is 0.0004352675168775022\n",
      "epoch: 15 step: 281, loss is 0.0002903669374063611\n",
      "epoch: 15 step: 282, loss is 0.0008325466769747436\n",
      "epoch: 15 step: 283, loss is 0.0006439638091251254\n",
      "epoch: 15 step: 284, loss is 0.0015952779212966561\n",
      "epoch: 15 step: 285, loss is 0.0013551890151575208\n",
      "epoch: 15 step: 286, loss is 0.0001884052180685103\n",
      "epoch: 15 step: 287, loss is 0.0008450283785350621\n",
      "epoch: 15 step: 288, loss is 0.0007807834190316498\n",
      "epoch: 15 step: 289, loss is 0.0004285820759832859\n",
      "epoch: 15 step: 290, loss is 0.00031421618768945336\n",
      "epoch: 15 step: 291, loss is 0.0007827224326319993\n",
      "epoch: 15 step: 292, loss is 0.0009421652066521347\n",
      "epoch: 15 step: 293, loss is 0.0004077133780810982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 294, loss is 0.0004509486607275903\n",
      "epoch: 15 step: 295, loss is 0.0007626868900842965\n",
      "epoch: 15 step: 296, loss is 0.0013168661389499903\n",
      "epoch: 15 step: 297, loss is 0.000990594970062375\n",
      "epoch: 15 step: 298, loss is 0.0011406532721593976\n",
      "epoch: 15 step: 299, loss is 0.00047319597797468305\n",
      "epoch: 15 step: 300, loss is 0.0005253254203125834\n",
      "epoch: 15 step: 301, loss is 0.0005030580214224756\n",
      "epoch: 15 step: 302, loss is 0.0002759854542091489\n",
      "epoch: 15 step: 303, loss is 0.0005208019865676761\n",
      "epoch: 15 step: 304, loss is 0.00023697905999142677\n",
      "epoch: 15 step: 305, loss is 0.0006589306867681444\n",
      "epoch: 15 step: 306, loss is 0.000999665935523808\n",
      "epoch: 15 step: 307, loss is 0.000491666083689779\n",
      "epoch: 15 step: 308, loss is 0.00027134662377648056\n",
      "epoch: 15 step: 309, loss is 0.0008563647861592472\n",
      "epoch: 15 step: 310, loss is 0.0005051094340160489\n",
      "epoch: 15 step: 311, loss is 0.00037789123598486185\n",
      "epoch: 15 step: 312, loss is 0.0009694233885966241\n",
      "epoch: 15 step: 313, loss is 0.0011659871088340878\n",
      "epoch: 15 step: 314, loss is 0.0003961720212828368\n",
      "epoch: 15 step: 315, loss is 0.00012561978655867279\n",
      "epoch: 15 step: 316, loss is 0.0009184818482026458\n",
      "epoch: 15 step: 317, loss is 0.00031884326017461717\n",
      "epoch: 15 step: 318, loss is 0.0009842001600190997\n",
      "epoch: 15 step: 319, loss is 0.0005270628025755286\n",
      "epoch: 15 step: 320, loss is 0.0008487036102451384\n",
      "epoch: 15 step: 321, loss is 0.0007778212311677635\n",
      "epoch: 15 step: 322, loss is 0.0007248942274600267\n",
      "epoch: 15 step: 323, loss is 0.0008840450318530202\n",
      "epoch: 15 step: 324, loss is 0.0011749822879210114\n",
      "epoch: 15 step: 325, loss is 0.0009070607484318316\n",
      "epoch: 15 step: 326, loss is 0.0006152286077849567\n",
      "epoch: 15 step: 327, loss is 0.0005520245176739991\n",
      "epoch: 15 step: 328, loss is 0.0006985269137658179\n",
      "epoch: 15 step: 329, loss is 0.0007406646618619561\n",
      "epoch: 15 step: 330, loss is 0.00022909384279046208\n",
      "epoch: 15 step: 331, loss is 0.0006140186451375484\n",
      "epoch: 15 step: 332, loss is 0.0009061545715667307\n",
      "epoch: 15 step: 333, loss is 0.0006048555951565504\n",
      "epoch: 15 step: 334, loss is 0.000818837434053421\n",
      "epoch: 15 step: 335, loss is 0.0012811925262212753\n",
      "epoch: 15 step: 336, loss is 0.0002441768301650882\n",
      "epoch: 15 step: 337, loss is 0.0014098992105573416\n",
      "epoch: 15 step: 338, loss is 0.0007836484001018107\n",
      "epoch: 15 step: 339, loss is 0.0004987507709302008\n",
      "epoch: 15 step: 340, loss is 0.0003236308693885803\n",
      "epoch: 15 step: 341, loss is 0.001190916053019464\n",
      "epoch: 15 step: 342, loss is 0.000651627779006958\n",
      "epoch: 15 step: 343, loss is 0.00023030753072816879\n",
      "epoch: 15 step: 344, loss is 0.00026700072339735925\n",
      "epoch: 15 step: 345, loss is 0.00039527579792775214\n",
      "epoch: 15 step: 346, loss is 0.0007321504526771605\n",
      "epoch: 15 step: 347, loss is 0.0008220310555770993\n",
      "epoch: 15 step: 348, loss is 0.00129396328702569\n",
      "epoch: 15 step: 349, loss is 0.0006540853064507246\n",
      "epoch: 15 step: 350, loss is 0.001152500743046403\n",
      "epoch: 15 step: 351, loss is 0.00201526191085577\n",
      "epoch: 15 step: 352, loss is 0.0006109412643127143\n",
      "epoch: 15 step: 353, loss is 0.0008457889780402184\n",
      "epoch: 15 step: 354, loss is 0.0006107721710577607\n",
      "epoch: 15 step: 355, loss is 0.00037294687354005873\n",
      "epoch: 15 step: 356, loss is 0.0011708253296092153\n",
      "epoch: 15 step: 357, loss is 0.00043609447311609983\n",
      "epoch: 15 step: 358, loss is 0.0009260329534299672\n",
      "epoch: 15 step: 359, loss is 0.0005931557971052825\n",
      "epoch: 15 step: 360, loss is 0.0008370080613531172\n",
      "epoch: 15 step: 361, loss is 0.0005455681821331382\n",
      "epoch: 15 step: 362, loss is 0.0008144416497088969\n",
      "epoch: 15 step: 363, loss is 0.001134010381065309\n",
      "epoch: 15 step: 364, loss is 0.000489763158839196\n",
      "epoch: 15 step: 365, loss is 0.0006586435483768582\n",
      "epoch: 15 step: 366, loss is 0.0007161156390793622\n",
      "epoch: 15 step: 367, loss is 0.0010043848305940628\n",
      "epoch: 15 step: 368, loss is 0.00043108154204674065\n",
      "epoch: 15 step: 369, loss is 0.0009818715043365955\n",
      "epoch: 15 step: 370, loss is 0.000637652410659939\n",
      "epoch: 15 step: 371, loss is 0.00163835019338876\n",
      "epoch: 15 step: 372, loss is 0.0006793219945393503\n",
      "epoch: 15 step: 373, loss is 0.0018982948968186975\n",
      "epoch: 15 step: 374, loss is 0.0008586767944507301\n",
      "epoch: 15 step: 375, loss is 0.0006149405962787569\n",
      "Train epoch time: 12031.259 ms, per step time: 32.083 ms\n",
      "epoch: 16 step: 1, loss is 0.0016498800832778215\n",
      "epoch: 16 step: 2, loss is 0.0009486562339589\n",
      "epoch: 16 step: 3, loss is 0.0010791965760290623\n",
      "epoch: 16 step: 4, loss is 0.001200958387926221\n",
      "epoch: 16 step: 5, loss is 0.0009071711101569235\n",
      "epoch: 16 step: 6, loss is 0.0011486258590593934\n",
      "epoch: 16 step: 7, loss is 0.0009104585042223334\n",
      "epoch: 16 step: 8, loss is 0.0009851718787103891\n",
      "epoch: 16 step: 9, loss is 0.0020085496362298727\n",
      "epoch: 16 step: 10, loss is 0.0007909092819318175\n",
      "epoch: 16 step: 11, loss is 0.0015093585243448615\n",
      "epoch: 16 step: 12, loss is 0.0012065679766237736\n",
      "epoch: 16 step: 13, loss is 0.0012563815107569098\n",
      "epoch: 16 step: 14, loss is 0.0010399612365290523\n",
      "epoch: 16 step: 15, loss is 0.0005658304435200989\n",
      "epoch: 16 step: 16, loss is 0.001498773111961782\n",
      "epoch: 16 step: 17, loss is 0.000260304834228009\n",
      "epoch: 16 step: 18, loss is 0.0008545945747755468\n",
      "epoch: 16 step: 19, loss is 0.0007855319418013096\n",
      "epoch: 16 step: 20, loss is 0.0007468539988622069\n",
      "epoch: 16 step: 21, loss is 0.0020524468272924423\n",
      "epoch: 16 step: 22, loss is 0.00177864043507725\n",
      "epoch: 16 step: 23, loss is 0.00012017849803669378\n",
      "epoch: 16 step: 24, loss is 0.0005899766692891717\n",
      "epoch: 16 step: 25, loss is 0.0007153998012654483\n",
      "epoch: 16 step: 26, loss is 0.000242064445046708\n",
      "epoch: 16 step: 27, loss is 0.0009401518036611378\n",
      "epoch: 16 step: 28, loss is 0.0002994482056237757\n",
      "epoch: 16 step: 29, loss is 0.001383508089929819\n",
      "epoch: 16 step: 30, loss is 0.0015764918643981218\n",
      "epoch: 16 step: 31, loss is 0.0007508838316425681\n",
      "epoch: 16 step: 32, loss is 0.0009179660701192915\n",
      "epoch: 16 step: 33, loss is 0.00020565668819472194\n",
      "epoch: 16 step: 34, loss is 0.0004299054853618145\n",
      "epoch: 16 step: 35, loss is 0.0017855039332062006\n",
      "epoch: 16 step: 36, loss is 0.0008375952602364123\n",
      "epoch: 16 step: 37, loss is 0.0006342657143250108\n",
      "epoch: 16 step: 38, loss is 0.0019253913778811693\n",
      "epoch: 16 step: 39, loss is 0.0005859768716618419\n",
      "epoch: 16 step: 40, loss is 0.0008644726476632059\n",
      "epoch: 16 step: 41, loss is 0.002414081944152713\n",
      "epoch: 16 step: 42, loss is 0.00041999956010840833\n",
      "epoch: 16 step: 43, loss is 0.0006320890970528126\n",
      "epoch: 16 step: 44, loss is 0.0005215434939600527\n",
      "epoch: 16 step: 45, loss is 0.00022469817486125976\n",
      "epoch: 16 step: 46, loss is 0.00045647454680874944\n",
      "epoch: 16 step: 47, loss is 0.00027337006758898497\n",
      "epoch: 16 step: 48, loss is 0.0012488799402490258\n",
      "epoch: 16 step: 49, loss is 0.0003838665725197643\n",
      "epoch: 16 step: 50, loss is 0.0009031606605276465\n",
      "epoch: 16 step: 51, loss is 0.000547087867744267\n",
      "epoch: 16 step: 52, loss is 0.0002710728731472045\n",
      "epoch: 16 step: 53, loss is 0.0012414215598255396\n",
      "epoch: 16 step: 54, loss is 0.0008107806788757443\n",
      "epoch: 16 step: 55, loss is 0.000517844338901341\n",
      "epoch: 16 step: 56, loss is 0.00045868026791140437\n",
      "epoch: 16 step: 57, loss is 0.0009705653646960855\n",
      "epoch: 16 step: 58, loss is 0.0005690415855497122\n",
      "epoch: 16 step: 59, loss is 0.0005616494454443455\n",
      "epoch: 16 step: 60, loss is 0.000820576271507889\n",
      "epoch: 16 step: 61, loss is 0.0017434775363653898\n",
      "epoch: 16 step: 62, loss is 0.0009141726768575609\n",
      "epoch: 16 step: 63, loss is 0.0014590403297916055\n",
      "epoch: 16 step: 64, loss is 0.00043011398520320654\n",
      "epoch: 16 step: 65, loss is 0.0003425450704526156\n",
      "epoch: 16 step: 66, loss is 0.0010920894565060735\n",
      "epoch: 16 step: 67, loss is 0.00043261126847937703\n",
      "epoch: 16 step: 68, loss is 0.0005258135497570038\n",
      "epoch: 16 step: 69, loss is 0.0009596511954441667\n",
      "epoch: 16 step: 70, loss is 0.0008650947129353881\n",
      "epoch: 16 step: 71, loss is 0.0008060730760917068\n",
      "epoch: 16 step: 72, loss is 0.0009486260241828859\n",
      "epoch: 16 step: 73, loss is 0.00018309954612050205\n",
      "epoch: 16 step: 74, loss is 0.0012771133333444595\n",
      "epoch: 16 step: 75, loss is 0.0008107329485937953\n",
      "epoch: 16 step: 76, loss is 0.0007997620268724859\n",
      "epoch: 16 step: 77, loss is 0.001385458861477673\n",
      "epoch: 16 step: 78, loss is 0.000764159020036459\n",
      "epoch: 16 step: 79, loss is 0.0013196223881095648\n",
      "epoch: 16 step: 80, loss is 0.0018008534098044038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 81, loss is 0.0013106727274134755\n",
      "epoch: 16 step: 82, loss is 0.0011665128404274583\n",
      "epoch: 16 step: 83, loss is 0.0007717133848927915\n",
      "epoch: 16 step: 84, loss is 0.00043436128180474043\n",
      "epoch: 16 step: 85, loss is 0.0014254851266741753\n",
      "epoch: 16 step: 86, loss is 0.0004250459314789623\n",
      "epoch: 16 step: 87, loss is 0.0007519448408856988\n",
      "epoch: 16 step: 88, loss is 0.0006931675598025322\n",
      "epoch: 16 step: 89, loss is 0.0005203367327339947\n",
      "epoch: 16 step: 90, loss is 0.00022429095406550914\n",
      "epoch: 16 step: 91, loss is 0.0006428243359550834\n",
      "epoch: 16 step: 92, loss is 0.001078276545740664\n",
      "epoch: 16 step: 93, loss is 0.000684284430462867\n",
      "epoch: 16 step: 94, loss is 0.0005606918130069971\n",
      "epoch: 16 step: 95, loss is 0.0003516699653118849\n",
      "epoch: 16 step: 96, loss is 0.00037969826371409\n",
      "epoch: 16 step: 97, loss is 0.0006690045702271163\n",
      "epoch: 16 step: 98, loss is 0.0005604725447483361\n",
      "epoch: 16 step: 99, loss is 0.0003322681877762079\n",
      "epoch: 16 step: 100, loss is 0.00045056079397909343\n",
      "epoch: 16 step: 101, loss is 0.000506423064507544\n",
      "epoch: 16 step: 102, loss is 0.0007359778974205256\n",
      "epoch: 16 step: 103, loss is 0.0009072630782611668\n",
      "epoch: 16 step: 104, loss is 0.0005545400199480355\n",
      "epoch: 16 step: 105, loss is 0.0006049999501556158\n",
      "epoch: 16 step: 106, loss is 0.0015188471879810095\n",
      "epoch: 16 step: 107, loss is 0.0007426252705045044\n",
      "epoch: 16 step: 108, loss is 0.0007459269254468381\n",
      "epoch: 16 step: 109, loss is 0.0006545268115587533\n",
      "epoch: 16 step: 110, loss is 0.0010818007867783308\n",
      "epoch: 16 step: 111, loss is 0.0007253962685354054\n",
      "epoch: 16 step: 112, loss is 0.0013462136266753078\n",
      "epoch: 16 step: 113, loss is 0.0017624112078920007\n",
      "epoch: 16 step: 114, loss is 0.0004982143873348832\n",
      "epoch: 16 step: 115, loss is 0.0007029552944004536\n",
      "epoch: 16 step: 116, loss is 0.00039678989560343325\n",
      "epoch: 16 step: 117, loss is 0.0004932861775159836\n",
      "epoch: 16 step: 118, loss is 0.0007009069086052477\n",
      "epoch: 16 step: 119, loss is 0.00037334527587518096\n",
      "epoch: 16 step: 120, loss is 0.0007898142212070525\n",
      "epoch: 16 step: 121, loss is 0.0004486425023060292\n",
      "epoch: 16 step: 122, loss is 0.001256953226402402\n",
      "epoch: 16 step: 123, loss is 0.0002364205865887925\n",
      "epoch: 16 step: 124, loss is 0.0013207722222432494\n",
      "epoch: 16 step: 125, loss is 0.0005046931910328567\n",
      "epoch: 16 step: 126, loss is 0.0006634900928474963\n",
      "epoch: 16 step: 127, loss is 0.0004778526199515909\n",
      "epoch: 16 step: 128, loss is 0.0011295170988887548\n",
      "epoch: 16 step: 129, loss is 0.0007039743941277266\n",
      "epoch: 16 step: 130, loss is 0.0008651453536003828\n",
      "epoch: 16 step: 131, loss is 0.0008526594610884786\n",
      "epoch: 16 step: 132, loss is 0.0015418484108522534\n",
      "epoch: 16 step: 133, loss is 0.0003957364533562213\n",
      "epoch: 16 step: 134, loss is 0.0005925691802985966\n",
      "epoch: 16 step: 135, loss is 0.0005938804242759943\n",
      "epoch: 16 step: 136, loss is 0.0006565165822394192\n",
      "epoch: 16 step: 137, loss is 0.00034257539664395154\n",
      "epoch: 16 step: 138, loss is 0.0006047133938409388\n",
      "epoch: 16 step: 139, loss is 0.0005765881505794823\n",
      "epoch: 16 step: 140, loss is 0.0014461807440966368\n",
      "epoch: 16 step: 141, loss is 0.0006693624309264123\n",
      "epoch: 16 step: 142, loss is 0.0021827369928359985\n",
      "epoch: 16 step: 143, loss is 0.0006064735352993011\n",
      "epoch: 16 step: 144, loss is 0.0009491095552220941\n",
      "epoch: 16 step: 145, loss is 0.0007896877359598875\n",
      "epoch: 16 step: 146, loss is 0.0015481298323720694\n",
      "epoch: 16 step: 147, loss is 0.0006863471935503185\n",
      "epoch: 16 step: 148, loss is 0.0007376418798230588\n",
      "epoch: 16 step: 149, loss is 0.0005830908776260912\n",
      "epoch: 16 step: 150, loss is 0.0005943860160186887\n",
      "epoch: 16 step: 151, loss is 0.0009539189632050693\n",
      "epoch: 16 step: 152, loss is 0.0004228233592584729\n",
      "epoch: 16 step: 153, loss is 0.0007681760471314192\n",
      "epoch: 16 step: 154, loss is 0.0005570115754380822\n",
      "epoch: 16 step: 155, loss is 0.00038780554314143956\n",
      "epoch: 16 step: 156, loss is 0.0005549272755160928\n",
      "epoch: 16 step: 157, loss is 0.0004512362356763333\n",
      "epoch: 16 step: 158, loss is 0.0008169888751581311\n",
      "epoch: 16 step: 159, loss is 0.0007588648586533964\n",
      "epoch: 16 step: 160, loss is 0.0008314350852742791\n",
      "epoch: 16 step: 161, loss is 0.0005026485305279493\n",
      "epoch: 16 step: 162, loss is 0.001222900114953518\n",
      "epoch: 16 step: 163, loss is 0.0004668540204875171\n",
      "epoch: 16 step: 164, loss is 0.0005440087406896055\n",
      "epoch: 16 step: 165, loss is 0.0005895713693462312\n",
      "epoch: 16 step: 166, loss is 0.0003993418940808624\n",
      "epoch: 16 step: 167, loss is 0.0007316968403756618\n",
      "epoch: 16 step: 168, loss is 0.0007041968638077378\n",
      "epoch: 16 step: 169, loss is 0.0008135156822390854\n",
      "epoch: 16 step: 170, loss is 0.0005748461117036641\n",
      "epoch: 16 step: 171, loss is 0.0005033807246945798\n",
      "epoch: 16 step: 172, loss is 0.0008912734920158982\n",
      "epoch: 16 step: 173, loss is 0.0009231570875272155\n",
      "epoch: 16 step: 174, loss is 0.0010925180977210402\n",
      "epoch: 16 step: 175, loss is 0.00046785251470282674\n",
      "epoch: 16 step: 176, loss is 0.0006588177056983113\n",
      "epoch: 16 step: 177, loss is 0.0007163441041484475\n",
      "epoch: 16 step: 178, loss is 0.0010323765454813838\n",
      "epoch: 16 step: 179, loss is 0.0008139288984239101\n",
      "epoch: 16 step: 180, loss is 0.0002722193894442171\n",
      "epoch: 16 step: 181, loss is 0.0010454830480739474\n",
      "epoch: 16 step: 182, loss is 0.000583757006097585\n",
      "epoch: 16 step: 183, loss is 0.0004290444776415825\n",
      "epoch: 16 step: 184, loss is 0.0005993311642669141\n",
      "epoch: 16 step: 185, loss is 0.0028339121490716934\n",
      "epoch: 16 step: 186, loss is 0.00039392049075104296\n",
      "epoch: 16 step: 187, loss is 0.0005448675365187228\n",
      "epoch: 16 step: 188, loss is 0.0007598676020279527\n",
      "epoch: 16 step: 189, loss is 0.001834062859416008\n",
      "epoch: 16 step: 190, loss is 0.000656250340398401\n",
      "epoch: 16 step: 191, loss is 0.0006744214915670455\n",
      "epoch: 16 step: 192, loss is 0.00017829157877713442\n",
      "epoch: 16 step: 193, loss is 0.000894236087333411\n",
      "epoch: 16 step: 194, loss is 0.0008875012281350791\n",
      "epoch: 16 step: 195, loss is 0.00039859162643551826\n",
      "epoch: 16 step: 196, loss is 0.0005800455110147595\n",
      "epoch: 16 step: 197, loss is 0.0008917627274058759\n",
      "epoch: 16 step: 198, loss is 0.0006101932958699763\n",
      "epoch: 16 step: 199, loss is 0.0005676305736415088\n",
      "epoch: 16 step: 200, loss is 0.0005126193282194436\n",
      "epoch: 16 step: 201, loss is 0.0006980277830734849\n",
      "epoch: 16 step: 202, loss is 0.0006911382079124451\n",
      "epoch: 16 step: 203, loss is 0.0006214911118149757\n",
      "epoch: 16 step: 204, loss is 0.0016981088556349277\n",
      "epoch: 16 step: 205, loss is 0.0007101933588273823\n",
      "epoch: 16 step: 206, loss is 0.0005800322396680713\n",
      "epoch: 16 step: 207, loss is 0.0010219586547464132\n",
      "epoch: 16 step: 208, loss is 0.0006424295133911073\n",
      "epoch: 16 step: 209, loss is 0.0010204380378127098\n",
      "epoch: 16 step: 210, loss is 0.0006000490975566208\n",
      "epoch: 16 step: 211, loss is 0.0003448540810495615\n",
      "epoch: 16 step: 212, loss is 0.00033761837403289974\n",
      "epoch: 16 step: 213, loss is 0.00038179889088496566\n",
      "epoch: 16 step: 214, loss is 0.0005359760252758861\n",
      "epoch: 16 step: 215, loss is 0.0003486917121335864\n",
      "epoch: 16 step: 216, loss is 0.0006476695416495204\n",
      "epoch: 16 step: 217, loss is 0.00015531927056144923\n",
      "epoch: 16 step: 218, loss is 0.0005502306157723069\n",
      "epoch: 16 step: 219, loss is 0.0008630197262391448\n",
      "epoch: 16 step: 220, loss is 0.0003424990572966635\n",
      "epoch: 16 step: 221, loss is 0.0011077161179855466\n",
      "epoch: 16 step: 222, loss is 0.0002144760510418564\n",
      "epoch: 16 step: 223, loss is 0.000543240224942565\n",
      "epoch: 16 step: 224, loss is 0.0003131563717033714\n",
      "epoch: 16 step: 225, loss is 0.0013053768780082464\n",
      "epoch: 16 step: 226, loss is 0.0002819208020810038\n",
      "epoch: 16 step: 227, loss is 0.0003868221247103065\n",
      "epoch: 16 step: 228, loss is 0.0005853361217305064\n",
      "epoch: 16 step: 229, loss is 0.00034675170900300145\n",
      "epoch: 16 step: 230, loss is 0.00041879122727550566\n",
      "epoch: 16 step: 231, loss is 0.0015413898508995771\n",
      "epoch: 16 step: 232, loss is 0.0004529594734776765\n",
      "epoch: 16 step: 233, loss is 0.00024238284095190465\n",
      "epoch: 16 step: 234, loss is 0.0011689323000609875\n",
      "epoch: 16 step: 235, loss is 0.00048798209172673523\n",
      "epoch: 16 step: 236, loss is 0.0004912314470857382\n",
      "epoch: 16 step: 237, loss is 0.0010618101805448532\n",
      "epoch: 16 step: 238, loss is 0.0005659166490659118\n",
      "epoch: 16 step: 239, loss is 0.00038038601633161306\n",
      "epoch: 16 step: 240, loss is 0.0007258959230966866\n",
      "epoch: 16 step: 241, loss is 0.001017365837469697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 242, loss is 0.0007487108814530075\n",
      "epoch: 16 step: 243, loss is 0.0011950890766456723\n",
      "epoch: 16 step: 244, loss is 0.0004746537306345999\n",
      "epoch: 16 step: 245, loss is 0.0006467988714575768\n",
      "epoch: 16 step: 246, loss is 0.0009565805667079985\n",
      "epoch: 16 step: 247, loss is 0.0003405327151995152\n",
      "epoch: 16 step: 248, loss is 0.00048312608851119876\n",
      "epoch: 16 step: 249, loss is 0.0007680118433199823\n",
      "epoch: 16 step: 250, loss is 0.0005907852901145816\n",
      "epoch: 16 step: 251, loss is 0.000996027491055429\n",
      "epoch: 16 step: 252, loss is 0.0011217724531888962\n",
      "epoch: 16 step: 253, loss is 0.00038899198989383876\n",
      "epoch: 16 step: 254, loss is 0.0006840867572464049\n",
      "epoch: 16 step: 255, loss is 0.000725619844160974\n",
      "epoch: 16 step: 256, loss is 0.0010595725616440177\n",
      "epoch: 16 step: 257, loss is 0.0006392086506821215\n",
      "epoch: 16 step: 258, loss is 0.0005071620689705014\n",
      "epoch: 16 step: 259, loss is 0.0007557586650364101\n",
      "epoch: 16 step: 260, loss is 0.00032633301452733576\n",
      "epoch: 16 step: 261, loss is 0.0006471493979915977\n",
      "epoch: 16 step: 262, loss is 0.0006390555645339191\n",
      "epoch: 16 step: 263, loss is 0.0004727478662971407\n",
      "epoch: 16 step: 264, loss is 0.000991082633845508\n",
      "epoch: 16 step: 265, loss is 0.0016986127011477947\n",
      "epoch: 16 step: 266, loss is 0.0011056987568736076\n",
      "epoch: 16 step: 267, loss is 0.0003717656072694808\n",
      "epoch: 16 step: 268, loss is 0.0005131465150043368\n",
      "epoch: 16 step: 269, loss is 0.00019337535195518285\n",
      "epoch: 16 step: 270, loss is 0.0009324338170699775\n",
      "epoch: 16 step: 271, loss is 0.0012549818493425846\n",
      "epoch: 16 step: 272, loss is 0.0002729288244154304\n",
      "epoch: 16 step: 273, loss is 0.00038903113454580307\n",
      "epoch: 16 step: 274, loss is 0.0001993468904402107\n",
      "epoch: 16 step: 275, loss is 0.0005201014573685825\n",
      "epoch: 16 step: 276, loss is 0.00036135021946392953\n",
      "epoch: 16 step: 277, loss is 0.001295680645853281\n",
      "epoch: 16 step: 278, loss is 0.0006048415671102703\n",
      "epoch: 16 step: 279, loss is 0.0004513156018219888\n",
      "epoch: 16 step: 280, loss is 0.00048453814815729856\n",
      "epoch: 16 step: 281, loss is 0.00045223828055895865\n",
      "epoch: 16 step: 282, loss is 0.00030468081240542233\n",
      "epoch: 16 step: 283, loss is 0.0009570238762535155\n",
      "epoch: 16 step: 284, loss is 0.0007355990237556398\n",
      "epoch: 16 step: 285, loss is 0.00148785172495991\n",
      "epoch: 16 step: 286, loss is 0.00013095996109768748\n",
      "epoch: 16 step: 287, loss is 0.0009407901670783758\n",
      "epoch: 16 step: 288, loss is 0.0008132986840792\n",
      "epoch: 16 step: 289, loss is 0.00036094061215408146\n",
      "epoch: 16 step: 290, loss is 0.0003634723834693432\n",
      "epoch: 16 step: 291, loss is 0.00048765959218144417\n",
      "epoch: 16 step: 292, loss is 0.000503658433444798\n",
      "epoch: 16 step: 293, loss is 0.00039043661672621965\n",
      "epoch: 16 step: 294, loss is 0.00031496566953137517\n",
      "epoch: 16 step: 295, loss is 0.000747751269955188\n",
      "epoch: 16 step: 296, loss is 0.0005089216865599155\n",
      "epoch: 16 step: 297, loss is 0.0003694795595947653\n",
      "epoch: 16 step: 298, loss is 0.000494531646836549\n",
      "epoch: 16 step: 299, loss is 0.0009307157597504556\n",
      "epoch: 16 step: 300, loss is 0.0004321382148191333\n",
      "epoch: 16 step: 301, loss is 0.0003599023330025375\n",
      "epoch: 16 step: 302, loss is 0.0006864424794912338\n",
      "epoch: 16 step: 303, loss is 0.0004884940572082996\n",
      "epoch: 16 step: 304, loss is 0.0006986486841924489\n",
      "epoch: 16 step: 305, loss is 0.0003795281518250704\n",
      "epoch: 16 step: 306, loss is 0.0001550812303321436\n",
      "epoch: 16 step: 307, loss is 0.0003075950953643769\n",
      "epoch: 16 step: 308, loss is 0.0006503447075374424\n",
      "epoch: 16 step: 309, loss is 0.0003650775761343539\n",
      "epoch: 16 step: 310, loss is 0.0008138661505654454\n",
      "epoch: 16 step: 311, loss is 0.000845608941745013\n",
      "epoch: 16 step: 312, loss is 0.00029177754186093807\n",
      "epoch: 16 step: 313, loss is 0.00032421573996543884\n",
      "epoch: 16 step: 314, loss is 0.0005202421452850103\n",
      "epoch: 16 step: 315, loss is 0.00020431927987374365\n",
      "epoch: 16 step: 316, loss is 0.0016171443276107311\n",
      "epoch: 16 step: 317, loss is 0.0009515602723695338\n",
      "epoch: 16 step: 318, loss is 0.0005035221693105996\n",
      "epoch: 16 step: 319, loss is 0.0008827483397908509\n",
      "epoch: 16 step: 320, loss is 0.0008143163868226111\n",
      "epoch: 16 step: 321, loss is 0.0019725579768419266\n",
      "epoch: 16 step: 322, loss is 0.0003846040344797075\n",
      "epoch: 16 step: 323, loss is 0.000444192934082821\n",
      "epoch: 16 step: 324, loss is 0.0008177831768989563\n",
      "epoch: 16 step: 325, loss is 0.0005837003118358552\n",
      "epoch: 16 step: 326, loss is 0.00020148453768342733\n",
      "epoch: 16 step: 327, loss is 0.00043397952686063945\n",
      "epoch: 16 step: 328, loss is 0.0005055494839325547\n",
      "epoch: 16 step: 329, loss is 0.0003926139324903488\n",
      "epoch: 16 step: 330, loss is 0.0008530430495738983\n",
      "epoch: 16 step: 331, loss is 0.000526447081938386\n",
      "epoch: 16 step: 332, loss is 0.0014931026380509138\n",
      "epoch: 16 step: 333, loss is 0.0008324835798703134\n",
      "epoch: 16 step: 334, loss is 0.000212272658245638\n",
      "epoch: 16 step: 335, loss is 0.0008765116217546165\n",
      "epoch: 16 step: 336, loss is 0.0003799832484219223\n",
      "epoch: 16 step: 337, loss is 0.0006721967365592718\n",
      "epoch: 16 step: 338, loss is 0.0007198695675469935\n",
      "epoch: 16 step: 339, loss is 0.0005369694554246962\n",
      "epoch: 16 step: 340, loss is 0.0005081252893432975\n",
      "epoch: 16 step: 341, loss is 0.0010429747635498643\n",
      "epoch: 16 step: 342, loss is 0.0008142589358612895\n",
      "epoch: 16 step: 343, loss is 0.0007154028862714767\n",
      "epoch: 16 step: 344, loss is 0.000815381295979023\n",
      "epoch: 16 step: 345, loss is 0.0010397551814094186\n",
      "epoch: 16 step: 346, loss is 0.0014383879024535418\n",
      "epoch: 16 step: 347, loss is 0.0007811701507307589\n",
      "epoch: 16 step: 348, loss is 0.000287830043816939\n",
      "epoch: 16 step: 349, loss is 0.00024605393991805613\n",
      "epoch: 16 step: 350, loss is 0.0004155760398134589\n",
      "epoch: 16 step: 351, loss is 0.0007294524693861604\n",
      "epoch: 16 step: 352, loss is 0.001584238838404417\n",
      "epoch: 16 step: 353, loss is 0.0015419217525050044\n",
      "epoch: 16 step: 354, loss is 0.002117631258442998\n",
      "epoch: 16 step: 355, loss is 0.0013729569036513567\n",
      "epoch: 16 step: 356, loss is 0.00028752972139045596\n",
      "epoch: 16 step: 357, loss is 0.0003836129908449948\n",
      "epoch: 16 step: 358, loss is 0.0005926803569309413\n",
      "epoch: 16 step: 359, loss is 0.0012825335143133998\n",
      "epoch: 16 step: 360, loss is 0.0008190221269614995\n",
      "epoch: 16 step: 361, loss is 0.001054073334671557\n",
      "epoch: 16 step: 362, loss is 0.00042336428305134177\n",
      "epoch: 16 step: 363, loss is 0.0003078002773690969\n",
      "epoch: 16 step: 364, loss is 0.000295430509140715\n",
      "epoch: 16 step: 365, loss is 0.00029960204847157\n",
      "epoch: 16 step: 366, loss is 0.00028593139722943306\n",
      "epoch: 16 step: 367, loss is 0.00026851979782804847\n",
      "epoch: 16 step: 368, loss is 0.0004110639274585992\n",
      "epoch: 16 step: 369, loss is 0.000899154634680599\n",
      "epoch: 16 step: 370, loss is 0.0005407794960774481\n",
      "epoch: 16 step: 371, loss is 0.0008741507772356272\n",
      "epoch: 16 step: 372, loss is 0.0013795987470075488\n",
      "epoch: 16 step: 373, loss is 0.0006083968328312039\n",
      "epoch: 16 step: 374, loss is 0.00015141017502173781\n",
      "epoch: 16 step: 375, loss is 0.0011571148643270135\n",
      "Train epoch time: 11945.289 ms, per step time: 31.854 ms\n",
      "epoch: 17 step: 1, loss is 0.0018558810697868466\n",
      "epoch: 17 step: 2, loss is 0.00043162101064808667\n",
      "epoch: 17 step: 3, loss is 0.00032936508068814874\n",
      "epoch: 17 step: 4, loss is 0.0008480427204631269\n",
      "epoch: 17 step: 5, loss is 0.0004163478151895106\n",
      "epoch: 17 step: 6, loss is 0.0005530397174879909\n",
      "epoch: 17 step: 7, loss is 0.0010539302602410316\n",
      "epoch: 17 step: 8, loss is 0.0007083453820087016\n",
      "epoch: 17 step: 9, loss is 0.0007972437888383865\n",
      "epoch: 17 step: 10, loss is 0.0006836635293439031\n",
      "epoch: 17 step: 11, loss is 0.0010171798057854176\n",
      "epoch: 17 step: 12, loss is 0.00040544901276007295\n",
      "epoch: 17 step: 13, loss is 0.0003354859072715044\n",
      "epoch: 17 step: 14, loss is 0.000570012372918427\n",
      "epoch: 17 step: 15, loss is 0.00034042770857922733\n",
      "epoch: 17 step: 16, loss is 0.0012565795332193375\n",
      "epoch: 17 step: 17, loss is 0.0011096529196947813\n",
      "epoch: 17 step: 18, loss is 0.00020488296286202967\n",
      "epoch: 17 step: 19, loss is 0.00033018566318787634\n",
      "epoch: 17 step: 20, loss is 0.0003213088202755898\n",
      "epoch: 17 step: 21, loss is 0.0009507948998361826\n",
      "epoch: 17 step: 22, loss is 0.0002260661858599633\n",
      "epoch: 17 step: 23, loss is 0.0013363674515858293\n",
      "epoch: 17 step: 24, loss is 0.0002797393826767802\n",
      "epoch: 17 step: 25, loss is 0.0005082898424006999\n",
      "epoch: 17 step: 26, loss is 0.0012075328268110752\n",
      "epoch: 17 step: 27, loss is 0.0006443207385018468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 28, loss is 0.00047884631203487515\n",
      "epoch: 17 step: 29, loss is 0.0010407111840322614\n",
      "epoch: 17 step: 30, loss is 0.0012356509687379003\n",
      "epoch: 17 step: 31, loss is 0.00020903354743495584\n",
      "epoch: 17 step: 32, loss is 0.0006125145591795444\n",
      "epoch: 17 step: 33, loss is 0.0009513127733953297\n",
      "epoch: 17 step: 34, loss is 0.0008513666689395905\n",
      "epoch: 17 step: 35, loss is 0.0005272321868687868\n",
      "epoch: 17 step: 36, loss is 0.0016948477132245898\n",
      "epoch: 17 step: 37, loss is 0.0002123986923834309\n",
      "epoch: 17 step: 38, loss is 0.00037053879350423813\n",
      "epoch: 17 step: 39, loss is 0.0006228808779269457\n",
      "epoch: 17 step: 40, loss is 0.0005215817946009338\n",
      "epoch: 17 step: 41, loss is 0.000733107968699187\n",
      "epoch: 17 step: 42, loss is 0.0011603509774431586\n",
      "epoch: 17 step: 43, loss is 0.0008607141207903624\n",
      "epoch: 17 step: 44, loss is 0.000572299410123378\n",
      "epoch: 17 step: 45, loss is 0.0004748071078211069\n",
      "epoch: 17 step: 46, loss is 0.0009601629571989179\n",
      "epoch: 17 step: 47, loss is 0.0013023278443142772\n",
      "epoch: 17 step: 48, loss is 0.000477293913718313\n",
      "epoch: 17 step: 49, loss is 0.0007833232521079481\n",
      "epoch: 17 step: 50, loss is 0.0007152038742788136\n",
      "epoch: 17 step: 51, loss is 0.0006947299116291106\n",
      "epoch: 17 step: 52, loss is 0.0005547510809265077\n",
      "epoch: 17 step: 53, loss is 0.00042821752140298486\n",
      "epoch: 17 step: 54, loss is 0.0004495696339290589\n",
      "epoch: 17 step: 55, loss is 0.0007640997646376491\n",
      "epoch: 17 step: 56, loss is 0.0005301047931425273\n",
      "epoch: 17 step: 57, loss is 0.0007327469647862017\n",
      "epoch: 17 step: 58, loss is 0.0005711159901693463\n",
      "epoch: 17 step: 59, loss is 0.0014882860705256462\n",
      "epoch: 17 step: 60, loss is 0.0004623935092240572\n",
      "epoch: 17 step: 61, loss is 0.0005035173962824047\n",
      "epoch: 17 step: 62, loss is 0.0006052430253475904\n",
      "epoch: 17 step: 63, loss is 0.0006608867552131414\n",
      "epoch: 17 step: 64, loss is 0.0008386675035580993\n",
      "epoch: 17 step: 65, loss is 0.000859675114043057\n",
      "epoch: 17 step: 66, loss is 0.0004469057603273541\n",
      "epoch: 17 step: 67, loss is 0.0003153093857690692\n",
      "epoch: 17 step: 68, loss is 0.000508455908857286\n",
      "epoch: 17 step: 69, loss is 0.00013553787721320987\n",
      "epoch: 17 step: 70, loss is 0.0004747982893604785\n",
      "epoch: 17 step: 71, loss is 0.0006342572742141783\n",
      "epoch: 17 step: 72, loss is 0.0006927845533937216\n",
      "epoch: 17 step: 73, loss is 0.0007670857012271881\n",
      "epoch: 17 step: 74, loss is 0.0009421723079867661\n",
      "epoch: 17 step: 75, loss is 0.0008072102209553123\n",
      "epoch: 17 step: 76, loss is 0.0006191104766912758\n",
      "epoch: 17 step: 77, loss is 0.0010161299724131823\n",
      "epoch: 17 step: 78, loss is 0.0004461914941202849\n",
      "epoch: 17 step: 79, loss is 0.0009181352215819061\n",
      "epoch: 17 step: 80, loss is 0.0005252731498330832\n",
      "epoch: 17 step: 81, loss is 0.0004342497559264302\n",
      "epoch: 17 step: 82, loss is 0.00020042818505316973\n",
      "epoch: 17 step: 83, loss is 0.00046210529399104416\n",
      "epoch: 17 step: 84, loss is 0.0005675564170815051\n",
      "epoch: 17 step: 85, loss is 0.0006037307321093976\n",
      "epoch: 17 step: 86, loss is 0.001558766234666109\n",
      "epoch: 17 step: 87, loss is 0.00038146006409078836\n",
      "epoch: 17 step: 88, loss is 0.00025614400510676205\n",
      "epoch: 17 step: 89, loss is 0.0013562405947595835\n",
      "epoch: 17 step: 90, loss is 0.0012097109574824572\n",
      "epoch: 17 step: 91, loss is 0.001362720737233758\n",
      "epoch: 17 step: 92, loss is 0.0009189580450765789\n",
      "epoch: 17 step: 93, loss is 0.0005781231448054314\n",
      "epoch: 17 step: 94, loss is 0.001013055327348411\n",
      "epoch: 17 step: 95, loss is 0.0007388441590592265\n",
      "epoch: 17 step: 96, loss is 0.0005935440422035754\n",
      "epoch: 17 step: 97, loss is 0.000502299633808434\n",
      "epoch: 17 step: 98, loss is 0.0003482608590275049\n",
      "epoch: 17 step: 99, loss is 0.0007929593557491899\n",
      "epoch: 17 step: 100, loss is 0.00017949090397451073\n",
      "epoch: 17 step: 101, loss is 0.00047215077211149037\n",
      "epoch: 17 step: 102, loss is 0.0007198681705631316\n",
      "epoch: 17 step: 103, loss is 0.0005152414669282734\n",
      "epoch: 17 step: 104, loss is 0.000797287211753428\n",
      "epoch: 17 step: 105, loss is 0.00028126713004894555\n",
      "epoch: 17 step: 106, loss is 0.0005159683059900999\n",
      "epoch: 17 step: 107, loss is 0.0003916281566489488\n",
      "epoch: 17 step: 108, loss is 0.0007423005299642682\n",
      "epoch: 17 step: 109, loss is 0.0008771343273110688\n",
      "epoch: 17 step: 110, loss is 0.00021606351947411895\n",
      "epoch: 17 step: 111, loss is 0.0008153988746926188\n",
      "epoch: 17 step: 112, loss is 0.000507035874761641\n",
      "epoch: 17 step: 113, loss is 0.0008694459684193134\n",
      "epoch: 17 step: 114, loss is 0.0005107814795337617\n",
      "epoch: 17 step: 115, loss is 0.0007693584775552154\n",
      "epoch: 17 step: 116, loss is 0.0016179936937987804\n",
      "epoch: 17 step: 117, loss is 0.0010580449597910047\n",
      "epoch: 17 step: 118, loss is 0.0005511783529073\n",
      "epoch: 17 step: 119, loss is 0.001254960661754012\n",
      "epoch: 17 step: 120, loss is 0.0009828552138060331\n",
      "epoch: 17 step: 121, loss is 0.0006730228196829557\n",
      "epoch: 17 step: 122, loss is 0.0006327626761049032\n",
      "epoch: 17 step: 123, loss is 0.00030796811915934086\n",
      "epoch: 17 step: 124, loss is 0.0009276651544496417\n",
      "epoch: 17 step: 125, loss is 0.0007266371394507587\n",
      "epoch: 17 step: 126, loss is 0.0005634390981867909\n",
      "epoch: 17 step: 127, loss is 0.0005026729195378721\n",
      "epoch: 17 step: 128, loss is 0.0006095526623539627\n",
      "epoch: 17 step: 129, loss is 0.0002645498316269368\n",
      "epoch: 17 step: 130, loss is 0.0007886368548497558\n",
      "epoch: 17 step: 131, loss is 0.0004957251949235797\n",
      "epoch: 17 step: 132, loss is 0.0012925992486998439\n",
      "epoch: 17 step: 133, loss is 0.0009343942510895431\n",
      "epoch: 17 step: 134, loss is 0.0004013960715383291\n",
      "epoch: 17 step: 135, loss is 0.0002623674226924777\n",
      "epoch: 17 step: 136, loss is 0.000571905926335603\n",
      "epoch: 17 step: 137, loss is 0.00035710184602066875\n",
      "epoch: 17 step: 138, loss is 0.000913491181563586\n",
      "epoch: 17 step: 139, loss is 0.00027493544621393085\n",
      "epoch: 17 step: 140, loss is 0.0018558511510491371\n",
      "epoch: 17 step: 141, loss is 0.0009964285418391228\n",
      "epoch: 17 step: 142, loss is 0.00022011272085364908\n",
      "epoch: 17 step: 143, loss is 0.000948391214478761\n",
      "epoch: 17 step: 144, loss is 0.0004723526944871992\n",
      "epoch: 17 step: 145, loss is 0.0002489642647560686\n",
      "epoch: 17 step: 146, loss is 0.0006878438871353865\n",
      "epoch: 17 step: 147, loss is 0.000695328984875232\n",
      "epoch: 17 step: 148, loss is 0.00026983104180544615\n",
      "epoch: 17 step: 149, loss is 0.000594686483964324\n",
      "epoch: 17 step: 150, loss is 0.0007012069690972567\n",
      "epoch: 17 step: 151, loss is 0.0011116251116618514\n",
      "epoch: 17 step: 152, loss is 0.0003648680867627263\n",
      "epoch: 17 step: 153, loss is 0.0012185402447357774\n",
      "epoch: 17 step: 154, loss is 0.0009171045967377722\n",
      "epoch: 17 step: 155, loss is 0.00037232882459647954\n",
      "epoch: 17 step: 156, loss is 0.00034506930387578905\n",
      "epoch: 17 step: 157, loss is 0.0007839112658984959\n",
      "epoch: 17 step: 158, loss is 0.0010089862626045942\n",
      "epoch: 17 step: 159, loss is 0.0007516485638916492\n",
      "epoch: 17 step: 160, loss is 0.0009427486802451313\n",
      "epoch: 17 step: 161, loss is 0.0006313292542472482\n",
      "epoch: 17 step: 162, loss is 0.0008023710106499493\n",
      "epoch: 17 step: 163, loss is 0.0009875288233160973\n",
      "epoch: 17 step: 164, loss is 0.0011321164201945066\n",
      "epoch: 17 step: 165, loss is 0.000318831269396469\n",
      "epoch: 17 step: 166, loss is 0.0007497920305468142\n",
      "epoch: 17 step: 167, loss is 0.0003512709809001535\n",
      "epoch: 17 step: 168, loss is 0.0008022458641789854\n",
      "epoch: 17 step: 169, loss is 0.0005886871367692947\n",
      "epoch: 17 step: 170, loss is 0.0013335321564227343\n",
      "epoch: 17 step: 171, loss is 0.0014053387567400932\n",
      "epoch: 17 step: 172, loss is 5.3540050430456176e-05\n",
      "epoch: 17 step: 173, loss is 0.0005734729347750545\n",
      "epoch: 17 step: 174, loss is 0.00031922044581733644\n",
      "epoch: 17 step: 175, loss is 0.0001336054556304589\n",
      "epoch: 17 step: 176, loss is 0.0004462299693841487\n",
      "epoch: 17 step: 177, loss is 0.0006141309277154505\n",
      "epoch: 17 step: 178, loss is 0.0008252427796833217\n",
      "epoch: 17 step: 179, loss is 0.0006014959653839469\n",
      "epoch: 17 step: 180, loss is 0.0005184721085242927\n",
      "epoch: 17 step: 181, loss is 0.0005363540258258581\n",
      "epoch: 17 step: 182, loss is 0.0007472512079402804\n",
      "epoch: 17 step: 183, loss is 0.0007423112983815372\n",
      "epoch: 17 step: 184, loss is 0.0011309622786939144\n",
      "epoch: 17 step: 185, loss is 0.0003811434144154191\n",
      "epoch: 17 step: 186, loss is 0.0004684074083343148\n",
      "epoch: 17 step: 187, loss is 0.0013263021828606725\n",
      "epoch: 17 step: 188, loss is 0.0006578355096280575\n",
      "epoch: 17 step: 189, loss is 0.0003398312837816775\n",
      "epoch: 17 step: 190, loss is 0.0005200544255785644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 191, loss is 0.0006392018403857946\n",
      "epoch: 17 step: 192, loss is 0.0014201682060956955\n",
      "epoch: 17 step: 193, loss is 0.0004359304439276457\n",
      "epoch: 17 step: 194, loss is 0.0001598167873453349\n",
      "epoch: 17 step: 195, loss is 0.0005569207714870572\n",
      "epoch: 17 step: 196, loss is 0.000511651043780148\n",
      "epoch: 17 step: 197, loss is 0.0002715203445404768\n",
      "epoch: 17 step: 198, loss is 0.0003830545174423605\n",
      "epoch: 17 step: 199, loss is 0.0007682569557800889\n",
      "epoch: 17 step: 200, loss is 0.0004985122941434383\n",
      "epoch: 17 step: 201, loss is 0.0008866083226166666\n",
      "epoch: 17 step: 202, loss is 0.0011650233063846827\n",
      "epoch: 17 step: 203, loss is 0.0006360983825288713\n",
      "epoch: 17 step: 204, loss is 0.0006430544890463352\n",
      "epoch: 17 step: 205, loss is 0.0006368676549755037\n",
      "epoch: 17 step: 206, loss is 0.0012896595289930701\n",
      "epoch: 17 step: 207, loss is 0.0006925550987944007\n",
      "epoch: 17 step: 208, loss is 0.00111199461389333\n",
      "epoch: 17 step: 209, loss is 0.0011384361423552036\n",
      "epoch: 17 step: 210, loss is 0.0010749251814559102\n",
      "epoch: 17 step: 211, loss is 0.0004125149571336806\n",
      "epoch: 17 step: 212, loss is 0.00035280900192447007\n",
      "epoch: 17 step: 213, loss is 0.0012011837679892778\n",
      "epoch: 17 step: 214, loss is 0.00047497698687948287\n",
      "epoch: 17 step: 215, loss is 0.0005091896164231002\n",
      "epoch: 17 step: 216, loss is 0.0019392452668398619\n",
      "epoch: 17 step: 217, loss is 0.0006454900722019374\n",
      "epoch: 17 step: 218, loss is 0.0007286237669177353\n",
      "epoch: 17 step: 219, loss is 0.0013423034688457847\n",
      "epoch: 17 step: 220, loss is 0.0007330755470320582\n",
      "epoch: 17 step: 221, loss is 0.0003936681605409831\n",
      "epoch: 17 step: 222, loss is 0.00012047633936163038\n",
      "epoch: 17 step: 223, loss is 0.0006204996607266366\n",
      "epoch: 17 step: 224, loss is 0.00038419218617491424\n",
      "epoch: 17 step: 225, loss is 0.0009746014839038253\n",
      "epoch: 17 step: 226, loss is 0.0006846269243396819\n",
      "epoch: 17 step: 227, loss is 0.001371782855130732\n",
      "epoch: 17 step: 228, loss is 0.0005807289853692055\n",
      "epoch: 17 step: 229, loss is 0.0005899745156057179\n",
      "epoch: 17 step: 230, loss is 0.0004391297698020935\n",
      "epoch: 17 step: 231, loss is 0.0004136938077863306\n",
      "epoch: 17 step: 232, loss is 0.0008542576688341796\n",
      "epoch: 17 step: 233, loss is 0.0003521151083987206\n",
      "epoch: 17 step: 234, loss is 0.0007699667476117611\n",
      "epoch: 17 step: 235, loss is 0.000397122377762571\n",
      "epoch: 17 step: 236, loss is 0.0008259328315034509\n",
      "epoch: 17 step: 237, loss is 0.000250000914093107\n",
      "epoch: 17 step: 238, loss is 0.0009537061559967697\n",
      "epoch: 17 step: 239, loss is 0.0016060394700616598\n",
      "epoch: 17 step: 240, loss is 0.0007567888242192566\n",
      "epoch: 17 step: 241, loss is 0.0007194830686785281\n",
      "epoch: 17 step: 242, loss is 0.0006600023480132222\n",
      "epoch: 17 step: 243, loss is 0.000818643078673631\n",
      "epoch: 17 step: 244, loss is 0.002215417567640543\n",
      "epoch: 17 step: 245, loss is 0.00017780846974346787\n",
      "epoch: 17 step: 246, loss is 0.0006578256725333631\n",
      "epoch: 17 step: 247, loss is 0.0006430212524719536\n",
      "epoch: 17 step: 248, loss is 0.0006458815769292414\n",
      "epoch: 17 step: 249, loss is 0.00042521380237303674\n",
      "epoch: 17 step: 250, loss is 0.00032499994267709553\n",
      "epoch: 17 step: 251, loss is 0.0008806121186353266\n",
      "epoch: 17 step: 252, loss is 0.0003690686135087162\n",
      "epoch: 17 step: 253, loss is 0.00077055738074705\n",
      "epoch: 17 step: 254, loss is 0.0008869345183484256\n",
      "epoch: 17 step: 255, loss is 0.0005510213086381555\n",
      "epoch: 17 step: 256, loss is 0.0005152081721462309\n",
      "epoch: 17 step: 257, loss is 0.0011796813923865557\n",
      "epoch: 17 step: 258, loss is 0.001275041839107871\n",
      "epoch: 17 step: 259, loss is 0.000506713695358485\n",
      "epoch: 17 step: 260, loss is 0.0007613342604599893\n",
      "epoch: 17 step: 261, loss is 0.0008790641441009939\n",
      "epoch: 17 step: 262, loss is 0.0016783068422228098\n",
      "epoch: 17 step: 263, loss is 0.0008359623607248068\n",
      "epoch: 17 step: 264, loss is 0.0008305578376166523\n",
      "epoch: 17 step: 265, loss is 0.00022199894010555\n",
      "epoch: 17 step: 266, loss is 0.0003357719106134027\n",
      "epoch: 17 step: 267, loss is 0.00043388886842876673\n",
      "epoch: 17 step: 268, loss is 0.00036035891389474273\n",
      "epoch: 17 step: 269, loss is 0.0009933741530403495\n",
      "epoch: 17 step: 270, loss is 0.0006012907833792269\n",
      "epoch: 17 step: 271, loss is 0.0006376172532327473\n",
      "epoch: 17 step: 272, loss is 0.00042200167081318796\n",
      "epoch: 17 step: 273, loss is 0.0005515053053386509\n",
      "epoch: 17 step: 274, loss is 0.0004282190348021686\n",
      "epoch: 17 step: 275, loss is 0.0006668856949545443\n",
      "epoch: 17 step: 276, loss is 0.0008595370454713702\n",
      "epoch: 17 step: 277, loss is 0.0007256957469508052\n",
      "epoch: 17 step: 278, loss is 0.0004894741578027606\n",
      "epoch: 17 step: 279, loss is 0.0004676927928812802\n",
      "epoch: 17 step: 280, loss is 0.0004991345922462642\n",
      "epoch: 17 step: 281, loss is 0.0005512934876605868\n",
      "epoch: 17 step: 282, loss is 0.0005222160252742469\n",
      "epoch: 17 step: 283, loss is 0.0004064598469994962\n",
      "epoch: 17 step: 284, loss is 0.0011272912379354239\n",
      "epoch: 17 step: 285, loss is 0.003153860569000244\n",
      "epoch: 17 step: 286, loss is 0.0006422466831281781\n",
      "epoch: 17 step: 287, loss is 0.00033184318454004824\n",
      "epoch: 17 step: 288, loss is 0.0008582047303207219\n",
      "epoch: 17 step: 289, loss is 0.0013362548779696226\n",
      "epoch: 17 step: 290, loss is 0.0007745887851342559\n",
      "epoch: 17 step: 291, loss is 0.0010510882129892707\n",
      "epoch: 17 step: 292, loss is 0.0015133339911699295\n",
      "epoch: 17 step: 293, loss is 0.0003274654154665768\n",
      "epoch: 17 step: 294, loss is 0.001315968343988061\n",
      "epoch: 17 step: 295, loss is 0.00024088133068289608\n",
      "epoch: 17 step: 296, loss is 0.0006455206894315779\n",
      "epoch: 17 step: 297, loss is 0.00016521956422366202\n",
      "epoch: 17 step: 298, loss is 0.000771367340348661\n",
      "epoch: 17 step: 299, loss is 0.0004267015610821545\n",
      "epoch: 17 step: 300, loss is 0.0011679403251037002\n",
      "epoch: 17 step: 301, loss is 0.0003576636081561446\n",
      "epoch: 17 step: 302, loss is 0.0001935956533998251\n",
      "epoch: 17 step: 303, loss is 0.002305415226146579\n",
      "epoch: 17 step: 304, loss is 0.0007716140826232731\n",
      "epoch: 17 step: 305, loss is 0.0006731889443472028\n",
      "epoch: 17 step: 306, loss is 0.001368254073895514\n",
      "epoch: 17 step: 307, loss is 0.0007896519382484257\n",
      "epoch: 17 step: 308, loss is 0.0006187399267219007\n",
      "epoch: 17 step: 309, loss is 0.001557889161631465\n",
      "epoch: 17 step: 310, loss is 0.0008542226278223097\n",
      "epoch: 17 step: 311, loss is 0.0009712642058730125\n",
      "epoch: 17 step: 312, loss is 0.0013102577067911625\n",
      "epoch: 17 step: 313, loss is 0.00035202328581362963\n",
      "epoch: 17 step: 314, loss is 0.0001724081375868991\n",
      "epoch: 17 step: 315, loss is 0.0004670785856433213\n",
      "epoch: 17 step: 316, loss is 0.0008463957929052413\n",
      "epoch: 17 step: 317, loss is 0.000981427263468504\n",
      "epoch: 17 step: 318, loss is 0.00045232693082652986\n",
      "epoch: 17 step: 319, loss is 0.001207366120070219\n",
      "epoch: 17 step: 320, loss is 0.0011897285003215075\n",
      "epoch: 17 step: 321, loss is 0.0002667938533704728\n",
      "epoch: 17 step: 322, loss is 0.0005306029343046248\n",
      "epoch: 17 step: 323, loss is 0.0007186923758126795\n",
      "epoch: 17 step: 324, loss is 0.0011873907642439008\n",
      "epoch: 17 step: 325, loss is 0.0003911902604158968\n",
      "epoch: 17 step: 326, loss is 0.0006012296071276069\n",
      "epoch: 17 step: 327, loss is 0.0002290857519255951\n",
      "epoch: 17 step: 328, loss is 0.0008280109614133835\n",
      "epoch: 17 step: 329, loss is 0.0007498996565118432\n",
      "epoch: 17 step: 330, loss is 0.0009893839014694095\n",
      "epoch: 17 step: 331, loss is 0.00025174784241244197\n",
      "epoch: 17 step: 332, loss is 0.0006159627228043973\n",
      "epoch: 17 step: 333, loss is 0.0004107401182409376\n",
      "epoch: 17 step: 334, loss is 0.000553558231331408\n",
      "epoch: 17 step: 335, loss is 0.0004739204596262425\n",
      "epoch: 17 step: 336, loss is 0.00023730062821414322\n",
      "epoch: 17 step: 337, loss is 0.00121759669855237\n",
      "epoch: 17 step: 338, loss is 0.000443609751528129\n",
      "epoch: 17 step: 339, loss is 0.0010659353574737906\n",
      "epoch: 17 step: 340, loss is 0.0006098232697695494\n",
      "epoch: 17 step: 341, loss is 0.0006150613771751523\n",
      "epoch: 17 step: 342, loss is 0.00033771322341635823\n",
      "epoch: 17 step: 343, loss is 0.0003149403491988778\n",
      "epoch: 17 step: 344, loss is 0.00035322681651450694\n",
      "epoch: 17 step: 345, loss is 0.0008085662266239524\n",
      "epoch: 17 step: 346, loss is 0.0018932893872261047\n",
      "epoch: 17 step: 347, loss is 0.0009514949633739889\n",
      "epoch: 17 step: 348, loss is 0.0011234921403229237\n",
      "epoch: 17 step: 349, loss is 0.000689581036567688\n",
      "epoch: 17 step: 350, loss is 0.0004924386739730835\n",
      "epoch: 17 step: 351, loss is 0.0005900394171476364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 352, loss is 0.0004619568935595453\n",
      "epoch: 17 step: 353, loss is 0.0005995780229568481\n",
      "epoch: 17 step: 354, loss is 0.0010614331113174558\n",
      "epoch: 17 step: 355, loss is 0.0001703504240140319\n",
      "epoch: 17 step: 356, loss is 0.0007187531446106732\n",
      "epoch: 17 step: 357, loss is 0.0002831659512594342\n",
      "epoch: 17 step: 358, loss is 0.001234722207300365\n",
      "epoch: 17 step: 359, loss is 0.00046804259181953967\n",
      "epoch: 17 step: 360, loss is 0.0001310819643549621\n",
      "epoch: 17 step: 361, loss is 0.0002020919491769746\n",
      "epoch: 17 step: 362, loss is 0.0009775063954293728\n",
      "epoch: 17 step: 363, loss is 0.00037806094042025506\n",
      "epoch: 17 step: 364, loss is 0.0003711720637511462\n",
      "epoch: 17 step: 365, loss is 0.00044090315350331366\n",
      "epoch: 17 step: 366, loss is 0.0008243382326327264\n",
      "epoch: 17 step: 367, loss is 0.0007873756694607437\n",
      "epoch: 17 step: 368, loss is 0.0005204618209972978\n",
      "epoch: 17 step: 369, loss is 0.0010257199173793197\n",
      "epoch: 17 step: 370, loss is 0.0005656908033415675\n",
      "epoch: 17 step: 371, loss is 0.0009782095439732075\n",
      "epoch: 17 step: 372, loss is 0.00046815071254968643\n",
      "epoch: 17 step: 373, loss is 0.00010724476305767894\n",
      "epoch: 17 step: 374, loss is 0.0009111195686273277\n",
      "epoch: 17 step: 375, loss is 0.0003763870627153665\n",
      "Train epoch time: 12033.025 ms, per step time: 32.088 ms\n",
      "epoch: 18 step: 1, loss is 0.00043551233829930425\n",
      "epoch: 18 step: 2, loss is 0.000628715381026268\n",
      "epoch: 18 step: 3, loss is 0.0006298061343841255\n",
      "epoch: 18 step: 4, loss is 0.00056646135635674\n",
      "epoch: 18 step: 5, loss is 0.000582509150262922\n",
      "epoch: 18 step: 6, loss is 0.0006062165484763682\n",
      "epoch: 18 step: 7, loss is 0.0019789384678006172\n",
      "epoch: 18 step: 8, loss is 0.0012524754274636507\n",
      "epoch: 18 step: 9, loss is 0.00027358843362890184\n",
      "epoch: 18 step: 10, loss is 0.0006727493018843234\n",
      "epoch: 18 step: 11, loss is 0.0009325374849140644\n",
      "epoch: 18 step: 12, loss is 0.0013621826656162739\n",
      "epoch: 18 step: 13, loss is 0.0003278352087363601\n",
      "epoch: 18 step: 14, loss is 0.000693506735842675\n",
      "epoch: 18 step: 15, loss is 0.0006751606124453247\n",
      "epoch: 18 step: 16, loss is 0.0005876199575141072\n",
      "epoch: 18 step: 17, loss is 0.001995198428630829\n",
      "epoch: 18 step: 18, loss is 0.0003765886358451098\n",
      "epoch: 18 step: 19, loss is 0.00019995428738184273\n",
      "epoch: 18 step: 20, loss is 0.0002833048056345433\n",
      "epoch: 18 step: 21, loss is 0.0013486433308571577\n",
      "epoch: 18 step: 22, loss is 0.0007754568941891193\n",
      "epoch: 18 step: 23, loss is 0.0003186555113643408\n",
      "epoch: 18 step: 24, loss is 0.0007765456684865057\n",
      "epoch: 18 step: 25, loss is 0.0008993462543003261\n",
      "epoch: 18 step: 26, loss is 0.0001733693788992241\n",
      "epoch: 18 step: 27, loss is 0.0004802350595127791\n",
      "epoch: 18 step: 28, loss is 0.0004489922139327973\n",
      "epoch: 18 step: 29, loss is 0.000822198111563921\n",
      "epoch: 18 step: 30, loss is 0.00011090802581747994\n",
      "epoch: 18 step: 31, loss is 0.0004349478695075959\n",
      "epoch: 18 step: 32, loss is 0.0001887842663563788\n",
      "epoch: 18 step: 33, loss is 0.000812496873550117\n",
      "epoch: 18 step: 34, loss is 0.00031247452716343105\n",
      "epoch: 18 step: 35, loss is 0.0008790040737949312\n",
      "epoch: 18 step: 36, loss is 0.0007809175876900554\n",
      "epoch: 18 step: 37, loss is 0.0003422803711146116\n",
      "epoch: 18 step: 38, loss is 0.0012545606587082148\n",
      "epoch: 18 step: 39, loss is 0.0002977096592076123\n",
      "epoch: 18 step: 40, loss is 0.0006843098090030253\n",
      "epoch: 18 step: 41, loss is 0.0004911569994874299\n",
      "epoch: 18 step: 42, loss is 0.00040105689549818635\n",
      "epoch: 18 step: 43, loss is 0.0005722035421058536\n",
      "epoch: 18 step: 44, loss is 0.0008330523851327598\n",
      "epoch: 18 step: 45, loss is 0.0008117372053675354\n",
      "epoch: 18 step: 46, loss is 0.0010386841604486108\n",
      "epoch: 18 step: 47, loss is 0.0007124081603251398\n",
      "epoch: 18 step: 48, loss is 0.0010726589243859053\n",
      "epoch: 18 step: 49, loss is 0.0010484573431313038\n",
      "epoch: 18 step: 50, loss is 0.00046005245530977845\n",
      "epoch: 18 step: 51, loss is 0.0006260417867451906\n",
      "epoch: 18 step: 52, loss is 0.0009583065984770656\n",
      "epoch: 18 step: 53, loss is 0.0014680060558021069\n",
      "epoch: 18 step: 54, loss is 0.0004516493354458362\n",
      "epoch: 18 step: 55, loss is 0.00044042320223525167\n",
      "epoch: 18 step: 56, loss is 0.0012755554635077715\n",
      "epoch: 18 step: 57, loss is 0.0009190391283482313\n",
      "epoch: 18 step: 58, loss is 0.0007343387696892023\n",
      "epoch: 18 step: 59, loss is 0.0019752266816794872\n",
      "epoch: 18 step: 60, loss is 0.0005938532412983477\n",
      "epoch: 18 step: 61, loss is 0.00023161619901657104\n",
      "epoch: 18 step: 62, loss is 0.0014822902157902718\n",
      "epoch: 18 step: 63, loss is 0.000809444347396493\n",
      "epoch: 18 step: 64, loss is 0.0006847353070043027\n",
      "epoch: 18 step: 65, loss is 0.0008505586301907897\n",
      "epoch: 18 step: 66, loss is 0.0009374197106808424\n",
      "epoch: 18 step: 67, loss is 0.0004320384468883276\n",
      "epoch: 18 step: 68, loss is 0.0005139801069162786\n",
      "epoch: 18 step: 69, loss is 0.00031106657115742564\n",
      "epoch: 18 step: 70, loss is 0.0008940341067500412\n",
      "epoch: 18 step: 71, loss is 0.000491476384922862\n",
      "epoch: 18 step: 72, loss is 0.00015507916396018118\n",
      "epoch: 18 step: 73, loss is 0.0003287490108050406\n",
      "epoch: 18 step: 74, loss is 0.00044953764881938696\n",
      "epoch: 18 step: 75, loss is 0.0005819695070385933\n",
      "epoch: 18 step: 76, loss is 0.000742163450922817\n",
      "epoch: 18 step: 77, loss is 0.0009267572895623744\n",
      "epoch: 18 step: 78, loss is 0.0009448091732338071\n",
      "epoch: 18 step: 79, loss is 0.00039662476046942174\n",
      "epoch: 18 step: 80, loss is 0.0008882734109647572\n",
      "epoch: 18 step: 81, loss is 0.0021458500996232033\n",
      "epoch: 18 step: 82, loss is 0.0006783948047086596\n",
      "epoch: 18 step: 83, loss is 0.0006425583851523697\n",
      "epoch: 18 step: 84, loss is 0.0010735554387792945\n",
      "epoch: 18 step: 85, loss is 0.00025736071984283626\n",
      "epoch: 18 step: 86, loss is 0.0004859691543970257\n",
      "epoch: 18 step: 87, loss is 0.0009675277979113162\n",
      "epoch: 18 step: 88, loss is 0.00118374137673527\n",
      "epoch: 18 step: 89, loss is 0.0010611617472022772\n",
      "epoch: 18 step: 90, loss is 0.0005908567109145224\n",
      "epoch: 18 step: 91, loss is 0.000770236540120095\n",
      "epoch: 18 step: 92, loss is 0.0003912427055183798\n",
      "epoch: 18 step: 93, loss is 0.00036040483973920345\n",
      "epoch: 18 step: 94, loss is 0.000842018227558583\n",
      "epoch: 18 step: 95, loss is 0.0006784900324419141\n",
      "epoch: 18 step: 96, loss is 0.000632336363196373\n",
      "epoch: 18 step: 97, loss is 0.000607426802162081\n",
      "epoch: 18 step: 98, loss is 0.0015504945768043399\n",
      "epoch: 18 step: 99, loss is 0.0008247215882875025\n",
      "epoch: 18 step: 100, loss is 0.0003904509940184653\n",
      "epoch: 18 step: 101, loss is 0.0008315074373967946\n",
      "epoch: 18 step: 102, loss is 0.0009818818653002381\n",
      "epoch: 18 step: 103, loss is 0.0011615395778790116\n",
      "epoch: 18 step: 104, loss is 0.0008469719905406237\n",
      "epoch: 18 step: 105, loss is 0.000800365989562124\n",
      "epoch: 18 step: 106, loss is 0.0012086103670299053\n",
      "epoch: 18 step: 107, loss is 0.001743315253406763\n",
      "epoch: 18 step: 108, loss is 0.0009647110709920526\n",
      "epoch: 18 step: 109, loss is 0.0006765592261217535\n",
      "epoch: 18 step: 110, loss is 0.0012635515304282308\n",
      "epoch: 18 step: 111, loss is 0.0003874639514833689\n",
      "epoch: 18 step: 112, loss is 0.00021956473938189447\n",
      "epoch: 18 step: 113, loss is 0.0004754619731102139\n",
      "epoch: 18 step: 114, loss is 0.0010444129584357142\n",
      "epoch: 18 step: 115, loss is 0.0007811153773218393\n",
      "epoch: 18 step: 116, loss is 0.0003011971421074122\n",
      "epoch: 18 step: 117, loss is 0.0007992690661922097\n",
      "epoch: 18 step: 118, loss is 0.0005614525871351361\n",
      "epoch: 18 step: 119, loss is 0.0007528800633735955\n",
      "epoch: 18 step: 120, loss is 0.0007701368303969502\n",
      "epoch: 18 step: 121, loss is 0.0008943445864133537\n",
      "epoch: 18 step: 122, loss is 0.00016742020670790225\n",
      "epoch: 18 step: 123, loss is 0.0001872240100055933\n",
      "epoch: 18 step: 124, loss is 0.0001691072538960725\n",
      "epoch: 18 step: 125, loss is 0.0010230805492028594\n",
      "epoch: 18 step: 126, loss is 0.0002848072908818722\n",
      "epoch: 18 step: 127, loss is 0.0005680890753865242\n",
      "epoch: 18 step: 128, loss is 0.00047972812899388373\n",
      "epoch: 18 step: 129, loss is 0.0007460276247002184\n",
      "epoch: 18 step: 130, loss is 0.00037898673326708376\n",
      "epoch: 18 step: 131, loss is 0.0004205031436868012\n",
      "epoch: 18 step: 132, loss is 0.0007837899029254913\n",
      "epoch: 18 step: 133, loss is 0.000719054660294205\n",
      "epoch: 18 step: 134, loss is 0.0004527198034338653\n",
      "epoch: 18 step: 135, loss is 0.00047311288653872907\n",
      "epoch: 18 step: 136, loss is 0.0008665387285873294\n",
      "epoch: 18 step: 137, loss is 0.0009061964228749275\n",
      "epoch: 18 step: 138, loss is 0.0005150124779902399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 139, loss is 0.0005584068712778389\n",
      "epoch: 18 step: 140, loss is 0.0009927846258506179\n",
      "epoch: 18 step: 141, loss is 0.0007077869959175587\n",
      "epoch: 18 step: 142, loss is 0.0004244759911671281\n",
      "epoch: 18 step: 143, loss is 0.0008650468662381172\n",
      "epoch: 18 step: 144, loss is 0.00034642673563212156\n",
      "epoch: 18 step: 145, loss is 0.00036064829328097403\n",
      "epoch: 18 step: 146, loss is 0.0005812380695715547\n",
      "epoch: 18 step: 147, loss is 0.0006575616425834596\n",
      "epoch: 18 step: 148, loss is 0.0006496995920315385\n",
      "epoch: 18 step: 149, loss is 0.000558147206902504\n",
      "epoch: 18 step: 150, loss is 0.00013382823090068996\n",
      "epoch: 18 step: 151, loss is 0.000521395995747298\n",
      "epoch: 18 step: 152, loss is 0.0023594640661031008\n",
      "epoch: 18 step: 153, loss is 0.000877993879839778\n",
      "epoch: 18 step: 154, loss is 0.0006236674380488694\n",
      "epoch: 18 step: 155, loss is 0.0003861536388285458\n",
      "epoch: 18 step: 156, loss is 0.000860663887578994\n",
      "epoch: 18 step: 157, loss is 0.00041417195461690426\n",
      "epoch: 18 step: 158, loss is 0.0006482356111519039\n",
      "epoch: 18 step: 159, loss is 0.001013457658700645\n",
      "epoch: 18 step: 160, loss is 0.0006979504250921309\n",
      "epoch: 18 step: 161, loss is 0.00038390044937841594\n",
      "epoch: 18 step: 162, loss is 0.0016548704588785768\n",
      "epoch: 18 step: 163, loss is 0.0006156428717076778\n",
      "epoch: 18 step: 164, loss is 0.0007186020375229418\n",
      "epoch: 18 step: 165, loss is 0.0005556506221182644\n",
      "epoch: 18 step: 166, loss is 0.0004269318305887282\n",
      "epoch: 18 step: 167, loss is 0.0005718790926039219\n",
      "epoch: 18 step: 168, loss is 0.0005733433063142002\n",
      "epoch: 18 step: 169, loss is 0.00035524298436939716\n",
      "epoch: 18 step: 170, loss is 0.000757378526031971\n",
      "epoch: 18 step: 171, loss is 0.00024253099400084466\n",
      "epoch: 18 step: 172, loss is 0.0005656019784510136\n",
      "epoch: 18 step: 173, loss is 0.0005833650939166546\n",
      "epoch: 18 step: 174, loss is 0.0006611277349293232\n",
      "epoch: 18 step: 175, loss is 0.0015863394364714622\n",
      "epoch: 18 step: 176, loss is 0.0002190490922657773\n",
      "epoch: 18 step: 177, loss is 0.000565668276976794\n",
      "epoch: 18 step: 178, loss is 0.0004943550447933376\n",
      "epoch: 18 step: 179, loss is 0.0005762334330938756\n",
      "epoch: 18 step: 180, loss is 0.0003804143634624779\n",
      "epoch: 18 step: 181, loss is 0.0008846095879562199\n",
      "epoch: 18 step: 182, loss is 0.0008019341621547937\n",
      "epoch: 18 step: 183, loss is 0.0003678426437545568\n",
      "epoch: 18 step: 184, loss is 0.0006541890907101333\n",
      "epoch: 18 step: 185, loss is 0.0005403859540820122\n",
      "epoch: 18 step: 186, loss is 0.0008984594605863094\n",
      "epoch: 18 step: 187, loss is 0.0004820202011615038\n",
      "epoch: 18 step: 188, loss is 0.0008077586535364389\n",
      "epoch: 18 step: 189, loss is 0.0006611373391933739\n",
      "epoch: 18 step: 190, loss is 0.0014233964029699564\n",
      "epoch: 18 step: 191, loss is 0.0007422241033054888\n",
      "epoch: 18 step: 192, loss is 0.0005114792147651315\n",
      "epoch: 18 step: 193, loss is 0.0009718577493913472\n",
      "epoch: 18 step: 194, loss is 0.0008723128121346235\n",
      "epoch: 18 step: 195, loss is 0.0012629686389118433\n",
      "epoch: 18 step: 196, loss is 0.0004628211900126189\n",
      "epoch: 18 step: 197, loss is 0.0009238466154783964\n",
      "epoch: 18 step: 198, loss is 0.0001213656723848544\n",
      "epoch: 18 step: 199, loss is 0.0003853028465528041\n",
      "epoch: 18 step: 200, loss is 0.00023383014195133\n",
      "epoch: 18 step: 201, loss is 0.0012425685999915004\n",
      "epoch: 18 step: 202, loss is 0.0003226090339012444\n",
      "epoch: 18 step: 203, loss is 0.0009477295097894967\n",
      "epoch: 18 step: 204, loss is 0.001429084804840386\n",
      "epoch: 18 step: 205, loss is 0.0007666666060686111\n",
      "epoch: 18 step: 206, loss is 0.0009511191165074706\n",
      "epoch: 18 step: 207, loss is 0.001539182965643704\n",
      "epoch: 18 step: 208, loss is 0.0005629723891615868\n",
      "epoch: 18 step: 209, loss is 0.00033254027948714793\n",
      "epoch: 18 step: 210, loss is 0.0008453836780972779\n",
      "epoch: 18 step: 211, loss is 0.0005378851783461869\n",
      "epoch: 18 step: 212, loss is 0.00043500529136508703\n",
      "epoch: 18 step: 213, loss is 0.0006209033890627325\n",
      "epoch: 18 step: 214, loss is 0.0007145543931983411\n",
      "epoch: 18 step: 215, loss is 0.0014960283879190683\n",
      "epoch: 18 step: 216, loss is 0.0004088743298780173\n",
      "epoch: 18 step: 217, loss is 0.0014433638425543904\n",
      "epoch: 18 step: 218, loss is 0.0008175139664672315\n",
      "epoch: 18 step: 219, loss is 0.0012393816141411662\n",
      "epoch: 18 step: 220, loss is 0.0006328062154352665\n",
      "epoch: 18 step: 221, loss is 0.0009972269181162119\n",
      "epoch: 18 step: 222, loss is 0.000553782912902534\n",
      "epoch: 18 step: 223, loss is 0.0007198255625553429\n",
      "epoch: 18 step: 224, loss is 0.0006144496146589518\n",
      "epoch: 18 step: 225, loss is 0.00041424119262956083\n",
      "epoch: 18 step: 226, loss is 0.0007622010307386518\n",
      "epoch: 18 step: 227, loss is 0.0006137103191576898\n",
      "epoch: 18 step: 228, loss is 0.0007775211124680936\n",
      "epoch: 18 step: 229, loss is 0.00045416358625516295\n",
      "epoch: 18 step: 230, loss is 0.00045621622120961547\n",
      "epoch: 18 step: 231, loss is 0.000920248101465404\n",
      "epoch: 18 step: 232, loss is 0.001025782199576497\n",
      "epoch: 18 step: 233, loss is 0.0007476157625205815\n",
      "epoch: 18 step: 234, loss is 0.00047622527927160263\n",
      "epoch: 18 step: 235, loss is 0.0005744967493228614\n",
      "epoch: 18 step: 236, loss is 0.00016306077304761857\n",
      "epoch: 18 step: 237, loss is 0.0005067427991889417\n",
      "epoch: 18 step: 238, loss is 0.0007148931617848575\n",
      "epoch: 18 step: 239, loss is 0.0007897332543507218\n",
      "epoch: 18 step: 240, loss is 0.00021373422350734472\n",
      "epoch: 18 step: 241, loss is 0.00020830256107728928\n",
      "epoch: 18 step: 242, loss is 0.001142782042734325\n",
      "epoch: 18 step: 243, loss is 0.0007080664508976042\n",
      "epoch: 18 step: 244, loss is 0.0004683174774982035\n",
      "epoch: 18 step: 245, loss is 0.00037217067438177764\n",
      "epoch: 18 step: 246, loss is 0.0006584342918358743\n",
      "epoch: 18 step: 247, loss is 0.0006348499446175992\n",
      "epoch: 18 step: 248, loss is 0.000585044443141669\n",
      "epoch: 18 step: 249, loss is 0.0006398165132850409\n",
      "epoch: 18 step: 250, loss is 0.0008464160491712391\n",
      "epoch: 18 step: 251, loss is 0.0006424065795727074\n",
      "epoch: 18 step: 252, loss is 0.0015079539734870195\n",
      "epoch: 18 step: 253, loss is 0.0013416296569630504\n",
      "epoch: 18 step: 254, loss is 0.0008122817962430418\n",
      "epoch: 18 step: 255, loss is 0.00047313160030171275\n",
      "epoch: 18 step: 256, loss is 0.0004247059114277363\n",
      "epoch: 18 step: 257, loss is 0.0006445288308896124\n",
      "epoch: 18 step: 258, loss is 0.0007268058834597468\n",
      "epoch: 18 step: 259, loss is 0.00035326206125319004\n",
      "epoch: 18 step: 260, loss is 0.0013426045188680291\n",
      "epoch: 18 step: 261, loss is 0.0004332158714532852\n",
      "epoch: 18 step: 262, loss is 0.0009444833849556744\n",
      "epoch: 18 step: 263, loss is 0.0005565094179473817\n",
      "epoch: 18 step: 264, loss is 0.00034056493313983083\n",
      "epoch: 18 step: 265, loss is 0.0010385989444330335\n",
      "epoch: 18 step: 266, loss is 0.0005261691985651851\n",
      "epoch: 18 step: 267, loss is 0.0010491147404536605\n",
      "epoch: 18 step: 268, loss is 0.00014123209984973073\n",
      "epoch: 18 step: 269, loss is 0.000747727113775909\n",
      "epoch: 18 step: 270, loss is 0.0007989677251316607\n",
      "epoch: 18 step: 271, loss is 0.0002884859568439424\n",
      "epoch: 18 step: 272, loss is 0.0011487968731671572\n",
      "epoch: 18 step: 273, loss is 0.0002438580704620108\n",
      "epoch: 18 step: 274, loss is 0.00023125825100578368\n",
      "epoch: 18 step: 275, loss is 0.0004861444467678666\n",
      "epoch: 18 step: 276, loss is 0.0016014804132282734\n",
      "epoch: 18 step: 277, loss is 0.0005863498081453145\n",
      "epoch: 18 step: 278, loss is 0.0013871394330635667\n",
      "epoch: 18 step: 279, loss is 0.0008521789568476379\n",
      "epoch: 18 step: 280, loss is 0.0008172379457391798\n",
      "epoch: 18 step: 281, loss is 0.0011110580526292324\n",
      "epoch: 18 step: 282, loss is 0.00014722930791322142\n",
      "epoch: 18 step: 283, loss is 0.0005214127595536411\n",
      "epoch: 18 step: 284, loss is 0.00031982289510779083\n",
      "epoch: 18 step: 285, loss is 0.0008534715743735433\n",
      "epoch: 18 step: 286, loss is 0.0010320832952857018\n",
      "epoch: 18 step: 287, loss is 0.0002846322604455054\n",
      "epoch: 18 step: 288, loss is 0.0011691396357491612\n",
      "epoch: 18 step: 289, loss is 0.0002792080631479621\n",
      "epoch: 18 step: 290, loss is 0.00018765583808999509\n",
      "epoch: 18 step: 291, loss is 0.0007259703706949949\n",
      "epoch: 18 step: 292, loss is 0.0006906057824380696\n",
      "epoch: 18 step: 293, loss is 0.0022815209813416004\n",
      "epoch: 18 step: 294, loss is 0.00044105868437327445\n",
      "epoch: 18 step: 295, loss is 0.0003404779126867652\n",
      "epoch: 18 step: 296, loss is 0.0005758772604167461\n",
      "epoch: 18 step: 297, loss is 0.00027097121346741915\n",
      "epoch: 18 step: 298, loss is 0.00039737336919642985\n",
      "epoch: 18 step: 299, loss is 0.00033231539418920875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 300, loss is 0.0014165473403409123\n",
      "epoch: 18 step: 301, loss is 0.001113162375986576\n",
      "epoch: 18 step: 302, loss is 0.0006139973411336541\n",
      "epoch: 18 step: 303, loss is 0.0003081661416217685\n",
      "epoch: 18 step: 304, loss is 0.0005241078906692564\n",
      "epoch: 18 step: 305, loss is 0.0003301127871964127\n",
      "epoch: 18 step: 306, loss is 0.00030192342819646\n",
      "epoch: 18 step: 307, loss is 0.00118452706374228\n",
      "epoch: 18 step: 308, loss is 0.0006626742542721331\n",
      "epoch: 18 step: 309, loss is 0.0007872584974393249\n",
      "epoch: 18 step: 310, loss is 0.0010566062992438674\n",
      "epoch: 18 step: 311, loss is 0.0014983488945290446\n",
      "epoch: 18 step: 312, loss is 0.000491863174829632\n",
      "epoch: 18 step: 313, loss is 0.0004490311839617789\n",
      "epoch: 18 step: 314, loss is 0.0005404682015068829\n",
      "epoch: 18 step: 315, loss is 0.000573553319554776\n",
      "epoch: 18 step: 316, loss is 0.0005240250611677766\n",
      "epoch: 18 step: 317, loss is 0.0002458792587276548\n",
      "epoch: 18 step: 318, loss is 0.0008984383312053978\n",
      "epoch: 18 step: 319, loss is 0.0007677130633965135\n",
      "epoch: 18 step: 320, loss is 0.002051200019195676\n",
      "epoch: 18 step: 321, loss is 0.0008689946262165904\n",
      "epoch: 18 step: 322, loss is 0.0012766156578436494\n",
      "epoch: 18 step: 323, loss is 0.0005195052362978458\n",
      "epoch: 18 step: 324, loss is 0.000434659217717126\n",
      "epoch: 18 step: 325, loss is 0.0014628879725933075\n",
      "epoch: 18 step: 326, loss is 0.0006930312956683338\n",
      "epoch: 18 step: 327, loss is 0.0017907200381159782\n",
      "epoch: 18 step: 328, loss is 0.0011074792128056288\n",
      "epoch: 18 step: 329, loss is 0.0008095407392829657\n",
      "epoch: 18 step: 330, loss is 0.0008058202220126987\n",
      "epoch: 18 step: 331, loss is 0.0008038117084652185\n",
      "epoch: 18 step: 332, loss is 0.0007496727630496025\n",
      "epoch: 18 step: 333, loss is 0.0006071818061172962\n",
      "epoch: 18 step: 334, loss is 0.0006346873706206679\n",
      "epoch: 18 step: 335, loss is 0.0010391122195869684\n",
      "epoch: 18 step: 336, loss is 0.0011649064254015684\n",
      "epoch: 18 step: 337, loss is 0.0005082799470983446\n",
      "epoch: 18 step: 338, loss is 0.0006594543810933828\n",
      "epoch: 18 step: 339, loss is 0.000768412952311337\n",
      "epoch: 18 step: 340, loss is 0.0002954061783384532\n",
      "epoch: 18 step: 341, loss is 0.0009656857582740486\n",
      "epoch: 18 step: 342, loss is 0.0006091902032494545\n",
      "epoch: 18 step: 343, loss is 0.0020131960045546293\n",
      "epoch: 18 step: 344, loss is 0.0006198938353918493\n",
      "epoch: 18 step: 345, loss is 0.0006624347879551351\n",
      "epoch: 18 step: 346, loss is 0.0008836403139866889\n",
      "epoch: 18 step: 347, loss is 0.0006171695422381163\n",
      "epoch: 18 step: 348, loss is 0.0005180087755434215\n",
      "epoch: 18 step: 349, loss is 0.00038984071579761803\n",
      "epoch: 18 step: 350, loss is 0.0008049351163208485\n",
      "epoch: 18 step: 351, loss is 0.0005433439509943128\n",
      "epoch: 18 step: 352, loss is 0.0007890276610851288\n",
      "epoch: 18 step: 353, loss is 0.00036998093128204346\n",
      "epoch: 18 step: 354, loss is 0.0007904284866526723\n",
      "epoch: 18 step: 355, loss is 0.0007808026857674122\n",
      "epoch: 18 step: 356, loss is 0.0006693532923236489\n",
      "epoch: 18 step: 357, loss is 0.0003296852228231728\n",
      "epoch: 18 step: 358, loss is 0.00014537108654621989\n",
      "epoch: 18 step: 359, loss is 0.0017944418359547853\n",
      "epoch: 18 step: 360, loss is 0.000769744161516428\n",
      "epoch: 18 step: 361, loss is 0.0008876016363501549\n",
      "epoch: 18 step: 362, loss is 0.001036916859447956\n",
      "epoch: 18 step: 363, loss is 0.00012995212455280125\n",
      "epoch: 18 step: 364, loss is 0.0006296794745139778\n",
      "epoch: 18 step: 365, loss is 0.0014957246603444219\n",
      "epoch: 18 step: 366, loss is 0.0004493995802477002\n",
      "epoch: 18 step: 367, loss is 0.00042650295654311776\n",
      "epoch: 18 step: 368, loss is 0.0005994406528770924\n",
      "epoch: 18 step: 369, loss is 0.0001814352726796642\n",
      "epoch: 18 step: 370, loss is 0.000363726110663265\n",
      "epoch: 18 step: 371, loss is 0.0006203727098181844\n",
      "epoch: 18 step: 372, loss is 0.0005291548441164196\n",
      "epoch: 18 step: 373, loss is 0.00028902862686663866\n",
      "epoch: 18 step: 374, loss is 0.0005387189448811114\n",
      "epoch: 18 step: 375, loss is 0.00035201842547394335\n",
      "Train epoch time: 11898.927 ms, per step time: 31.730 ms\n",
      "epoch: 19 step: 1, loss is 0.0003858250565826893\n",
      "epoch: 19 step: 2, loss is 0.0006247360724955797\n",
      "epoch: 19 step: 3, loss is 0.0008080215193331242\n",
      "epoch: 19 step: 4, loss is 0.0011414610780775547\n",
      "epoch: 19 step: 5, loss is 0.000458346214145422\n",
      "epoch: 19 step: 6, loss is 0.00046586262760683894\n",
      "epoch: 19 step: 7, loss is 0.00023663170577492565\n",
      "epoch: 19 step: 8, loss is 0.0014592433581128716\n",
      "epoch: 19 step: 9, loss is 0.00026136674568988383\n",
      "epoch: 19 step: 10, loss is 0.0006490043015219271\n",
      "epoch: 19 step: 11, loss is 0.0006382890278473496\n",
      "epoch: 19 step: 12, loss is 0.0006403755396604538\n",
      "epoch: 19 step: 13, loss is 0.0006505296914838254\n",
      "epoch: 19 step: 14, loss is 0.0008697218145243824\n",
      "epoch: 19 step: 15, loss is 0.000727748207282275\n",
      "epoch: 19 step: 16, loss is 0.0006846980541013181\n",
      "epoch: 19 step: 17, loss is 0.000542116176802665\n",
      "epoch: 19 step: 18, loss is 0.0014932075282558799\n",
      "epoch: 19 step: 19, loss is 0.001379784313030541\n",
      "epoch: 19 step: 20, loss is 0.0005047849845141172\n",
      "epoch: 19 step: 21, loss is 0.0007553101168014109\n",
      "epoch: 19 step: 22, loss is 0.00044357788283377886\n",
      "epoch: 19 step: 23, loss is 0.001402650959789753\n",
      "epoch: 19 step: 24, loss is 0.0006920360028743744\n",
      "epoch: 19 step: 25, loss is 0.0002970569476019591\n",
      "epoch: 19 step: 26, loss is 0.0012367458548396826\n",
      "epoch: 19 step: 27, loss is 0.0007633075001649559\n",
      "epoch: 19 step: 28, loss is 0.0005883409758098423\n",
      "epoch: 19 step: 29, loss is 0.001076876767911017\n",
      "epoch: 19 step: 30, loss is 3.811059286817908e-05\n",
      "epoch: 19 step: 31, loss is 0.00027306206175126135\n",
      "epoch: 19 step: 32, loss is 0.0004967935965396464\n",
      "epoch: 19 step: 33, loss is 0.0011423161486163735\n",
      "epoch: 19 step: 34, loss is 0.00031069255783222616\n",
      "epoch: 19 step: 35, loss is 0.0006736716604791582\n",
      "epoch: 19 step: 36, loss is 0.0008861900423653424\n",
      "epoch: 19 step: 37, loss is 0.0010552469175308943\n",
      "epoch: 19 step: 38, loss is 0.0008253654232248664\n",
      "epoch: 19 step: 39, loss is 0.0006421746220439672\n",
      "epoch: 19 step: 40, loss is 0.0006244382821023464\n",
      "epoch: 19 step: 41, loss is 0.0004114953044336289\n",
      "epoch: 19 step: 42, loss is 0.0004956530756317079\n",
      "epoch: 19 step: 43, loss is 0.0006302547408267856\n",
      "epoch: 19 step: 44, loss is 0.0011370736174285412\n",
      "epoch: 19 step: 45, loss is 0.0002995869726873934\n",
      "epoch: 19 step: 46, loss is 0.0004022722423542291\n",
      "epoch: 19 step: 47, loss is 0.0007452623685821891\n",
      "epoch: 19 step: 48, loss is 0.0007941370131447911\n",
      "epoch: 19 step: 49, loss is 0.0009305008570663631\n",
      "epoch: 19 step: 50, loss is 0.00026880917721427977\n",
      "epoch: 19 step: 51, loss is 0.0009097131551243365\n",
      "epoch: 19 step: 52, loss is 0.0009055373957380652\n",
      "epoch: 19 step: 53, loss is 0.00046488118823617697\n",
      "epoch: 19 step: 54, loss is 0.0011039413511753082\n",
      "epoch: 19 step: 55, loss is 0.0007269324269145727\n",
      "epoch: 19 step: 56, loss is 0.0006120354519225657\n",
      "epoch: 19 step: 57, loss is 0.0013061569770798087\n",
      "epoch: 19 step: 58, loss is 0.00024176861916203052\n",
      "epoch: 19 step: 59, loss is 0.0003050790692213923\n",
      "epoch: 19 step: 60, loss is 0.0003237576747778803\n",
      "epoch: 19 step: 61, loss is 0.0003125536604784429\n",
      "epoch: 19 step: 62, loss is 0.0003083763876929879\n",
      "epoch: 19 step: 63, loss is 0.0004953358438797295\n",
      "epoch: 19 step: 64, loss is 0.0009807568276301026\n",
      "epoch: 19 step: 65, loss is 0.00014718642341904342\n",
      "epoch: 19 step: 66, loss is 0.0006478057475760579\n",
      "epoch: 19 step: 67, loss is 0.0015875850804150105\n",
      "epoch: 19 step: 68, loss is 0.0009022331214509904\n",
      "epoch: 19 step: 69, loss is 0.0005526711465790868\n",
      "epoch: 19 step: 70, loss is 0.000899732462130487\n",
      "epoch: 19 step: 71, loss is 0.00034408486681059003\n",
      "epoch: 19 step: 72, loss is 0.0007609232561662793\n",
      "epoch: 19 step: 73, loss is 0.0008143980521708727\n",
      "epoch: 19 step: 74, loss is 0.0005543183069676161\n",
      "epoch: 19 step: 75, loss is 0.0002437328948872164\n",
      "epoch: 19 step: 76, loss is 0.0003546236839611083\n",
      "epoch: 19 step: 77, loss is 0.0007548840367235243\n",
      "epoch: 19 step: 78, loss is 0.0006915699341334403\n",
      "epoch: 19 step: 79, loss is 0.0003899116418324411\n",
      "epoch: 19 step: 80, loss is 0.0007693310617469251\n",
      "epoch: 19 step: 81, loss is 0.0005228048539720476\n",
      "epoch: 19 step: 82, loss is 0.0002618652943056077\n",
      "epoch: 19 step: 83, loss is 0.0013031231937929988\n",
      "epoch: 19 step: 84, loss is 0.0007324364851228893\n",
      "epoch: 19 step: 85, loss is 0.0015092880930751562\n",
      "epoch: 19 step: 86, loss is 0.0007097808411344886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 87, loss is 0.0011519822292029858\n",
      "epoch: 19 step: 88, loss is 0.0006266917334869504\n",
      "epoch: 19 step: 89, loss is 0.0005448012379929423\n",
      "epoch: 19 step: 90, loss is 0.000921144091989845\n",
      "epoch: 19 step: 91, loss is 0.0016088266856968403\n",
      "epoch: 19 step: 92, loss is 0.0010738455457612872\n",
      "epoch: 19 step: 93, loss is 0.0008960824343375862\n",
      "epoch: 19 step: 94, loss is 0.00029453521710820496\n",
      "epoch: 19 step: 95, loss is 0.0009487940696999431\n",
      "epoch: 19 step: 96, loss is 0.0007080905488692224\n",
      "epoch: 19 step: 97, loss is 0.00021556833235081285\n",
      "epoch: 19 step: 98, loss is 0.0015882252482697368\n",
      "epoch: 19 step: 99, loss is 0.0006275250343605876\n",
      "epoch: 19 step: 100, loss is 0.0007318856078200042\n",
      "epoch: 19 step: 101, loss is 0.0005382142262533307\n",
      "epoch: 19 step: 102, loss is 0.0012609277619048953\n",
      "epoch: 19 step: 103, loss is 0.0007357558934018016\n",
      "epoch: 19 step: 104, loss is 0.0005133210215717554\n",
      "epoch: 19 step: 105, loss is 0.0003592856228351593\n",
      "epoch: 19 step: 106, loss is 0.000392710353480652\n",
      "epoch: 19 step: 107, loss is 0.0007403108756989241\n",
      "epoch: 19 step: 108, loss is 0.0006243391544558108\n",
      "epoch: 19 step: 109, loss is 0.0009143751231022179\n",
      "epoch: 19 step: 110, loss is 0.0005345370736904442\n",
      "epoch: 19 step: 111, loss is 0.000992446206510067\n",
      "epoch: 19 step: 112, loss is 0.0012781909899786115\n",
      "epoch: 19 step: 113, loss is 0.0002579958236310631\n",
      "epoch: 19 step: 114, loss is 0.0008365896646864712\n",
      "epoch: 19 step: 115, loss is 0.0005281625781208277\n",
      "epoch: 19 step: 116, loss is 0.0010094208410009742\n",
      "epoch: 19 step: 117, loss is 0.00024118916189763695\n",
      "epoch: 19 step: 118, loss is 0.0008291106787510216\n",
      "epoch: 19 step: 119, loss is 0.0005667072255164385\n",
      "epoch: 19 step: 120, loss is 0.0005244892090559006\n",
      "epoch: 19 step: 121, loss is 0.0005347185069695115\n",
      "epoch: 19 step: 122, loss is 0.002268287120386958\n",
      "epoch: 19 step: 123, loss is 0.0008712820708751678\n",
      "epoch: 19 step: 124, loss is 0.000388312095310539\n",
      "epoch: 19 step: 125, loss is 0.000617119250819087\n",
      "epoch: 19 step: 126, loss is 0.00022778699349146336\n",
      "epoch: 19 step: 127, loss is 0.0010423118947073817\n",
      "epoch: 19 step: 128, loss is 0.000813293328974396\n",
      "epoch: 19 step: 129, loss is 0.0011874329065904021\n",
      "epoch: 19 step: 130, loss is 0.0005569743225350976\n",
      "epoch: 19 step: 131, loss is 0.002386793727055192\n",
      "epoch: 19 step: 132, loss is 0.0005838640499860048\n",
      "epoch: 19 step: 133, loss is 0.0007035121670924127\n",
      "epoch: 19 step: 134, loss is 0.0004747165075968951\n",
      "epoch: 19 step: 135, loss is 0.0011487752199172974\n",
      "epoch: 19 step: 136, loss is 0.0010271240025758743\n",
      "epoch: 19 step: 137, loss is 0.00048639666056260467\n",
      "epoch: 19 step: 138, loss is 0.0005227933288551867\n",
      "epoch: 19 step: 139, loss is 0.0006965408101677895\n",
      "epoch: 19 step: 140, loss is 0.0009754994534887373\n",
      "epoch: 19 step: 141, loss is 0.00033329823054373264\n",
      "epoch: 19 step: 142, loss is 0.0006750564207322896\n",
      "epoch: 19 step: 143, loss is 0.0007885954692028463\n",
      "epoch: 19 step: 144, loss is 0.0005802770610898733\n",
      "epoch: 19 step: 145, loss is 0.0009698279900476336\n",
      "epoch: 19 step: 146, loss is 0.0009750311728566885\n",
      "epoch: 19 step: 147, loss is 0.0004351525567471981\n",
      "epoch: 19 step: 148, loss is 0.00016210177273023874\n",
      "epoch: 19 step: 149, loss is 0.0007363008335232735\n",
      "epoch: 19 step: 150, loss is 0.0017484409036114812\n",
      "epoch: 19 step: 151, loss is 0.0009970922255888581\n",
      "epoch: 19 step: 152, loss is 0.0017578493570908904\n",
      "epoch: 19 step: 153, loss is 0.0013354237889871001\n",
      "epoch: 19 step: 154, loss is 0.0004750408115796745\n",
      "epoch: 19 step: 155, loss is 0.0005604061880148947\n",
      "epoch: 19 step: 156, loss is 0.00013368688814807683\n",
      "epoch: 19 step: 157, loss is 0.0007413250277750194\n",
      "epoch: 19 step: 158, loss is 0.0009062269236892462\n",
      "epoch: 19 step: 159, loss is 0.0008334438316524029\n",
      "epoch: 19 step: 160, loss is 0.0005768771516159177\n",
      "epoch: 19 step: 161, loss is 0.0003200186765752733\n",
      "epoch: 19 step: 162, loss is 0.00030397673253901303\n",
      "epoch: 19 step: 163, loss is 0.0002107376785716042\n",
      "epoch: 19 step: 164, loss is 0.0006276156636886299\n",
      "epoch: 19 step: 165, loss is 0.00029848903068341315\n",
      "epoch: 19 step: 166, loss is 0.0008071931079030037\n",
      "epoch: 19 step: 167, loss is 0.0009170554112643003\n",
      "epoch: 19 step: 168, loss is 0.0006354100769385695\n",
      "epoch: 19 step: 169, loss is 0.001946197240613401\n",
      "epoch: 19 step: 170, loss is 0.00022583619283977896\n",
      "epoch: 19 step: 171, loss is 0.0008038216619752347\n",
      "epoch: 19 step: 172, loss is 0.0002072821807814762\n",
      "epoch: 19 step: 173, loss is 0.0003229791473131627\n",
      "epoch: 19 step: 174, loss is 0.0003551846893969923\n",
      "epoch: 19 step: 175, loss is 0.000796465901657939\n",
      "epoch: 19 step: 176, loss is 0.0005845283158123493\n",
      "epoch: 19 step: 177, loss is 0.0007419418543577194\n",
      "epoch: 19 step: 178, loss is 0.0008784923702478409\n",
      "epoch: 19 step: 179, loss is 0.001438093138858676\n",
      "epoch: 19 step: 180, loss is 0.0004645834560506046\n",
      "epoch: 19 step: 181, loss is 0.0010784160112962127\n",
      "epoch: 19 step: 182, loss is 0.00037632809835486114\n",
      "epoch: 19 step: 183, loss is 8.404510299442336e-05\n",
      "epoch: 19 step: 184, loss is 0.0003045401244889945\n",
      "epoch: 19 step: 185, loss is 0.000510336016304791\n",
      "epoch: 19 step: 186, loss is 0.0003017206909134984\n",
      "epoch: 19 step: 187, loss is 0.0005510358023457229\n",
      "epoch: 19 step: 188, loss is 0.00141612789593637\n",
      "epoch: 19 step: 189, loss is 0.00041593448258936405\n",
      "epoch: 19 step: 190, loss is 0.0004976809141226113\n",
      "epoch: 19 step: 191, loss is 0.0005933973006904125\n",
      "epoch: 19 step: 192, loss is 0.0012524735648185015\n",
      "epoch: 19 step: 193, loss is 0.0006798704853281379\n",
      "epoch: 19 step: 194, loss is 0.00037588615668937564\n",
      "epoch: 19 step: 195, loss is 0.0008220316958613694\n",
      "epoch: 19 step: 196, loss is 0.000523514929227531\n",
      "epoch: 19 step: 197, loss is 0.000580089574214071\n",
      "epoch: 19 step: 198, loss is 0.0005109591293148696\n",
      "epoch: 19 step: 199, loss is 0.0006342247361317277\n",
      "epoch: 19 step: 200, loss is 0.0007920213975012302\n",
      "epoch: 19 step: 201, loss is 8.36075923871249e-05\n",
      "epoch: 19 step: 202, loss is 0.000642258208245039\n",
      "epoch: 19 step: 203, loss is 0.0011522528948262334\n",
      "epoch: 19 step: 204, loss is 0.0014498064992949367\n",
      "epoch: 19 step: 205, loss is 0.0006322183180600405\n",
      "epoch: 19 step: 206, loss is 0.00041524769039824605\n",
      "epoch: 19 step: 207, loss is 0.00048304785741493106\n",
      "epoch: 19 step: 208, loss is 0.00027847583987750113\n",
      "epoch: 19 step: 209, loss is 0.0005151141667738557\n",
      "epoch: 19 step: 210, loss is 0.0009487532661296427\n",
      "epoch: 19 step: 211, loss is 0.0008965847082436085\n",
      "epoch: 19 step: 212, loss is 0.0007650849292986095\n",
      "epoch: 19 step: 213, loss is 0.0005731830606237054\n",
      "epoch: 19 step: 214, loss is 0.0002088487963192165\n",
      "epoch: 19 step: 215, loss is 0.000266664574155584\n",
      "epoch: 19 step: 216, loss is 0.00024246767861768603\n",
      "epoch: 19 step: 217, loss is 0.0008063953137025237\n",
      "epoch: 19 step: 218, loss is 0.0008675951976329088\n",
      "epoch: 19 step: 219, loss is 0.0008370435680262744\n",
      "epoch: 19 step: 220, loss is 0.0004957272903993726\n",
      "epoch: 19 step: 221, loss is 0.0012463681632652879\n",
      "epoch: 19 step: 222, loss is 0.0008206157363019884\n",
      "epoch: 19 step: 223, loss is 0.00029774708673357964\n",
      "epoch: 19 step: 224, loss is 0.0006012985249981284\n",
      "epoch: 19 step: 225, loss is 0.0010116025805473328\n",
      "epoch: 19 step: 226, loss is 0.0003269559529144317\n",
      "epoch: 19 step: 227, loss is 0.0007097230409272015\n",
      "epoch: 19 step: 228, loss is 0.0004416224837768823\n",
      "epoch: 19 step: 229, loss is 0.0002101781137753278\n",
      "epoch: 19 step: 230, loss is 0.0020777354948222637\n",
      "epoch: 19 step: 231, loss is 0.0004103670653421432\n",
      "epoch: 19 step: 232, loss is 0.0004818997113034129\n",
      "epoch: 19 step: 233, loss is 0.00046533768181689084\n",
      "epoch: 19 step: 234, loss is 0.0007314761751331389\n",
      "epoch: 19 step: 235, loss is 0.0004991799360141158\n",
      "epoch: 19 step: 236, loss is 0.0009287410648539662\n",
      "epoch: 19 step: 237, loss is 0.00019531256111804396\n",
      "epoch: 19 step: 238, loss is 0.0008330570999532938\n",
      "epoch: 19 step: 239, loss is 0.0008438005461357534\n",
      "epoch: 19 step: 240, loss is 0.0003008017665706575\n",
      "epoch: 19 step: 241, loss is 0.0010485154343768954\n",
      "epoch: 19 step: 242, loss is 0.0008354145684279501\n",
      "epoch: 19 step: 243, loss is 0.0007914958987385035\n",
      "epoch: 19 step: 244, loss is 0.0007184748537838459\n",
      "epoch: 19 step: 245, loss is 0.0006187437102198601\n",
      "epoch: 19 step: 246, loss is 0.0004277560510672629\n",
      "epoch: 19 step: 247, loss is 0.0006984147476032376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 248, loss is 0.0006088908412493765\n",
      "epoch: 19 step: 249, loss is 0.0013071817811578512\n",
      "epoch: 19 step: 250, loss is 0.0004784232296515256\n",
      "epoch: 19 step: 251, loss is 0.0007110688020475209\n",
      "epoch: 19 step: 252, loss is 0.000777075591031462\n",
      "epoch: 19 step: 253, loss is 0.001475622528232634\n",
      "epoch: 19 step: 254, loss is 0.0006083998014219105\n",
      "epoch: 19 step: 255, loss is 0.0005437411600723863\n",
      "epoch: 19 step: 256, loss is 0.0007354755070991814\n",
      "epoch: 19 step: 257, loss is 0.00046566990204155445\n",
      "epoch: 19 step: 258, loss is 0.0006526322104036808\n",
      "epoch: 19 step: 259, loss is 0.0011485888389870524\n",
      "epoch: 19 step: 260, loss is 0.00013500724162440747\n",
      "epoch: 19 step: 261, loss is 0.0007181758410297334\n",
      "epoch: 19 step: 262, loss is 0.0004315765982028097\n",
      "epoch: 19 step: 263, loss is 0.0007449849508702755\n",
      "epoch: 19 step: 264, loss is 0.00030695906025357544\n",
      "epoch: 19 step: 265, loss is 0.0009604257065802813\n",
      "epoch: 19 step: 266, loss is 0.0008717738091945648\n",
      "epoch: 19 step: 267, loss is 0.0001446273672627285\n",
      "epoch: 19 step: 268, loss is 0.0010746194748207927\n",
      "epoch: 19 step: 269, loss is 0.0002737005997914821\n",
      "epoch: 19 step: 270, loss is 0.0012866694014519453\n",
      "epoch: 19 step: 271, loss is 0.00048055799561552703\n",
      "epoch: 19 step: 272, loss is 0.0006957522127777338\n",
      "epoch: 19 step: 273, loss is 0.0006822978612035513\n",
      "epoch: 19 step: 274, loss is 0.00023985658481251448\n",
      "epoch: 19 step: 275, loss is 0.0001667117467150092\n",
      "epoch: 19 step: 276, loss is 0.0007895659073255956\n",
      "epoch: 19 step: 277, loss is 0.0009339902317151427\n",
      "epoch: 19 step: 278, loss is 0.0003084827621933073\n",
      "epoch: 19 step: 279, loss is 0.0005190675146877766\n",
      "epoch: 19 step: 280, loss is 0.00032765817013569176\n",
      "epoch: 19 step: 281, loss is 0.0012601810740306973\n",
      "epoch: 19 step: 282, loss is 0.00037838149000890553\n",
      "epoch: 19 step: 283, loss is 0.0004795418062712997\n",
      "epoch: 19 step: 284, loss is 0.0009789725299924612\n",
      "epoch: 19 step: 285, loss is 0.001004619407467544\n",
      "epoch: 19 step: 286, loss is 0.0006728823063895106\n",
      "epoch: 19 step: 287, loss is 0.0014610305661335588\n",
      "epoch: 19 step: 288, loss is 0.0008549058111384511\n",
      "epoch: 19 step: 289, loss is 0.0002385429834248498\n",
      "epoch: 19 step: 290, loss is 0.0005381584633141756\n",
      "epoch: 19 step: 291, loss is 0.0004795342101715505\n",
      "epoch: 19 step: 292, loss is 0.0012580802431330085\n",
      "epoch: 19 step: 293, loss is 0.00036665183142758906\n",
      "epoch: 19 step: 294, loss is 0.0008777815965004265\n",
      "epoch: 19 step: 295, loss is 0.0012740276288241148\n",
      "epoch: 19 step: 296, loss is 0.0006842805887572467\n",
      "epoch: 19 step: 297, loss is 0.00033781828824430704\n",
      "epoch: 19 step: 298, loss is 0.0009069565567187965\n",
      "epoch: 19 step: 299, loss is 0.000740797258913517\n",
      "epoch: 19 step: 300, loss is 0.0017475648783147335\n",
      "epoch: 19 step: 301, loss is 0.00031208575819619\n",
      "epoch: 19 step: 302, loss is 0.00028388065402396023\n",
      "epoch: 19 step: 303, loss is 0.00020643130119424313\n",
      "epoch: 19 step: 304, loss is 0.0009487264323979616\n",
      "epoch: 19 step: 305, loss is 0.00025541443028487265\n",
      "epoch: 19 step: 306, loss is 0.0009969399543479085\n",
      "epoch: 19 step: 307, loss is 0.0006158815231174231\n",
      "epoch: 19 step: 308, loss is 0.0011567329056560993\n",
      "epoch: 19 step: 309, loss is 0.001006143749691546\n",
      "epoch: 19 step: 310, loss is 0.000928822613786906\n",
      "epoch: 19 step: 311, loss is 0.0008936448721215129\n",
      "epoch: 19 step: 312, loss is 0.0008157695410773158\n",
      "epoch: 19 step: 313, loss is 0.00022222043480724096\n",
      "epoch: 19 step: 314, loss is 0.00047233770601451397\n",
      "epoch: 19 step: 315, loss is 0.0009598155156709254\n",
      "epoch: 19 step: 316, loss is 0.0004158334049861878\n",
      "epoch: 19 step: 317, loss is 0.0007273756200447679\n",
      "epoch: 19 step: 318, loss is 0.0008519947296008468\n",
      "epoch: 19 step: 319, loss is 0.00038658041739836335\n",
      "epoch: 19 step: 320, loss is 0.0003960919857490808\n",
      "epoch: 19 step: 321, loss is 0.00019606755813583732\n",
      "epoch: 19 step: 322, loss is 0.0007818083977326751\n",
      "epoch: 19 step: 323, loss is 0.0003625197568908334\n",
      "epoch: 19 step: 324, loss is 0.0007908007828518748\n",
      "epoch: 19 step: 325, loss is 0.00145143351983279\n",
      "epoch: 19 step: 326, loss is 0.0009406679309904575\n",
      "epoch: 19 step: 327, loss is 0.0003754383942577988\n",
      "epoch: 19 step: 328, loss is 0.0003198024060111493\n",
      "epoch: 19 step: 329, loss is 0.00037799912388436496\n",
      "epoch: 19 step: 330, loss is 0.0008735285955481231\n",
      "epoch: 19 step: 331, loss is 0.00037038623122498393\n",
      "epoch: 19 step: 332, loss is 0.00044159506796859205\n",
      "epoch: 19 step: 333, loss is 0.0005216654972173274\n",
      "epoch: 19 step: 334, loss is 0.0007011182024143636\n",
      "epoch: 19 step: 335, loss is 0.0005838393117301166\n",
      "epoch: 19 step: 336, loss is 0.000540397479198873\n",
      "epoch: 19 step: 337, loss is 0.0008145380415953696\n",
      "epoch: 19 step: 338, loss is 0.0008159821736626327\n",
      "epoch: 19 step: 339, loss is 0.0003735736245289445\n",
      "epoch: 19 step: 340, loss is 0.0002780381473712623\n",
      "epoch: 19 step: 341, loss is 0.0006665918626822531\n",
      "epoch: 19 step: 342, loss is 0.0012001963332295418\n",
      "epoch: 19 step: 343, loss is 0.0003918135189451277\n",
      "epoch: 19 step: 344, loss is 0.0004405133950058371\n",
      "epoch: 19 step: 345, loss is 0.0012923585018143058\n",
      "epoch: 19 step: 346, loss is 0.0008202558383345604\n",
      "epoch: 19 step: 347, loss is 0.0005602735909633338\n",
      "epoch: 19 step: 348, loss is 0.00026466455892659724\n",
      "epoch: 19 step: 349, loss is 0.000932220253162086\n",
      "epoch: 19 step: 350, loss is 0.00039070326602086425\n",
      "epoch: 19 step: 351, loss is 0.0005087750614620745\n",
      "epoch: 19 step: 352, loss is 0.0006878691492602229\n",
      "epoch: 19 step: 353, loss is 0.0011931966291740537\n",
      "epoch: 19 step: 354, loss is 0.00032245356123894453\n",
      "epoch: 19 step: 355, loss is 0.0005328581319190562\n",
      "epoch: 19 step: 356, loss is 0.0015643177321180701\n",
      "epoch: 19 step: 357, loss is 0.00020286475773900747\n",
      "epoch: 19 step: 358, loss is 0.00046326854499056935\n",
      "epoch: 19 step: 359, loss is 0.000608214468229562\n",
      "epoch: 19 step: 360, loss is 0.00033727748086676\n",
      "epoch: 19 step: 361, loss is 0.0009841159917414188\n",
      "epoch: 19 step: 362, loss is 0.00035758671583607793\n",
      "epoch: 19 step: 363, loss is 0.0006636437028646469\n",
      "epoch: 19 step: 364, loss is 0.0015211752615869045\n",
      "epoch: 19 step: 365, loss is 0.0004915500176139176\n",
      "epoch: 19 step: 366, loss is 0.0008054441423155367\n",
      "epoch: 19 step: 367, loss is 0.0007706480100750923\n",
      "epoch: 19 step: 368, loss is 0.0017464825650677085\n",
      "epoch: 19 step: 369, loss is 0.0002845645940396935\n",
      "epoch: 19 step: 370, loss is 0.0004947282723151147\n",
      "epoch: 19 step: 371, loss is 0.000653029594104737\n",
      "epoch: 19 step: 372, loss is 0.000748653314076364\n",
      "epoch: 19 step: 373, loss is 0.0011611260706558824\n",
      "epoch: 19 step: 374, loss is 0.0005322755896486342\n",
      "epoch: 19 step: 375, loss is 0.001014174660667777\n",
      "Train epoch time: 12002.501 ms, per step time: 32.007 ms\n",
      "epoch: 20 step: 1, loss is 0.00027978396974503994\n",
      "epoch: 20 step: 2, loss is 0.0004838425957132131\n",
      "epoch: 20 step: 3, loss is 0.0005041206604801118\n",
      "epoch: 20 step: 4, loss is 0.0002369735884713009\n",
      "epoch: 20 step: 5, loss is 0.0004941519000567496\n",
      "epoch: 20 step: 6, loss is 0.0016266538295894861\n",
      "epoch: 20 step: 7, loss is 0.0007000761106610298\n",
      "epoch: 20 step: 8, loss is 0.0001649327896302566\n",
      "epoch: 20 step: 9, loss is 0.000585840200074017\n",
      "epoch: 20 step: 10, loss is 0.0009076392743736506\n",
      "epoch: 20 step: 11, loss is 0.0005260795005597174\n",
      "epoch: 20 step: 12, loss is 0.0005885811988264322\n",
      "epoch: 20 step: 13, loss is 0.0002458167145960033\n",
      "epoch: 20 step: 14, loss is 0.00157713214866817\n",
      "epoch: 20 step: 15, loss is 0.0005463838460855186\n",
      "epoch: 20 step: 16, loss is 0.0010934475576505065\n",
      "epoch: 20 step: 17, loss is 0.0005308266845531762\n",
      "epoch: 20 step: 18, loss is 0.0006117116427049041\n",
      "epoch: 20 step: 19, loss is 0.00027414504438638687\n",
      "epoch: 20 step: 20, loss is 0.0001846321829361841\n",
      "epoch: 20 step: 21, loss is 0.001674635917879641\n",
      "epoch: 20 step: 22, loss is 0.0011839072685688734\n",
      "epoch: 20 step: 23, loss is 0.0005120824207551777\n",
      "epoch: 20 step: 24, loss is 0.0007396995206363499\n",
      "epoch: 20 step: 25, loss is 0.00021993445989210159\n",
      "epoch: 20 step: 26, loss is 0.0002998173295054585\n",
      "epoch: 20 step: 27, loss is 0.0006866423063911498\n",
      "epoch: 20 step: 28, loss is 0.0010700523853302002\n",
      "epoch: 20 step: 29, loss is 0.0005196369020268321\n",
      "epoch: 20 step: 30, loss is 0.000783308525569737\n",
      "epoch: 20 step: 31, loss is 0.0006398690165951848\n",
      "epoch: 20 step: 32, loss is 0.0005717297317460179\n",
      "epoch: 20 step: 33, loss is 0.0002147078193956986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 34, loss is 0.000824561167974025\n",
      "epoch: 20 step: 35, loss is 0.0002546265604905784\n",
      "epoch: 20 step: 36, loss is 0.0003367677563801408\n",
      "epoch: 20 step: 37, loss is 0.0009609530679881573\n",
      "epoch: 20 step: 38, loss is 0.0007462823996320367\n",
      "epoch: 20 step: 39, loss is 0.0010103012900799513\n",
      "epoch: 20 step: 40, loss is 0.0002537028631195426\n",
      "epoch: 20 step: 41, loss is 0.00019922846695408225\n",
      "epoch: 20 step: 42, loss is 0.0004885047092102468\n",
      "epoch: 20 step: 43, loss is 0.000618111458607018\n",
      "epoch: 20 step: 44, loss is 0.0007763909525237978\n",
      "epoch: 20 step: 45, loss is 0.0006799260736443102\n",
      "epoch: 20 step: 46, loss is 0.00044348789379000664\n",
      "epoch: 20 step: 47, loss is 0.0009493583929724991\n",
      "epoch: 20 step: 48, loss is 0.0008600890869274735\n",
      "epoch: 20 step: 49, loss is 0.0004318802966736257\n",
      "epoch: 20 step: 50, loss is 0.00027596772997640073\n",
      "epoch: 20 step: 51, loss is 0.0005102577270008624\n",
      "epoch: 20 step: 52, loss is 0.001337408204562962\n",
      "epoch: 20 step: 53, loss is 0.0005103108705952764\n",
      "epoch: 20 step: 54, loss is 0.001184130902402103\n",
      "epoch: 20 step: 55, loss is 0.0006375709781423211\n",
      "epoch: 20 step: 56, loss is 0.00020740341278724372\n",
      "epoch: 20 step: 57, loss is 0.0024648159742355347\n",
      "epoch: 20 step: 58, loss is 0.0006996181909926236\n",
      "epoch: 20 step: 59, loss is 0.0004394613206386566\n",
      "epoch: 20 step: 60, loss is 0.0002784843964036554\n",
      "epoch: 20 step: 61, loss is 0.0003454358084127307\n",
      "epoch: 20 step: 62, loss is 0.0008558835834264755\n",
      "epoch: 20 step: 63, loss is 0.0024023782461881638\n",
      "epoch: 20 step: 64, loss is 0.0007664039731025696\n",
      "epoch: 20 step: 65, loss is 0.0005852985777892172\n",
      "epoch: 20 step: 66, loss is 0.0006818128749728203\n",
      "epoch: 20 step: 67, loss is 0.00030218431493267417\n",
      "epoch: 20 step: 68, loss is 0.0007514802855439484\n",
      "epoch: 20 step: 69, loss is 0.0008344140951521695\n",
      "epoch: 20 step: 70, loss is 0.0005301331984810531\n",
      "epoch: 20 step: 71, loss is 0.0006803568103350699\n",
      "epoch: 20 step: 72, loss is 0.0006437530391849577\n",
      "epoch: 20 step: 73, loss is 0.0009188354015350342\n",
      "epoch: 20 step: 74, loss is 0.0010123858228325844\n",
      "epoch: 20 step: 75, loss is 0.0004668198525905609\n",
      "epoch: 20 step: 76, loss is 0.0006823055446147919\n",
      "epoch: 20 step: 77, loss is 0.0005466399015858769\n",
      "epoch: 20 step: 78, loss is 0.0005591174704022706\n",
      "epoch: 20 step: 79, loss is 0.0007069518906064332\n",
      "epoch: 20 step: 80, loss is 0.00028022125479765236\n",
      "epoch: 20 step: 81, loss is 0.001536122290417552\n",
      "epoch: 20 step: 82, loss is 0.00017408972780685872\n",
      "epoch: 20 step: 83, loss is 0.0002577852865215391\n",
      "epoch: 20 step: 84, loss is 0.0006530957762151957\n",
      "epoch: 20 step: 85, loss is 0.0006669924478046596\n",
      "epoch: 20 step: 86, loss is 0.0009375736117362976\n",
      "epoch: 20 step: 87, loss is 0.0011259298771619797\n",
      "epoch: 20 step: 88, loss is 0.0003825318126473576\n",
      "epoch: 20 step: 89, loss is 0.001134771853685379\n",
      "epoch: 20 step: 90, loss is 0.0007227759924717247\n",
      "epoch: 20 step: 91, loss is 0.0004058190679643303\n",
      "epoch: 20 step: 92, loss is 0.0006153996218927205\n",
      "epoch: 20 step: 93, loss is 0.0005855390918441117\n",
      "epoch: 20 step: 94, loss is 0.0005436844658106565\n",
      "epoch: 20 step: 95, loss is 0.0021128980442881584\n",
      "epoch: 20 step: 96, loss is 0.0010468648979440331\n",
      "epoch: 20 step: 97, loss is 0.0005413824110291898\n",
      "epoch: 20 step: 98, loss is 0.000481866009067744\n",
      "epoch: 20 step: 99, loss is 0.00041447050170972943\n",
      "epoch: 20 step: 100, loss is 0.0008105916786007583\n",
      "epoch: 20 step: 101, loss is 0.0009334817295894027\n",
      "epoch: 20 step: 102, loss is 0.0002611044910736382\n",
      "epoch: 20 step: 103, loss is 0.00044368000817485154\n",
      "epoch: 20 step: 104, loss is 0.00037216738564893603\n",
      "epoch: 20 step: 105, loss is 0.000214216677704826\n",
      "epoch: 20 step: 106, loss is 0.0010561636881902814\n",
      "epoch: 20 step: 107, loss is 0.0008342241635546088\n",
      "epoch: 20 step: 108, loss is 0.0011106054298579693\n",
      "epoch: 20 step: 109, loss is 0.0005350408027879894\n",
      "epoch: 20 step: 110, loss is 0.0006086695939302444\n",
      "epoch: 20 step: 111, loss is 0.0007732855738140643\n",
      "epoch: 20 step: 112, loss is 0.000480310816783458\n",
      "epoch: 20 step: 113, loss is 0.0006589346448890865\n",
      "epoch: 20 step: 114, loss is 0.0001283463934669271\n",
      "epoch: 20 step: 115, loss is 0.0003957624139729887\n",
      "epoch: 20 step: 116, loss is 0.00048531207721680403\n",
      "epoch: 20 step: 117, loss is 0.0005386606208048761\n",
      "epoch: 20 step: 118, loss is 0.0007174132624641061\n",
      "epoch: 20 step: 119, loss is 0.00043254473712295294\n",
      "epoch: 20 step: 120, loss is 0.0006990086985751987\n",
      "epoch: 20 step: 121, loss is 0.0009314336348325014\n",
      "epoch: 20 step: 122, loss is 0.0005511444178409874\n",
      "epoch: 20 step: 123, loss is 0.0009065670892596245\n",
      "epoch: 20 step: 124, loss is 0.0008086283341981471\n",
      "epoch: 20 step: 125, loss is 0.0005355527973733842\n",
      "epoch: 20 step: 126, loss is 0.0011219569714739919\n",
      "epoch: 20 step: 127, loss is 0.0007378655136562884\n",
      "epoch: 20 step: 128, loss is 0.0017396013718098402\n",
      "epoch: 20 step: 129, loss is 0.0006594303995370865\n",
      "epoch: 20 step: 130, loss is 0.0006797215319238603\n",
      "epoch: 20 step: 131, loss is 0.0005799125647172332\n",
      "epoch: 20 step: 132, loss is 0.0003077838628087193\n",
      "epoch: 20 step: 133, loss is 0.0011166761396452785\n",
      "epoch: 20 step: 134, loss is 0.0003693851758725941\n",
      "epoch: 20 step: 135, loss is 0.0007795389974489808\n",
      "epoch: 20 step: 136, loss is 0.0006343130953609943\n",
      "epoch: 20 step: 137, loss is 0.0011677240254357457\n",
      "epoch: 20 step: 138, loss is 0.0007446363451890647\n",
      "epoch: 20 step: 139, loss is 0.00035899720387533307\n",
      "epoch: 20 step: 140, loss is 0.00028590671718120575\n",
      "epoch: 20 step: 141, loss is 0.0016371628735214472\n",
      "epoch: 20 step: 142, loss is 0.0004298357234802097\n",
      "epoch: 20 step: 143, loss is 0.0013671490596607327\n",
      "epoch: 20 step: 144, loss is 0.0005869038868695498\n",
      "epoch: 20 step: 145, loss is 0.0004862011701334268\n",
      "epoch: 20 step: 146, loss is 0.0007619117386639118\n",
      "epoch: 20 step: 147, loss is 0.0006743870326317847\n",
      "epoch: 20 step: 148, loss is 0.0006789229810237885\n",
      "epoch: 20 step: 149, loss is 0.0005030168103985488\n",
      "epoch: 20 step: 150, loss is 0.0004159481613896787\n",
      "epoch: 20 step: 151, loss is 0.0006260779337026179\n",
      "epoch: 20 step: 152, loss is 0.0007795735145919025\n",
      "epoch: 20 step: 153, loss is 0.0005081762792542577\n",
      "epoch: 20 step: 154, loss is 0.0008819143986329436\n",
      "epoch: 20 step: 155, loss is 0.0009308612206950784\n",
      "epoch: 20 step: 156, loss is 0.0004883400979451835\n",
      "epoch: 20 step: 157, loss is 0.0004242358263581991\n",
      "epoch: 20 step: 158, loss is 0.0003176041354890913\n",
      "epoch: 20 step: 159, loss is 0.0003152776334900409\n",
      "epoch: 20 step: 160, loss is 0.000968520762398839\n",
      "epoch: 20 step: 161, loss is 0.0006696691270917654\n",
      "epoch: 20 step: 162, loss is 0.0019581883680075407\n",
      "epoch: 20 step: 163, loss is 0.00035244200262241066\n",
      "epoch: 20 step: 164, loss is 0.00032545291469432414\n",
      "epoch: 20 step: 165, loss is 0.00026777933817356825\n",
      "epoch: 20 step: 166, loss is 0.00025406875647604465\n",
      "epoch: 20 step: 167, loss is 0.0005533478106372058\n",
      "epoch: 20 step: 168, loss is 0.000335337856085971\n",
      "epoch: 20 step: 169, loss is 0.0007613221532665193\n",
      "epoch: 20 step: 170, loss is 0.000692513887770474\n",
      "epoch: 20 step: 171, loss is 0.0003149287949781865\n",
      "epoch: 20 step: 172, loss is 0.00014887246652506292\n",
      "epoch: 20 step: 173, loss is 0.00027010709163732827\n",
      "epoch: 20 step: 174, loss is 0.0006770232575945556\n",
      "epoch: 20 step: 175, loss is 0.0011268573580309749\n",
      "epoch: 20 step: 176, loss is 0.0011120153358206153\n",
      "epoch: 20 step: 177, loss is 0.0009593414142727852\n",
      "epoch: 20 step: 178, loss is 0.00039235432632267475\n",
      "epoch: 20 step: 179, loss is 0.00029487491701729596\n",
      "epoch: 20 step: 180, loss is 0.00030420831171795726\n",
      "epoch: 20 step: 181, loss is 0.0010560016380622983\n",
      "epoch: 20 step: 182, loss is 0.001120881293900311\n",
      "epoch: 20 step: 183, loss is 0.0011485643917694688\n",
      "epoch: 20 step: 184, loss is 0.0005893132765777409\n",
      "epoch: 20 step: 185, loss is 0.0004486791731324047\n",
      "epoch: 20 step: 186, loss is 0.00020979307009838521\n",
      "epoch: 20 step: 187, loss is 0.00023009232245385647\n",
      "epoch: 20 step: 188, loss is 0.0012534413253888488\n",
      "epoch: 20 step: 189, loss is 0.0005483705317601562\n",
      "epoch: 20 step: 190, loss is 0.00070882064756006\n",
      "epoch: 20 step: 191, loss is 0.0007376780267804861\n",
      "epoch: 20 step: 192, loss is 0.0014359288616105914\n",
      "epoch: 20 step: 193, loss is 0.0012740251841023564\n",
      "epoch: 20 step: 194, loss is 0.0004698527918662876\n",
      "epoch: 20 step: 195, loss is 0.001069891732186079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 196, loss is 0.0009389857295900583\n",
      "epoch: 20 step: 197, loss is 0.0007666288292966783\n",
      "epoch: 20 step: 198, loss is 0.0004010103002656251\n",
      "epoch: 20 step: 199, loss is 0.0006079258746467531\n",
      "epoch: 20 step: 200, loss is 0.00139157276134938\n",
      "epoch: 20 step: 201, loss is 0.0005160646396689117\n",
      "epoch: 20 step: 202, loss is 0.0010923418449237943\n",
      "epoch: 20 step: 203, loss is 0.0013461792841553688\n",
      "epoch: 20 step: 204, loss is 0.0004237642278894782\n",
      "epoch: 20 step: 205, loss is 0.0006392335053533316\n",
      "epoch: 20 step: 206, loss is 0.00048826963757164776\n",
      "epoch: 20 step: 207, loss is 0.001024900353513658\n",
      "epoch: 20 step: 208, loss is 0.0006899611908011138\n",
      "epoch: 20 step: 209, loss is 0.0002486279117874801\n",
      "epoch: 20 step: 210, loss is 0.0006727634463459253\n",
      "epoch: 20 step: 211, loss is 0.00030474181403405964\n",
      "epoch: 20 step: 212, loss is 0.00030955832335166633\n",
      "epoch: 20 step: 213, loss is 0.0015901023289188743\n",
      "epoch: 20 step: 214, loss is 0.0006530805840156972\n",
      "epoch: 20 step: 215, loss is 0.0010794327827170491\n",
      "epoch: 20 step: 216, loss is 0.0009139387984760106\n",
      "epoch: 20 step: 217, loss is 0.0008022556430660188\n",
      "epoch: 20 step: 218, loss is 0.0008813712629489601\n",
      "epoch: 20 step: 219, loss is 0.0009674727916717529\n",
      "epoch: 20 step: 220, loss is 0.0004754187539219856\n",
      "epoch: 20 step: 221, loss is 0.0007324855541810393\n",
      "epoch: 20 step: 222, loss is 0.0005163489258848131\n",
      "epoch: 20 step: 223, loss is 0.0013233475619927049\n",
      "epoch: 20 step: 224, loss is 0.0008283059578388929\n",
      "epoch: 20 step: 225, loss is 0.000330707203829661\n",
      "epoch: 20 step: 226, loss is 0.001191411865875125\n",
      "epoch: 20 step: 227, loss is 0.0008273191633634269\n",
      "epoch: 20 step: 228, loss is 0.0010014981962740421\n",
      "epoch: 20 step: 229, loss is 0.0006459261639975011\n",
      "epoch: 20 step: 230, loss is 0.0009199396008625627\n",
      "epoch: 20 step: 231, loss is 0.0010019988985732198\n",
      "epoch: 20 step: 232, loss is 0.00031205761479213834\n",
      "epoch: 20 step: 233, loss is 0.00025226103025488555\n",
      "epoch: 20 step: 234, loss is 0.0004982206737622619\n",
      "epoch: 20 step: 235, loss is 0.0006398705299943686\n",
      "epoch: 20 step: 236, loss is 0.0008029478485696018\n",
      "epoch: 20 step: 237, loss is 0.000667339947540313\n",
      "epoch: 20 step: 238, loss is 0.0014399619540199637\n",
      "epoch: 20 step: 239, loss is 0.000993488123640418\n",
      "epoch: 20 step: 240, loss is 0.0005537177203223109\n",
      "epoch: 20 step: 241, loss is 0.00029862072551622987\n",
      "epoch: 20 step: 242, loss is 0.0005607302300632\n",
      "epoch: 20 step: 243, loss is 0.0005871437024325132\n",
      "epoch: 20 step: 244, loss is 0.00037495754077099264\n",
      "epoch: 20 step: 245, loss is 0.000717034621629864\n",
      "epoch: 20 step: 246, loss is 0.00048215483548119664\n",
      "epoch: 20 step: 247, loss is 0.0008125688182190061\n",
      "epoch: 20 step: 248, loss is 0.0005593771347776055\n",
      "epoch: 20 step: 249, loss is 0.00025514618027955294\n",
      "epoch: 20 step: 250, loss is 0.0006119850440882146\n",
      "epoch: 20 step: 251, loss is 0.00052416737889871\n",
      "epoch: 20 step: 252, loss is 0.0004691636422649026\n",
      "epoch: 20 step: 253, loss is 0.0002071463968604803\n",
      "epoch: 20 step: 254, loss is 0.000362016522558406\n",
      "epoch: 20 step: 255, loss is 0.0008660568855702877\n",
      "epoch: 20 step: 256, loss is 0.0009372652275487781\n",
      "epoch: 20 step: 257, loss is 0.001224835286848247\n",
      "epoch: 20 step: 258, loss is 0.0004433411522768438\n",
      "epoch: 20 step: 259, loss is 0.0005333690205588937\n",
      "epoch: 20 step: 260, loss is 0.0009488987270742655\n",
      "epoch: 20 step: 261, loss is 0.0006104495842009783\n",
      "epoch: 20 step: 262, loss is 0.0004669529153034091\n",
      "epoch: 20 step: 263, loss is 0.0004838223976548761\n",
      "epoch: 20 step: 264, loss is 0.0018442616565153003\n",
      "epoch: 20 step: 265, loss is 0.0010894713923335075\n",
      "epoch: 20 step: 266, loss is 0.0002851816825568676\n",
      "epoch: 20 step: 267, loss is 0.000656063319183886\n",
      "epoch: 20 step: 268, loss is 0.0007218596874736249\n",
      "epoch: 20 step: 269, loss is 0.0017818674677982926\n",
      "epoch: 20 step: 270, loss is 0.000780073634814471\n",
      "epoch: 20 step: 271, loss is 0.0004533037426881492\n",
      "epoch: 20 step: 272, loss is 0.0006962436600588262\n",
      "epoch: 20 step: 273, loss is 0.0002508333418518305\n",
      "epoch: 20 step: 274, loss is 0.0012732582399621606\n",
      "epoch: 20 step: 275, loss is 0.0008596550324000418\n",
      "epoch: 20 step: 276, loss is 0.0005450913449749351\n",
      "epoch: 20 step: 277, loss is 0.0003371897037141025\n",
      "epoch: 20 step: 278, loss is 0.0009738823282532394\n",
      "epoch: 20 step: 279, loss is 0.0005001386161893606\n",
      "epoch: 20 step: 280, loss is 0.000894565659109503\n",
      "epoch: 20 step: 281, loss is 0.0008410190348513424\n",
      "epoch: 20 step: 282, loss is 0.0012614125153049827\n",
      "epoch: 20 step: 283, loss is 0.00032469144207425416\n",
      "epoch: 20 step: 284, loss is 0.0009909863583743572\n",
      "epoch: 20 step: 285, loss is 0.0008409436559304595\n",
      "epoch: 20 step: 286, loss is 0.0009039143333211541\n",
      "epoch: 20 step: 287, loss is 0.000980378477834165\n",
      "epoch: 20 step: 288, loss is 0.0013517688494175673\n",
      "epoch: 20 step: 289, loss is 0.0011042023543268442\n",
      "epoch: 20 step: 290, loss is 0.0005777847254648805\n",
      "epoch: 20 step: 291, loss is 0.00023564157891087234\n",
      "epoch: 20 step: 292, loss is 0.00041698606219142675\n",
      "epoch: 20 step: 293, loss is 0.00036141122109256685\n",
      "epoch: 20 step: 294, loss is 0.0006364592700265348\n",
      "epoch: 20 step: 295, loss is 0.000411226530559361\n",
      "epoch: 20 step: 296, loss is 0.0007234907825477421\n",
      "epoch: 20 step: 297, loss is 0.0003932508989237249\n",
      "epoch: 20 step: 298, loss is 0.0005581704317592084\n",
      "epoch: 20 step: 299, loss is 0.0003425253089517355\n",
      "epoch: 20 step: 300, loss is 0.0005251261754892766\n",
      "epoch: 20 step: 301, loss is 0.00045612320536747575\n",
      "epoch: 20 step: 302, loss is 0.0002719498297665268\n",
      "epoch: 20 step: 303, loss is 0.0011138448026031256\n",
      "epoch: 20 step: 304, loss is 0.0002645225322339684\n",
      "epoch: 20 step: 305, loss is 0.0004486276884563267\n",
      "epoch: 20 step: 306, loss is 0.00034902384504675865\n",
      "epoch: 20 step: 307, loss is 0.0005101488786749542\n",
      "epoch: 20 step: 308, loss is 0.0003920283925253898\n",
      "epoch: 20 step: 309, loss is 0.0010189019376412034\n",
      "epoch: 20 step: 310, loss is 0.00023283612972591072\n",
      "epoch: 20 step: 311, loss is 0.0005730149568989873\n",
      "epoch: 20 step: 312, loss is 0.0015251904260367155\n",
      "epoch: 20 step: 313, loss is 0.00018955756968352944\n",
      "epoch: 20 step: 314, loss is 0.00035891146399080753\n",
      "epoch: 20 step: 315, loss is 0.0004906410467810929\n",
      "epoch: 20 step: 316, loss is 0.001753971097059548\n",
      "epoch: 20 step: 317, loss is 0.00052887067431584\n",
      "epoch: 20 step: 318, loss is 0.0014884162228554487\n",
      "epoch: 20 step: 319, loss is 0.0006054120603948832\n",
      "epoch: 20 step: 320, loss is 0.0015846426831558347\n",
      "epoch: 20 step: 321, loss is 0.000738264003302902\n",
      "epoch: 20 step: 322, loss is 0.00040071862167678773\n",
      "epoch: 20 step: 323, loss is 0.000683259277138859\n",
      "epoch: 20 step: 324, loss is 0.001598634640686214\n",
      "epoch: 20 step: 325, loss is 0.0007360503659583628\n",
      "epoch: 20 step: 326, loss is 0.0004839812754653394\n",
      "epoch: 20 step: 327, loss is 0.000319244631100446\n",
      "epoch: 20 step: 328, loss is 0.001153274904936552\n",
      "epoch: 20 step: 329, loss is 0.0010632502380758524\n",
      "epoch: 20 step: 330, loss is 0.0005729592521674931\n",
      "epoch: 20 step: 331, loss is 0.0004659012774936855\n",
      "epoch: 20 step: 332, loss is 0.00014867764548398554\n",
      "epoch: 20 step: 333, loss is 0.0010372610995545983\n",
      "epoch: 20 step: 334, loss is 0.0007582214311696589\n",
      "epoch: 20 step: 335, loss is 0.0003590975538827479\n",
      "epoch: 20 step: 336, loss is 0.0005691604455932975\n",
      "epoch: 20 step: 337, loss is 0.001221239217557013\n",
      "epoch: 20 step: 338, loss is 0.00038748778752051294\n",
      "epoch: 20 step: 339, loss is 0.0004629648174159229\n",
      "epoch: 20 step: 340, loss is 0.0009992757113650441\n",
      "epoch: 20 step: 341, loss is 0.0004378350276965648\n",
      "epoch: 20 step: 342, loss is 0.00021082282182760537\n",
      "epoch: 20 step: 343, loss is 0.0009646476828493178\n",
      "epoch: 20 step: 344, loss is 0.0005596673581749201\n",
      "epoch: 20 step: 345, loss is 0.00038978859083727\n",
      "epoch: 20 step: 346, loss is 0.00042118041892535985\n",
      "epoch: 20 step: 347, loss is 0.0004965740954503417\n",
      "epoch: 20 step: 348, loss is 0.0009771210607141256\n",
      "epoch: 20 step: 349, loss is 0.0006550564430654049\n",
      "epoch: 20 step: 350, loss is 0.0010362364118918777\n",
      "epoch: 20 step: 351, loss is 0.0012287093559280038\n",
      "epoch: 20 step: 352, loss is 0.00035719224251806736\n",
      "epoch: 20 step: 353, loss is 0.0005782245425507426\n",
      "epoch: 20 step: 354, loss is 0.001088008750230074\n",
      "epoch: 20 step: 355, loss is 0.0006312739569693804\n",
      "epoch: 20 step: 356, loss is 0.0006677422788925469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 357, loss is 0.0003505145141389221\n",
      "epoch: 20 step: 358, loss is 0.0003038753056898713\n",
      "epoch: 20 step: 359, loss is 0.0008035330683924258\n",
      "epoch: 20 step: 360, loss is 0.0009074985282495618\n",
      "epoch: 20 step: 361, loss is 0.0013577991630882025\n",
      "epoch: 20 step: 362, loss is 0.0007680791895836592\n",
      "epoch: 20 step: 363, loss is 0.0004360392049420625\n",
      "epoch: 20 step: 364, loss is 0.0008174881804734468\n",
      "epoch: 20 step: 365, loss is 0.0006408381159417331\n",
      "epoch: 20 step: 366, loss is 0.0009176853927783668\n",
      "epoch: 20 step: 367, loss is 0.0001574125053593889\n",
      "epoch: 20 step: 368, loss is 0.0011765718227252364\n",
      "epoch: 20 step: 369, loss is 0.0013981051743030548\n",
      "epoch: 20 step: 370, loss is 0.0008916523074731231\n",
      "epoch: 20 step: 371, loss is 0.0007052022265270352\n",
      "epoch: 20 step: 372, loss is 0.00038659319397993386\n",
      "epoch: 20 step: 373, loss is 0.0005385997937992215\n",
      "epoch: 20 step: 374, loss is 0.0006583705544471741\n",
      "epoch: 20 step: 375, loss is 0.00044186183367855847\n",
      "Train epoch time: 11970.066 ms, per step time: 31.920 ms\n",
      "epoch: 21 step: 1, loss is 0.0011129736667498946\n",
      "epoch: 21 step: 2, loss is 0.0005824863910675049\n",
      "epoch: 21 step: 3, loss is 0.0007129088626243174\n",
      "epoch: 21 step: 4, loss is 0.0008115209639072418\n",
      "epoch: 21 step: 5, loss is 0.00018160039326176047\n",
      "epoch: 21 step: 6, loss is 0.00023447448620572686\n",
      "epoch: 21 step: 7, loss is 0.000988922780379653\n",
      "epoch: 21 step: 8, loss is 0.00048298650654032826\n",
      "epoch: 21 step: 9, loss is 0.001042744843289256\n",
      "epoch: 21 step: 10, loss is 0.0010675201192498207\n",
      "epoch: 21 step: 11, loss is 0.0004555142077151686\n",
      "epoch: 21 step: 12, loss is 0.0019832050893455744\n",
      "epoch: 21 step: 13, loss is 0.0006515262648463249\n",
      "epoch: 21 step: 14, loss is 0.000587431772146374\n",
      "epoch: 21 step: 15, loss is 0.000823160691652447\n",
      "epoch: 21 step: 16, loss is 0.001362379640340805\n",
      "epoch: 21 step: 17, loss is 0.001324416371062398\n",
      "epoch: 21 step: 18, loss is 0.0006211267318576574\n",
      "epoch: 21 step: 19, loss is 0.0007459865882992744\n",
      "epoch: 21 step: 20, loss is 0.0006219338974915445\n",
      "epoch: 21 step: 21, loss is 0.0008781978394836187\n",
      "epoch: 21 step: 22, loss is 0.0004175311769358814\n",
      "epoch: 21 step: 23, loss is 0.0009137897286564112\n",
      "epoch: 21 step: 24, loss is 0.0007790960953570902\n",
      "epoch: 21 step: 25, loss is 0.0003077652945648879\n",
      "epoch: 21 step: 26, loss is 0.00024012877838686109\n",
      "epoch: 21 step: 27, loss is 0.000429980835178867\n",
      "epoch: 21 step: 28, loss is 0.0010276063112542033\n",
      "epoch: 21 step: 29, loss is 0.0004946822882629931\n",
      "epoch: 21 step: 30, loss is 0.0008327196119353175\n",
      "epoch: 21 step: 31, loss is 0.0007419574540108442\n",
      "epoch: 21 step: 32, loss is 0.00032208606717176735\n",
      "epoch: 21 step: 33, loss is 0.00029129203176125884\n",
      "epoch: 21 step: 34, loss is 0.00023919732484500855\n",
      "epoch: 21 step: 35, loss is 0.0005180919542908669\n",
      "epoch: 21 step: 36, loss is 0.0010345083428546786\n",
      "epoch: 21 step: 37, loss is 0.0017472514882683754\n",
      "epoch: 21 step: 38, loss is 0.0002010852622333914\n",
      "epoch: 21 step: 39, loss is 0.00038979967939667404\n",
      "epoch: 21 step: 40, loss is 0.0005271815462037921\n",
      "epoch: 21 step: 41, loss is 0.0010456120362505317\n",
      "epoch: 21 step: 42, loss is 0.00042139290599152446\n",
      "epoch: 21 step: 43, loss is 0.00023570032499264926\n",
      "epoch: 21 step: 44, loss is 0.0004976927884854376\n",
      "epoch: 21 step: 45, loss is 0.001341056078672409\n",
      "epoch: 21 step: 46, loss is 0.0009349394240416586\n",
      "epoch: 21 step: 47, loss is 0.0003197769110556692\n",
      "epoch: 21 step: 48, loss is 0.0003786174056585878\n",
      "epoch: 21 step: 49, loss is 0.00024718540953472257\n",
      "epoch: 21 step: 50, loss is 0.0020906892605125904\n",
      "epoch: 21 step: 51, loss is 0.00030850651091896\n",
      "epoch: 21 step: 52, loss is 0.0007851161644794047\n",
      "epoch: 21 step: 53, loss is 0.0009252431918866932\n",
      "epoch: 21 step: 54, loss is 0.00016076504834927619\n",
      "epoch: 21 step: 55, loss is 0.0003797232930082828\n",
      "epoch: 21 step: 56, loss is 0.0004090866132173687\n",
      "epoch: 21 step: 57, loss is 0.00028072879649698734\n",
      "epoch: 21 step: 58, loss is 0.0005360736977308989\n",
      "epoch: 21 step: 59, loss is 0.00026421615621075034\n",
      "epoch: 21 step: 60, loss is 0.00043750464101321995\n",
      "epoch: 21 step: 61, loss is 0.0006147114909254014\n",
      "epoch: 21 step: 62, loss is 0.00031060565379448235\n",
      "epoch: 21 step: 63, loss is 0.000871081545483321\n",
      "epoch: 21 step: 64, loss is 0.0006482016760855913\n",
      "epoch: 21 step: 65, loss is 0.0005131374346092343\n",
      "epoch: 21 step: 66, loss is 0.0008958062971942127\n",
      "epoch: 21 step: 67, loss is 0.00028244967688806355\n",
      "epoch: 21 step: 68, loss is 0.0005941724521107972\n",
      "epoch: 21 step: 69, loss is 0.00032179936533793807\n",
      "epoch: 21 step: 70, loss is 0.0015940325101837516\n",
      "epoch: 21 step: 71, loss is 0.0005010985187254846\n",
      "epoch: 21 step: 72, loss is 0.00044219710980542004\n",
      "epoch: 21 step: 73, loss is 0.0005735870217904449\n",
      "epoch: 21 step: 74, loss is 0.001349981059320271\n",
      "epoch: 21 step: 75, loss is 0.00046918931184336543\n",
      "epoch: 21 step: 76, loss is 0.000939684163313359\n",
      "epoch: 21 step: 77, loss is 0.0015500047011300921\n",
      "epoch: 21 step: 78, loss is 0.0004141754761803895\n",
      "epoch: 21 step: 79, loss is 0.0006109241512604058\n",
      "epoch: 21 step: 80, loss is 0.0011837997008115053\n",
      "epoch: 21 step: 81, loss is 0.0004068455600645393\n",
      "epoch: 21 step: 82, loss is 0.000774519401602447\n",
      "epoch: 21 step: 83, loss is 0.0006870896904729307\n",
      "epoch: 21 step: 84, loss is 0.0005556936375796795\n",
      "epoch: 21 step: 85, loss is 0.0003688028082251549\n",
      "epoch: 21 step: 86, loss is 0.0004980168305337429\n",
      "epoch: 21 step: 87, loss is 0.0005988365155644715\n",
      "epoch: 21 step: 88, loss is 0.0015155213186517358\n",
      "epoch: 21 step: 89, loss is 0.0010285252938047051\n",
      "epoch: 21 step: 90, loss is 0.0011446720454841852\n",
      "epoch: 21 step: 91, loss is 0.0005218151491135359\n",
      "epoch: 21 step: 92, loss is 0.001389525830745697\n",
      "epoch: 21 step: 93, loss is 0.00056029501138255\n",
      "epoch: 21 step: 94, loss is 0.0007589581073261797\n",
      "epoch: 21 step: 95, loss is 0.0010107989655807614\n",
      "epoch: 21 step: 96, loss is 0.0013982919044792652\n",
      "epoch: 21 step: 97, loss is 0.0012621646746993065\n",
      "epoch: 21 step: 98, loss is 0.0006573346327058971\n",
      "epoch: 21 step: 99, loss is 0.00028685590950772166\n",
      "epoch: 21 step: 100, loss is 0.0007146530551835895\n",
      "epoch: 21 step: 101, loss is 0.0007637343951500952\n",
      "epoch: 21 step: 102, loss is 0.0009131728438660502\n",
      "epoch: 21 step: 103, loss is 0.0013878433965146542\n",
      "epoch: 21 step: 104, loss is 0.001052701030857861\n",
      "epoch: 21 step: 105, loss is 0.0011346724350005388\n",
      "epoch: 21 step: 106, loss is 0.0011912116315215826\n",
      "epoch: 21 step: 107, loss is 0.0005125741008669138\n",
      "epoch: 21 step: 108, loss is 0.0014027366414666176\n",
      "epoch: 21 step: 109, loss is 0.000251085904892534\n",
      "epoch: 21 step: 110, loss is 0.0006938842707313597\n",
      "epoch: 21 step: 111, loss is 0.0009094595443457365\n",
      "epoch: 21 step: 112, loss is 0.0011315271258354187\n",
      "epoch: 21 step: 113, loss is 0.00109392951708287\n",
      "epoch: 21 step: 114, loss is 0.0006731065805070102\n",
      "epoch: 21 step: 115, loss is 0.000729525345377624\n",
      "epoch: 21 step: 116, loss is 0.0007452716236002743\n",
      "epoch: 21 step: 117, loss is 0.000431130756624043\n",
      "epoch: 21 step: 118, loss is 0.0009334647911600769\n",
      "epoch: 21 step: 119, loss is 0.000892758893314749\n",
      "epoch: 21 step: 120, loss is 0.003204366425052285\n",
      "epoch: 21 step: 121, loss is 0.0006981712067499757\n",
      "epoch: 21 step: 122, loss is 0.0007251038332469761\n",
      "epoch: 21 step: 123, loss is 0.0006615505553781986\n",
      "epoch: 21 step: 124, loss is 0.0005800173967145383\n",
      "epoch: 21 step: 125, loss is 0.0012073562247678638\n",
      "epoch: 21 step: 126, loss is 0.0005210518720559776\n",
      "epoch: 21 step: 127, loss is 0.0012738077202811837\n",
      "epoch: 21 step: 128, loss is 0.0010528465500101447\n",
      "epoch: 21 step: 129, loss is 0.0007111361483111978\n",
      "epoch: 21 step: 130, loss is 0.0007224383298307657\n",
      "epoch: 21 step: 131, loss is 0.0010884716175496578\n",
      "epoch: 21 step: 132, loss is 0.0011682563927024603\n",
      "epoch: 21 step: 133, loss is 0.0007691842038184404\n",
      "epoch: 21 step: 134, loss is 0.0005366194527596235\n",
      "epoch: 21 step: 135, loss is 0.0004916058387607336\n",
      "epoch: 21 step: 136, loss is 0.0012170635163784027\n",
      "epoch: 21 step: 137, loss is 0.00035422423388808966\n",
      "epoch: 21 step: 138, loss is 0.0005022688419558108\n",
      "epoch: 21 step: 139, loss is 0.000688965548761189\n",
      "epoch: 21 step: 140, loss is 0.0007652108906768262\n",
      "epoch: 21 step: 141, loss is 0.0004749444196932018\n",
      "epoch: 21 step: 142, loss is 0.00038456168840639293\n",
      "epoch: 21 step: 143, loss is 0.0008767541730776429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 144, loss is 0.0006275735795497894\n",
      "epoch: 21 step: 145, loss is 0.0011461508693173528\n",
      "epoch: 21 step: 146, loss is 0.00037569552659988403\n",
      "epoch: 21 step: 147, loss is 0.0005875850911252201\n",
      "epoch: 21 step: 148, loss is 0.000981789198704064\n",
      "epoch: 21 step: 149, loss is 0.0006758174858987331\n",
      "epoch: 21 step: 150, loss is 0.0006522962939925492\n",
      "epoch: 21 step: 151, loss is 0.00048082656576298177\n",
      "epoch: 21 step: 152, loss is 0.0003047268546652049\n",
      "epoch: 21 step: 153, loss is 0.0001634482032386586\n",
      "epoch: 21 step: 154, loss is 0.0010654906509444118\n",
      "epoch: 21 step: 155, loss is 0.00018483980966266245\n",
      "epoch: 21 step: 156, loss is 0.0004857669700868428\n",
      "epoch: 21 step: 157, loss is 0.0007440960616804659\n",
      "epoch: 21 step: 158, loss is 0.0006450518849305809\n",
      "epoch: 21 step: 159, loss is 0.0007423286442644894\n",
      "epoch: 21 step: 160, loss is 0.0003582182980608195\n",
      "epoch: 21 step: 161, loss is 0.0010851533152163029\n",
      "epoch: 21 step: 162, loss is 0.0009335049544461071\n",
      "epoch: 21 step: 163, loss is 0.0011823518434539437\n",
      "epoch: 21 step: 164, loss is 0.0004040743224322796\n",
      "epoch: 21 step: 165, loss is 0.0014197592390701175\n",
      "epoch: 21 step: 166, loss is 0.0005675661959685385\n",
      "epoch: 21 step: 167, loss is 0.0006411683280020952\n",
      "epoch: 21 step: 168, loss is 0.001078020315617323\n",
      "epoch: 21 step: 169, loss is 0.0014033348998054862\n",
      "epoch: 21 step: 170, loss is 0.00048662989865988493\n",
      "epoch: 21 step: 171, loss is 0.0007084239623509347\n",
      "epoch: 21 step: 172, loss is 0.0009577367454767227\n",
      "epoch: 21 step: 173, loss is 0.00026907239225693047\n",
      "epoch: 21 step: 174, loss is 0.0009703368996270001\n",
      "epoch: 21 step: 175, loss is 0.0009013680391944945\n",
      "epoch: 21 step: 176, loss is 0.0004894993035122752\n",
      "epoch: 21 step: 177, loss is 0.0013815568527206779\n",
      "epoch: 21 step: 178, loss is 0.0007388666272163391\n",
      "epoch: 21 step: 179, loss is 0.0009602441568858922\n",
      "epoch: 21 step: 180, loss is 0.0009082467295229435\n",
      "epoch: 21 step: 181, loss is 0.0008833264582790434\n",
      "epoch: 21 step: 182, loss is 0.001037039328366518\n",
      "epoch: 21 step: 183, loss is 0.0003079411981161684\n",
      "epoch: 21 step: 184, loss is 0.00011596394324442372\n",
      "epoch: 21 step: 185, loss is 0.0011126399040222168\n",
      "epoch: 21 step: 186, loss is 0.00046262837713584304\n",
      "epoch: 21 step: 187, loss is 0.001221542595885694\n",
      "epoch: 21 step: 188, loss is 0.0007327039493247867\n",
      "epoch: 21 step: 189, loss is 0.000639701378531754\n",
      "epoch: 21 step: 190, loss is 0.0003946616197936237\n",
      "epoch: 21 step: 191, loss is 0.0007456421153619885\n",
      "epoch: 21 step: 192, loss is 0.0003914536500815302\n",
      "epoch: 21 step: 193, loss is 0.0005152962985448539\n",
      "epoch: 21 step: 194, loss is 0.000783124181907624\n",
      "epoch: 21 step: 195, loss is 0.0005388460704125464\n",
      "epoch: 21 step: 196, loss is 0.0010589153971523046\n",
      "epoch: 21 step: 197, loss is 0.00036192548577673733\n",
      "epoch: 21 step: 198, loss is 0.0006251329323276877\n",
      "epoch: 21 step: 199, loss is 0.0005563749582506716\n",
      "epoch: 21 step: 200, loss is 0.0003916849382221699\n",
      "epoch: 21 step: 201, loss is 0.00039490163908340037\n",
      "epoch: 21 step: 202, loss is 0.0009436354739591479\n",
      "epoch: 21 step: 203, loss is 0.0004907475085929036\n",
      "epoch: 21 step: 204, loss is 0.0008138398989103734\n",
      "epoch: 21 step: 205, loss is 0.0007389694801531732\n",
      "epoch: 21 step: 206, loss is 0.0019108835840597749\n",
      "epoch: 21 step: 207, loss is 0.0005213003605604172\n",
      "epoch: 21 step: 208, loss is 0.00021299987565726042\n",
      "epoch: 21 step: 209, loss is 0.0007437968743033707\n",
      "epoch: 21 step: 210, loss is 0.0006135213770903647\n",
      "epoch: 21 step: 211, loss is 0.0005797823541797698\n",
      "epoch: 21 step: 212, loss is 0.0021475504618138075\n",
      "epoch: 21 step: 213, loss is 0.0005303129437379539\n",
      "epoch: 21 step: 214, loss is 0.0005326385726220906\n",
      "epoch: 21 step: 215, loss is 0.000401526311179623\n",
      "epoch: 21 step: 216, loss is 0.00026551788323558867\n",
      "epoch: 21 step: 217, loss is 0.0005540497368201613\n",
      "epoch: 21 step: 218, loss is 0.0010404076892882586\n",
      "epoch: 21 step: 219, loss is 0.0010558809153735638\n",
      "epoch: 21 step: 220, loss is 0.000669725879561156\n",
      "epoch: 21 step: 221, loss is 0.0005169517826288939\n",
      "epoch: 21 step: 222, loss is 0.001068461686372757\n",
      "epoch: 21 step: 223, loss is 0.00010955896868836135\n",
      "epoch: 21 step: 224, loss is 0.001270295586436987\n",
      "epoch: 21 step: 225, loss is 0.0007459614425897598\n",
      "epoch: 21 step: 226, loss is 0.0014701393665745854\n",
      "epoch: 21 step: 227, loss is 0.0006849107448942959\n",
      "epoch: 21 step: 228, loss is 0.0004895159509032965\n",
      "epoch: 21 step: 229, loss is 0.0007794055854901671\n",
      "epoch: 21 step: 230, loss is 0.0010909686097875237\n",
      "epoch: 21 step: 231, loss is 0.00068293372169137\n",
      "epoch: 21 step: 232, loss is 0.0002497800160199404\n",
      "epoch: 21 step: 233, loss is 0.0008087594178505242\n",
      "epoch: 21 step: 234, loss is 0.0007154849590733647\n",
      "epoch: 21 step: 235, loss is 0.0003399066044948995\n",
      "epoch: 21 step: 236, loss is 0.0004402552731335163\n",
      "epoch: 21 step: 237, loss is 0.00019566825358197093\n",
      "epoch: 21 step: 238, loss is 0.0006219425704330206\n",
      "epoch: 21 step: 239, loss is 0.0008039232925511897\n",
      "epoch: 21 step: 240, loss is 0.0014649549266323447\n",
      "epoch: 21 step: 241, loss is 0.0010320314904674888\n",
      "epoch: 21 step: 242, loss is 0.0011709542013704777\n",
      "epoch: 21 step: 243, loss is 3.653088424471207e-05\n",
      "epoch: 21 step: 244, loss is 0.0009347540908493102\n",
      "epoch: 21 step: 245, loss is 0.00042884756112471223\n",
      "epoch: 21 step: 246, loss is 0.0006519906455650926\n",
      "epoch: 21 step: 247, loss is 0.0011581056751310825\n",
      "epoch: 21 step: 248, loss is 0.0005356568726710975\n",
      "epoch: 21 step: 249, loss is 0.0007212611380964518\n",
      "epoch: 21 step: 250, loss is 0.0008784851524978876\n",
      "epoch: 21 step: 251, loss is 0.0004967859713360667\n",
      "epoch: 21 step: 252, loss is 0.0004925511893816292\n",
      "epoch: 21 step: 253, loss is 0.0012730354210361838\n",
      "epoch: 21 step: 254, loss is 0.0006585974479094148\n",
      "epoch: 21 step: 255, loss is 0.0003609161649364978\n",
      "epoch: 21 step: 256, loss is 0.0005389595753513277\n",
      "epoch: 21 step: 257, loss is 0.0003529363020788878\n",
      "epoch: 21 step: 258, loss is 0.0006025385810062289\n",
      "epoch: 21 step: 259, loss is 0.0003842961450573057\n",
      "epoch: 21 step: 260, loss is 0.0009045128244906664\n",
      "epoch: 21 step: 261, loss is 0.0013134705368429422\n",
      "epoch: 21 step: 262, loss is 0.0007742953603155911\n",
      "epoch: 21 step: 263, loss is 0.0012985847424715757\n",
      "epoch: 21 step: 264, loss is 0.0007516402984037995\n",
      "epoch: 21 step: 265, loss is 0.0008147681364789605\n",
      "epoch: 21 step: 266, loss is 0.0015210077399387956\n",
      "epoch: 21 step: 267, loss is 0.0012946986826136708\n",
      "epoch: 21 step: 268, loss is 0.0012486219638958573\n",
      "epoch: 21 step: 269, loss is 0.00015636699390597641\n",
      "epoch: 21 step: 270, loss is 0.00033495909883640707\n",
      "epoch: 21 step: 271, loss is 0.0006578578031621873\n",
      "epoch: 21 step: 272, loss is 0.00042551764636300504\n",
      "epoch: 21 step: 273, loss is 0.00021439589909277856\n",
      "epoch: 21 step: 274, loss is 0.0005891168839298189\n",
      "epoch: 21 step: 275, loss is 0.0011013811454176903\n",
      "epoch: 21 step: 276, loss is 0.0007972190505824983\n",
      "epoch: 21 step: 277, loss is 0.00039181738975457847\n",
      "epoch: 21 step: 278, loss is 0.001213414128869772\n",
      "epoch: 21 step: 279, loss is 0.0005202864413149655\n",
      "epoch: 21 step: 280, loss is 0.00023278416483663023\n",
      "epoch: 21 step: 281, loss is 0.0009781564585864544\n",
      "epoch: 21 step: 282, loss is 0.0005377624765969813\n",
      "epoch: 21 step: 283, loss is 0.0006321988184936345\n",
      "epoch: 21 step: 284, loss is 0.0004994150949642062\n",
      "epoch: 21 step: 285, loss is 0.0006297951331362128\n",
      "epoch: 21 step: 286, loss is 0.00036819741944782436\n",
      "epoch: 21 step: 287, loss is 0.0009507101494818926\n",
      "epoch: 21 step: 288, loss is 0.0005329918349161744\n",
      "epoch: 21 step: 289, loss is 0.0007531455485150218\n",
      "epoch: 21 step: 290, loss is 0.00037393104867078364\n",
      "epoch: 21 step: 291, loss is 0.0003503684129100293\n",
      "epoch: 21 step: 292, loss is 0.0012611700221896172\n",
      "epoch: 21 step: 293, loss is 0.0004984955885447562\n",
      "epoch: 21 step: 294, loss is 0.0004423231293912977\n",
      "epoch: 21 step: 295, loss is 0.0007696668617427349\n",
      "epoch: 21 step: 296, loss is 0.0009260365040972829\n",
      "epoch: 21 step: 297, loss is 0.0005752179422415793\n",
      "epoch: 21 step: 298, loss is 0.0010272138752043247\n",
      "epoch: 21 step: 299, loss is 0.0015153343556448817\n",
      "epoch: 21 step: 300, loss is 0.0004011143173556775\n",
      "epoch: 21 step: 301, loss is 0.001013546483591199\n",
      "epoch: 21 step: 302, loss is 0.0006746570579707623\n",
      "epoch: 21 step: 303, loss is 0.0006215409375727177\n",
      "epoch: 21 step: 304, loss is 0.0005154433310963213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 305, loss is 0.0014971387572586536\n",
      "epoch: 21 step: 306, loss is 0.0003394945524632931\n",
      "epoch: 21 step: 307, loss is 0.00039710989221930504\n",
      "epoch: 21 step: 308, loss is 0.0005121332360431552\n",
      "epoch: 21 step: 309, loss is 0.00033505167812108994\n",
      "epoch: 21 step: 310, loss is 0.0006717077922075987\n",
      "epoch: 21 step: 311, loss is 0.0002596586418803781\n",
      "epoch: 21 step: 312, loss is 0.0007859435281716287\n",
      "epoch: 21 step: 313, loss is 0.0004797806032001972\n",
      "epoch: 21 step: 314, loss is 0.00022595026530325413\n",
      "epoch: 21 step: 315, loss is 0.000608605332672596\n",
      "epoch: 21 step: 316, loss is 0.0007035162416286767\n",
      "epoch: 21 step: 317, loss is 0.0009138145833276212\n",
      "epoch: 21 step: 318, loss is 0.0012815119698643684\n",
      "epoch: 21 step: 319, loss is 0.0010542756645008922\n",
      "epoch: 21 step: 320, loss is 0.0004982285900041461\n",
      "epoch: 21 step: 321, loss is 0.00023516446526627988\n",
      "epoch: 21 step: 322, loss is 0.0010819811141118407\n",
      "epoch: 21 step: 323, loss is 0.00036954160896129906\n",
      "epoch: 21 step: 324, loss is 0.00032970585743896663\n",
      "epoch: 21 step: 325, loss is 0.0007809852831996977\n",
      "epoch: 21 step: 326, loss is 0.00016803891048766673\n",
      "epoch: 21 step: 327, loss is 0.00048738799523562193\n",
      "epoch: 21 step: 328, loss is 0.00039161089807748795\n",
      "epoch: 21 step: 329, loss is 0.0012860200367867947\n",
      "epoch: 21 step: 330, loss is 0.00036015239311382174\n",
      "epoch: 21 step: 331, loss is 0.0002203198819188401\n",
      "epoch: 21 step: 332, loss is 0.0005021471879445016\n",
      "epoch: 21 step: 333, loss is 0.0012209470150992274\n",
      "epoch: 21 step: 334, loss is 0.0004728018247988075\n",
      "epoch: 21 step: 335, loss is 0.0003629517159424722\n",
      "epoch: 21 step: 336, loss is 0.0004770333180204034\n",
      "epoch: 21 step: 337, loss is 0.0010708498302847147\n",
      "epoch: 21 step: 338, loss is 0.0004383166669867933\n",
      "epoch: 21 step: 339, loss is 0.0009204099769704044\n",
      "epoch: 21 step: 340, loss is 0.00038341156323440373\n",
      "epoch: 21 step: 341, loss is 0.0007231297786347568\n",
      "epoch: 21 step: 342, loss is 0.00042585539631545544\n",
      "epoch: 21 step: 343, loss is 0.0008011190220713615\n",
      "epoch: 21 step: 344, loss is 0.0010829443344846368\n",
      "epoch: 21 step: 345, loss is 0.0006089418311603367\n",
      "epoch: 21 step: 346, loss is 0.0006356265512295067\n",
      "epoch: 21 step: 347, loss is 0.0006775724468752742\n",
      "epoch: 21 step: 348, loss is 0.0007282668957486749\n",
      "epoch: 21 step: 349, loss is 0.0015090141678228974\n",
      "epoch: 21 step: 350, loss is 0.0008186039631254971\n",
      "epoch: 21 step: 351, loss is 0.0010461249621585011\n",
      "epoch: 21 step: 352, loss is 0.000939302088227123\n",
      "epoch: 21 step: 353, loss is 0.0008962868014350533\n",
      "epoch: 21 step: 354, loss is 0.0002163645112887025\n",
      "epoch: 21 step: 355, loss is 0.0010536041809245944\n",
      "epoch: 21 step: 356, loss is 0.0006812409847043455\n",
      "epoch: 21 step: 357, loss is 0.000465092045487836\n",
      "epoch: 21 step: 358, loss is 0.00030168486409820616\n",
      "epoch: 21 step: 359, loss is 0.000947794527746737\n",
      "epoch: 21 step: 360, loss is 0.0015279720537364483\n",
      "epoch: 21 step: 361, loss is 0.0005603309837169945\n",
      "epoch: 21 step: 362, loss is 0.0008075232617557049\n",
      "epoch: 21 step: 363, loss is 0.0007172543555498123\n",
      "epoch: 21 step: 364, loss is 0.0010922932997345924\n",
      "epoch: 21 step: 365, loss is 0.0003931019455194473\n",
      "epoch: 21 step: 366, loss is 0.0011285532964393497\n",
      "epoch: 21 step: 367, loss is 0.0007983119576238096\n",
      "epoch: 21 step: 368, loss is 0.0004326542839407921\n",
      "epoch: 21 step: 369, loss is 0.0007249471382237971\n",
      "epoch: 21 step: 370, loss is 0.0004016626626253128\n",
      "epoch: 21 step: 371, loss is 0.00048706409870646894\n",
      "epoch: 21 step: 372, loss is 0.0005093105719424784\n",
      "epoch: 21 step: 373, loss is 0.0002910094626713544\n",
      "epoch: 21 step: 374, loss is 0.00022039593022782356\n",
      "epoch: 21 step: 375, loss is 0.0005997112020850182\n",
      "Train epoch time: 11862.797 ms, per step time: 31.634 ms\n",
      "epoch: 22 step: 1, loss is 0.001240008044987917\n",
      "epoch: 22 step: 2, loss is 0.000701952027156949\n",
      "epoch: 22 step: 3, loss is 0.0003637635090854019\n",
      "epoch: 22 step: 4, loss is 0.00014990819909144193\n",
      "epoch: 22 step: 5, loss is 0.000256236206041649\n",
      "epoch: 22 step: 6, loss is 0.00035269788349978626\n",
      "epoch: 22 step: 7, loss is 0.00134757487103343\n",
      "epoch: 22 step: 8, loss is 0.0005224627675488591\n",
      "epoch: 22 step: 9, loss is 0.00046835074317641556\n",
      "epoch: 22 step: 10, loss is 0.0007367853540927172\n",
      "epoch: 22 step: 11, loss is 0.0005134288803674281\n",
      "epoch: 22 step: 12, loss is 0.0009098807931877673\n",
      "epoch: 22 step: 13, loss is 0.00041253931703977287\n",
      "epoch: 22 step: 14, loss is 0.0011420950759202242\n",
      "epoch: 22 step: 15, loss is 0.002082045190036297\n",
      "epoch: 22 step: 16, loss is 0.0003937232540920377\n",
      "epoch: 22 step: 17, loss is 0.0008381645893678069\n",
      "epoch: 22 step: 18, loss is 0.0014102159766480327\n",
      "epoch: 22 step: 19, loss is 0.00149599090218544\n",
      "epoch: 22 step: 20, loss is 0.0012992460979148746\n",
      "epoch: 22 step: 21, loss is 0.0009083464392460883\n",
      "epoch: 22 step: 22, loss is 0.000830095203127712\n",
      "epoch: 22 step: 23, loss is 0.0015038832789286971\n",
      "epoch: 22 step: 24, loss is 0.00045525783207267523\n",
      "epoch: 22 step: 25, loss is 0.0016321134753525257\n",
      "epoch: 22 step: 26, loss is 0.001179985818453133\n",
      "epoch: 22 step: 27, loss is 0.0010533828753978014\n",
      "epoch: 22 step: 28, loss is 0.0004776595742441714\n",
      "epoch: 22 step: 29, loss is 0.00033878686372190714\n",
      "epoch: 22 step: 30, loss is 0.0004588713636621833\n",
      "epoch: 22 step: 31, loss is 0.001041717128828168\n",
      "epoch: 22 step: 32, loss is 0.0007711309008300304\n",
      "epoch: 22 step: 33, loss is 0.0007215358200483024\n",
      "epoch: 22 step: 34, loss is 0.00043755274964496493\n",
      "epoch: 22 step: 35, loss is 0.0007517430931329727\n",
      "epoch: 22 step: 36, loss is 0.0007585342973470688\n",
      "epoch: 22 step: 37, loss is 0.000385561230359599\n",
      "epoch: 22 step: 38, loss is 0.0011320483172312379\n",
      "epoch: 22 step: 39, loss is 0.0003253564646001905\n",
      "epoch: 22 step: 40, loss is 0.0009944337652996182\n",
      "epoch: 22 step: 41, loss is 0.0004430272674653679\n",
      "epoch: 22 step: 42, loss is 0.0010765176266431808\n",
      "epoch: 22 step: 43, loss is 0.0007463849033229053\n",
      "epoch: 22 step: 44, loss is 0.00043822271982207894\n",
      "epoch: 22 step: 45, loss is 0.001039012218825519\n",
      "epoch: 22 step: 46, loss is 0.0005704685463570058\n",
      "epoch: 22 step: 47, loss is 0.0009277207427658141\n",
      "epoch: 22 step: 48, loss is 0.0010256178211420774\n",
      "epoch: 22 step: 49, loss is 0.0001168784947367385\n",
      "epoch: 22 step: 50, loss is 0.0013068851549178362\n",
      "epoch: 22 step: 51, loss is 0.0006797508103772998\n",
      "epoch: 22 step: 52, loss is 0.0007146553252823651\n",
      "epoch: 22 step: 53, loss is 0.0012804969446733594\n",
      "epoch: 22 step: 54, loss is 0.0005430129822343588\n",
      "epoch: 22 step: 55, loss is 0.0006443739403039217\n",
      "epoch: 22 step: 56, loss is 0.0005879332893528044\n",
      "epoch: 22 step: 57, loss is 0.0006883463356643915\n",
      "epoch: 22 step: 58, loss is 0.0004542010137811303\n",
      "epoch: 22 step: 59, loss is 0.00021186459343880415\n",
      "epoch: 22 step: 60, loss is 0.0006385204615071416\n",
      "epoch: 22 step: 61, loss is 0.0005473193596117198\n",
      "epoch: 22 step: 62, loss is 0.00025976833421736956\n",
      "epoch: 22 step: 63, loss is 0.00041340437019243836\n",
      "epoch: 22 step: 64, loss is 0.00010899105109274387\n",
      "epoch: 22 step: 65, loss is 0.0005168997449800372\n",
      "epoch: 22 step: 66, loss is 0.0003992339188698679\n",
      "epoch: 22 step: 67, loss is 0.0009113477426581085\n",
      "epoch: 22 step: 68, loss is 0.0007522719679400325\n",
      "epoch: 22 step: 69, loss is 0.0007601789548061788\n",
      "epoch: 22 step: 70, loss is 0.00010570580343483016\n",
      "epoch: 22 step: 71, loss is 0.0008612850797362626\n",
      "epoch: 22 step: 72, loss is 0.0008343295194208622\n",
      "epoch: 22 step: 73, loss is 0.000977774616330862\n",
      "epoch: 22 step: 74, loss is 0.0005632250686176121\n",
      "epoch: 22 step: 75, loss is 0.0006241266964934766\n",
      "epoch: 22 step: 76, loss is 0.0009224009700119495\n",
      "epoch: 22 step: 77, loss is 0.0004821958427783102\n",
      "epoch: 22 step: 78, loss is 0.00048810182488523424\n",
      "epoch: 22 step: 79, loss is 0.00118719891179353\n",
      "epoch: 22 step: 80, loss is 0.00035923291579820216\n",
      "epoch: 22 step: 81, loss is 0.0003531788242980838\n",
      "epoch: 22 step: 82, loss is 0.000590523995924741\n",
      "epoch: 22 step: 83, loss is 0.0005829426227137446\n",
      "epoch: 22 step: 84, loss is 0.0010929519776254892\n",
      "epoch: 22 step: 85, loss is 0.0005589401116594672\n",
      "epoch: 22 step: 86, loss is 0.0008139602723531425\n",
      "epoch: 22 step: 87, loss is 0.000630143447779119\n",
      "epoch: 22 step: 88, loss is 0.0003295774513389915\n",
      "epoch: 22 step: 89, loss is 0.0005472023040056229\n",
      "epoch: 22 step: 90, loss is 0.0002509765326976776\n",
      "epoch: 22 step: 91, loss is 0.0008695158758200705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 92, loss is 0.000796679116319865\n",
      "epoch: 22 step: 93, loss is 0.000233128055697307\n",
      "epoch: 22 step: 94, loss is 0.0012343627167865634\n",
      "epoch: 22 step: 95, loss is 0.00043190125143155456\n",
      "epoch: 22 step: 96, loss is 0.00035190602648071945\n",
      "epoch: 22 step: 97, loss is 0.0001874866138678044\n",
      "epoch: 22 step: 98, loss is 0.0005903010023757815\n",
      "epoch: 22 step: 99, loss is 0.0005050217732787132\n",
      "epoch: 22 step: 100, loss is 0.0015198965556919575\n",
      "epoch: 22 step: 101, loss is 0.0003628564882092178\n",
      "epoch: 22 step: 102, loss is 0.0008623572066426277\n",
      "epoch: 22 step: 103, loss is 0.0011456891661509871\n",
      "epoch: 22 step: 104, loss is 0.0007088180864229798\n",
      "epoch: 22 step: 105, loss is 0.00032382269273512065\n",
      "epoch: 22 step: 106, loss is 0.001029039267450571\n",
      "epoch: 22 step: 107, loss is 0.0006616147584281862\n",
      "epoch: 22 step: 108, loss is 0.0005202846368774772\n",
      "epoch: 22 step: 109, loss is 0.0005778716295026243\n",
      "epoch: 22 step: 110, loss is 0.0006205676472745836\n",
      "epoch: 22 step: 111, loss is 0.00024703986127860844\n",
      "epoch: 22 step: 112, loss is 0.0013816211139783263\n",
      "epoch: 22 step: 113, loss is 0.0017664675833657384\n",
      "epoch: 22 step: 114, loss is 0.0003529231180436909\n",
      "epoch: 22 step: 115, loss is 0.0003782583517022431\n",
      "epoch: 22 step: 116, loss is 0.0010343256872147322\n",
      "epoch: 22 step: 117, loss is 0.0008306578965857625\n",
      "epoch: 22 step: 118, loss is 0.0005198410362936556\n",
      "epoch: 22 step: 119, loss is 0.0008904653368517756\n",
      "epoch: 22 step: 120, loss is 0.0011327777756378055\n",
      "epoch: 22 step: 121, loss is 0.0005739235202781856\n",
      "epoch: 22 step: 122, loss is 0.000448884122306481\n",
      "epoch: 22 step: 123, loss is 0.0006573447026312351\n",
      "epoch: 22 step: 124, loss is 0.0006357368547469378\n",
      "epoch: 22 step: 125, loss is 0.000473958469228819\n",
      "epoch: 22 step: 126, loss is 0.0003951989347115159\n",
      "epoch: 22 step: 127, loss is 0.0005092185456305742\n",
      "epoch: 22 step: 128, loss is 0.0017901950050145388\n",
      "epoch: 22 step: 129, loss is 0.00048327588592655957\n",
      "epoch: 22 step: 130, loss is 0.0012481054291129112\n",
      "epoch: 22 step: 131, loss is 0.0008414211333729327\n",
      "epoch: 22 step: 132, loss is 0.0011134521337226033\n",
      "epoch: 22 step: 133, loss is 0.0007863204227760434\n",
      "epoch: 22 step: 134, loss is 0.0004932241863571107\n",
      "epoch: 22 step: 135, loss is 0.0005965924938209355\n",
      "epoch: 22 step: 136, loss is 0.000454661319963634\n",
      "epoch: 22 step: 137, loss is 0.0006489275838248432\n",
      "epoch: 22 step: 138, loss is 0.0009596960735507309\n",
      "epoch: 22 step: 139, loss is 0.0005411396268755198\n",
      "epoch: 22 step: 140, loss is 0.0006451380322687328\n",
      "epoch: 22 step: 141, loss is 0.0007524006068706512\n",
      "epoch: 22 step: 142, loss is 0.0007725641480647027\n",
      "epoch: 22 step: 143, loss is 0.0007726387702859938\n",
      "epoch: 22 step: 144, loss is 0.00030086119659245014\n",
      "epoch: 22 step: 145, loss is 0.000961734214797616\n",
      "epoch: 22 step: 146, loss is 0.0001225307787535712\n",
      "epoch: 22 step: 147, loss is 0.0005191077943891287\n",
      "epoch: 22 step: 148, loss is 0.0005248759989626706\n",
      "epoch: 22 step: 149, loss is 0.0008748041582293808\n",
      "epoch: 22 step: 150, loss is 0.00025565922260284424\n",
      "epoch: 22 step: 151, loss is 0.0011490017641335726\n",
      "epoch: 22 step: 152, loss is 0.0011814411263912916\n",
      "epoch: 22 step: 153, loss is 0.00042020651744678617\n",
      "epoch: 22 step: 154, loss is 0.0006883566966280341\n",
      "epoch: 22 step: 155, loss is 0.0006008550990372896\n",
      "epoch: 22 step: 156, loss is 0.0005493938224390149\n",
      "epoch: 22 step: 157, loss is 0.0012607838725671172\n",
      "epoch: 22 step: 158, loss is 0.001654624822549522\n",
      "epoch: 22 step: 159, loss is 0.0001947309501701966\n",
      "epoch: 22 step: 160, loss is 0.0004637587408069521\n",
      "epoch: 22 step: 161, loss is 0.0009569924441166222\n",
      "epoch: 22 step: 162, loss is 0.0007974204490892589\n",
      "epoch: 22 step: 163, loss is 0.0006745811551809311\n",
      "epoch: 22 step: 164, loss is 0.0015967012150213122\n",
      "epoch: 22 step: 165, loss is 0.0006321631954051554\n",
      "epoch: 22 step: 166, loss is 0.0007833306444808841\n",
      "epoch: 22 step: 167, loss is 0.00018954550614580512\n",
      "epoch: 22 step: 168, loss is 0.000628283538389951\n",
      "epoch: 22 step: 169, loss is 0.00045943993609398603\n",
      "epoch: 22 step: 170, loss is 0.00027706072432920337\n",
      "epoch: 22 step: 171, loss is 0.0004167550359852612\n",
      "epoch: 22 step: 172, loss is 0.0006316699436865747\n",
      "epoch: 22 step: 173, loss is 0.0004238878027535975\n",
      "epoch: 22 step: 174, loss is 0.000624511914793402\n",
      "epoch: 22 step: 175, loss is 0.0006144197541289032\n",
      "epoch: 22 step: 176, loss is 0.0005999042186886072\n",
      "epoch: 22 step: 177, loss is 0.0004694509843830019\n",
      "epoch: 22 step: 178, loss is 0.001231957576237619\n",
      "epoch: 22 step: 179, loss is 0.0006570382392965257\n",
      "epoch: 22 step: 180, loss is 0.000514124461915344\n",
      "epoch: 22 step: 181, loss is 0.00025853837723843753\n",
      "epoch: 22 step: 182, loss is 0.00041748155490495265\n",
      "epoch: 22 step: 183, loss is 0.00025155916227959096\n",
      "epoch: 22 step: 184, loss is 0.0007584136328659952\n",
      "epoch: 22 step: 185, loss is 0.0005290847620926797\n",
      "epoch: 22 step: 186, loss is 0.00040378179983235896\n",
      "epoch: 22 step: 187, loss is 0.0009335511713288724\n",
      "epoch: 22 step: 188, loss is 0.0007341286400333047\n",
      "epoch: 22 step: 189, loss is 0.0015595885924994946\n",
      "epoch: 22 step: 190, loss is 0.00044479392818175256\n",
      "epoch: 22 step: 191, loss is 0.00038123500416986644\n",
      "epoch: 22 step: 192, loss is 0.0006231011939235032\n",
      "epoch: 22 step: 193, loss is 0.0006120346370153129\n",
      "epoch: 22 step: 194, loss is 0.0021163164637982845\n",
      "epoch: 22 step: 195, loss is 0.0003975388244725764\n",
      "epoch: 22 step: 196, loss is 0.00010788816871354356\n",
      "epoch: 22 step: 197, loss is 0.00038829754339531064\n",
      "epoch: 22 step: 198, loss is 0.00029910641023889184\n",
      "epoch: 22 step: 199, loss is 0.0010530980071052909\n",
      "epoch: 22 step: 200, loss is 0.0009756482322700322\n",
      "epoch: 22 step: 201, loss is 0.0006929992232471704\n",
      "epoch: 22 step: 202, loss is 0.00020512468472588807\n",
      "epoch: 22 step: 203, loss is 0.0001707213668851182\n",
      "epoch: 22 step: 204, loss is 0.00012565584620460868\n",
      "epoch: 22 step: 205, loss is 0.0003243998799007386\n",
      "epoch: 22 step: 206, loss is 0.0010892143473029137\n",
      "epoch: 22 step: 207, loss is 0.001407434931024909\n",
      "epoch: 22 step: 208, loss is 0.0003293858317192644\n",
      "epoch: 22 step: 209, loss is 0.0009410805068910122\n",
      "epoch: 22 step: 210, loss is 0.0003658432397060096\n",
      "epoch: 22 step: 211, loss is 0.000575290760025382\n",
      "epoch: 22 step: 212, loss is 0.00028343647136352956\n",
      "epoch: 22 step: 213, loss is 0.0012506049824878573\n",
      "epoch: 22 step: 214, loss is 0.0004356702556833625\n",
      "epoch: 22 step: 215, loss is 0.0003796960227191448\n",
      "epoch: 22 step: 216, loss is 0.0005307208630256355\n",
      "epoch: 22 step: 217, loss is 0.0007168322918005288\n",
      "epoch: 22 step: 218, loss is 0.0003987032687291503\n",
      "epoch: 22 step: 219, loss is 0.0007059881463646889\n",
      "epoch: 22 step: 220, loss is 0.001293814042583108\n",
      "epoch: 22 step: 221, loss is 0.0005168438656255603\n",
      "epoch: 22 step: 222, loss is 0.002136056777089834\n",
      "epoch: 22 step: 223, loss is 0.0003927902434952557\n",
      "epoch: 22 step: 224, loss is 0.0007596744108013809\n",
      "epoch: 22 step: 225, loss is 0.0007486988324671984\n",
      "epoch: 22 step: 226, loss is 0.0009480320732109249\n",
      "epoch: 22 step: 227, loss is 0.0009136158623732626\n",
      "epoch: 22 step: 228, loss is 0.0009169206605292857\n",
      "epoch: 22 step: 229, loss is 0.0006900064763613045\n",
      "epoch: 22 step: 230, loss is 0.0005509213078767061\n",
      "epoch: 22 step: 231, loss is 0.0014660627348348498\n",
      "epoch: 22 step: 232, loss is 0.0003675630141515285\n",
      "epoch: 22 step: 233, loss is 0.0007384775672107935\n",
      "epoch: 22 step: 234, loss is 0.0005859258235432208\n",
      "epoch: 22 step: 235, loss is 0.0011313915019854903\n",
      "epoch: 22 step: 236, loss is 0.00040087595698423684\n",
      "epoch: 22 step: 237, loss is 0.00022328169143293053\n",
      "epoch: 22 step: 238, loss is 0.0006983019993640482\n",
      "epoch: 22 step: 239, loss is 0.0004984117113053799\n",
      "epoch: 22 step: 240, loss is 0.00044742797035723925\n",
      "epoch: 22 step: 241, loss is 0.0003896244743373245\n",
      "epoch: 22 step: 242, loss is 0.0007062381482683122\n",
      "epoch: 22 step: 243, loss is 8.967806934379041e-05\n",
      "epoch: 22 step: 244, loss is 0.0009416536777280271\n",
      "epoch: 22 step: 245, loss is 0.0010248799808323383\n",
      "epoch: 22 step: 246, loss is 0.0010594947962090373\n",
      "epoch: 22 step: 247, loss is 0.00044397605233825743\n",
      "epoch: 22 step: 248, loss is 0.00032605876913294196\n",
      "epoch: 22 step: 249, loss is 0.0009172390564344823\n",
      "epoch: 22 step: 250, loss is 0.0004436756717041135\n",
      "epoch: 22 step: 251, loss is 0.0004834807477891445\n",
      "epoch: 22 step: 252, loss is 0.0005426790448836982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 253, loss is 0.00036684039514511824\n",
      "epoch: 22 step: 254, loss is 0.0016294086817651987\n",
      "epoch: 22 step: 255, loss is 0.001113704638555646\n",
      "epoch: 22 step: 256, loss is 0.0005846998537890613\n",
      "epoch: 22 step: 257, loss is 0.00026828577392734587\n",
      "epoch: 22 step: 258, loss is 0.001029033912345767\n",
      "epoch: 22 step: 259, loss is 0.0004520244838204235\n",
      "epoch: 22 step: 260, loss is 0.0009473069803789258\n",
      "epoch: 22 step: 261, loss is 0.0005213920376263559\n",
      "epoch: 22 step: 262, loss is 0.0017668359214439988\n",
      "epoch: 22 step: 263, loss is 0.0009197940235026181\n",
      "epoch: 22 step: 264, loss is 0.0005421724054031074\n",
      "epoch: 22 step: 265, loss is 0.0006288666627369821\n",
      "epoch: 22 step: 266, loss is 0.00045884522842243314\n",
      "epoch: 22 step: 267, loss is 0.0008325647213496268\n",
      "epoch: 22 step: 268, loss is 0.000960352539550513\n",
      "epoch: 22 step: 269, loss is 0.00047965155681595206\n",
      "epoch: 22 step: 270, loss is 0.0005684838397428393\n",
      "epoch: 22 step: 271, loss is 0.0006798384129069746\n",
      "epoch: 22 step: 272, loss is 0.0005972763756290078\n",
      "epoch: 22 step: 273, loss is 0.0003584357909858227\n",
      "epoch: 22 step: 274, loss is 0.0007382760522887111\n",
      "epoch: 22 step: 275, loss is 0.0003303603152744472\n",
      "epoch: 22 step: 276, loss is 0.000508112832903862\n",
      "epoch: 22 step: 277, loss is 0.0009729258017614484\n",
      "epoch: 22 step: 278, loss is 0.00037022322067059577\n",
      "epoch: 22 step: 279, loss is 0.000435628549894318\n",
      "epoch: 22 step: 280, loss is 0.0010693370131775737\n",
      "epoch: 22 step: 281, loss is 0.000567437382414937\n",
      "epoch: 22 step: 282, loss is 0.0009617794421501458\n",
      "epoch: 22 step: 283, loss is 0.0007926308899186552\n",
      "epoch: 22 step: 284, loss is 0.00036120027652941644\n",
      "epoch: 22 step: 285, loss is 0.0006360979750752449\n",
      "epoch: 22 step: 286, loss is 0.0006564634386450052\n",
      "epoch: 22 step: 287, loss is 0.0008759836200624704\n",
      "epoch: 22 step: 288, loss is 0.0006284598493948579\n",
      "epoch: 22 step: 289, loss is 0.0005481966654770076\n",
      "epoch: 22 step: 290, loss is 0.0002786552649922669\n",
      "epoch: 22 step: 291, loss is 0.0005471276817843318\n",
      "epoch: 22 step: 292, loss is 0.0008682062616571784\n",
      "epoch: 22 step: 293, loss is 0.0011137002147734165\n",
      "epoch: 22 step: 294, loss is 0.00033748819259926677\n",
      "epoch: 22 step: 295, loss is 0.0007274494273588061\n",
      "epoch: 22 step: 296, loss is 0.0006977937300689518\n",
      "epoch: 22 step: 297, loss is 0.0006425795145332813\n",
      "epoch: 22 step: 298, loss is 0.0008343079243786633\n",
      "epoch: 22 step: 299, loss is 0.001567934756167233\n",
      "epoch: 22 step: 300, loss is 0.00047473894665017724\n",
      "epoch: 22 step: 301, loss is 0.0005347971455194056\n",
      "epoch: 22 step: 302, loss is 0.001341971685178578\n",
      "epoch: 22 step: 303, loss is 0.0011242880718782544\n",
      "epoch: 22 step: 304, loss is 0.0006959362654015422\n",
      "epoch: 22 step: 305, loss is 0.0008539417758584023\n",
      "epoch: 22 step: 306, loss is 0.000673338770866394\n",
      "epoch: 22 step: 307, loss is 0.00039971305523067713\n",
      "epoch: 22 step: 308, loss is 0.000783513649366796\n",
      "epoch: 22 step: 309, loss is 0.0006799189723096788\n",
      "epoch: 22 step: 310, loss is 0.000987551873549819\n",
      "epoch: 22 step: 311, loss is 0.0004055438912473619\n",
      "epoch: 22 step: 312, loss is 0.0011938129318878055\n",
      "epoch: 22 step: 313, loss is 0.0005380430375225842\n",
      "epoch: 22 step: 314, loss is 0.0006869579083286226\n",
      "epoch: 22 step: 315, loss is 0.000284370849840343\n",
      "epoch: 22 step: 316, loss is 0.0007173565682023764\n",
      "epoch: 22 step: 317, loss is 0.0014217121060937643\n",
      "epoch: 22 step: 318, loss is 0.0011631782399490476\n",
      "epoch: 22 step: 319, loss is 0.0009786792797967792\n",
      "epoch: 22 step: 320, loss is 0.0006097315927036107\n",
      "epoch: 22 step: 321, loss is 0.0003786101588048041\n",
      "epoch: 22 step: 322, loss is 0.0005034480127505958\n",
      "epoch: 22 step: 323, loss is 0.0010819440940394998\n",
      "epoch: 22 step: 324, loss is 0.0008169928332790732\n",
      "epoch: 22 step: 325, loss is 0.00015141096082516015\n",
      "epoch: 22 step: 326, loss is 0.0005681556067429483\n",
      "epoch: 22 step: 327, loss is 0.000458122871350497\n",
      "epoch: 22 step: 328, loss is 0.0007304437458515167\n",
      "epoch: 22 step: 329, loss is 0.0007361644529737532\n",
      "epoch: 22 step: 330, loss is 0.00036536529660224915\n",
      "epoch: 22 step: 331, loss is 0.0009466071496717632\n",
      "epoch: 22 step: 332, loss is 0.0003268189320806414\n",
      "epoch: 22 step: 333, loss is 0.0012507890351116657\n",
      "epoch: 22 step: 334, loss is 0.0016454256838187575\n",
      "epoch: 22 step: 335, loss is 0.00036077346885576844\n",
      "epoch: 22 step: 336, loss is 0.0005819222424179316\n",
      "epoch: 22 step: 337, loss is 7.149043813114986e-05\n",
      "epoch: 22 step: 338, loss is 0.0008405189146287739\n",
      "epoch: 22 step: 339, loss is 0.0001965380070032552\n",
      "epoch: 22 step: 340, loss is 0.00012526038335636258\n",
      "epoch: 22 step: 341, loss is 0.0002734878798946738\n",
      "epoch: 22 step: 342, loss is 0.0008749549160711467\n",
      "epoch: 22 step: 343, loss is 0.0009331448236480355\n",
      "epoch: 22 step: 344, loss is 0.0014987112954258919\n",
      "epoch: 22 step: 345, loss is 0.0007062072982080281\n",
      "epoch: 22 step: 346, loss is 0.0007648176979273558\n",
      "epoch: 22 step: 347, loss is 0.001601668307557702\n",
      "epoch: 22 step: 348, loss is 0.0002811117155943066\n",
      "epoch: 22 step: 349, loss is 0.00033561597228981555\n",
      "epoch: 22 step: 350, loss is 0.00024807589943520725\n",
      "epoch: 22 step: 351, loss is 0.0005553093506023288\n",
      "epoch: 22 step: 352, loss is 0.0004602686094585806\n",
      "epoch: 22 step: 353, loss is 0.0003784534928854555\n",
      "epoch: 22 step: 354, loss is 0.0005144992028363049\n",
      "epoch: 22 step: 355, loss is 0.0006433978560380638\n",
      "epoch: 22 step: 356, loss is 0.0006068995571695268\n",
      "epoch: 22 step: 357, loss is 0.0007216691737994552\n",
      "epoch: 22 step: 358, loss is 0.0007735228282399476\n",
      "epoch: 22 step: 359, loss is 0.000469662481918931\n",
      "epoch: 22 step: 360, loss is 0.0007925537065602839\n",
      "epoch: 22 step: 361, loss is 0.00045279585174284875\n",
      "epoch: 22 step: 362, loss is 0.0004015943268314004\n",
      "epoch: 22 step: 363, loss is 0.001681875204667449\n",
      "epoch: 22 step: 364, loss is 0.0003099367022514343\n",
      "epoch: 22 step: 365, loss is 0.00016493661678396165\n",
      "epoch: 22 step: 366, loss is 0.0003378067340236157\n",
      "epoch: 22 step: 367, loss is 0.0011377583723515272\n",
      "epoch: 22 step: 368, loss is 0.00010389566887170076\n",
      "epoch: 22 step: 369, loss is 0.00022025952057447284\n",
      "epoch: 22 step: 370, loss is 0.00016967662668321282\n",
      "epoch: 22 step: 371, loss is 0.0007293052622117102\n",
      "epoch: 22 step: 372, loss is 0.0006694399053230882\n",
      "epoch: 22 step: 373, loss is 0.0010770928347483277\n",
      "epoch: 22 step: 374, loss is 0.0006435767863877118\n",
      "epoch: 22 step: 375, loss is 0.00014169565110933036\n",
      "Train epoch time: 11913.234 ms, per step time: 31.769 ms\n",
      "epoch: 23 step: 1, loss is 0.00037302670534700155\n",
      "epoch: 23 step: 2, loss is 0.0013256772654131055\n",
      "epoch: 23 step: 3, loss is 0.0010944409295916557\n",
      "epoch: 23 step: 4, loss is 0.0006935791461728513\n",
      "epoch: 23 step: 5, loss is 0.00046154201845638454\n",
      "epoch: 23 step: 6, loss is 0.00038476227200590074\n",
      "epoch: 23 step: 7, loss is 0.00040711238398216665\n",
      "epoch: 23 step: 8, loss is 0.0007461485220119357\n",
      "epoch: 23 step: 9, loss is 0.0004159307572990656\n",
      "epoch: 23 step: 10, loss is 0.0005882809055037796\n",
      "epoch: 23 step: 11, loss is 0.0005301841301843524\n",
      "epoch: 23 step: 12, loss is 0.0005351758445613086\n",
      "epoch: 23 step: 13, loss is 0.0007381355972029269\n",
      "epoch: 23 step: 14, loss is 0.0007029593689367175\n",
      "epoch: 23 step: 15, loss is 0.0011564046144485474\n",
      "epoch: 23 step: 16, loss is 0.0004386487998999655\n",
      "epoch: 23 step: 17, loss is 0.0007629065657965839\n",
      "epoch: 23 step: 18, loss is 0.001038327463902533\n",
      "epoch: 23 step: 19, loss is 0.0009655930334702134\n",
      "epoch: 23 step: 20, loss is 0.00040287701995112\n",
      "epoch: 23 step: 21, loss is 0.0009844565065577626\n",
      "epoch: 23 step: 22, loss is 0.0010920879431068897\n",
      "epoch: 23 step: 23, loss is 0.0006801881827414036\n",
      "epoch: 23 step: 24, loss is 0.0010220007970929146\n",
      "epoch: 23 step: 25, loss is 0.0010698674013838172\n",
      "epoch: 23 step: 26, loss is 0.0005649341619573534\n",
      "epoch: 23 step: 27, loss is 0.0008766576065681875\n",
      "epoch: 23 step: 28, loss is 0.0009353362256661057\n",
      "epoch: 23 step: 29, loss is 0.00016971922013908625\n",
      "epoch: 23 step: 30, loss is 0.0002125572646036744\n",
      "epoch: 23 step: 31, loss is 0.0013047741958871484\n",
      "epoch: 23 step: 32, loss is 0.0002827435964718461\n",
      "epoch: 23 step: 33, loss is 0.000387191423214972\n",
      "epoch: 23 step: 34, loss is 0.0007137107313610613\n",
      "epoch: 23 step: 35, loss is 0.0007470562122762203\n",
      "epoch: 23 step: 36, loss is 0.0006602521170862019\n",
      "epoch: 23 step: 37, loss is 0.0002528214536141604\n",
      "epoch: 23 step: 38, loss is 0.00030272910953499377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 39, loss is 0.0007683583535254002\n",
      "epoch: 23 step: 40, loss is 0.0014037719229236245\n",
      "epoch: 23 step: 41, loss is 0.0010156834032386541\n",
      "epoch: 23 step: 42, loss is 0.0008893837803043425\n",
      "epoch: 23 step: 43, loss is 0.0008957135141827166\n",
      "epoch: 23 step: 44, loss is 0.00016848029918037355\n",
      "epoch: 23 step: 45, loss is 0.0005688134697265923\n",
      "epoch: 23 step: 46, loss is 0.0010547579731792212\n",
      "epoch: 23 step: 47, loss is 0.0010989895090460777\n",
      "epoch: 23 step: 48, loss is 0.0007725249161012471\n",
      "epoch: 23 step: 49, loss is 0.0008032848127186298\n",
      "epoch: 23 step: 50, loss is 0.0007003334467299283\n",
      "epoch: 23 step: 51, loss is 0.0005339458002708852\n",
      "epoch: 23 step: 52, loss is 0.0011066546430811286\n",
      "epoch: 23 step: 53, loss is 0.0008577474509365857\n",
      "epoch: 23 step: 54, loss is 0.001018965500406921\n",
      "epoch: 23 step: 55, loss is 0.0010016656015068293\n",
      "epoch: 23 step: 56, loss is 0.000602627347689122\n",
      "epoch: 23 step: 57, loss is 0.0010582880349829793\n",
      "epoch: 23 step: 58, loss is 0.0008002868853509426\n",
      "epoch: 23 step: 59, loss is 0.000704300997313112\n",
      "epoch: 23 step: 60, loss is 0.0007281586877070367\n",
      "epoch: 23 step: 61, loss is 0.0005284713697619736\n",
      "epoch: 23 step: 62, loss is 0.0005390336737036705\n",
      "epoch: 23 step: 63, loss is 0.0005968304467387497\n",
      "epoch: 23 step: 64, loss is 0.00037307594902813435\n",
      "epoch: 23 step: 65, loss is 0.00020567471801768988\n",
      "epoch: 23 step: 66, loss is 0.0002881494292523712\n",
      "epoch: 23 step: 67, loss is 0.000380099518224597\n",
      "epoch: 23 step: 68, loss is 0.0006977635785005987\n",
      "epoch: 23 step: 69, loss is 0.00090486352564767\n",
      "epoch: 23 step: 70, loss is 0.0008071900228969753\n",
      "epoch: 23 step: 71, loss is 0.00015416069072671235\n",
      "epoch: 23 step: 72, loss is 0.0006494040135294199\n",
      "epoch: 23 step: 73, loss is 0.0014717252925038338\n",
      "epoch: 23 step: 74, loss is 0.00042493888759054244\n",
      "epoch: 23 step: 75, loss is 0.0003290608583483845\n",
      "epoch: 23 step: 76, loss is 0.0006227809935808182\n",
      "epoch: 23 step: 77, loss is 0.00014338645269162953\n",
      "epoch: 23 step: 78, loss is 0.00023512615007348359\n",
      "epoch: 23 step: 79, loss is 0.0004838170425500721\n",
      "epoch: 23 step: 80, loss is 0.0007846986991353333\n",
      "epoch: 23 step: 81, loss is 0.0011064100544899702\n",
      "epoch: 23 step: 82, loss is 0.0004764238547068089\n",
      "epoch: 23 step: 83, loss is 0.001444794237613678\n",
      "epoch: 23 step: 84, loss is 0.0013878822792321444\n",
      "epoch: 23 step: 85, loss is 0.0011021679965779185\n",
      "epoch: 23 step: 86, loss is 0.0008492991328239441\n",
      "epoch: 23 step: 87, loss is 0.0010851132683455944\n",
      "epoch: 23 step: 88, loss is 0.0002114999369950965\n",
      "epoch: 23 step: 89, loss is 0.0004077321500517428\n",
      "epoch: 23 step: 90, loss is 0.00043325035949237645\n",
      "epoch: 23 step: 91, loss is 0.0007283954182639718\n",
      "epoch: 23 step: 92, loss is 0.00019943593360949308\n",
      "epoch: 23 step: 93, loss is 0.0010617983061820269\n",
      "epoch: 23 step: 94, loss is 0.0012388788163661957\n",
      "epoch: 23 step: 95, loss is 0.0010734045645222068\n",
      "epoch: 23 step: 96, loss is 0.001743067055940628\n",
      "epoch: 23 step: 97, loss is 0.001405365881510079\n",
      "epoch: 23 step: 98, loss is 0.00019802158931270242\n",
      "epoch: 23 step: 99, loss is 0.0003685441624838859\n",
      "epoch: 23 step: 100, loss is 0.0012122825719416142\n",
      "epoch: 23 step: 101, loss is 0.0007279965211637318\n",
      "epoch: 23 step: 102, loss is 0.0013235594378784299\n",
      "epoch: 23 step: 103, loss is 0.0005728196119889617\n",
      "epoch: 23 step: 104, loss is 0.0004762931203003973\n",
      "epoch: 23 step: 105, loss is 0.0004813616396859288\n",
      "epoch: 23 step: 106, loss is 0.0005656310822814703\n",
      "epoch: 23 step: 107, loss is 0.0007708508055657148\n",
      "epoch: 23 step: 108, loss is 0.0005202177562750876\n",
      "epoch: 23 step: 109, loss is 0.0004292102821636945\n",
      "epoch: 23 step: 110, loss is 0.0007152395555749536\n",
      "epoch: 23 step: 111, loss is 0.0007823994383215904\n",
      "epoch: 23 step: 112, loss is 0.0007700543501414359\n",
      "epoch: 23 step: 113, loss is 0.0028318827971816063\n",
      "epoch: 23 step: 114, loss is 0.0009357630624435842\n",
      "epoch: 23 step: 115, loss is 0.0011850461596623063\n",
      "epoch: 23 step: 116, loss is 0.00059587910072878\n",
      "epoch: 23 step: 117, loss is 0.0006028907373547554\n",
      "epoch: 23 step: 118, loss is 0.0004864753282163292\n",
      "epoch: 23 step: 119, loss is 0.0006821706774644554\n",
      "epoch: 23 step: 120, loss is 0.000429225736297667\n",
      "epoch: 23 step: 121, loss is 0.00033603262272663414\n",
      "epoch: 23 step: 122, loss is 0.0012689396971836686\n",
      "epoch: 23 step: 123, loss is 0.000673174683470279\n",
      "epoch: 23 step: 124, loss is 0.0009957357542589307\n",
      "epoch: 23 step: 125, loss is 0.0009561702609062195\n",
      "epoch: 23 step: 126, loss is 0.0006284406408667564\n",
      "epoch: 23 step: 127, loss is 0.0004934807075187564\n",
      "epoch: 23 step: 128, loss is 0.0008587443735450506\n",
      "epoch: 23 step: 129, loss is 0.0005069716135039926\n",
      "epoch: 23 step: 130, loss is 0.0007997711654752493\n",
      "epoch: 23 step: 131, loss is 0.0005257101729512215\n",
      "epoch: 23 step: 132, loss is 0.0006925790221430361\n",
      "epoch: 23 step: 133, loss is 0.00048552488442510366\n",
      "epoch: 23 step: 134, loss is 0.0005323464865796268\n",
      "epoch: 23 step: 135, loss is 0.0009310635505244136\n",
      "epoch: 23 step: 136, loss is 0.00041830490226857364\n",
      "epoch: 23 step: 137, loss is 0.0016817993018776178\n",
      "epoch: 23 step: 138, loss is 0.0012520840391516685\n",
      "epoch: 23 step: 139, loss is 0.001631018822081387\n",
      "epoch: 23 step: 140, loss is 0.0004924764507450163\n",
      "epoch: 23 step: 141, loss is 0.0011850547743961215\n",
      "epoch: 23 step: 142, loss is 0.00019275651720818132\n",
      "epoch: 23 step: 143, loss is 0.0005050113541074097\n",
      "epoch: 23 step: 144, loss is 0.0005291624693199992\n",
      "epoch: 23 step: 145, loss is 0.00036192964762449265\n",
      "epoch: 23 step: 146, loss is 0.0005577707779593766\n",
      "epoch: 23 step: 147, loss is 0.00139910401776433\n",
      "epoch: 23 step: 148, loss is 0.0005799216451123357\n",
      "epoch: 23 step: 149, loss is 0.0005472624907270074\n",
      "epoch: 23 step: 150, loss is 0.0010078649502247572\n",
      "epoch: 23 step: 151, loss is 0.001093520550057292\n",
      "epoch: 23 step: 152, loss is 0.00043181751971133053\n",
      "epoch: 23 step: 153, loss is 0.0007412483100779355\n",
      "epoch: 23 step: 154, loss is 0.000340334081556648\n",
      "epoch: 23 step: 155, loss is 0.0007880385965108871\n",
      "epoch: 23 step: 156, loss is 0.00020128664618823677\n",
      "epoch: 23 step: 157, loss is 0.0008697935845702887\n",
      "epoch: 23 step: 158, loss is 0.0005366953555494547\n",
      "epoch: 23 step: 159, loss is 0.0005067305755801499\n",
      "epoch: 23 step: 160, loss is 0.0007574857445433736\n",
      "epoch: 23 step: 161, loss is 0.0004941722145304084\n",
      "epoch: 23 step: 162, loss is 0.00030456422246061265\n",
      "epoch: 23 step: 163, loss is 0.0006095776334404945\n",
      "epoch: 23 step: 164, loss is 0.0005929092294536531\n",
      "epoch: 23 step: 165, loss is 0.0007101870141923428\n",
      "epoch: 23 step: 166, loss is 0.0005908359889872372\n",
      "epoch: 23 step: 167, loss is 0.0006458618445321918\n",
      "epoch: 23 step: 168, loss is 0.0008045524009503424\n",
      "epoch: 23 step: 169, loss is 0.00034597355988807976\n",
      "epoch: 23 step: 170, loss is 0.0003975203726440668\n",
      "epoch: 23 step: 171, loss is 0.0014641935704275966\n",
      "epoch: 23 step: 172, loss is 0.0009248389396816492\n",
      "epoch: 23 step: 173, loss is 0.0002837055071722716\n",
      "epoch: 23 step: 174, loss is 0.000605281675234437\n",
      "epoch: 23 step: 175, loss is 0.0006538996240124106\n",
      "epoch: 23 step: 176, loss is 0.0005691340775229037\n",
      "epoch: 23 step: 177, loss is 0.0003982564085163176\n",
      "epoch: 23 step: 178, loss is 0.00040490436367690563\n",
      "epoch: 23 step: 179, loss is 0.0002679713361430913\n",
      "epoch: 23 step: 180, loss is 0.0012634126469492912\n",
      "epoch: 23 step: 181, loss is 0.00034859072184190154\n",
      "epoch: 23 step: 182, loss is 0.0004802825569640845\n",
      "epoch: 23 step: 183, loss is 0.0002866204013116658\n",
      "epoch: 23 step: 184, loss is 0.0014155193930491805\n",
      "epoch: 23 step: 185, loss is 0.0003391215577721596\n",
      "epoch: 23 step: 186, loss is 0.0010586068965494633\n",
      "epoch: 23 step: 187, loss is 0.00048245664220303297\n",
      "epoch: 23 step: 188, loss is 0.0001329746301053092\n",
      "epoch: 23 step: 189, loss is 0.00043191941222175956\n",
      "epoch: 23 step: 190, loss is 0.0005188575596548617\n",
      "epoch: 23 step: 191, loss is 0.00018153898417949677\n",
      "epoch: 23 step: 192, loss is 0.0006039072177372873\n",
      "epoch: 23 step: 193, loss is 0.0010024334769695997\n",
      "epoch: 23 step: 194, loss is 0.0012752662878483534\n",
      "epoch: 23 step: 195, loss is 0.0012419400736689568\n",
      "epoch: 23 step: 196, loss is 0.0005877686198800802\n",
      "epoch: 23 step: 197, loss is 8.681992039782926e-05\n",
      "epoch: 23 step: 198, loss is 0.0010547421406954527\n",
      "epoch: 23 step: 199, loss is 0.0007158155203796923\n",
      "epoch: 23 step: 200, loss is 0.000778628746047616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 201, loss is 0.0005557616823352873\n",
      "epoch: 23 step: 202, loss is 0.00045630295062437654\n",
      "epoch: 23 step: 203, loss is 0.0006844027666375041\n",
      "epoch: 23 step: 204, loss is 0.000665601110085845\n",
      "epoch: 23 step: 205, loss is 0.00043099478352814913\n",
      "epoch: 23 step: 206, loss is 0.0004710196517407894\n",
      "epoch: 23 step: 207, loss is 0.0012703012907877564\n",
      "epoch: 23 step: 208, loss is 0.0006240533548407257\n",
      "epoch: 23 step: 209, loss is 0.000647136359475553\n",
      "epoch: 23 step: 210, loss is 0.0006373095093294978\n",
      "epoch: 23 step: 211, loss is 0.0008031087345443666\n",
      "epoch: 23 step: 212, loss is 0.0004509814898483455\n",
      "epoch: 23 step: 213, loss is 0.0009659575880505145\n",
      "epoch: 23 step: 214, loss is 0.001548857195302844\n",
      "epoch: 23 step: 215, loss is 0.0011346996761858463\n",
      "epoch: 23 step: 216, loss is 0.00035513669718056917\n",
      "epoch: 23 step: 217, loss is 0.0011523282155394554\n",
      "epoch: 23 step: 218, loss is 0.0012617801548913121\n",
      "epoch: 23 step: 219, loss is 0.0002517842222005129\n",
      "epoch: 23 step: 220, loss is 0.001400965265929699\n",
      "epoch: 23 step: 221, loss is 0.0003198524937033653\n",
      "epoch: 23 step: 222, loss is 0.0008231200627051294\n",
      "epoch: 23 step: 223, loss is 0.0004895148449577391\n",
      "epoch: 23 step: 224, loss is 0.0006259783986024559\n",
      "epoch: 23 step: 225, loss is 0.0012807692401111126\n",
      "epoch: 23 step: 226, loss is 0.0003966580261476338\n",
      "epoch: 23 step: 227, loss is 0.00017238000873476267\n",
      "epoch: 23 step: 228, loss is 0.00046873235260136425\n",
      "epoch: 23 step: 229, loss is 0.0006125699728727341\n",
      "epoch: 23 step: 230, loss is 0.000938848708756268\n",
      "epoch: 23 step: 231, loss is 0.0002696022856980562\n",
      "epoch: 23 step: 232, loss is 0.0007363010663539171\n",
      "epoch: 23 step: 233, loss is 0.00045477101230062544\n",
      "epoch: 23 step: 234, loss is 0.0006951304385438561\n",
      "epoch: 23 step: 235, loss is 0.0004385450738482177\n",
      "epoch: 23 step: 236, loss is 0.0010774836409837008\n",
      "epoch: 23 step: 237, loss is 0.00044255272950977087\n",
      "epoch: 23 step: 238, loss is 0.00026293410337530077\n",
      "epoch: 23 step: 239, loss is 0.0002738710609264672\n",
      "epoch: 23 step: 240, loss is 0.0003058672300539911\n",
      "epoch: 23 step: 241, loss is 0.0009176298044621944\n",
      "epoch: 23 step: 242, loss is 0.001132452511228621\n",
      "epoch: 23 step: 243, loss is 0.0003210399590898305\n",
      "epoch: 23 step: 244, loss is 0.0009855609387159348\n",
      "epoch: 23 step: 245, loss is 0.0007961429073475301\n",
      "epoch: 23 step: 246, loss is 0.0003678921202663332\n",
      "epoch: 23 step: 247, loss is 0.00040026992792263627\n",
      "epoch: 23 step: 248, loss is 0.0004864366783294827\n",
      "epoch: 23 step: 249, loss is 0.0011724962387233973\n",
      "epoch: 23 step: 250, loss is 0.00026141051785089076\n",
      "epoch: 23 step: 251, loss is 0.0007338767754845321\n",
      "epoch: 23 step: 252, loss is 0.0005152930389158428\n",
      "epoch: 23 step: 253, loss is 0.0003073146508540958\n",
      "epoch: 23 step: 254, loss is 0.0013865630608052015\n",
      "epoch: 23 step: 255, loss is 0.0012089380761608481\n",
      "epoch: 23 step: 256, loss is 0.00020853530440945178\n",
      "epoch: 23 step: 257, loss is 0.0009891688823699951\n",
      "epoch: 23 step: 258, loss is 0.001432207995094359\n",
      "epoch: 23 step: 259, loss is 0.00048043704009614885\n",
      "epoch: 23 step: 260, loss is 0.000737181690055877\n",
      "epoch: 23 step: 261, loss is 0.0012504501501098275\n",
      "epoch: 23 step: 262, loss is 0.00079637166345492\n",
      "epoch: 23 step: 263, loss is 0.0012418277328833938\n",
      "epoch: 23 step: 264, loss is 0.000639492180198431\n",
      "epoch: 23 step: 265, loss is 0.0006344272405840456\n",
      "epoch: 23 step: 266, loss is 0.0009700471418909729\n",
      "epoch: 23 step: 267, loss is 0.0006009682547301054\n",
      "epoch: 23 step: 268, loss is 0.0007137994398362935\n",
      "epoch: 23 step: 269, loss is 0.0012559584574773908\n",
      "epoch: 23 step: 270, loss is 0.00154607102740556\n",
      "epoch: 23 step: 271, loss is 0.00025193855981342494\n",
      "epoch: 23 step: 272, loss is 0.00026928517036139965\n",
      "epoch: 23 step: 273, loss is 0.0013876023003831506\n",
      "epoch: 23 step: 274, loss is 0.0006144044455140829\n",
      "epoch: 23 step: 275, loss is 0.0007645495934411883\n",
      "epoch: 23 step: 276, loss is 0.0006279373192228377\n",
      "epoch: 23 step: 277, loss is 0.0005816702032461762\n",
      "epoch: 23 step: 278, loss is 0.001318046823143959\n",
      "epoch: 23 step: 279, loss is 0.0005860846722498536\n",
      "epoch: 23 step: 280, loss is 0.00040073200943879783\n",
      "epoch: 23 step: 281, loss is 0.00037219611112959683\n",
      "epoch: 23 step: 282, loss is 0.0001534261100459844\n",
      "epoch: 23 step: 283, loss is 0.000582604028750211\n",
      "epoch: 23 step: 284, loss is 0.0006043433677405119\n",
      "epoch: 23 step: 285, loss is 0.0010440926998853683\n",
      "epoch: 23 step: 286, loss is 0.0010056756436824799\n",
      "epoch: 23 step: 287, loss is 0.0005636803689412773\n",
      "epoch: 23 step: 288, loss is 0.0009261025115847588\n",
      "epoch: 23 step: 289, loss is 0.001023047138005495\n",
      "epoch: 23 step: 290, loss is 0.0006106619839556515\n",
      "epoch: 23 step: 291, loss is 0.00015352921036537737\n",
      "epoch: 23 step: 292, loss is 0.0008710008696652949\n",
      "epoch: 23 step: 293, loss is 0.0004111435264348984\n",
      "epoch: 23 step: 294, loss is 0.0006387277971953154\n",
      "epoch: 23 step: 295, loss is 0.0006571036647073925\n",
      "epoch: 23 step: 296, loss is 0.00030187901575118303\n",
      "epoch: 23 step: 297, loss is 0.0009352181223221123\n",
      "epoch: 23 step: 298, loss is 0.00030353100737556815\n",
      "epoch: 23 step: 299, loss is 0.0011774235172197223\n",
      "epoch: 23 step: 300, loss is 0.0010399786988273263\n",
      "epoch: 23 step: 301, loss is 0.0006996173760853708\n",
      "epoch: 23 step: 302, loss is 0.0006220134673640132\n",
      "epoch: 23 step: 303, loss is 0.0006711209425702691\n",
      "epoch: 23 step: 304, loss is 0.00041900077485479414\n",
      "epoch: 23 step: 305, loss is 0.0011071986518800259\n",
      "epoch: 23 step: 306, loss is 0.0005056177615188062\n",
      "epoch: 23 step: 307, loss is 0.0004143729747738689\n",
      "epoch: 23 step: 308, loss is 0.0003816730168182403\n",
      "epoch: 23 step: 309, loss is 0.0005575948162004352\n",
      "epoch: 23 step: 310, loss is 0.0003424055757932365\n",
      "epoch: 23 step: 311, loss is 0.0008276018779724836\n",
      "epoch: 23 step: 312, loss is 0.000450987572548911\n",
      "epoch: 23 step: 313, loss is 0.0003924158518202603\n",
      "epoch: 23 step: 314, loss is 0.00046003921306692064\n",
      "epoch: 23 step: 315, loss is 0.0008372318116016686\n",
      "epoch: 23 step: 316, loss is 0.0002733439614530653\n",
      "epoch: 23 step: 317, loss is 0.0004024821100756526\n",
      "epoch: 23 step: 318, loss is 0.0004609579045791179\n",
      "epoch: 23 step: 319, loss is 0.0004750376974698156\n",
      "epoch: 23 step: 320, loss is 0.000552452402189374\n",
      "epoch: 23 step: 321, loss is 0.00044429959962144494\n",
      "epoch: 23 step: 322, loss is 0.0012862125877290964\n",
      "epoch: 23 step: 323, loss is 0.0003922257455997169\n",
      "epoch: 23 step: 324, loss is 0.00036167906364426017\n",
      "epoch: 23 step: 325, loss is 0.00039921997813507915\n",
      "epoch: 23 step: 326, loss is 0.00034482456976547837\n",
      "epoch: 23 step: 327, loss is 0.0007026959792710841\n",
      "epoch: 23 step: 328, loss is 0.0006907829083502293\n",
      "epoch: 23 step: 329, loss is 0.00033739188802428544\n",
      "epoch: 23 step: 330, loss is 0.00043188108247704804\n",
      "epoch: 23 step: 331, loss is 0.0005655476707033813\n",
      "epoch: 23 step: 332, loss is 0.0007283216109499335\n",
      "epoch: 23 step: 333, loss is 0.0003034002147614956\n",
      "epoch: 23 step: 334, loss is 0.0008569872588850558\n",
      "epoch: 23 step: 335, loss is 0.0004523770767264068\n",
      "epoch: 23 step: 336, loss is 0.0010413395939394832\n",
      "epoch: 23 step: 337, loss is 0.0009844002779573202\n",
      "epoch: 23 step: 338, loss is 0.0003564429935067892\n",
      "epoch: 23 step: 339, loss is 0.0007732473313808441\n",
      "epoch: 23 step: 340, loss is 0.00019025144865736365\n",
      "epoch: 23 step: 341, loss is 0.0016087447293102741\n",
      "epoch: 23 step: 342, loss is 0.0006611804128624499\n",
      "epoch: 23 step: 343, loss is 0.00039340739022009075\n",
      "epoch: 23 step: 344, loss is 0.000538731983397156\n",
      "epoch: 23 step: 345, loss is 0.001122907386161387\n",
      "epoch: 23 step: 346, loss is 0.0001594230270711705\n",
      "epoch: 23 step: 347, loss is 0.0012537470320239663\n",
      "epoch: 23 step: 348, loss is 0.0002776812470983714\n",
      "epoch: 23 step: 349, loss is 0.0009761642431840301\n",
      "epoch: 23 step: 350, loss is 0.0006660032086074352\n",
      "epoch: 23 step: 351, loss is 0.0005085747689008713\n",
      "epoch: 23 step: 352, loss is 0.000524535309523344\n",
      "epoch: 23 step: 353, loss is 0.0002917440142482519\n",
      "epoch: 23 step: 354, loss is 0.0007379994494840503\n",
      "epoch: 23 step: 355, loss is 0.00042727382970042527\n",
      "epoch: 23 step: 356, loss is 0.0007874867878854275\n",
      "epoch: 23 step: 357, loss is 0.001588197541423142\n",
      "epoch: 23 step: 358, loss is 0.0005731904529966414\n",
      "epoch: 23 step: 359, loss is 0.000714827619958669\n",
      "epoch: 23 step: 360, loss is 0.00032367947278544307\n",
      "epoch: 23 step: 361, loss is 0.00012816264643333852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 362, loss is 0.000697372539434582\n",
      "epoch: 23 step: 363, loss is 0.0005132570513524115\n",
      "epoch: 23 step: 364, loss is 0.0008769122650846839\n",
      "epoch: 23 step: 365, loss is 9.711005259305239e-05\n",
      "epoch: 23 step: 366, loss is 0.00038516728091053665\n",
      "epoch: 23 step: 367, loss is 0.0006156911258585751\n",
      "epoch: 23 step: 368, loss is 0.0013905996456742287\n",
      "epoch: 23 step: 369, loss is 0.0006022177985869348\n",
      "epoch: 23 step: 370, loss is 0.0004270060744602233\n",
      "epoch: 23 step: 371, loss is 0.0003369776241015643\n",
      "epoch: 23 step: 372, loss is 0.0010208666790276766\n",
      "epoch: 23 step: 373, loss is 0.0006169284461066127\n",
      "epoch: 23 step: 374, loss is 0.0005365427350625396\n",
      "epoch: 23 step: 375, loss is 0.00011796169565059245\n",
      "Train epoch time: 12104.102 ms, per step time: 32.278 ms\n",
      "epoch: 24 step: 1, loss is 0.00048684776993468404\n",
      "epoch: 24 step: 2, loss is 0.0003616469039116055\n",
      "epoch: 24 step: 3, loss is 0.0003512377734296024\n",
      "epoch: 24 step: 4, loss is 0.0005719541804865003\n",
      "epoch: 24 step: 5, loss is 0.0005207504727877676\n",
      "epoch: 24 step: 6, loss is 0.0008340771892108023\n",
      "epoch: 24 step: 7, loss is 0.00039350753650069237\n",
      "epoch: 24 step: 8, loss is 0.0007940345676615834\n",
      "epoch: 24 step: 9, loss is 0.0006638600607402623\n",
      "epoch: 24 step: 10, loss is 0.00043214578181505203\n",
      "epoch: 24 step: 11, loss is 0.0006107463268563151\n",
      "epoch: 24 step: 12, loss is 0.0005354124587029219\n",
      "epoch: 24 step: 13, loss is 0.000527573109138757\n",
      "epoch: 24 step: 14, loss is 0.00030181114561855793\n",
      "epoch: 24 step: 15, loss is 0.0013142699608579278\n",
      "epoch: 24 step: 16, loss is 0.00030753854662179947\n",
      "epoch: 24 step: 17, loss is 0.0005989110795781016\n",
      "epoch: 24 step: 18, loss is 0.0002907504967879504\n",
      "epoch: 24 step: 19, loss is 0.0005161208682693541\n",
      "epoch: 24 step: 20, loss is 0.00020927841251250356\n",
      "epoch: 24 step: 21, loss is 0.0004035539459437132\n",
      "epoch: 24 step: 22, loss is 0.0005111868376843631\n",
      "epoch: 24 step: 23, loss is 0.00019740089192055166\n",
      "epoch: 24 step: 24, loss is 0.0003434909740462899\n",
      "epoch: 24 step: 25, loss is 0.0008247822406701744\n",
      "epoch: 24 step: 26, loss is 0.0004251277132425457\n",
      "epoch: 24 step: 27, loss is 0.00017036942881532013\n",
      "epoch: 24 step: 28, loss is 0.0006482248427346349\n",
      "epoch: 24 step: 29, loss is 0.000865028821863234\n",
      "epoch: 24 step: 30, loss is 0.0003114759747404605\n",
      "epoch: 24 step: 31, loss is 0.00027236371533945203\n",
      "epoch: 24 step: 32, loss is 0.0004452763532754034\n",
      "epoch: 24 step: 33, loss is 0.0013216719962656498\n",
      "epoch: 24 step: 34, loss is 0.0003572169516701251\n",
      "epoch: 24 step: 35, loss is 0.0008375527104362845\n",
      "epoch: 24 step: 36, loss is 0.0010589782614260912\n",
      "epoch: 24 step: 37, loss is 0.0015904500614851713\n",
      "epoch: 24 step: 38, loss is 0.001283376943320036\n",
      "epoch: 24 step: 39, loss is 0.00034331195638515055\n",
      "epoch: 24 step: 40, loss is 0.00034356178366579115\n",
      "epoch: 24 step: 41, loss is 0.00024437185493297875\n",
      "epoch: 24 step: 42, loss is 0.0011342751095071435\n",
      "epoch: 24 step: 43, loss is 0.001105366158299148\n",
      "epoch: 24 step: 44, loss is 0.0007221391424536705\n",
      "epoch: 24 step: 45, loss is 0.0006586028612218797\n",
      "epoch: 24 step: 46, loss is 0.0008001273963600397\n",
      "epoch: 24 step: 47, loss is 0.0007938044145703316\n",
      "epoch: 24 step: 48, loss is 0.00024869502522051334\n",
      "epoch: 24 step: 49, loss is 0.0015324654523283243\n",
      "epoch: 24 step: 50, loss is 0.0003738633240573108\n",
      "epoch: 24 step: 51, loss is 0.0014098755782470107\n",
      "epoch: 24 step: 52, loss is 0.0004999557277187705\n",
      "epoch: 24 step: 53, loss is 0.0007319350261241198\n",
      "epoch: 24 step: 54, loss is 0.00020146797760389745\n",
      "epoch: 24 step: 55, loss is 0.001635908498428762\n",
      "epoch: 24 step: 56, loss is 0.0006231413572095335\n",
      "epoch: 24 step: 57, loss is 0.001006969716399908\n",
      "epoch: 24 step: 58, loss is 0.001166880247183144\n",
      "epoch: 24 step: 59, loss is 0.0005427374271675944\n",
      "epoch: 24 step: 60, loss is 0.0006601907662115991\n",
      "epoch: 24 step: 61, loss is 0.00041148916352540255\n",
      "epoch: 24 step: 62, loss is 0.00034489951212890446\n",
      "epoch: 24 step: 63, loss is 0.0007469744305126369\n",
      "epoch: 24 step: 64, loss is 0.0009962558979168534\n",
      "epoch: 24 step: 65, loss is 0.0009090457460843027\n",
      "epoch: 24 step: 66, loss is 0.0010182864498347044\n",
      "epoch: 24 step: 67, loss is 0.0003967703669331968\n",
      "epoch: 24 step: 68, loss is 0.001232184818945825\n",
      "epoch: 24 step: 69, loss is 0.0004636688099708408\n",
      "epoch: 24 step: 70, loss is 0.00047038952470757067\n",
      "epoch: 24 step: 71, loss is 0.0009851696668192744\n",
      "epoch: 24 step: 72, loss is 0.0006647167028859258\n",
      "epoch: 24 step: 73, loss is 0.0007635728688910604\n",
      "epoch: 24 step: 74, loss is 0.000549379619769752\n",
      "epoch: 24 step: 75, loss is 0.00041448723641224205\n",
      "epoch: 24 step: 76, loss is 0.0006621167995035648\n",
      "epoch: 24 step: 77, loss is 0.000786148535553366\n",
      "epoch: 24 step: 78, loss is 0.00026357939350418746\n",
      "epoch: 24 step: 79, loss is 0.0006753497291356325\n",
      "epoch: 24 step: 80, loss is 0.0010513669112697244\n",
      "epoch: 24 step: 81, loss is 0.00046468706568703055\n",
      "epoch: 24 step: 82, loss is 0.0015737209469079971\n",
      "epoch: 24 step: 83, loss is 0.0002289921831106767\n",
      "epoch: 24 step: 84, loss is 0.0008369599236175418\n",
      "epoch: 24 step: 85, loss is 0.00028067827224731445\n",
      "epoch: 24 step: 86, loss is 0.0005338836344890296\n",
      "epoch: 24 step: 87, loss is 0.0006697726785205305\n",
      "epoch: 24 step: 88, loss is 0.0006157971220090985\n",
      "epoch: 24 step: 89, loss is 0.0007926204707473516\n",
      "epoch: 24 step: 90, loss is 0.0009639016934670508\n",
      "epoch: 24 step: 91, loss is 0.0005464236601255834\n",
      "epoch: 24 step: 92, loss is 0.00033026322489604354\n",
      "epoch: 24 step: 93, loss is 0.0005086048040539026\n",
      "epoch: 24 step: 94, loss is 0.00044953657197766006\n",
      "epoch: 24 step: 95, loss is 0.0006223598029464483\n",
      "epoch: 24 step: 96, loss is 0.0006660305662080646\n",
      "epoch: 24 step: 97, loss is 0.0009879008866846561\n",
      "epoch: 24 step: 98, loss is 0.0006787074962630868\n",
      "epoch: 24 step: 99, loss is 0.0011648036306723952\n",
      "epoch: 24 step: 100, loss is 0.0009149812976829708\n",
      "epoch: 24 step: 101, loss is 0.0005249162786640227\n",
      "epoch: 24 step: 102, loss is 0.0009168513934127986\n",
      "epoch: 24 step: 103, loss is 0.0007911325083114207\n",
      "epoch: 24 step: 104, loss is 0.0005638105212710798\n",
      "epoch: 24 step: 105, loss is 0.000737406313419342\n",
      "epoch: 24 step: 106, loss is 0.000952013477217406\n",
      "epoch: 24 step: 107, loss is 0.0006450469954870641\n",
      "epoch: 24 step: 108, loss is 0.00104398129042238\n",
      "epoch: 24 step: 109, loss is 0.0007791417883709073\n",
      "epoch: 24 step: 110, loss is 0.001340170856565237\n",
      "epoch: 24 step: 111, loss is 0.0012569981627166271\n",
      "epoch: 24 step: 112, loss is 0.0007155790808610618\n",
      "epoch: 24 step: 113, loss is 0.0004333379038143903\n",
      "epoch: 24 step: 114, loss is 0.00021747525897808373\n",
      "epoch: 24 step: 115, loss is 0.0003695042396429926\n",
      "epoch: 24 step: 116, loss is 0.0003645454708021134\n",
      "epoch: 24 step: 117, loss is 0.00034832884557545185\n",
      "epoch: 24 step: 118, loss is 0.0006502062315121293\n",
      "epoch: 24 step: 119, loss is 0.00045091364881955087\n",
      "epoch: 24 step: 120, loss is 0.0007506370893679559\n",
      "epoch: 24 step: 121, loss is 0.00028118069167248905\n",
      "epoch: 24 step: 122, loss is 0.0013733393279835582\n",
      "epoch: 24 step: 123, loss is 0.0006758150411769748\n",
      "epoch: 24 step: 124, loss is 0.0003887161728926003\n",
      "epoch: 24 step: 125, loss is 0.0014624824980273843\n",
      "epoch: 24 step: 126, loss is 0.000308001646772027\n",
      "epoch: 24 step: 127, loss is 0.00046970820403657854\n",
      "epoch: 24 step: 128, loss is 0.000381407153327018\n",
      "epoch: 24 step: 129, loss is 0.0009594756993465126\n",
      "epoch: 24 step: 130, loss is 0.000681805016938597\n",
      "epoch: 24 step: 131, loss is 0.0010547052370384336\n",
      "epoch: 24 step: 132, loss is 0.0005863994592800736\n",
      "epoch: 24 step: 133, loss is 0.0008271241094917059\n",
      "epoch: 24 step: 134, loss is 0.0005054296925663948\n",
      "epoch: 24 step: 135, loss is 0.00039282446959987283\n",
      "epoch: 24 step: 136, loss is 0.0008040705579333007\n",
      "epoch: 24 step: 137, loss is 0.0005304679507389665\n",
      "epoch: 24 step: 138, loss is 0.0004901415668427944\n",
      "epoch: 24 step: 139, loss is 0.0004887322429567575\n",
      "epoch: 24 step: 140, loss is 0.0012999220052734017\n",
      "epoch: 24 step: 141, loss is 0.0004468351253308356\n",
      "epoch: 24 step: 142, loss is 0.0009431702201254666\n",
      "epoch: 24 step: 143, loss is 0.0005231421673670411\n",
      "epoch: 24 step: 144, loss is 0.0008879813249222934\n",
      "epoch: 24 step: 145, loss is 0.0012593058636412024\n",
      "epoch: 24 step: 146, loss is 0.0009060435695573688\n",
      "epoch: 24 step: 147, loss is 0.0010172376642003655\n",
      "epoch: 24 step: 148, loss is 0.0008292830898426473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 149, loss is 8.127211913233623e-05\n",
      "epoch: 24 step: 150, loss is 0.0008030712488107383\n",
      "epoch: 24 step: 151, loss is 0.00015424482990056276\n",
      "epoch: 24 step: 152, loss is 0.0005551124922931194\n",
      "epoch: 24 step: 153, loss is 0.0006969011155888438\n",
      "epoch: 24 step: 154, loss is 0.0006842433358542621\n",
      "epoch: 24 step: 155, loss is 0.0005826474516652524\n",
      "epoch: 24 step: 156, loss is 0.0011866000713780522\n",
      "epoch: 24 step: 157, loss is 0.0005508965696208179\n",
      "epoch: 24 step: 158, loss is 0.0004805878270417452\n",
      "epoch: 24 step: 159, loss is 0.0011152141960337758\n",
      "epoch: 24 step: 160, loss is 0.0006282251561060548\n",
      "epoch: 24 step: 161, loss is 0.0004223071155138314\n",
      "epoch: 24 step: 162, loss is 0.0009403678704984486\n",
      "epoch: 24 step: 163, loss is 0.0005791232688352466\n",
      "epoch: 24 step: 164, loss is 0.0010653811041265726\n",
      "epoch: 24 step: 165, loss is 0.0016235866351053119\n",
      "epoch: 24 step: 166, loss is 0.0005492548807524145\n",
      "epoch: 24 step: 167, loss is 0.0006815163069404662\n",
      "epoch: 24 step: 168, loss is 0.00029609957709908485\n",
      "epoch: 24 step: 169, loss is 0.000363149621989578\n",
      "epoch: 24 step: 170, loss is 0.0014117428800091147\n",
      "epoch: 24 step: 171, loss is 0.001592774991877377\n",
      "epoch: 24 step: 172, loss is 0.000738976988941431\n",
      "epoch: 24 step: 173, loss is 0.0009229902643710375\n",
      "epoch: 24 step: 174, loss is 0.00016942179354373366\n",
      "epoch: 24 step: 175, loss is 0.001092179911211133\n",
      "epoch: 24 step: 176, loss is 0.0005627174978144467\n",
      "epoch: 24 step: 177, loss is 0.00035803831997327507\n",
      "epoch: 24 step: 178, loss is 0.0009932226967066526\n",
      "epoch: 24 step: 179, loss is 0.000612998497672379\n",
      "epoch: 24 step: 180, loss is 0.0005591351073235273\n",
      "epoch: 24 step: 181, loss is 0.0006498986622318625\n",
      "epoch: 24 step: 182, loss is 0.0009894565446302295\n",
      "epoch: 24 step: 183, loss is 0.0002643950283527374\n",
      "epoch: 24 step: 184, loss is 0.0005799888749606907\n",
      "epoch: 24 step: 185, loss is 0.0008435940835624933\n",
      "epoch: 24 step: 186, loss is 0.0011842979583889246\n",
      "epoch: 24 step: 187, loss is 0.0004849578836001456\n",
      "epoch: 24 step: 188, loss is 0.0004606885777320713\n",
      "epoch: 24 step: 189, loss is 0.001025581150315702\n",
      "epoch: 24 step: 190, loss is 0.0012473397655412555\n",
      "epoch: 24 step: 191, loss is 0.0016481971833854914\n",
      "epoch: 24 step: 192, loss is 0.00037915940629318357\n",
      "epoch: 24 step: 193, loss is 0.0001498871570220217\n",
      "epoch: 24 step: 194, loss is 0.0004782524483744055\n",
      "epoch: 24 step: 195, loss is 0.00011447499127825722\n",
      "epoch: 24 step: 196, loss is 0.0007324243779294193\n",
      "epoch: 24 step: 197, loss is 0.000546053983271122\n",
      "epoch: 24 step: 198, loss is 0.00044038661872036755\n",
      "epoch: 24 step: 199, loss is 0.00038754180422984064\n",
      "epoch: 24 step: 200, loss is 0.0008087216410785913\n",
      "epoch: 24 step: 201, loss is 0.00036656958400271833\n",
      "epoch: 24 step: 202, loss is 0.00013784176553599536\n",
      "epoch: 24 step: 203, loss is 0.0009560056496411562\n",
      "epoch: 24 step: 204, loss is 0.000568535877391696\n",
      "epoch: 24 step: 205, loss is 0.00039085617754608393\n",
      "epoch: 24 step: 206, loss is 0.0007927595288492739\n",
      "epoch: 24 step: 207, loss is 0.0007134419283829629\n",
      "epoch: 24 step: 208, loss is 0.0010309393983334303\n",
      "epoch: 24 step: 209, loss is 0.0005335747264325619\n",
      "epoch: 24 step: 210, loss is 0.0003789793117903173\n",
      "epoch: 24 step: 211, loss is 0.0008945174631662667\n",
      "epoch: 24 step: 212, loss is 0.0003556351875886321\n",
      "epoch: 24 step: 213, loss is 0.0006837528198957443\n",
      "epoch: 24 step: 214, loss is 0.00043789317714981735\n",
      "epoch: 24 step: 215, loss is 0.0006783326389268041\n",
      "epoch: 24 step: 216, loss is 0.0004462056385818869\n",
      "epoch: 24 step: 217, loss is 0.0003553262213245034\n",
      "epoch: 24 step: 218, loss is 0.0005818085628561676\n",
      "epoch: 24 step: 219, loss is 0.000795612286310643\n",
      "epoch: 24 step: 220, loss is 0.0006922458996996284\n",
      "epoch: 24 step: 221, loss is 0.00019553369202185422\n",
      "epoch: 24 step: 222, loss is 0.0007145803538151085\n",
      "epoch: 24 step: 223, loss is 0.00048228574451059103\n",
      "epoch: 24 step: 224, loss is 0.00035013395245186985\n",
      "epoch: 24 step: 225, loss is 0.0006027788622304797\n",
      "epoch: 24 step: 226, loss is 0.0004435134760569781\n",
      "epoch: 24 step: 227, loss is 0.0012784259160980582\n",
      "epoch: 24 step: 228, loss is 0.0008922853739932179\n",
      "epoch: 24 step: 229, loss is 0.0006873781094327569\n",
      "epoch: 24 step: 230, loss is 0.0006188147235661745\n",
      "epoch: 24 step: 231, loss is 0.0008131650392897427\n",
      "epoch: 24 step: 232, loss is 0.0005806410335935652\n",
      "epoch: 24 step: 233, loss is 0.00031945796217769384\n",
      "epoch: 24 step: 234, loss is 0.0008920106338337064\n",
      "epoch: 24 step: 235, loss is 0.00019147724378854036\n",
      "epoch: 24 step: 236, loss is 0.0003606358077377081\n",
      "epoch: 24 step: 237, loss is 0.0014520402764901519\n",
      "epoch: 24 step: 238, loss is 0.0008959440747275949\n",
      "epoch: 24 step: 239, loss is 0.0008318581385537982\n",
      "epoch: 24 step: 240, loss is 0.0013597619254142046\n",
      "epoch: 24 step: 241, loss is 0.0009919832227751613\n",
      "epoch: 24 step: 242, loss is 0.0010017637396231294\n",
      "epoch: 24 step: 243, loss is 0.0005015136557631195\n",
      "epoch: 24 step: 244, loss is 0.0006987581728026271\n",
      "epoch: 24 step: 245, loss is 0.00027340202359482646\n",
      "epoch: 24 step: 246, loss is 0.000734337663743645\n",
      "epoch: 24 step: 247, loss is 0.0006194824818521738\n",
      "epoch: 24 step: 248, loss is 0.0005704688956029713\n",
      "epoch: 24 step: 249, loss is 0.0004375138087198138\n",
      "epoch: 24 step: 250, loss is 0.0006582083879038692\n",
      "epoch: 24 step: 251, loss is 0.000949980050791055\n",
      "epoch: 24 step: 252, loss is 0.0012738130753859878\n",
      "epoch: 24 step: 253, loss is 0.0008194147958420217\n",
      "epoch: 24 step: 254, loss is 0.0004753143584821373\n",
      "epoch: 24 step: 255, loss is 0.00048179211444221437\n",
      "epoch: 24 step: 256, loss is 0.00026934107881970704\n",
      "epoch: 24 step: 257, loss is 0.000932845869101584\n",
      "epoch: 24 step: 258, loss is 0.0006338578532449901\n",
      "epoch: 24 step: 259, loss is 0.0006681085214950144\n",
      "epoch: 24 step: 260, loss is 0.0006789779872633517\n",
      "epoch: 24 step: 261, loss is 0.0015116488793864846\n",
      "epoch: 24 step: 262, loss is 0.0007433959981426597\n",
      "epoch: 24 step: 263, loss is 0.0004815014835912734\n",
      "epoch: 24 step: 264, loss is 0.00034520289045758545\n",
      "epoch: 24 step: 265, loss is 0.0010401350446045399\n",
      "epoch: 24 step: 266, loss is 0.00100140820723027\n",
      "epoch: 24 step: 267, loss is 0.0004667338798753917\n",
      "epoch: 24 step: 268, loss is 0.0008850826416164637\n",
      "epoch: 24 step: 269, loss is 0.000854389916639775\n",
      "epoch: 24 step: 270, loss is 0.0009082092437893152\n",
      "epoch: 24 step: 271, loss is 0.000328423164319247\n",
      "epoch: 24 step: 272, loss is 0.0005296620656736195\n",
      "epoch: 24 step: 273, loss is 0.0007156673236750066\n",
      "epoch: 24 step: 274, loss is 0.0011730880942195654\n",
      "epoch: 24 step: 275, loss is 0.00024253263836726546\n",
      "epoch: 24 step: 276, loss is 0.0006372909410856664\n",
      "epoch: 24 step: 277, loss is 0.0002364153042435646\n",
      "epoch: 24 step: 278, loss is 0.0007680779090151191\n",
      "epoch: 24 step: 279, loss is 0.0003372103092260659\n",
      "epoch: 24 step: 280, loss is 0.0004543895774986595\n",
      "epoch: 24 step: 281, loss is 0.0009735152707435191\n",
      "epoch: 24 step: 282, loss is 0.001061194809153676\n",
      "epoch: 24 step: 283, loss is 0.0004141024546697736\n",
      "epoch: 24 step: 284, loss is 0.0014387412229552865\n",
      "epoch: 24 step: 285, loss is 0.00021912387455813587\n",
      "epoch: 24 step: 286, loss is 0.0011872975155711174\n",
      "epoch: 24 step: 287, loss is 0.0022310444619506598\n",
      "epoch: 24 step: 288, loss is 0.00016214136849157512\n",
      "epoch: 24 step: 289, loss is 0.0005990246427245438\n",
      "epoch: 24 step: 290, loss is 0.0006947428337298334\n",
      "epoch: 24 step: 291, loss is 0.00010730823851190507\n",
      "epoch: 24 step: 292, loss is 0.0008098739781416953\n",
      "epoch: 24 step: 293, loss is 0.0005983358714729548\n",
      "epoch: 24 step: 294, loss is 0.00046178093180060387\n",
      "epoch: 24 step: 295, loss is 0.0019143761601299047\n",
      "epoch: 24 step: 296, loss is 0.00034362118458375335\n",
      "epoch: 24 step: 297, loss is 0.0002344204403925687\n",
      "epoch: 24 step: 298, loss is 0.0005544342566281557\n",
      "epoch: 24 step: 299, loss is 0.0009931772947311401\n",
      "epoch: 24 step: 300, loss is 0.0011895219795405865\n",
      "epoch: 24 step: 301, loss is 0.0010533732129260898\n",
      "epoch: 24 step: 302, loss is 0.0006212196312844753\n",
      "epoch: 24 step: 303, loss is 0.00031985287205316126\n",
      "epoch: 24 step: 304, loss is 0.00065205356804654\n",
      "epoch: 24 step: 305, loss is 0.0004567888972815126\n",
      "epoch: 24 step: 306, loss is 0.0006690255249850452\n",
      "epoch: 24 step: 307, loss is 0.000709220243152231\n",
      "epoch: 24 step: 308, loss is 0.0008988399058580399\n",
      "epoch: 24 step: 309, loss is 0.0005819764919579029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 310, loss is 0.00095655198674649\n",
      "epoch: 24 step: 311, loss is 0.0009865949396044016\n",
      "epoch: 24 step: 312, loss is 0.0006977861630730331\n",
      "epoch: 24 step: 313, loss is 0.00026235252153128386\n",
      "epoch: 24 step: 314, loss is 0.0005584305035881698\n",
      "epoch: 24 step: 315, loss is 0.00038048464921303093\n",
      "epoch: 24 step: 316, loss is 0.0007330935914069414\n",
      "epoch: 24 step: 317, loss is 0.0006710703019052744\n",
      "epoch: 24 step: 318, loss is 0.0005161528824828565\n",
      "epoch: 24 step: 319, loss is 0.00042560967267490923\n",
      "epoch: 24 step: 320, loss is 0.000571656390093267\n",
      "epoch: 24 step: 321, loss is 0.0004256267857272178\n",
      "epoch: 24 step: 322, loss is 0.0005776348407380283\n",
      "epoch: 24 step: 323, loss is 0.000527962576597929\n",
      "epoch: 24 step: 324, loss is 0.000272027391474694\n",
      "epoch: 24 step: 325, loss is 0.0005242073675617576\n",
      "epoch: 24 step: 326, loss is 0.0007608339656144381\n",
      "epoch: 24 step: 327, loss is 0.0016182068502530456\n",
      "epoch: 24 step: 328, loss is 0.0006289823213592172\n",
      "epoch: 24 step: 329, loss is 0.0013455540174618363\n",
      "epoch: 24 step: 330, loss is 0.00019911487470380962\n",
      "epoch: 24 step: 331, loss is 0.002231915481388569\n",
      "epoch: 24 step: 332, loss is 0.000319301791023463\n",
      "epoch: 24 step: 333, loss is 0.0006485232152044773\n",
      "epoch: 24 step: 334, loss is 0.0002747767139226198\n",
      "epoch: 24 step: 335, loss is 0.000850005482789129\n",
      "epoch: 24 step: 336, loss is 0.0003201719664502889\n",
      "epoch: 24 step: 337, loss is 0.0011788849951699376\n",
      "epoch: 24 step: 338, loss is 0.0010878336615860462\n",
      "epoch: 24 step: 339, loss is 0.0006914926343597472\n",
      "epoch: 24 step: 340, loss is 0.00036829093005508184\n",
      "epoch: 24 step: 341, loss is 0.00038568777381442487\n",
      "epoch: 24 step: 342, loss is 0.0005442023393698037\n",
      "epoch: 24 step: 343, loss is 0.00048517429968342185\n",
      "epoch: 24 step: 344, loss is 0.0006805752054788172\n",
      "epoch: 24 step: 345, loss is 0.00017818606283981353\n",
      "epoch: 24 step: 346, loss is 0.0009196670725941658\n",
      "epoch: 24 step: 347, loss is 0.0006409573252312839\n",
      "epoch: 24 step: 348, loss is 0.0009903984609991312\n",
      "epoch: 24 step: 349, loss is 0.0003864675236400217\n",
      "epoch: 24 step: 350, loss is 0.000631625996902585\n",
      "epoch: 24 step: 351, loss is 0.0016403173794969916\n",
      "epoch: 24 step: 352, loss is 0.0005219718441367149\n",
      "epoch: 24 step: 353, loss is 0.0009513501427136362\n",
      "epoch: 24 step: 354, loss is 0.0012102387845516205\n",
      "epoch: 24 step: 355, loss is 0.0006191640277393162\n",
      "epoch: 24 step: 356, loss is 0.00030652291025035083\n",
      "epoch: 24 step: 357, loss is 0.00042797348578460515\n",
      "epoch: 24 step: 358, loss is 0.0007470494601875544\n",
      "epoch: 24 step: 359, loss is 0.0007803782355040312\n",
      "epoch: 24 step: 360, loss is 0.0012419563718140125\n",
      "epoch: 24 step: 361, loss is 0.0003204457461833954\n",
      "epoch: 24 step: 362, loss is 0.0011901709949597716\n",
      "epoch: 24 step: 363, loss is 0.00017321700579486787\n",
      "epoch: 24 step: 364, loss is 0.0019691241905093193\n",
      "epoch: 24 step: 365, loss is 0.0002714293950702995\n",
      "epoch: 24 step: 366, loss is 0.00027251712162978947\n",
      "epoch: 24 step: 367, loss is 0.0012093218974769115\n",
      "epoch: 24 step: 368, loss is 0.0005089382757432759\n",
      "epoch: 24 step: 369, loss is 0.0003568560932762921\n",
      "epoch: 24 step: 370, loss is 0.000959057651925832\n",
      "epoch: 24 step: 371, loss is 0.0004163676640018821\n",
      "epoch: 24 step: 372, loss is 0.001825213199481368\n",
      "epoch: 24 step: 373, loss is 0.0007778438739478588\n",
      "epoch: 24 step: 374, loss is 0.0006589352851733565\n",
      "epoch: 24 step: 375, loss is 0.00038235459942370653\n",
      "Train epoch time: 11998.165 ms, per step time: 31.995 ms\n",
      "epoch: 25 step: 1, loss is 0.00038914315518923104\n",
      "epoch: 25 step: 2, loss is 0.0005211829557083547\n",
      "epoch: 25 step: 3, loss is 0.0005167982308194041\n",
      "epoch: 25 step: 4, loss is 0.00034008926013484597\n",
      "epoch: 25 step: 5, loss is 0.0006110541289672256\n",
      "epoch: 25 step: 6, loss is 0.0007806076318956912\n",
      "epoch: 25 step: 7, loss is 0.0008517091046087444\n",
      "epoch: 25 step: 8, loss is 0.0010189077584072948\n",
      "epoch: 25 step: 9, loss is 0.0005633122054859996\n",
      "epoch: 25 step: 10, loss is 0.0006954102427698672\n",
      "epoch: 25 step: 11, loss is 0.0011364780366420746\n",
      "epoch: 25 step: 12, loss is 0.0006614667363464832\n",
      "epoch: 25 step: 13, loss is 0.0014037752989679575\n",
      "epoch: 25 step: 14, loss is 0.000951748457737267\n",
      "epoch: 25 step: 15, loss is 0.00036295686732046306\n",
      "epoch: 25 step: 16, loss is 0.0004674876690842211\n",
      "epoch: 25 step: 17, loss is 0.00043794154771603644\n",
      "epoch: 25 step: 18, loss is 0.0007654560031369328\n",
      "epoch: 25 step: 19, loss is 0.0010214793728664517\n",
      "epoch: 25 step: 20, loss is 0.0004696903342846781\n",
      "epoch: 25 step: 21, loss is 0.0007963927346281707\n",
      "epoch: 25 step: 22, loss is 0.0005994596285745502\n",
      "epoch: 25 step: 23, loss is 0.0009382126736454666\n",
      "epoch: 25 step: 24, loss is 0.0006375655066221952\n",
      "epoch: 25 step: 25, loss is 0.0007813764968886971\n",
      "epoch: 25 step: 26, loss is 0.0007669737678952515\n",
      "epoch: 25 step: 27, loss is 0.0007867888198234141\n",
      "epoch: 25 step: 28, loss is 0.000604809436481446\n",
      "epoch: 25 step: 29, loss is 0.00029597472166642547\n",
      "epoch: 25 step: 30, loss is 0.0007297617848962545\n",
      "epoch: 25 step: 31, loss is 0.0003563194186426699\n",
      "epoch: 25 step: 32, loss is 0.00026018687640316784\n",
      "epoch: 25 step: 33, loss is 0.0010853236308321357\n",
      "epoch: 25 step: 34, loss is 0.0003103120834566653\n",
      "epoch: 25 step: 35, loss is 0.0004279866989236325\n",
      "epoch: 25 step: 36, loss is 0.0018672680016607046\n",
      "epoch: 25 step: 37, loss is 0.0007441696361638606\n",
      "epoch: 25 step: 38, loss is 0.0010360699379816651\n",
      "epoch: 25 step: 39, loss is 0.0003995471342932433\n",
      "epoch: 25 step: 40, loss is 0.0007574878982268274\n",
      "epoch: 25 step: 41, loss is 0.0008039500098675489\n",
      "epoch: 25 step: 42, loss is 0.0006257437635213137\n",
      "epoch: 25 step: 43, loss is 0.00048536714166402817\n",
      "epoch: 25 step: 44, loss is 0.0008040809188969433\n",
      "epoch: 25 step: 45, loss is 0.0010638062376528978\n",
      "epoch: 25 step: 46, loss is 0.000910273171029985\n",
      "epoch: 25 step: 47, loss is 0.0003598867042455822\n",
      "epoch: 25 step: 48, loss is 0.0003251367888879031\n",
      "epoch: 25 step: 49, loss is 0.0012084983754903078\n",
      "epoch: 25 step: 50, loss is 0.0004597226215992123\n",
      "epoch: 25 step: 51, loss is 0.0005521422135643661\n",
      "epoch: 25 step: 52, loss is 0.0004435639420989901\n",
      "epoch: 25 step: 53, loss is 0.0007868089014664292\n",
      "epoch: 25 step: 54, loss is 0.0007506688707508147\n",
      "epoch: 25 step: 55, loss is 0.0009805267909541726\n",
      "epoch: 25 step: 56, loss is 0.00015994979185052216\n",
      "epoch: 25 step: 57, loss is 0.0014162701554596424\n",
      "epoch: 25 step: 58, loss is 0.0003712199395522475\n",
      "epoch: 25 step: 59, loss is 0.000584908586461097\n",
      "epoch: 25 step: 60, loss is 0.0008042127592489123\n",
      "epoch: 25 step: 61, loss is 0.0008995122625492513\n",
      "epoch: 25 step: 62, loss is 0.0010407125810161233\n",
      "epoch: 25 step: 63, loss is 0.0005251059192232788\n",
      "epoch: 25 step: 64, loss is 0.00045938469702377915\n",
      "epoch: 25 step: 65, loss is 0.0002603502362035215\n",
      "epoch: 25 step: 66, loss is 0.001069800928235054\n",
      "epoch: 25 step: 67, loss is 0.0004763224860653281\n",
      "epoch: 25 step: 68, loss is 0.0010540010407567024\n",
      "epoch: 25 step: 69, loss is 0.0007835297146812081\n",
      "epoch: 25 step: 70, loss is 0.0004696322721429169\n",
      "epoch: 25 step: 71, loss is 0.00025976900360547006\n",
      "epoch: 25 step: 72, loss is 0.000373328774003312\n",
      "epoch: 25 step: 73, loss is 0.0007753601530566812\n",
      "epoch: 25 step: 74, loss is 0.0005316374008543789\n",
      "epoch: 25 step: 75, loss is 0.0005357913323678076\n",
      "epoch: 25 step: 76, loss is 0.0003417498373892158\n",
      "epoch: 25 step: 77, loss is 0.0006011654622852802\n",
      "epoch: 25 step: 78, loss is 0.00029566691955551505\n",
      "epoch: 25 step: 79, loss is 0.0012237537885084748\n",
      "epoch: 25 step: 80, loss is 0.0003527483786456287\n",
      "epoch: 25 step: 81, loss is 0.00024076644331216812\n",
      "epoch: 25 step: 82, loss is 0.0005148348864167929\n",
      "epoch: 25 step: 83, loss is 0.0009641365031711757\n",
      "epoch: 25 step: 84, loss is 0.00033897170214913785\n",
      "epoch: 25 step: 85, loss is 0.000255608931183815\n",
      "epoch: 25 step: 86, loss is 0.0008342740475200117\n",
      "epoch: 25 step: 87, loss is 0.0007927519036456943\n",
      "epoch: 25 step: 88, loss is 0.00034755037631839514\n",
      "epoch: 25 step: 89, loss is 0.0012011488433927298\n",
      "epoch: 25 step: 90, loss is 0.0006297577638179064\n",
      "epoch: 25 step: 91, loss is 0.0004051577707286924\n",
      "epoch: 25 step: 92, loss is 0.00028832961106672883\n",
      "epoch: 25 step: 93, loss is 0.0018352012848481536\n",
      "epoch: 25 step: 94, loss is 0.0004831502155866474\n",
      "epoch: 25 step: 95, loss is 0.0014988156035542488\n",
      "epoch: 25 step: 96, loss is 0.000637684075627476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 step: 97, loss is 0.00045109528582543135\n",
      "epoch: 25 step: 98, loss is 0.0007093047606758773\n",
      "epoch: 25 step: 99, loss is 0.0016086191171780229\n",
      "epoch: 25 step: 100, loss is 0.0008530582417733967\n",
      "epoch: 25 step: 101, loss is 0.000646105851046741\n",
      "epoch: 25 step: 102, loss is 0.0002379856159677729\n",
      "epoch: 25 step: 103, loss is 0.0011857823701575398\n",
      "epoch: 25 step: 104, loss is 0.0006833933875896037\n",
      "epoch: 25 step: 105, loss is 0.0006572282291017473\n",
      "epoch: 25 step: 106, loss is 0.00042975632823072374\n",
      "epoch: 25 step: 107, loss is 0.0014754612930119038\n",
      "epoch: 25 step: 108, loss is 0.0011064402060583234\n",
      "epoch: 25 step: 109, loss is 0.0006980749894864857\n",
      "epoch: 25 step: 110, loss is 0.0002769092097878456\n",
      "epoch: 25 step: 111, loss is 0.0017960368422791362\n",
      "epoch: 25 step: 112, loss is 0.0002950272464659065\n",
      "epoch: 25 step: 113, loss is 0.0012315320782363415\n",
      "epoch: 25 step: 114, loss is 0.0011930690379813313\n",
      "epoch: 25 step: 115, loss is 0.0005069078761152923\n",
      "epoch: 25 step: 116, loss is 0.0004663087020162493\n",
      "epoch: 25 step: 117, loss is 0.00045491004129871726\n",
      "epoch: 25 step: 118, loss is 0.0006576304440386593\n",
      "epoch: 25 step: 119, loss is 0.0005390207516029477\n",
      "epoch: 25 step: 120, loss is 0.0009812219068408012\n",
      "epoch: 25 step: 121, loss is 0.0004830736434087157\n",
      "epoch: 25 step: 122, loss is 0.000589527830015868\n",
      "epoch: 25 step: 123, loss is 0.0008773365989327431\n",
      "epoch: 25 step: 124, loss is 0.0012007993645966053\n",
      "epoch: 25 step: 125, loss is 0.00025182010722346604\n",
      "epoch: 25 step: 126, loss is 0.002387767657637596\n",
      "epoch: 25 step: 127, loss is 0.0006039878935553133\n",
      "epoch: 25 step: 128, loss is 0.0007916814647614956\n",
      "epoch: 25 step: 129, loss is 0.000396373332478106\n",
      "epoch: 25 step: 130, loss is 0.001338919042609632\n",
      "epoch: 25 step: 131, loss is 0.0006208992563188076\n",
      "epoch: 25 step: 132, loss is 0.00034973412402905524\n",
      "epoch: 25 step: 133, loss is 0.00033066669129766524\n",
      "epoch: 25 step: 134, loss is 0.0006271775346249342\n",
      "epoch: 25 step: 135, loss is 0.000668940250761807\n",
      "epoch: 25 step: 136, loss is 0.0021423555444926023\n",
      "epoch: 25 step: 137, loss is 0.00027527479687705636\n",
      "epoch: 25 step: 138, loss is 0.0004871792043559253\n",
      "epoch: 25 step: 139, loss is 0.00022411310055758804\n",
      "epoch: 25 step: 140, loss is 0.0002651116519700736\n",
      "epoch: 25 step: 141, loss is 0.0005539450794458389\n",
      "epoch: 25 step: 142, loss is 0.0008250453975051641\n",
      "epoch: 25 step: 143, loss is 0.0005270011606626213\n",
      "epoch: 25 step: 144, loss is 0.0010643374407663941\n",
      "epoch: 25 step: 145, loss is 0.0005749534466303885\n",
      "epoch: 25 step: 146, loss is 0.0013061900390312076\n",
      "epoch: 25 step: 147, loss is 0.00028934565489180386\n",
      "epoch: 25 step: 148, loss is 0.0005069553153589368\n",
      "epoch: 25 step: 149, loss is 0.001247421489097178\n",
      "epoch: 25 step: 150, loss is 0.0005150766228325665\n",
      "epoch: 25 step: 151, loss is 0.0004686476313509047\n",
      "epoch: 25 step: 152, loss is 0.000214804254937917\n",
      "epoch: 25 step: 153, loss is 0.00036146410275250673\n",
      "epoch: 25 step: 154, loss is 0.0009176026796922088\n",
      "epoch: 25 step: 155, loss is 0.0005401612143032253\n",
      "epoch: 25 step: 156, loss is 0.0002107128093484789\n",
      "epoch: 25 step: 157, loss is 0.000565755763091147\n",
      "epoch: 25 step: 158, loss is 0.0010637633968144655\n",
      "epoch: 25 step: 159, loss is 0.0006326144794002175\n",
      "epoch: 25 step: 160, loss is 0.0004681981517933309\n",
      "epoch: 25 step: 161, loss is 0.0002672532282304019\n",
      "epoch: 25 step: 162, loss is 0.0007839172030799091\n",
      "epoch: 25 step: 163, loss is 0.00024673601728864014\n",
      "epoch: 25 step: 164, loss is 0.0006883945898152888\n",
      "epoch: 25 step: 165, loss is 0.000476978748338297\n",
      "epoch: 25 step: 166, loss is 0.0003324582357890904\n",
      "epoch: 25 step: 167, loss is 0.00023150195193011314\n",
      "epoch: 25 step: 168, loss is 0.0010717968689277768\n",
      "epoch: 25 step: 169, loss is 0.0008373980526812375\n",
      "epoch: 25 step: 170, loss is 0.0004300869768485427\n",
      "epoch: 25 step: 171, loss is 0.0004018280596937984\n",
      "epoch: 25 step: 172, loss is 0.0003767457674257457\n",
      "epoch: 25 step: 173, loss is 0.000706400373019278\n",
      "epoch: 25 step: 174, loss is 0.0010439010802656412\n",
      "epoch: 25 step: 175, loss is 0.0010277032852172852\n",
      "epoch: 25 step: 176, loss is 0.0010416406439617276\n",
      "epoch: 25 step: 177, loss is 0.000860050437040627\n",
      "epoch: 25 step: 178, loss is 0.0009924082551151514\n",
      "epoch: 25 step: 179, loss is 0.0011264595668762922\n",
      "epoch: 25 step: 180, loss is 0.0009230808936990798\n",
      "epoch: 25 step: 181, loss is 0.0004267435579095036\n",
      "epoch: 25 step: 182, loss is 0.00040848011849448085\n",
      "epoch: 25 step: 183, loss is 0.0014585419557988644\n",
      "epoch: 25 step: 184, loss is 0.0014711742987856269\n",
      "epoch: 25 step: 185, loss is 0.00041227973997592926\n",
      "epoch: 25 step: 186, loss is 0.0013305408647283912\n",
      "epoch: 25 step: 187, loss is 0.0009678023052401841\n",
      "epoch: 25 step: 188, loss is 0.000648569199256599\n",
      "epoch: 25 step: 189, loss is 0.0003557350137270987\n",
      "epoch: 25 step: 190, loss is 0.0013284380547702312\n",
      "epoch: 25 step: 191, loss is 0.000998570234514773\n",
      "epoch: 25 step: 192, loss is 0.00032338520395569503\n",
      "epoch: 25 step: 193, loss is 0.001657328917644918\n",
      "epoch: 25 step: 194, loss is 0.000543748028576374\n",
      "epoch: 25 step: 195, loss is 0.0005248826346360147\n",
      "epoch: 25 step: 196, loss is 0.0004654935619328171\n",
      "epoch: 25 step: 197, loss is 0.0007127152057364583\n",
      "epoch: 25 step: 198, loss is 0.0003290114691480994\n",
      "epoch: 25 step: 199, loss is 0.0008788843406364322\n",
      "epoch: 25 step: 200, loss is 0.0005059331306256354\n",
      "epoch: 25 step: 201, loss is 0.0007907947874628007\n",
      "epoch: 25 step: 202, loss is 0.00032171912607736886\n",
      "epoch: 25 step: 203, loss is 0.0006639996427111328\n",
      "epoch: 25 step: 204, loss is 0.00036573398392647505\n",
      "epoch: 25 step: 205, loss is 0.0007341451710090041\n",
      "epoch: 25 step: 206, loss is 0.0005952824139967561\n",
      "epoch: 25 step: 207, loss is 0.0006544993375428021\n",
      "epoch: 25 step: 208, loss is 0.00027943222085013986\n",
      "epoch: 25 step: 209, loss is 0.001216692035086453\n",
      "epoch: 25 step: 210, loss is 9.745903662405908e-05\n",
      "epoch: 25 step: 211, loss is 0.0006354762008413672\n",
      "epoch: 25 step: 212, loss is 0.0005711773410439491\n",
      "epoch: 25 step: 213, loss is 0.00030711619183421135\n",
      "epoch: 25 step: 214, loss is 0.00040090372203849256\n",
      "epoch: 25 step: 215, loss is 0.00034345185849815607\n",
      "epoch: 25 step: 216, loss is 0.0004881685017608106\n",
      "epoch: 25 step: 217, loss is 0.00045470899203792214\n",
      "epoch: 25 step: 218, loss is 0.0006416261312551796\n",
      "epoch: 25 step: 219, loss is 0.00037174156750552356\n",
      "epoch: 25 step: 220, loss is 0.00027767359279096127\n",
      "epoch: 25 step: 221, loss is 0.0005971812643110752\n",
      "epoch: 25 step: 222, loss is 0.00046708108857274055\n",
      "epoch: 25 step: 223, loss is 0.001376828528009355\n",
      "epoch: 25 step: 224, loss is 0.00027888172189705074\n",
      "epoch: 25 step: 225, loss is 0.0010056995088234544\n",
      "epoch: 25 step: 226, loss is 0.0006932931719347835\n",
      "epoch: 25 step: 227, loss is 0.0011808427516371012\n",
      "epoch: 25 step: 228, loss is 0.0009407626930624247\n",
      "epoch: 25 step: 229, loss is 0.0012814020738005638\n",
      "epoch: 25 step: 230, loss is 0.0006606668466702104\n",
      "epoch: 25 step: 231, loss is 0.00040516251465305686\n",
      "epoch: 25 step: 232, loss is 0.0003242276725359261\n",
      "epoch: 25 step: 233, loss is 0.001036657951772213\n",
      "epoch: 25 step: 234, loss is 0.0002369654830545187\n",
      "epoch: 25 step: 235, loss is 0.0013204369461163878\n",
      "epoch: 25 step: 236, loss is 0.0013524036621674895\n",
      "epoch: 25 step: 237, loss is 0.0018026253674179316\n",
      "epoch: 25 step: 238, loss is 0.0006715147173963487\n",
      "epoch: 25 step: 239, loss is 0.0009417890687473118\n",
      "epoch: 25 step: 240, loss is 0.000698783784173429\n",
      "epoch: 25 step: 241, loss is 0.0006142078200355172\n",
      "epoch: 25 step: 242, loss is 0.0009527314687147737\n",
      "epoch: 25 step: 243, loss is 0.0011193042155355215\n",
      "epoch: 25 step: 244, loss is 0.00043863541213795543\n",
      "epoch: 25 step: 245, loss is 0.0003676167398225516\n",
      "epoch: 25 step: 246, loss is 0.0008291957201436162\n",
      "epoch: 25 step: 247, loss is 0.0013659566175192595\n",
      "epoch: 25 step: 248, loss is 0.0005829492583870888\n",
      "epoch: 25 step: 249, loss is 0.00030160052119754255\n",
      "epoch: 25 step: 250, loss is 0.0009237988851964474\n",
      "epoch: 25 step: 251, loss is 0.0006984884385019541\n",
      "epoch: 25 step: 252, loss is 0.00018305523553863168\n",
      "epoch: 25 step: 253, loss is 0.0004724207101389766\n",
      "epoch: 25 step: 254, loss is 0.00033834733767434955\n",
      "epoch: 25 step: 255, loss is 0.002054019132629037\n",
      "epoch: 25 step: 256, loss is 0.000563930079806596\n",
      "epoch: 25 step: 257, loss is 0.0005675542633980513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 step: 258, loss is 0.0008791440632194281\n",
      "epoch: 25 step: 259, loss is 0.0003765553410630673\n",
      "epoch: 25 step: 260, loss is 0.00046896791900508106\n",
      "epoch: 25 step: 261, loss is 0.0003958994639106095\n",
      "epoch: 25 step: 262, loss is 0.0008295724983327091\n",
      "epoch: 25 step: 263, loss is 0.00036166654899716377\n",
      "epoch: 25 step: 264, loss is 0.0007124275434762239\n",
      "epoch: 25 step: 265, loss is 0.00038667937042191625\n",
      "epoch: 25 step: 266, loss is 0.0005380365182645619\n",
      "epoch: 25 step: 267, loss is 0.0009151246049441397\n",
      "epoch: 25 step: 268, loss is 0.0010787768987938762\n",
      "epoch: 25 step: 269, loss is 0.0005782347870990634\n",
      "epoch: 25 step: 270, loss is 0.0008198978030122817\n",
      "epoch: 25 step: 271, loss is 0.00019477022578939795\n",
      "epoch: 25 step: 272, loss is 0.00035825074883177876\n",
      "epoch: 25 step: 273, loss is 0.00035327300429344177\n",
      "epoch: 25 step: 274, loss is 0.0012117567239329219\n",
      "epoch: 25 step: 275, loss is 0.00031588421552442014\n",
      "epoch: 25 step: 276, loss is 0.0006505772471427917\n",
      "epoch: 25 step: 277, loss is 0.00022154206817504019\n",
      "epoch: 25 step: 278, loss is 0.0008283323259092867\n",
      "epoch: 25 step: 279, loss is 0.000853878678753972\n",
      "epoch: 25 step: 280, loss is 0.0006372011266648769\n",
      "epoch: 25 step: 281, loss is 0.00085064786253497\n",
      "epoch: 25 step: 282, loss is 0.00048305108794011176\n",
      "epoch: 25 step: 283, loss is 0.0013565222034230828\n",
      "epoch: 25 step: 284, loss is 0.00037119004991836846\n",
      "epoch: 25 step: 285, loss is 0.00025651638861745596\n",
      "epoch: 25 step: 286, loss is 0.00043111288687214255\n",
      "epoch: 25 step: 287, loss is 0.0009306996362283826\n",
      "epoch: 25 step: 288, loss is 0.00039568502688780427\n",
      "epoch: 25 step: 289, loss is 0.000559117877855897\n",
      "epoch: 25 step: 290, loss is 0.0011163760209456086\n",
      "epoch: 25 step: 291, loss is 0.00030561647145077586\n",
      "epoch: 25 step: 292, loss is 0.0009170742705464363\n",
      "epoch: 25 step: 293, loss is 0.0012485848274081945\n",
      "epoch: 25 step: 294, loss is 0.0006796507514081895\n",
      "epoch: 25 step: 295, loss is 0.000506790354847908\n",
      "epoch: 25 step: 296, loss is 0.0003628569538705051\n",
      "epoch: 25 step: 297, loss is 7.445096707670018e-05\n",
      "epoch: 25 step: 298, loss is 0.0007419431349262595\n",
      "epoch: 25 step: 299, loss is 0.0013610683381557465\n",
      "epoch: 25 step: 300, loss is 0.0004467148974072188\n",
      "epoch: 25 step: 301, loss is 0.0008042644476518035\n",
      "epoch: 25 step: 302, loss is 0.0007520610233768821\n",
      "epoch: 25 step: 303, loss is 0.0007486575632356107\n",
      "epoch: 25 step: 304, loss is 0.0006301808170974255\n",
      "epoch: 25 step: 305, loss is 0.0009715455234982073\n",
      "epoch: 25 step: 306, loss is 0.001111068413592875\n",
      "epoch: 25 step: 307, loss is 0.0006597510073333979\n",
      "epoch: 25 step: 308, loss is 0.0002725109807215631\n",
      "epoch: 25 step: 309, loss is 0.0006155013106763363\n",
      "epoch: 25 step: 310, loss is 0.000979623873718083\n",
      "epoch: 25 step: 311, loss is 0.0005708562093786895\n",
      "epoch: 25 step: 312, loss is 0.0007763112080283463\n",
      "epoch: 25 step: 313, loss is 0.0009076306014321744\n",
      "epoch: 25 step: 314, loss is 0.0006127082160674036\n",
      "epoch: 25 step: 315, loss is 0.0004158896626904607\n",
      "epoch: 25 step: 316, loss is 0.0007231629570014775\n",
      "epoch: 25 step: 317, loss is 0.000620365550275892\n",
      "epoch: 25 step: 318, loss is 0.0006895895930938423\n",
      "epoch: 25 step: 319, loss is 0.0005957665853202343\n",
      "epoch: 25 step: 320, loss is 0.0003881388111039996\n",
      "epoch: 25 step: 321, loss is 0.0003385089512448758\n",
      "epoch: 25 step: 322, loss is 0.0006903769099153578\n",
      "epoch: 25 step: 323, loss is 0.0003567803360056132\n",
      "epoch: 25 step: 324, loss is 0.0007767609786242247\n",
      "epoch: 25 step: 325, loss is 0.00033119713771156967\n",
      "epoch: 25 step: 326, loss is 0.0005974705563858151\n",
      "epoch: 25 step: 327, loss is 0.0015324100386351347\n",
      "epoch: 25 step: 328, loss is 0.0002547984186094254\n",
      "epoch: 25 step: 329, loss is 0.0008438137592747808\n",
      "epoch: 25 step: 330, loss is 0.0007176465587690473\n",
      "epoch: 25 step: 331, loss is 0.0002744772646110505\n",
      "epoch: 25 step: 332, loss is 0.0006451608496718109\n",
      "epoch: 25 step: 333, loss is 0.0010264773154631257\n",
      "epoch: 25 step: 334, loss is 0.0007162196561694145\n",
      "epoch: 25 step: 335, loss is 0.000577845610678196\n",
      "epoch: 25 step: 336, loss is 0.001089849742129445\n",
      "epoch: 25 step: 337, loss is 0.0003329339378979057\n",
      "epoch: 25 step: 338, loss is 0.000698908930644393\n",
      "epoch: 25 step: 339, loss is 0.0003371384518686682\n",
      "epoch: 25 step: 340, loss is 0.000608290545642376\n",
      "epoch: 25 step: 341, loss is 0.001146563095971942\n",
      "epoch: 25 step: 342, loss is 0.000581613858230412\n",
      "epoch: 25 step: 343, loss is 0.0006526954239234328\n",
      "epoch: 25 step: 344, loss is 0.0002186706697102636\n",
      "epoch: 25 step: 345, loss is 0.0020386893302202225\n",
      "epoch: 25 step: 346, loss is 0.001896361238323152\n",
      "epoch: 25 step: 347, loss is 0.0006390026537701488\n",
      "epoch: 25 step: 348, loss is 0.0008468689047731459\n",
      "epoch: 25 step: 349, loss is 0.0004629149625543505\n",
      "epoch: 25 step: 350, loss is 0.0005154434475116432\n",
      "epoch: 25 step: 351, loss is 0.0006802636780776083\n",
      "epoch: 25 step: 352, loss is 0.0003668720310088247\n",
      "epoch: 25 step: 353, loss is 0.0006579020409844816\n",
      "epoch: 25 step: 354, loss is 0.00048735790187492967\n",
      "epoch: 25 step: 355, loss is 0.0003445122274570167\n",
      "epoch: 25 step: 356, loss is 0.0005295054288581014\n",
      "epoch: 25 step: 357, loss is 0.0005474695353768766\n",
      "epoch: 25 step: 358, loss is 0.00035865133395418525\n",
      "epoch: 25 step: 359, loss is 0.0009732360485941172\n",
      "epoch: 25 step: 360, loss is 0.0006060067098587751\n",
      "epoch: 25 step: 361, loss is 0.0013618041994050145\n",
      "epoch: 25 step: 362, loss is 0.0007912905421108007\n",
      "epoch: 25 step: 363, loss is 0.0003893743269145489\n",
      "epoch: 25 step: 364, loss is 0.00031601425143890083\n",
      "epoch: 25 step: 365, loss is 0.0005791347939521074\n",
      "epoch: 25 step: 366, loss is 0.00035571574699133635\n",
      "epoch: 25 step: 367, loss is 0.0006624457309953868\n",
      "epoch: 25 step: 368, loss is 0.00041202871943823993\n",
      "epoch: 25 step: 369, loss is 0.0006310903117991984\n",
      "epoch: 25 step: 370, loss is 0.0013669864274561405\n",
      "epoch: 25 step: 371, loss is 0.0014491197653114796\n",
      "epoch: 25 step: 372, loss is 0.0011924008140340447\n",
      "epoch: 25 step: 373, loss is 0.00043177808402106166\n",
      "epoch: 25 step: 374, loss is 0.0014219952281564474\n",
      "epoch: 25 step: 375, loss is 0.0006395054515451193\n",
      "Train epoch time: 12056.299 ms, per step time: 32.150 ms\n",
      "epoch: 26 step: 1, loss is 0.0004903894732706249\n",
      "epoch: 26 step: 2, loss is 0.0004306849732529372\n",
      "epoch: 26 step: 3, loss is 0.0010007410310208797\n",
      "epoch: 26 step: 4, loss is 0.00093829445540905\n",
      "epoch: 26 step: 5, loss is 0.001196700963191688\n",
      "epoch: 26 step: 6, loss is 0.0006702121463604271\n",
      "epoch: 26 step: 7, loss is 0.00032327554072253406\n",
      "epoch: 26 step: 8, loss is 0.0002825568662956357\n",
      "epoch: 26 step: 9, loss is 0.00039087742334231734\n",
      "epoch: 26 step: 10, loss is 0.0006371678318828344\n",
      "epoch: 26 step: 11, loss is 0.0009390369523316622\n",
      "epoch: 26 step: 12, loss is 0.00026219949359074235\n",
      "epoch: 26 step: 13, loss is 0.000521245354320854\n",
      "epoch: 26 step: 14, loss is 0.00044063746463507414\n",
      "epoch: 26 step: 15, loss is 0.0005333232693374157\n",
      "epoch: 26 step: 16, loss is 0.0008975958917289972\n",
      "epoch: 26 step: 17, loss is 0.0006354802753776312\n",
      "epoch: 26 step: 18, loss is 0.00030801614047959447\n",
      "epoch: 26 step: 19, loss is 0.0002626313653308898\n",
      "epoch: 26 step: 20, loss is 0.00035237721749581397\n",
      "epoch: 26 step: 21, loss is 0.0007629277533851564\n",
      "epoch: 26 step: 22, loss is 0.0005069857579655945\n",
      "epoch: 26 step: 23, loss is 0.0014448883011937141\n",
      "epoch: 26 step: 24, loss is 0.0010905395029112697\n",
      "epoch: 26 step: 25, loss is 0.00033921271096915007\n",
      "epoch: 26 step: 26, loss is 0.0004610730102285743\n",
      "epoch: 26 step: 27, loss is 0.000584907887969166\n",
      "epoch: 26 step: 28, loss is 0.0003837933763861656\n",
      "epoch: 26 step: 29, loss is 0.0005095385713502765\n",
      "epoch: 26 step: 30, loss is 0.00032463204115629196\n",
      "epoch: 26 step: 31, loss is 0.0011228625662624836\n",
      "epoch: 26 step: 32, loss is 0.0005322772194631398\n",
      "epoch: 26 step: 33, loss is 0.00038017466431483626\n",
      "epoch: 26 step: 34, loss is 0.0007125666597858071\n",
      "epoch: 26 step: 35, loss is 0.0006311945035122335\n",
      "epoch: 26 step: 36, loss is 0.0004988124128431082\n",
      "epoch: 26 step: 37, loss is 0.00043643539538607\n",
      "epoch: 26 step: 38, loss is 0.0007669375627301633\n",
      "epoch: 26 step: 39, loss is 0.000578353472519666\n",
      "epoch: 26 step: 40, loss is 0.00019827738287858665\n",
      "epoch: 26 step: 41, loss is 0.0010282802395522594\n",
      "epoch: 26 step: 42, loss is 0.00024939962895587087\n",
      "epoch: 26 step: 43, loss is 0.00034541208879090846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 step: 44, loss is 0.001199719263240695\n",
      "epoch: 26 step: 45, loss is 0.0008345892420038581\n",
      "epoch: 26 step: 46, loss is 0.0013993344036862254\n",
      "epoch: 26 step: 47, loss is 0.001234331401064992\n",
      "epoch: 26 step: 48, loss is 0.0004045841924380511\n",
      "epoch: 26 step: 49, loss is 0.0005942674470134079\n",
      "epoch: 26 step: 50, loss is 0.0005719566252082586\n",
      "epoch: 26 step: 51, loss is 0.0009397579124197364\n",
      "epoch: 26 step: 52, loss is 0.0005454274360090494\n",
      "epoch: 26 step: 53, loss is 0.000966485298704356\n",
      "epoch: 26 step: 54, loss is 0.0006133854039944708\n",
      "epoch: 26 step: 55, loss is 0.0013141812523826957\n",
      "epoch: 26 step: 56, loss is 0.0009345543221570551\n",
      "epoch: 26 step: 57, loss is 0.0007620056858286262\n",
      "epoch: 26 step: 58, loss is 0.0005953077925369143\n",
      "epoch: 26 step: 59, loss is 0.000578166451305151\n",
      "epoch: 26 step: 60, loss is 0.0013177705695852637\n",
      "epoch: 26 step: 61, loss is 0.0009971263352781534\n",
      "epoch: 26 step: 62, loss is 0.00017672225658316165\n",
      "epoch: 26 step: 63, loss is 0.00021432848006952554\n",
      "epoch: 26 step: 64, loss is 0.0002494183136150241\n",
      "epoch: 26 step: 65, loss is 0.00021334523626137525\n",
      "epoch: 26 step: 66, loss is 0.0002906876034103334\n",
      "epoch: 26 step: 67, loss is 0.0006342619890347123\n",
      "epoch: 26 step: 68, loss is 0.0006941897445358336\n",
      "epoch: 26 step: 69, loss is 0.0003971167025156319\n",
      "epoch: 26 step: 70, loss is 0.0007081674411892891\n",
      "epoch: 26 step: 71, loss is 0.0003316345682833344\n",
      "epoch: 26 step: 72, loss is 0.0006176166352815926\n",
      "epoch: 26 step: 73, loss is 0.000927262706682086\n",
      "epoch: 26 step: 74, loss is 0.0010755297262221575\n",
      "epoch: 26 step: 75, loss is 0.0004091541632078588\n",
      "epoch: 26 step: 76, loss is 0.0002533565566409379\n",
      "epoch: 26 step: 77, loss is 0.0009583957144059241\n",
      "epoch: 26 step: 78, loss is 0.0004744121397379786\n",
      "epoch: 26 step: 79, loss is 0.000351023772964254\n",
      "epoch: 26 step: 80, loss is 0.0005039366078563035\n",
      "epoch: 26 step: 81, loss is 0.000818339001853019\n",
      "epoch: 26 step: 82, loss is 0.00026796164456754923\n",
      "epoch: 26 step: 83, loss is 0.0013524858513846993\n",
      "epoch: 26 step: 84, loss is 0.0002785272372420877\n",
      "epoch: 26 step: 85, loss is 0.00041081607923842967\n",
      "epoch: 26 step: 86, loss is 0.0013544290559366345\n",
      "epoch: 26 step: 87, loss is 0.0002909529721364379\n",
      "epoch: 26 step: 88, loss is 0.0014967622701078653\n",
      "epoch: 26 step: 89, loss is 0.0011481413384899497\n",
      "epoch: 26 step: 90, loss is 0.00045837712241336703\n",
      "epoch: 26 step: 91, loss is 0.0002694103168323636\n",
      "epoch: 26 step: 92, loss is 0.0009966320358216763\n",
      "epoch: 26 step: 93, loss is 0.00023176305694505572\n",
      "epoch: 26 step: 94, loss is 0.0007420256151817739\n",
      "epoch: 26 step: 95, loss is 0.0010237212991341949\n",
      "epoch: 26 step: 96, loss is 0.0008475259528495371\n",
      "epoch: 26 step: 97, loss is 0.00019460442126728594\n",
      "epoch: 26 step: 98, loss is 0.0009242352098226547\n",
      "epoch: 26 step: 99, loss is 0.0009679581853561103\n",
      "epoch: 26 step: 100, loss is 0.0007559743826277554\n",
      "epoch: 26 step: 101, loss is 0.0007065865211188793\n",
      "epoch: 26 step: 102, loss is 0.0004237329703755677\n",
      "epoch: 26 step: 103, loss is 0.0015913876704871655\n",
      "epoch: 26 step: 104, loss is 0.0006559453322552145\n",
      "epoch: 26 step: 105, loss is 0.0002290351694682613\n",
      "epoch: 26 step: 106, loss is 0.0009690761798992753\n",
      "epoch: 26 step: 107, loss is 0.0010965581750497222\n",
      "epoch: 26 step: 108, loss is 0.00020967899763491005\n",
      "epoch: 26 step: 109, loss is 0.0005594498361460865\n",
      "epoch: 26 step: 110, loss is 0.0006204318488016725\n",
      "epoch: 26 step: 111, loss is 0.0003465078480076045\n",
      "epoch: 26 step: 112, loss is 0.000904834596440196\n",
      "epoch: 26 step: 113, loss is 0.0005346479010768235\n",
      "epoch: 26 step: 114, loss is 0.0005305517115630209\n",
      "epoch: 26 step: 115, loss is 0.00028512696735560894\n",
      "epoch: 26 step: 116, loss is 0.0003688001015689224\n",
      "epoch: 26 step: 117, loss is 0.0008870899328030646\n",
      "epoch: 26 step: 118, loss is 0.0007657482638023794\n",
      "epoch: 26 step: 119, loss is 0.0014779901830479503\n",
      "epoch: 26 step: 120, loss is 0.0008676411816850305\n",
      "epoch: 26 step: 121, loss is 0.0006037518032826483\n",
      "epoch: 26 step: 122, loss is 0.0004314263060223311\n",
      "epoch: 26 step: 123, loss is 0.0004014430451206863\n",
      "epoch: 26 step: 124, loss is 0.0006095994031056762\n",
      "epoch: 26 step: 125, loss is 0.00024829088943079114\n",
      "epoch: 26 step: 126, loss is 0.0007351104868575931\n",
      "epoch: 26 step: 127, loss is 0.0007007244857959449\n",
      "epoch: 26 step: 128, loss is 0.0007091258303262293\n",
      "epoch: 26 step: 129, loss is 0.0005661531467922032\n",
      "epoch: 26 step: 130, loss is 0.000520434055943042\n",
      "epoch: 26 step: 131, loss is 0.0007363823242485523\n",
      "epoch: 26 step: 132, loss is 0.0006366725428961217\n",
      "epoch: 26 step: 133, loss is 0.0010268978076055646\n",
      "epoch: 26 step: 134, loss is 0.0007124560070224106\n",
      "epoch: 26 step: 135, loss is 0.0008685414795763791\n",
      "epoch: 26 step: 136, loss is 0.0007494870806112885\n",
      "epoch: 26 step: 137, loss is 0.0017760137561708689\n",
      "epoch: 26 step: 138, loss is 0.00018586590886116028\n",
      "epoch: 26 step: 139, loss is 0.0002796876651700586\n",
      "epoch: 26 step: 140, loss is 0.0008475521462969482\n",
      "epoch: 26 step: 141, loss is 0.00042090940405614674\n",
      "epoch: 26 step: 142, loss is 0.0007223444990813732\n",
      "epoch: 26 step: 143, loss is 0.0005712143029086292\n",
      "epoch: 26 step: 144, loss is 0.0007766785565763712\n",
      "epoch: 26 step: 145, loss is 0.0003482240135781467\n",
      "epoch: 26 step: 146, loss is 0.0002039757528109476\n",
      "epoch: 26 step: 147, loss is 0.0007101306109689176\n",
      "epoch: 26 step: 148, loss is 0.0005092552746646106\n",
      "epoch: 26 step: 149, loss is 0.00026356783928349614\n",
      "epoch: 26 step: 150, loss is 0.0005166264600120485\n",
      "epoch: 26 step: 151, loss is 0.0006062475731596351\n",
      "epoch: 26 step: 152, loss is 0.00024539485457353294\n",
      "epoch: 26 step: 153, loss is 0.00036347482819110155\n",
      "epoch: 26 step: 154, loss is 0.001028480939567089\n",
      "epoch: 26 step: 155, loss is 0.0008263951749540865\n",
      "epoch: 26 step: 156, loss is 0.0010778451105579734\n",
      "epoch: 26 step: 157, loss is 0.0009099921444430947\n",
      "epoch: 26 step: 158, loss is 0.0010412582196295261\n",
      "epoch: 26 step: 159, loss is 0.00031872958061285317\n",
      "epoch: 26 step: 160, loss is 0.0004153053741902113\n",
      "epoch: 26 step: 161, loss is 0.0008098994730971754\n",
      "epoch: 26 step: 162, loss is 0.0023438665084540844\n",
      "epoch: 26 step: 163, loss is 0.0017431812593713403\n",
      "epoch: 26 step: 164, loss is 0.0006431647925637662\n",
      "epoch: 26 step: 165, loss is 0.0004647559253498912\n",
      "epoch: 26 step: 166, loss is 0.0007035933085717261\n",
      "epoch: 26 step: 167, loss is 0.0001852575660450384\n",
      "epoch: 26 step: 168, loss is 0.000525788520462811\n",
      "epoch: 26 step: 169, loss is 0.0011108058970421553\n",
      "epoch: 26 step: 170, loss is 0.001650722580961883\n",
      "epoch: 26 step: 171, loss is 0.0007443162030540407\n",
      "epoch: 26 step: 172, loss is 0.00024828340974636376\n",
      "epoch: 26 step: 173, loss is 0.0007937931804917753\n",
      "epoch: 26 step: 174, loss is 0.00079472700599581\n",
      "epoch: 26 step: 175, loss is 0.00018649440607987344\n",
      "epoch: 26 step: 176, loss is 0.0008071504416875541\n",
      "epoch: 26 step: 177, loss is 0.0002506281598471105\n",
      "epoch: 26 step: 178, loss is 0.000300477520795539\n",
      "epoch: 26 step: 179, loss is 0.0007663763826712966\n",
      "epoch: 26 step: 180, loss is 0.0008422466344200075\n",
      "epoch: 26 step: 181, loss is 0.0017472332110628486\n",
      "epoch: 26 step: 182, loss is 0.0004317809361964464\n",
      "epoch: 26 step: 183, loss is 0.0005205970373935997\n",
      "epoch: 26 step: 184, loss is 0.0003865320759359747\n",
      "epoch: 26 step: 185, loss is 0.001116267405450344\n",
      "epoch: 26 step: 186, loss is 0.00040349000482819974\n",
      "epoch: 26 step: 187, loss is 0.0006705780397169292\n",
      "epoch: 26 step: 188, loss is 0.00046975925215519965\n",
      "epoch: 26 step: 189, loss is 0.0006592617137357593\n",
      "epoch: 26 step: 190, loss is 0.000684256898239255\n",
      "epoch: 26 step: 191, loss is 0.0007598525262437761\n",
      "epoch: 26 step: 192, loss is 0.0007279491983354092\n",
      "epoch: 26 step: 193, loss is 0.0005858087679371238\n",
      "epoch: 26 step: 194, loss is 0.0005705885123461485\n",
      "epoch: 26 step: 195, loss is 0.00023569392214994878\n",
      "epoch: 26 step: 196, loss is 0.00048629086813889444\n",
      "epoch: 26 step: 197, loss is 0.00040161830838769674\n",
      "epoch: 26 step: 198, loss is 0.0006259045330807567\n",
      "epoch: 26 step: 199, loss is 0.0008134162635542452\n",
      "epoch: 26 step: 200, loss is 0.0006307721487246454\n",
      "epoch: 26 step: 201, loss is 0.0005538953701034188\n",
      "epoch: 26 step: 202, loss is 0.0008625000482425094\n",
      "epoch: 26 step: 203, loss is 0.0010641815606504679\n",
      "epoch: 26 step: 204, loss is 0.0008369846036657691\n",
      "epoch: 26 step: 205, loss is 0.00043264374835416675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 step: 206, loss is 0.0012082763714715838\n",
      "epoch: 26 step: 207, loss is 0.0006505976198241115\n",
      "epoch: 26 step: 208, loss is 0.0006461554439738393\n",
      "epoch: 26 step: 209, loss is 0.0009065603371709585\n",
      "epoch: 26 step: 210, loss is 0.0004898785846307874\n",
      "epoch: 26 step: 211, loss is 0.0007583326078020036\n",
      "epoch: 26 step: 212, loss is 0.0003700822126120329\n",
      "epoch: 26 step: 213, loss is 0.0005999725544825196\n",
      "epoch: 26 step: 214, loss is 0.0008940643165260553\n",
      "epoch: 26 step: 215, loss is 0.000614817370660603\n",
      "epoch: 26 step: 216, loss is 0.0004311297961976379\n",
      "epoch: 26 step: 217, loss is 0.001300828531384468\n",
      "epoch: 26 step: 218, loss is 0.00048597477143630385\n",
      "epoch: 26 step: 219, loss is 0.000730502069927752\n",
      "epoch: 26 step: 220, loss is 0.0004961195518262684\n",
      "epoch: 26 step: 221, loss is 0.0014590787468478084\n",
      "epoch: 26 step: 222, loss is 0.0011792200384661555\n",
      "epoch: 26 step: 223, loss is 0.0002771994040813297\n",
      "epoch: 26 step: 224, loss is 0.0004860087647102773\n",
      "epoch: 26 step: 225, loss is 0.0002446942962706089\n",
      "epoch: 26 step: 226, loss is 0.0007243951549753547\n",
      "epoch: 26 step: 227, loss is 0.0007263925508596003\n",
      "epoch: 26 step: 228, loss is 0.0010540233924984932\n",
      "epoch: 26 step: 229, loss is 0.001604773453436792\n",
      "epoch: 26 step: 230, loss is 0.0005697400774806738\n",
      "epoch: 26 step: 231, loss is 0.0004623608256224543\n",
      "epoch: 26 step: 232, loss is 0.00023639782739337534\n",
      "epoch: 26 step: 233, loss is 0.00037002807948738337\n",
      "epoch: 26 step: 234, loss is 0.0011415641056373715\n",
      "epoch: 26 step: 235, loss is 0.0004750443040393293\n",
      "epoch: 26 step: 236, loss is 0.00040536781307309866\n",
      "epoch: 26 step: 237, loss is 0.000578348757699132\n",
      "epoch: 26 step: 238, loss is 0.0003413843805901706\n",
      "epoch: 26 step: 239, loss is 0.00048082321882247925\n",
      "epoch: 26 step: 240, loss is 0.0017223020549863577\n",
      "epoch: 26 step: 241, loss is 0.0013357079587876797\n",
      "epoch: 26 step: 242, loss is 0.00040742725832387805\n",
      "epoch: 26 step: 243, loss is 0.0001280336728086695\n",
      "epoch: 26 step: 244, loss is 0.0005970668280497193\n",
      "epoch: 26 step: 245, loss is 0.0002838952641468495\n",
      "epoch: 26 step: 246, loss is 0.0004651892522815615\n",
      "epoch: 26 step: 247, loss is 0.0003239221405237913\n",
      "epoch: 26 step: 248, loss is 0.00041877973126247525\n",
      "epoch: 26 step: 249, loss is 0.001344849355518818\n",
      "epoch: 26 step: 250, loss is 0.00021116939024068415\n",
      "epoch: 26 step: 251, loss is 0.0007185682188719511\n",
      "epoch: 26 step: 252, loss is 0.0014664055779576302\n",
      "epoch: 26 step: 253, loss is 0.0005757618346251547\n",
      "epoch: 26 step: 254, loss is 0.0016431515105068684\n",
      "epoch: 26 step: 255, loss is 0.0006260728114284575\n",
      "epoch: 26 step: 256, loss is 0.0003933748812414706\n",
      "epoch: 26 step: 257, loss is 0.00021585549984592944\n",
      "epoch: 26 step: 258, loss is 0.0004032646247651428\n",
      "epoch: 26 step: 259, loss is 0.0011655252892524004\n",
      "epoch: 26 step: 260, loss is 0.0005791657604277134\n",
      "epoch: 26 step: 261, loss is 0.0007242147112265229\n",
      "epoch: 26 step: 262, loss is 0.001547211199067533\n",
      "epoch: 26 step: 263, loss is 0.00021272199228405952\n",
      "epoch: 26 step: 264, loss is 0.00038618987309746444\n",
      "epoch: 26 step: 265, loss is 0.0005979756242595613\n",
      "epoch: 26 step: 266, loss is 0.0019000319298356771\n",
      "epoch: 26 step: 267, loss is 0.0009490253869444132\n",
      "epoch: 26 step: 268, loss is 0.0007077606278471649\n",
      "epoch: 26 step: 269, loss is 0.0002911633928306401\n",
      "epoch: 26 step: 270, loss is 0.00034389819484204054\n",
      "epoch: 26 step: 271, loss is 0.0007388306548818946\n",
      "epoch: 26 step: 272, loss is 0.000376941985450685\n",
      "epoch: 26 step: 273, loss is 0.0015600444748997688\n",
      "epoch: 26 step: 274, loss is 0.0006068611983209848\n",
      "epoch: 26 step: 275, loss is 0.00010701515566324815\n",
      "epoch: 26 step: 276, loss is 0.0001816617586882785\n",
      "epoch: 26 step: 277, loss is 0.0007778684957884252\n",
      "epoch: 26 step: 278, loss is 0.0006585321389138699\n",
      "epoch: 26 step: 279, loss is 0.0009439225541427732\n",
      "epoch: 26 step: 280, loss is 0.0007377609144896269\n",
      "epoch: 26 step: 281, loss is 0.0011688523227348924\n",
      "epoch: 26 step: 282, loss is 0.0010543259559199214\n",
      "epoch: 26 step: 283, loss is 0.0008777316543273628\n",
      "epoch: 26 step: 284, loss is 0.0004304472531657666\n",
      "epoch: 26 step: 285, loss is 0.0013752703089267015\n",
      "epoch: 26 step: 286, loss is 0.0010378867154940963\n",
      "epoch: 26 step: 287, loss is 0.0007363494951277971\n",
      "epoch: 26 step: 288, loss is 0.0003247488057240844\n",
      "epoch: 26 step: 289, loss is 0.0014452416216954589\n",
      "epoch: 26 step: 290, loss is 0.00022705674928147346\n",
      "epoch: 26 step: 291, loss is 0.002042326843366027\n",
      "epoch: 26 step: 292, loss is 0.000637852936051786\n",
      "epoch: 26 step: 293, loss is 0.0018984309863299131\n",
      "epoch: 26 step: 294, loss is 0.0008528599282726645\n",
      "epoch: 26 step: 295, loss is 0.0008526872261427343\n",
      "epoch: 26 step: 296, loss is 0.00020214534015394747\n",
      "epoch: 26 step: 297, loss is 0.0006863599992357194\n",
      "epoch: 26 step: 298, loss is 0.0006877610576339066\n",
      "epoch: 26 step: 299, loss is 0.001115360646508634\n",
      "epoch: 26 step: 300, loss is 0.0006095059798099101\n",
      "epoch: 26 step: 301, loss is 0.001267140731215477\n",
      "epoch: 26 step: 302, loss is 0.00032248542993329465\n",
      "epoch: 26 step: 303, loss is 0.000776420347392559\n",
      "epoch: 26 step: 304, loss is 0.0007352355751208961\n",
      "epoch: 26 step: 305, loss is 0.00036354176700115204\n",
      "epoch: 26 step: 306, loss is 0.0013689943589270115\n",
      "epoch: 26 step: 307, loss is 0.0011116571258753538\n",
      "epoch: 26 step: 308, loss is 0.0005509491311386228\n",
      "epoch: 26 step: 309, loss is 0.0004191845946479589\n",
      "epoch: 26 step: 310, loss is 0.0007088476559147239\n",
      "epoch: 26 step: 311, loss is 0.0005220953025855124\n",
      "epoch: 26 step: 312, loss is 0.00019108540436718613\n",
      "epoch: 26 step: 313, loss is 0.0006694888579659164\n",
      "epoch: 26 step: 314, loss is 0.0007824109634384513\n",
      "epoch: 26 step: 315, loss is 0.000793737533967942\n",
      "epoch: 26 step: 316, loss is 0.0005719595937989652\n",
      "epoch: 26 step: 317, loss is 0.0008215380948968232\n",
      "epoch: 26 step: 318, loss is 0.0009868510533124208\n",
      "epoch: 26 step: 319, loss is 0.0006986523512750864\n",
      "epoch: 26 step: 320, loss is 0.000494317093398422\n",
      "epoch: 26 step: 321, loss is 0.0007618886884301901\n",
      "epoch: 26 step: 322, loss is 0.0009806921007111669\n",
      "epoch: 26 step: 323, loss is 0.00040076757431961596\n",
      "epoch: 26 step: 324, loss is 0.0006497650756500661\n",
      "epoch: 26 step: 325, loss is 0.0015869165072217584\n",
      "epoch: 26 step: 326, loss is 0.0007064552046358585\n",
      "epoch: 26 step: 327, loss is 0.0002899670507758856\n",
      "epoch: 26 step: 328, loss is 0.00032513824407942593\n",
      "epoch: 26 step: 329, loss is 0.00015342464030254632\n",
      "epoch: 26 step: 330, loss is 0.000490271660964936\n",
      "epoch: 26 step: 331, loss is 0.0002695856965146959\n",
      "epoch: 26 step: 332, loss is 0.0007998972432687879\n",
      "epoch: 26 step: 333, loss is 0.0007186263101175427\n",
      "epoch: 26 step: 334, loss is 0.0005925099831074476\n",
      "epoch: 26 step: 335, loss is 0.0005663023330271244\n",
      "epoch: 26 step: 336, loss is 0.0007202718988992274\n",
      "epoch: 26 step: 337, loss is 0.0006905301124788821\n",
      "epoch: 26 step: 338, loss is 0.0008209203951992095\n",
      "epoch: 26 step: 339, loss is 0.0006376415840350091\n",
      "epoch: 26 step: 340, loss is 5.060778130427934e-05\n",
      "epoch: 26 step: 341, loss is 0.0005488727474585176\n",
      "epoch: 26 step: 342, loss is 0.0007143835537135601\n",
      "epoch: 26 step: 343, loss is 0.0005415527266450226\n",
      "epoch: 26 step: 344, loss is 0.0007212549680843949\n",
      "epoch: 26 step: 345, loss is 0.0006213060696609318\n",
      "epoch: 26 step: 346, loss is 0.0007892033900134265\n",
      "epoch: 26 step: 347, loss is 0.0005425744457170367\n",
      "epoch: 26 step: 348, loss is 0.0005358547205105424\n",
      "epoch: 26 step: 349, loss is 0.0015946775674819946\n",
      "epoch: 26 step: 350, loss is 0.0004305957118049264\n",
      "epoch: 26 step: 351, loss is 0.0007866990636102855\n",
      "epoch: 26 step: 352, loss is 0.000674389477353543\n",
      "epoch: 26 step: 353, loss is 0.0008181054145097733\n",
      "epoch: 26 step: 354, loss is 0.00035846265382133424\n",
      "epoch: 26 step: 355, loss is 0.0012854274827986956\n",
      "epoch: 26 step: 356, loss is 0.0005931639461778104\n",
      "epoch: 26 step: 357, loss is 0.0002284256916027516\n",
      "epoch: 26 step: 358, loss is 0.0004988022847101092\n",
      "epoch: 26 step: 359, loss is 0.0009103714255616069\n",
      "epoch: 26 step: 360, loss is 0.0004505495307967067\n",
      "epoch: 26 step: 361, loss is 0.0006877739797346294\n",
      "epoch: 26 step: 362, loss is 0.0009378794929943979\n",
      "epoch: 26 step: 363, loss is 0.0005323709920048714\n",
      "epoch: 26 step: 364, loss is 0.0009280836093239486\n",
      "epoch: 26 step: 365, loss is 0.0008733286522328854\n",
      "epoch: 26 step: 366, loss is 0.0010406478540971875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 step: 367, loss is 0.0007360837189480662\n",
      "epoch: 26 step: 368, loss is 0.00043691316386684775\n",
      "epoch: 26 step: 369, loss is 0.0006845888565294445\n",
      "epoch: 26 step: 370, loss is 0.00041155843064188957\n",
      "epoch: 26 step: 371, loss is 0.00015144604549277574\n",
      "epoch: 26 step: 372, loss is 0.000433777691796422\n",
      "epoch: 26 step: 373, loss is 0.001005914411507547\n",
      "epoch: 26 step: 374, loss is 0.001050146296620369\n",
      "epoch: 26 step: 375, loss is 0.0005858587683178484\n",
      "Train epoch time: 11948.751 ms, per step time: 31.863 ms\n",
      "epoch: 27 step: 1, loss is 0.0006847198819741607\n",
      "epoch: 27 step: 2, loss is 0.00016422798216808587\n",
      "epoch: 27 step: 3, loss is 0.0002965938183479011\n",
      "epoch: 27 step: 4, loss is 0.00036573444958776236\n",
      "epoch: 27 step: 5, loss is 0.000570404517930001\n",
      "epoch: 27 step: 6, loss is 0.000336565135512501\n",
      "epoch: 27 step: 7, loss is 0.0006225286051630974\n",
      "epoch: 27 step: 8, loss is 0.000721114338375628\n",
      "epoch: 27 step: 9, loss is 0.00033160901512019336\n",
      "epoch: 27 step: 10, loss is 0.0008121642167679965\n",
      "epoch: 27 step: 11, loss is 0.0006535945576615632\n",
      "epoch: 27 step: 12, loss is 0.0005715902661904693\n",
      "epoch: 27 step: 13, loss is 0.0025783879682421684\n",
      "epoch: 27 step: 14, loss is 0.0015012213261798024\n",
      "epoch: 27 step: 15, loss is 0.0006348802126012743\n",
      "epoch: 27 step: 16, loss is 0.0012005600146949291\n",
      "epoch: 27 step: 17, loss is 0.00026951381005346775\n",
      "epoch: 27 step: 18, loss is 0.0007830134709365666\n",
      "epoch: 27 step: 19, loss is 0.0006186802056618035\n",
      "epoch: 27 step: 20, loss is 0.0014564102748408914\n",
      "epoch: 27 step: 21, loss is 0.0003990266122855246\n",
      "epoch: 27 step: 22, loss is 0.00048277381574735045\n",
      "epoch: 27 step: 23, loss is 0.0008911704062484205\n",
      "epoch: 27 step: 24, loss is 0.0006863691960461438\n",
      "epoch: 27 step: 25, loss is 0.00045056705130264163\n",
      "epoch: 27 step: 26, loss is 0.001183958607725799\n",
      "epoch: 27 step: 27, loss is 0.0003051955427508801\n",
      "epoch: 27 step: 28, loss is 0.0012258918723091483\n",
      "epoch: 27 step: 29, loss is 0.0004550776502583176\n",
      "epoch: 27 step: 30, loss is 0.0011371731525287032\n",
      "epoch: 27 step: 31, loss is 0.0005059722461737692\n",
      "epoch: 27 step: 32, loss is 0.0005324220983311534\n",
      "epoch: 27 step: 33, loss is 0.0003620073548518121\n",
      "epoch: 27 step: 34, loss is 0.00033794756745919585\n",
      "epoch: 27 step: 35, loss is 0.0006299909437075257\n",
      "epoch: 27 step: 36, loss is 0.00030421101837418973\n",
      "epoch: 27 step: 37, loss is 0.0011807798873633146\n",
      "epoch: 27 step: 38, loss is 0.0010973872849717736\n",
      "epoch: 27 step: 39, loss is 0.00045562544255517423\n",
      "epoch: 27 step: 40, loss is 0.0006129161338321865\n",
      "epoch: 27 step: 41, loss is 0.00017423507233615965\n",
      "epoch: 27 step: 42, loss is 0.0002003483532462269\n",
      "epoch: 27 step: 43, loss is 0.00031549163395538926\n",
      "epoch: 27 step: 44, loss is 0.0010940941283479333\n",
      "epoch: 27 step: 45, loss is 0.0006657430785708129\n",
      "epoch: 27 step: 46, loss is 0.0003398010157980025\n",
      "epoch: 27 step: 47, loss is 0.0003717525105457753\n",
      "epoch: 27 step: 48, loss is 0.0008004758274182677\n",
      "epoch: 27 step: 49, loss is 0.0008391554583795369\n",
      "epoch: 27 step: 50, loss is 0.00042134991963393986\n",
      "epoch: 27 step: 51, loss is 0.00042687711538746953\n",
      "epoch: 27 step: 52, loss is 0.0007069010171107948\n",
      "epoch: 27 step: 53, loss is 0.000617952027823776\n",
      "epoch: 27 step: 54, loss is 0.00014921971887815744\n",
      "epoch: 27 step: 55, loss is 0.00029240897856652737\n",
      "epoch: 27 step: 56, loss is 0.0009277599165216088\n",
      "epoch: 27 step: 57, loss is 0.0011892663314938545\n",
      "epoch: 27 step: 58, loss is 0.00012548886297736317\n",
      "epoch: 27 step: 59, loss is 0.0009700493537820876\n",
      "epoch: 27 step: 60, loss is 0.0005811913870275021\n",
      "epoch: 27 step: 61, loss is 0.0006835237145423889\n",
      "epoch: 27 step: 62, loss is 0.0006802167627029121\n",
      "epoch: 27 step: 63, loss is 0.0007564876577816904\n",
      "epoch: 27 step: 64, loss is 0.0003403992741368711\n",
      "epoch: 27 step: 65, loss is 0.0009069719235412776\n",
      "epoch: 27 step: 66, loss is 0.00021561063476838171\n",
      "epoch: 27 step: 67, loss is 0.0006510565290227532\n",
      "epoch: 27 step: 68, loss is 0.0009567722445353866\n",
      "epoch: 27 step: 69, loss is 0.0003361855633556843\n",
      "epoch: 27 step: 70, loss is 0.0005014694179408252\n",
      "epoch: 27 step: 71, loss is 0.0016068064142018557\n",
      "epoch: 27 step: 72, loss is 0.0009291840833611786\n",
      "epoch: 27 step: 73, loss is 0.0008403241517953575\n",
      "epoch: 27 step: 74, loss is 0.0005060447729192674\n",
      "epoch: 27 step: 75, loss is 0.0011704578064382076\n",
      "epoch: 27 step: 76, loss is 0.0003376924723852426\n",
      "epoch: 27 step: 77, loss is 0.000672962109092623\n",
      "epoch: 27 step: 78, loss is 0.0014817413175478578\n",
      "epoch: 27 step: 79, loss is 0.00018623254436533898\n",
      "epoch: 27 step: 80, loss is 0.0018206258537247777\n",
      "epoch: 27 step: 81, loss is 0.0004982263781130314\n",
      "epoch: 27 step: 82, loss is 0.0004943775711581111\n",
      "epoch: 27 step: 83, loss is 0.00028861637110821903\n",
      "epoch: 27 step: 84, loss is 0.0009921753080561757\n",
      "epoch: 27 step: 85, loss is 0.0015370313776656985\n",
      "epoch: 27 step: 86, loss is 0.0006617031758651137\n",
      "epoch: 27 step: 87, loss is 0.0006493423716165125\n",
      "epoch: 27 step: 88, loss is 0.0007006670930422843\n",
      "epoch: 27 step: 89, loss is 0.00036950086359865963\n",
      "epoch: 27 step: 90, loss is 0.0005935917724855244\n",
      "epoch: 27 step: 91, loss is 0.0005721822381019592\n",
      "epoch: 27 step: 92, loss is 0.0004848074459005147\n",
      "epoch: 27 step: 93, loss is 0.00022121872461866587\n",
      "epoch: 27 step: 94, loss is 0.0001742352033033967\n",
      "epoch: 27 step: 95, loss is 0.0005268171662464738\n",
      "epoch: 27 step: 96, loss is 0.0006255679181776941\n",
      "epoch: 27 step: 97, loss is 0.00082994723925367\n",
      "epoch: 27 step: 98, loss is 0.0011032765032723546\n",
      "epoch: 27 step: 99, loss is 0.0007565080304630101\n",
      "epoch: 27 step: 100, loss is 0.0006472108070738614\n",
      "epoch: 27 step: 101, loss is 0.0005534918163903058\n",
      "epoch: 27 step: 102, loss is 0.0008807521080598235\n",
      "epoch: 27 step: 103, loss is 0.00039442480192519724\n",
      "epoch: 27 step: 104, loss is 0.0013732530642300844\n",
      "epoch: 27 step: 105, loss is 0.0008608614443801343\n",
      "epoch: 27 step: 106, loss is 0.0006459433352574706\n",
      "epoch: 27 step: 107, loss is 0.0010071451542899013\n",
      "epoch: 27 step: 108, loss is 0.000566330854780972\n",
      "epoch: 27 step: 109, loss is 0.0005781904328614473\n",
      "epoch: 27 step: 110, loss is 0.0004933190648443997\n",
      "epoch: 27 step: 111, loss is 0.0007617322262376547\n",
      "epoch: 27 step: 112, loss is 0.0004944421234540641\n",
      "epoch: 27 step: 113, loss is 0.0005758324405178428\n",
      "epoch: 27 step: 114, loss is 0.0003105601645074785\n",
      "epoch: 27 step: 115, loss is 0.00040971001726575196\n",
      "epoch: 27 step: 116, loss is 0.00045780633809044957\n",
      "epoch: 27 step: 117, loss is 0.0004890977288596332\n",
      "epoch: 27 step: 118, loss is 0.0002124276215909049\n",
      "epoch: 27 step: 119, loss is 0.0005777639453299344\n",
      "epoch: 27 step: 120, loss is 0.00043681313400156796\n",
      "epoch: 27 step: 121, loss is 0.0007836217992007732\n",
      "epoch: 27 step: 122, loss is 0.0008647628128528595\n",
      "epoch: 27 step: 123, loss is 0.0008126355824060738\n",
      "epoch: 27 step: 124, loss is 0.0012066317722201347\n",
      "epoch: 27 step: 125, loss is 0.0009125855285674334\n",
      "epoch: 27 step: 126, loss is 0.000726470781955868\n",
      "epoch: 27 step: 127, loss is 0.0003377222747076303\n",
      "epoch: 27 step: 128, loss is 0.0010919864289462566\n",
      "epoch: 27 step: 129, loss is 0.00031765233143232763\n",
      "epoch: 27 step: 130, loss is 0.0010450538247823715\n",
      "epoch: 27 step: 131, loss is 0.0010838471353054047\n",
      "epoch: 27 step: 132, loss is 0.00032159165129996836\n",
      "epoch: 27 step: 133, loss is 0.0004449147963896394\n",
      "epoch: 27 step: 134, loss is 0.0009258887148462236\n",
      "epoch: 27 step: 135, loss is 0.001038114307448268\n",
      "epoch: 27 step: 136, loss is 0.0006388703477568924\n",
      "epoch: 27 step: 137, loss is 0.0004112173046451062\n",
      "epoch: 27 step: 138, loss is 0.0005736686289310455\n",
      "epoch: 27 step: 139, loss is 0.001217851066030562\n",
      "epoch: 27 step: 140, loss is 0.0004288123163860291\n",
      "epoch: 27 step: 141, loss is 0.000311020907247439\n",
      "epoch: 27 step: 142, loss is 0.0007272922666743398\n",
      "epoch: 27 step: 143, loss is 0.0011185159673914313\n",
      "epoch: 27 step: 144, loss is 0.0006633427692577243\n",
      "epoch: 27 step: 145, loss is 0.0007099222275428474\n",
      "epoch: 27 step: 146, loss is 0.00040219086804427207\n",
      "epoch: 27 step: 147, loss is 0.0009469743235968053\n",
      "epoch: 27 step: 148, loss is 0.00039454869693145156\n",
      "epoch: 27 step: 149, loss is 0.0015392302302643657\n",
      "epoch: 27 step: 150, loss is 0.0003138421743642539\n",
      "epoch: 27 step: 151, loss is 0.0005821340600959957\n",
      "epoch: 27 step: 152, loss is 0.0005496287485584617\n",
      "epoch: 27 step: 153, loss is 0.0007108335266821086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 step: 154, loss is 0.00034564518136903644\n",
      "epoch: 27 step: 155, loss is 0.0008319148910231888\n",
      "epoch: 27 step: 156, loss is 0.0009985261131078005\n",
      "epoch: 27 step: 157, loss is 0.0005497194360941648\n",
      "epoch: 27 step: 158, loss is 0.00031937044695951045\n",
      "epoch: 27 step: 159, loss is 0.0005503949359990656\n",
      "epoch: 27 step: 160, loss is 0.0004366611537989229\n",
      "epoch: 27 step: 161, loss is 0.00046329048927873373\n",
      "epoch: 27 step: 162, loss is 0.0012031018268316984\n",
      "epoch: 27 step: 163, loss is 9.634550224291161e-05\n",
      "epoch: 27 step: 164, loss is 0.0013225607108324766\n",
      "epoch: 27 step: 165, loss is 0.0005993397207930684\n",
      "epoch: 27 step: 166, loss is 0.0003377308021299541\n",
      "epoch: 27 step: 167, loss is 0.00024575283168815076\n",
      "epoch: 27 step: 168, loss is 0.0009896054398268461\n",
      "epoch: 27 step: 169, loss is 0.0008753339643590152\n",
      "epoch: 27 step: 170, loss is 0.0007612186600454152\n",
      "epoch: 27 step: 171, loss is 0.0005896860966458917\n",
      "epoch: 27 step: 172, loss is 0.0005974604282528162\n",
      "epoch: 27 step: 173, loss is 0.00045483914436772466\n",
      "epoch: 27 step: 174, loss is 0.0009854485979303718\n",
      "epoch: 27 step: 175, loss is 0.0006156763411127031\n",
      "epoch: 27 step: 176, loss is 0.0005159914726391435\n",
      "epoch: 27 step: 177, loss is 0.0004080826183781028\n",
      "epoch: 27 step: 178, loss is 0.001071046106517315\n",
      "epoch: 27 step: 179, loss is 0.00032435834873467684\n",
      "epoch: 27 step: 180, loss is 0.0006689144065603614\n",
      "epoch: 27 step: 181, loss is 0.0004153347108513117\n",
      "epoch: 27 step: 182, loss is 0.00035742184263654053\n",
      "epoch: 27 step: 183, loss is 0.00046077746083028615\n",
      "epoch: 27 step: 184, loss is 0.00034341757418587804\n",
      "epoch: 27 step: 185, loss is 0.0005987560143694282\n",
      "epoch: 27 step: 186, loss is 0.00022944142983760685\n",
      "epoch: 27 step: 187, loss is 0.0009899763390421867\n",
      "epoch: 27 step: 188, loss is 0.0007001323392614722\n",
      "epoch: 27 step: 189, loss is 0.0014608236961066723\n",
      "epoch: 27 step: 190, loss is 0.0010726980399340391\n",
      "epoch: 27 step: 191, loss is 0.0007969361613504589\n",
      "epoch: 27 step: 192, loss is 0.0007750284275971353\n",
      "epoch: 27 step: 193, loss is 0.0016247995663434267\n",
      "epoch: 27 step: 194, loss is 0.0002676061412785202\n",
      "epoch: 27 step: 195, loss is 0.0006759399548172951\n",
      "epoch: 27 step: 196, loss is 0.0011687595397233963\n",
      "epoch: 27 step: 197, loss is 0.0004402783524710685\n",
      "epoch: 27 step: 198, loss is 0.00011185987386852503\n",
      "epoch: 27 step: 199, loss is 0.000353969051502645\n",
      "epoch: 27 step: 200, loss is 0.000458936468930915\n",
      "epoch: 27 step: 201, loss is 0.00021360022947192192\n",
      "epoch: 27 step: 202, loss is 0.0007173960912041366\n",
      "epoch: 27 step: 203, loss is 0.0009285179548896849\n",
      "epoch: 27 step: 204, loss is 0.0013156753266230226\n",
      "epoch: 27 step: 205, loss is 0.0007823086925782263\n",
      "epoch: 27 step: 206, loss is 0.0007468016119673848\n",
      "epoch: 27 step: 207, loss is 0.0006455369293689728\n",
      "epoch: 27 step: 208, loss is 0.00028694214415736496\n",
      "epoch: 27 step: 209, loss is 0.0012600639602169394\n",
      "epoch: 27 step: 210, loss is 0.0006448974017985165\n",
      "epoch: 27 step: 211, loss is 0.0007811886025592685\n",
      "epoch: 27 step: 212, loss is 0.000574721023440361\n",
      "epoch: 27 step: 213, loss is 0.0009741878602653742\n",
      "epoch: 27 step: 214, loss is 0.00048433657502755523\n",
      "epoch: 27 step: 215, loss is 0.0008285104995593429\n",
      "epoch: 27 step: 216, loss is 0.0006692627212032676\n",
      "epoch: 27 step: 217, loss is 0.0002995802497025579\n",
      "epoch: 27 step: 218, loss is 0.000887873989995569\n",
      "epoch: 27 step: 219, loss is 0.00044311510282568634\n",
      "epoch: 27 step: 220, loss is 0.0014902277616783977\n",
      "epoch: 27 step: 221, loss is 0.0002322234504390508\n",
      "epoch: 27 step: 222, loss is 0.0007145247072912753\n",
      "epoch: 27 step: 223, loss is 0.001348133897408843\n",
      "epoch: 27 step: 224, loss is 0.0008610368240624666\n",
      "epoch: 27 step: 225, loss is 0.0005587721825577319\n",
      "epoch: 27 step: 226, loss is 0.00040102109778672457\n",
      "epoch: 27 step: 227, loss is 0.0013874274445697665\n",
      "epoch: 27 step: 228, loss is 0.00032488725264556706\n",
      "epoch: 27 step: 229, loss is 0.0006458202260546386\n",
      "epoch: 27 step: 230, loss is 0.0007788974326103926\n",
      "epoch: 27 step: 231, loss is 0.0008792239241302013\n",
      "epoch: 27 step: 232, loss is 0.0008144210441969335\n",
      "epoch: 27 step: 233, loss is 0.0007265338790602982\n",
      "epoch: 27 step: 234, loss is 0.0009007540647871792\n",
      "epoch: 27 step: 235, loss is 0.0006354753277264535\n",
      "epoch: 27 step: 236, loss is 0.000538826803676784\n",
      "epoch: 27 step: 237, loss is 0.0005025746650062501\n",
      "epoch: 27 step: 238, loss is 0.0009545694338157773\n",
      "epoch: 27 step: 239, loss is 0.0008089504553936422\n",
      "epoch: 27 step: 240, loss is 0.00101379188708961\n",
      "epoch: 27 step: 241, loss is 0.0005254659336060286\n",
      "epoch: 27 step: 242, loss is 0.0003574950678739697\n",
      "epoch: 27 step: 243, loss is 0.0013089794665575027\n",
      "epoch: 27 step: 244, loss is 0.0010079889325425029\n",
      "epoch: 27 step: 245, loss is 0.00035556478542275727\n",
      "epoch: 27 step: 246, loss is 0.000268300500465557\n",
      "epoch: 27 step: 247, loss is 0.0007488637929782271\n",
      "epoch: 27 step: 248, loss is 0.0005840797093696892\n",
      "epoch: 27 step: 249, loss is 0.0002352383016841486\n",
      "epoch: 27 step: 250, loss is 0.0004018592298962176\n",
      "epoch: 27 step: 251, loss is 0.0005394432228058577\n",
      "epoch: 27 step: 252, loss is 0.0010776801500469446\n",
      "epoch: 27 step: 253, loss is 0.0002868667070288211\n",
      "epoch: 27 step: 254, loss is 0.0005737805622629821\n",
      "epoch: 27 step: 255, loss is 0.0003826696192845702\n",
      "epoch: 27 step: 256, loss is 0.001434973906725645\n",
      "epoch: 27 step: 257, loss is 0.000325292901834473\n",
      "epoch: 27 step: 258, loss is 0.0008826946723274887\n",
      "epoch: 27 step: 259, loss is 0.00042703680810518563\n",
      "epoch: 27 step: 260, loss is 0.0010957799386233091\n",
      "epoch: 27 step: 261, loss is 0.0013991891173645854\n",
      "epoch: 27 step: 262, loss is 0.0005190938245505095\n",
      "epoch: 27 step: 263, loss is 0.0005807280540466309\n",
      "epoch: 27 step: 264, loss is 0.0008627992356196046\n",
      "epoch: 27 step: 265, loss is 0.0008950317278504372\n",
      "epoch: 27 step: 266, loss is 0.0013099992647767067\n",
      "epoch: 27 step: 267, loss is 0.0006775109213776886\n",
      "epoch: 27 step: 268, loss is 0.0005629235529340804\n",
      "epoch: 27 step: 269, loss is 0.0009095536079257727\n",
      "epoch: 27 step: 270, loss is 0.0006036986014805734\n",
      "epoch: 27 step: 271, loss is 0.0008553110528737307\n",
      "epoch: 27 step: 272, loss is 0.0013199106324464083\n",
      "epoch: 27 step: 273, loss is 0.0011050405446439981\n",
      "epoch: 27 step: 274, loss is 0.00042438754462637007\n",
      "epoch: 27 step: 275, loss is 0.0013518831692636013\n",
      "epoch: 27 step: 276, loss is 0.00011696617730194703\n",
      "epoch: 27 step: 277, loss is 0.000673153146635741\n",
      "epoch: 27 step: 278, loss is 0.00022172273020260036\n",
      "epoch: 27 step: 279, loss is 0.0004330948868300766\n",
      "epoch: 27 step: 280, loss is 0.0006872746744193137\n",
      "epoch: 27 step: 281, loss is 0.0005455425125546753\n",
      "epoch: 27 step: 282, loss is 0.001005561207421124\n",
      "epoch: 27 step: 283, loss is 0.0009566723019815981\n",
      "epoch: 27 step: 284, loss is 0.0005211757961660624\n",
      "epoch: 27 step: 285, loss is 0.0008131080539897084\n",
      "epoch: 27 step: 286, loss is 0.0005501919658854604\n",
      "epoch: 27 step: 287, loss is 0.000905719178263098\n",
      "epoch: 27 step: 288, loss is 0.0010613732738420367\n",
      "epoch: 27 step: 289, loss is 0.0004985575214959681\n",
      "epoch: 27 step: 290, loss is 0.0003599345509428531\n",
      "epoch: 27 step: 291, loss is 0.00046672101598232985\n",
      "epoch: 27 step: 292, loss is 0.000622803287114948\n",
      "epoch: 27 step: 293, loss is 0.0005705333314836025\n",
      "epoch: 27 step: 294, loss is 0.0017563237342983484\n",
      "epoch: 27 step: 295, loss is 0.0008275803411379457\n",
      "epoch: 27 step: 296, loss is 0.0006282026879489422\n",
      "epoch: 27 step: 297, loss is 0.0005312571884132922\n",
      "epoch: 27 step: 298, loss is 0.0005750229465775192\n",
      "epoch: 27 step: 299, loss is 0.0009021138539537787\n",
      "epoch: 27 step: 300, loss is 0.0016816029092296958\n",
      "epoch: 27 step: 301, loss is 0.0005937787937000394\n",
      "epoch: 27 step: 302, loss is 0.0003164555528201163\n",
      "epoch: 27 step: 303, loss is 0.0005029017920605838\n",
      "epoch: 27 step: 304, loss is 0.0008174476097337902\n",
      "epoch: 27 step: 305, loss is 0.0004457743198145181\n",
      "epoch: 27 step: 306, loss is 0.0003149262920487672\n",
      "epoch: 27 step: 307, loss is 0.00034688322921283543\n",
      "epoch: 27 step: 308, loss is 0.00020825369574595243\n",
      "epoch: 27 step: 309, loss is 0.0002502778370399028\n",
      "epoch: 27 step: 310, loss is 0.00014699525490868837\n",
      "epoch: 27 step: 311, loss is 0.0002553199010435492\n",
      "epoch: 27 step: 312, loss is 0.0009015810210257769\n",
      "epoch: 27 step: 313, loss is 0.0006391823408193886\n",
      "epoch: 27 step: 314, loss is 0.0002872612967621535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 step: 315, loss is 0.00097938091494143\n",
      "epoch: 27 step: 316, loss is 0.00043728837044909596\n",
      "epoch: 27 step: 317, loss is 0.0002441836695652455\n",
      "epoch: 27 step: 318, loss is 0.0012830659979954362\n",
      "epoch: 27 step: 319, loss is 0.000641048769466579\n",
      "epoch: 27 step: 320, loss is 0.0001552993053337559\n",
      "epoch: 27 step: 321, loss is 0.00018597840971779078\n",
      "epoch: 27 step: 322, loss is 0.0008835115004330873\n",
      "epoch: 27 step: 323, loss is 0.000268483447143808\n",
      "epoch: 27 step: 324, loss is 0.0006035961559973657\n",
      "epoch: 27 step: 325, loss is 0.0005237114382907748\n",
      "epoch: 27 step: 326, loss is 0.0003576590970624238\n",
      "epoch: 27 step: 327, loss is 0.0009262482053600252\n",
      "epoch: 27 step: 328, loss is 0.0004922484513372183\n",
      "epoch: 27 step: 329, loss is 0.00016473974392283708\n",
      "epoch: 27 step: 330, loss is 0.000902182946447283\n",
      "epoch: 27 step: 331, loss is 0.00041251484071835876\n",
      "epoch: 27 step: 332, loss is 0.00036410443135537207\n",
      "epoch: 27 step: 333, loss is 0.0004797197470907122\n",
      "epoch: 27 step: 334, loss is 0.0016311517683789134\n",
      "epoch: 27 step: 335, loss is 0.0003367577737662941\n",
      "epoch: 27 step: 336, loss is 0.0005557798431254923\n",
      "epoch: 27 step: 337, loss is 0.00014813782763667405\n",
      "epoch: 27 step: 338, loss is 0.0005722697824239731\n",
      "epoch: 27 step: 339, loss is 0.0007651024498045444\n",
      "epoch: 27 step: 340, loss is 0.0021256008185446262\n",
      "epoch: 27 step: 341, loss is 0.0016073862789198756\n",
      "epoch: 27 step: 342, loss is 0.0005565208266489208\n",
      "epoch: 27 step: 343, loss is 0.0012488577049225569\n",
      "epoch: 27 step: 344, loss is 0.0006167783285491168\n",
      "epoch: 27 step: 345, loss is 0.0007577217184007168\n",
      "epoch: 27 step: 346, loss is 0.0007010751869529486\n",
      "epoch: 27 step: 347, loss is 0.0009644986130297184\n",
      "epoch: 27 step: 348, loss is 0.0005765140522271395\n",
      "epoch: 27 step: 349, loss is 0.0008763009682297707\n",
      "epoch: 27 step: 350, loss is 0.0003928166115656495\n",
      "epoch: 27 step: 351, loss is 0.0007847640663385391\n",
      "epoch: 27 step: 352, loss is 0.0011247212532907724\n",
      "epoch: 27 step: 353, loss is 0.0006380450213328004\n",
      "epoch: 27 step: 354, loss is 0.000308804475935176\n",
      "epoch: 27 step: 355, loss is 0.0006674949545413256\n",
      "epoch: 27 step: 356, loss is 0.00048511207569390535\n",
      "epoch: 27 step: 357, loss is 0.0010360174346715212\n",
      "epoch: 27 step: 358, loss is 0.0019355126423761249\n",
      "epoch: 27 step: 359, loss is 0.0006285718991421163\n",
      "epoch: 27 step: 360, loss is 0.00021699076751247048\n",
      "epoch: 27 step: 361, loss is 0.0009022753802128136\n",
      "epoch: 27 step: 362, loss is 0.00017272592231165618\n",
      "epoch: 27 step: 363, loss is 0.0007150499150156975\n",
      "epoch: 27 step: 364, loss is 0.0013638969976454973\n",
      "epoch: 27 step: 365, loss is 0.00027703348314389586\n",
      "epoch: 27 step: 366, loss is 0.00041693737148307264\n",
      "epoch: 27 step: 367, loss is 0.0004845910589210689\n",
      "epoch: 27 step: 368, loss is 0.00036873359931632876\n",
      "epoch: 27 step: 369, loss is 0.0004926581750623882\n",
      "epoch: 27 step: 370, loss is 0.0010921006323769689\n",
      "epoch: 27 step: 371, loss is 0.0010834785643965006\n",
      "epoch: 27 step: 372, loss is 0.000265008449787274\n",
      "epoch: 27 step: 373, loss is 0.00046129568363539875\n",
      "epoch: 27 step: 374, loss is 0.0007036136812530458\n",
      "epoch: 27 step: 375, loss is 0.0008111022179946303\n",
      "Train epoch time: 11930.557 ms, per step time: 31.815 ms\n",
      "epoch: 28 step: 1, loss is 0.00044949742732569575\n",
      "epoch: 28 step: 2, loss is 0.0012924177572131157\n",
      "epoch: 28 step: 3, loss is 0.0005123359733261168\n",
      "epoch: 28 step: 4, loss is 0.0005313566070981324\n",
      "epoch: 28 step: 5, loss is 0.0011208639480173588\n",
      "epoch: 28 step: 6, loss is 0.0010906938696280122\n",
      "epoch: 28 step: 7, loss is 0.001658101798966527\n",
      "epoch: 28 step: 8, loss is 0.00041601332486607134\n",
      "epoch: 28 step: 9, loss is 0.0011369751300662756\n",
      "epoch: 28 step: 10, loss is 0.0007469686097465456\n",
      "epoch: 28 step: 11, loss is 0.0011519108666107059\n",
      "epoch: 28 step: 12, loss is 0.0008050290634855628\n",
      "epoch: 28 step: 13, loss is 0.0006747266161255538\n",
      "epoch: 28 step: 14, loss is 0.00040903102490119636\n",
      "epoch: 28 step: 15, loss is 0.001345197088085115\n",
      "epoch: 28 step: 16, loss is 0.00032443521195091307\n",
      "epoch: 28 step: 17, loss is 0.0009971874533221126\n",
      "epoch: 28 step: 18, loss is 0.0005878870142623782\n",
      "epoch: 28 step: 19, loss is 0.0005259659956209362\n",
      "epoch: 28 step: 20, loss is 0.0006697492208331823\n",
      "epoch: 28 step: 21, loss is 0.0011032047914341092\n",
      "epoch: 28 step: 22, loss is 0.0010406030341982841\n",
      "epoch: 28 step: 23, loss is 0.0006229743012227118\n",
      "epoch: 28 step: 24, loss is 0.0007496380130760372\n",
      "epoch: 28 step: 25, loss is 0.0005074910586699843\n",
      "epoch: 28 step: 26, loss is 0.0010808001970872283\n",
      "epoch: 28 step: 27, loss is 0.0009493898833170533\n",
      "epoch: 28 step: 28, loss is 0.0016403697663918138\n",
      "epoch: 28 step: 29, loss is 0.0008885296992957592\n",
      "epoch: 28 step: 30, loss is 0.0009816342499107122\n",
      "epoch: 28 step: 31, loss is 0.0005298306350596249\n",
      "epoch: 28 step: 32, loss is 0.0007078239577822387\n",
      "epoch: 28 step: 33, loss is 0.0007436628802679479\n",
      "epoch: 28 step: 34, loss is 0.0006171525456011295\n",
      "epoch: 28 step: 35, loss is 0.0003268876171205193\n",
      "epoch: 28 step: 36, loss is 0.00029482028912752867\n",
      "epoch: 28 step: 37, loss is 0.00021277257474139333\n",
      "epoch: 28 step: 38, loss is 0.00041002820944413543\n",
      "epoch: 28 step: 39, loss is 0.00021623412612825632\n",
      "epoch: 28 step: 40, loss is 0.00025238425587303936\n",
      "epoch: 28 step: 41, loss is 0.0007708990597166121\n",
      "epoch: 28 step: 42, loss is 0.0014402715023607016\n",
      "epoch: 28 step: 43, loss is 0.0012537762522697449\n",
      "epoch: 28 step: 44, loss is 0.0004970913869328797\n",
      "epoch: 28 step: 45, loss is 0.0010670516639947891\n",
      "epoch: 28 step: 46, loss is 0.0007393781561404467\n",
      "epoch: 28 step: 47, loss is 0.0005616578855551779\n",
      "epoch: 28 step: 48, loss is 0.0004978998913429677\n",
      "epoch: 28 step: 49, loss is 0.001112758880481124\n",
      "epoch: 28 step: 50, loss is 0.00031440844759345055\n",
      "epoch: 28 step: 51, loss is 0.0003273584588896483\n",
      "epoch: 28 step: 52, loss is 0.0014764475636184216\n",
      "epoch: 28 step: 53, loss is 0.0007991977035999298\n",
      "epoch: 28 step: 54, loss is 0.0005498749669641256\n",
      "epoch: 28 step: 55, loss is 0.0008362397202290595\n",
      "epoch: 28 step: 56, loss is 0.0005334171582944691\n",
      "epoch: 28 step: 57, loss is 0.0007151782629080117\n",
      "epoch: 28 step: 58, loss is 0.0003950987884309143\n",
      "epoch: 28 step: 59, loss is 0.001061626011505723\n",
      "epoch: 28 step: 60, loss is 0.0005516854580491781\n",
      "epoch: 28 step: 61, loss is 0.0006955333519726992\n",
      "epoch: 28 step: 62, loss is 0.00081002211663872\n",
      "epoch: 28 step: 63, loss is 0.00020490166207309812\n",
      "epoch: 28 step: 64, loss is 0.0007147896103560925\n",
      "epoch: 28 step: 65, loss is 0.0005370205617509782\n",
      "epoch: 28 step: 66, loss is 0.0001814834395190701\n",
      "epoch: 28 step: 67, loss is 0.0009078751318156719\n",
      "epoch: 28 step: 68, loss is 0.0004984006518498063\n",
      "epoch: 28 step: 69, loss is 0.0009484501206316054\n",
      "epoch: 28 step: 70, loss is 0.0007645239820703864\n",
      "epoch: 28 step: 71, loss is 0.00043465636554174125\n",
      "epoch: 28 step: 72, loss is 0.0004076979239471257\n",
      "epoch: 28 step: 73, loss is 3.84440463676583e-05\n",
      "epoch: 28 step: 74, loss is 0.00044873819570057094\n",
      "epoch: 28 step: 75, loss is 0.00041130761383101344\n",
      "epoch: 28 step: 76, loss is 0.0007260395213961601\n",
      "epoch: 28 step: 77, loss is 0.0006441657315008342\n",
      "epoch: 28 step: 78, loss is 0.0012259763898327947\n",
      "epoch: 28 step: 79, loss is 0.0003523544000927359\n",
      "epoch: 28 step: 80, loss is 0.00018820013792719692\n",
      "epoch: 28 step: 81, loss is 0.0008860982488840818\n",
      "epoch: 28 step: 82, loss is 0.0020260573364794254\n",
      "epoch: 28 step: 83, loss is 0.0001396596198901534\n",
      "epoch: 28 step: 84, loss is 0.00046322273556143045\n",
      "epoch: 28 step: 85, loss is 0.0006081280298531055\n",
      "epoch: 28 step: 86, loss is 0.0006285600829869509\n",
      "epoch: 28 step: 87, loss is 0.0002762415970209986\n",
      "epoch: 28 step: 88, loss is 8.564138988731429e-05\n",
      "epoch: 28 step: 89, loss is 0.0005302027566358447\n",
      "epoch: 28 step: 90, loss is 0.0007481150096282363\n",
      "epoch: 28 step: 91, loss is 0.00016267618048004806\n",
      "epoch: 28 step: 92, loss is 0.0005942626157775521\n",
      "epoch: 28 step: 93, loss is 0.0012988306116312742\n",
      "epoch: 28 step: 94, loss is 0.00036052914219908416\n",
      "epoch: 28 step: 95, loss is 0.0004509864666033536\n",
      "epoch: 28 step: 96, loss is 0.0011436068452894688\n",
      "epoch: 28 step: 97, loss is 0.0010198741219937801\n",
      "epoch: 28 step: 98, loss is 0.0002484676078893244\n",
      "epoch: 28 step: 99, loss is 0.0010114106116816401\n",
      "epoch: 28 step: 100, loss is 0.00042449228931218386\n",
      "epoch: 28 step: 101, loss is 0.0007305866456590593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 step: 102, loss is 0.0007308886270038784\n",
      "epoch: 28 step: 103, loss is 0.0005671473336406052\n",
      "epoch: 28 step: 104, loss is 0.0005687993252649903\n",
      "epoch: 28 step: 105, loss is 0.0008745567174628377\n",
      "epoch: 28 step: 106, loss is 0.0006519652670249343\n",
      "epoch: 28 step: 107, loss is 0.0006292876205407083\n",
      "epoch: 28 step: 108, loss is 0.00017172572552226484\n",
      "epoch: 28 step: 109, loss is 0.0009369456092827022\n",
      "epoch: 28 step: 110, loss is 0.0007390042883343995\n",
      "epoch: 28 step: 111, loss is 0.0004762631142511964\n",
      "epoch: 28 step: 112, loss is 0.0007718474371358752\n",
      "epoch: 28 step: 113, loss is 0.0008809384889900684\n",
      "epoch: 28 step: 114, loss is 0.00022363761672750115\n",
      "epoch: 28 step: 115, loss is 0.00019283757137600332\n",
      "epoch: 28 step: 116, loss is 0.00040604377863928676\n",
      "epoch: 28 step: 117, loss is 0.0008062568376772106\n",
      "epoch: 28 step: 118, loss is 0.00022037632879801095\n",
      "epoch: 28 step: 119, loss is 0.0002927935856860131\n",
      "epoch: 28 step: 120, loss is 0.0006677964702248573\n",
      "epoch: 28 step: 121, loss is 0.0004290906072128564\n",
      "epoch: 28 step: 122, loss is 0.0006899200961925089\n",
      "epoch: 28 step: 123, loss is 0.0004282262234482914\n",
      "epoch: 28 step: 124, loss is 0.0007758450810797513\n",
      "epoch: 28 step: 125, loss is 0.0006234027678146958\n",
      "epoch: 28 step: 126, loss is 0.0003978142631240189\n",
      "epoch: 28 step: 127, loss is 0.0013359148288145661\n",
      "epoch: 28 step: 128, loss is 0.0010705288732424378\n",
      "epoch: 28 step: 129, loss is 0.00045628761290572584\n",
      "epoch: 28 step: 130, loss is 0.000948481319937855\n",
      "epoch: 28 step: 131, loss is 0.0009991966653615236\n",
      "epoch: 28 step: 132, loss is 0.0014387283008545637\n",
      "epoch: 28 step: 133, loss is 0.0011655186535790563\n",
      "epoch: 28 step: 134, loss is 0.00077188725117594\n",
      "epoch: 28 step: 135, loss is 0.00038220584974624217\n",
      "epoch: 28 step: 136, loss is 0.000631701375823468\n",
      "epoch: 28 step: 137, loss is 0.0008038179366849363\n",
      "epoch: 28 step: 138, loss is 0.0004191382904537022\n",
      "epoch: 28 step: 139, loss is 0.0004776623100042343\n",
      "epoch: 28 step: 140, loss is 0.00028779514832422137\n",
      "epoch: 28 step: 141, loss is 0.002046351321041584\n",
      "epoch: 28 step: 142, loss is 0.00046614898019470274\n",
      "epoch: 28 step: 143, loss is 0.0005463413544930518\n",
      "epoch: 28 step: 144, loss is 0.00023764383513480425\n",
      "epoch: 28 step: 145, loss is 0.0009087349171750247\n",
      "epoch: 28 step: 146, loss is 0.0005677898298017681\n",
      "epoch: 28 step: 147, loss is 0.0003680470399558544\n",
      "epoch: 28 step: 148, loss is 0.0007874240982346237\n",
      "epoch: 28 step: 149, loss is 0.00040634567267261446\n",
      "epoch: 28 step: 150, loss is 0.0003058655420318246\n",
      "epoch: 28 step: 151, loss is 0.00047667493345215917\n",
      "epoch: 28 step: 152, loss is 0.00041956224595196545\n",
      "epoch: 28 step: 153, loss is 0.00028616187046281993\n",
      "epoch: 28 step: 154, loss is 0.0015162848867475986\n",
      "epoch: 28 step: 155, loss is 0.0008821244118735194\n",
      "epoch: 28 step: 156, loss is 0.0004011533746961504\n",
      "epoch: 28 step: 157, loss is 0.000370063295122236\n",
      "epoch: 28 step: 158, loss is 0.0001918769266922027\n",
      "epoch: 28 step: 159, loss is 0.00028240427491255105\n",
      "epoch: 28 step: 160, loss is 0.0006459635915234685\n",
      "epoch: 28 step: 161, loss is 0.0003618008049670607\n",
      "epoch: 28 step: 162, loss is 0.000611376017332077\n",
      "epoch: 28 step: 163, loss is 0.0002788086421787739\n",
      "epoch: 28 step: 164, loss is 0.00022421737958211452\n",
      "epoch: 28 step: 165, loss is 0.00030974100809544325\n",
      "epoch: 28 step: 166, loss is 0.0005477794911712408\n",
      "epoch: 28 step: 167, loss is 0.0011489143362268806\n",
      "epoch: 28 step: 168, loss is 0.0009141371701844037\n",
      "epoch: 28 step: 169, loss is 0.0006738996598869562\n",
      "epoch: 28 step: 170, loss is 0.0007358118309639394\n",
      "epoch: 28 step: 171, loss is 0.0003174706071149558\n",
      "epoch: 28 step: 172, loss is 0.0006029706564731896\n",
      "epoch: 28 step: 173, loss is 0.001262540346942842\n",
      "epoch: 28 step: 174, loss is 0.00048220224562101066\n",
      "epoch: 28 step: 175, loss is 0.00027871032943949103\n",
      "epoch: 28 step: 176, loss is 0.0002263730129925534\n",
      "epoch: 28 step: 177, loss is 0.0007277755066752434\n",
      "epoch: 28 step: 178, loss is 0.0009231174481101334\n",
      "epoch: 28 step: 179, loss is 0.0014132033102214336\n",
      "epoch: 28 step: 180, loss is 0.00018145116337109357\n",
      "epoch: 28 step: 181, loss is 0.0004090721777174622\n",
      "epoch: 28 step: 182, loss is 0.0007605373975820839\n",
      "epoch: 28 step: 183, loss is 0.00029454973991960287\n",
      "epoch: 28 step: 184, loss is 0.0009057609713636339\n",
      "epoch: 28 step: 185, loss is 0.000898021156899631\n",
      "epoch: 28 step: 186, loss is 0.0003366786986589432\n",
      "epoch: 28 step: 187, loss is 0.0004406000371091068\n",
      "epoch: 28 step: 188, loss is 0.0005875043570995331\n",
      "epoch: 28 step: 189, loss is 0.0007614621426910162\n",
      "epoch: 28 step: 190, loss is 0.0002712262503337115\n",
      "epoch: 28 step: 191, loss is 0.0005120722926221788\n",
      "epoch: 28 step: 192, loss is 0.0008015428320504725\n",
      "epoch: 28 step: 193, loss is 0.0005024326965212822\n",
      "epoch: 28 step: 194, loss is 0.0004599550738930702\n",
      "epoch: 28 step: 195, loss is 0.0009215775644406676\n",
      "epoch: 28 step: 196, loss is 0.0006113804993219674\n",
      "epoch: 28 step: 197, loss is 0.0004956453922204673\n",
      "epoch: 28 step: 198, loss is 0.0013823526678606868\n",
      "epoch: 28 step: 199, loss is 0.0009119851747527719\n",
      "epoch: 28 step: 200, loss is 0.000656009535305202\n",
      "epoch: 28 step: 201, loss is 0.0009251237497664988\n",
      "epoch: 28 step: 202, loss is 0.0005291413399390876\n",
      "epoch: 28 step: 203, loss is 0.0005965189775452018\n",
      "epoch: 28 step: 204, loss is 0.0002973529335577041\n",
      "epoch: 28 step: 205, loss is 0.0006228459533303976\n",
      "epoch: 28 step: 206, loss is 0.000465518853161484\n",
      "epoch: 28 step: 207, loss is 0.0007012218702584505\n",
      "epoch: 28 step: 208, loss is 0.0016722908476367593\n",
      "epoch: 28 step: 209, loss is 0.0005210096132941544\n",
      "epoch: 28 step: 210, loss is 0.0010612846817821264\n",
      "epoch: 28 step: 211, loss is 0.0007176403305493295\n",
      "epoch: 28 step: 212, loss is 0.0010770168155431747\n",
      "epoch: 28 step: 213, loss is 0.00023375602904707193\n",
      "epoch: 28 step: 214, loss is 0.0003352868079673499\n",
      "epoch: 28 step: 215, loss is 0.001539183664135635\n",
      "epoch: 28 step: 216, loss is 0.0006488478975370526\n",
      "epoch: 28 step: 217, loss is 0.000799823144916445\n",
      "epoch: 28 step: 218, loss is 0.0004596029466483742\n",
      "epoch: 28 step: 219, loss is 0.000861341948620975\n",
      "epoch: 28 step: 220, loss is 0.000945369596593082\n",
      "epoch: 28 step: 221, loss is 0.0010239441180601716\n",
      "epoch: 28 step: 222, loss is 0.0007496330072171986\n",
      "epoch: 28 step: 223, loss is 0.0004931848379783332\n",
      "epoch: 28 step: 224, loss is 0.00034869564115069807\n",
      "epoch: 28 step: 225, loss is 0.00045065334415994585\n",
      "epoch: 28 step: 226, loss is 0.0006297851796261966\n",
      "epoch: 28 step: 227, loss is 0.0009673157474026084\n",
      "epoch: 28 step: 228, loss is 0.0011222235625609756\n",
      "epoch: 28 step: 229, loss is 0.0008612131350673735\n",
      "epoch: 28 step: 230, loss is 0.0004435645532794297\n",
      "epoch: 28 step: 231, loss is 0.00015393461217172444\n",
      "epoch: 28 step: 232, loss is 0.00038078290526755154\n",
      "epoch: 28 step: 233, loss is 0.0011005504056811333\n",
      "epoch: 28 step: 234, loss is 0.0007658217218704522\n",
      "epoch: 28 step: 235, loss is 0.0008769587147980928\n",
      "epoch: 28 step: 236, loss is 0.0008896460640244186\n",
      "epoch: 28 step: 237, loss is 0.0008384438115172088\n",
      "epoch: 28 step: 238, loss is 0.0009435369283892214\n",
      "epoch: 28 step: 239, loss is 0.0001847038947744295\n",
      "epoch: 28 step: 240, loss is 0.0004975529154762626\n",
      "epoch: 28 step: 241, loss is 0.0003595647867769003\n",
      "epoch: 28 step: 242, loss is 0.0006154614384286106\n",
      "epoch: 28 step: 243, loss is 0.0005151497898623347\n",
      "epoch: 28 step: 244, loss is 0.00040303642163053155\n",
      "epoch: 28 step: 245, loss is 0.0003261834499426186\n",
      "epoch: 28 step: 246, loss is 0.00041772000258788466\n",
      "epoch: 28 step: 247, loss is 0.0009193440200760961\n",
      "epoch: 28 step: 248, loss is 0.0007190408068709075\n",
      "epoch: 28 step: 249, loss is 0.000514854968059808\n",
      "epoch: 28 step: 250, loss is 0.0005682202172465622\n",
      "epoch: 28 step: 251, loss is 0.0005462724366225302\n",
      "epoch: 28 step: 252, loss is 0.00048524606972932816\n",
      "epoch: 28 step: 253, loss is 0.0007116846390999854\n",
      "epoch: 28 step: 254, loss is 0.0014216790441423655\n",
      "epoch: 28 step: 255, loss is 0.00036670261761173606\n",
      "epoch: 28 step: 256, loss is 0.000955628405790776\n",
      "epoch: 28 step: 257, loss is 0.00036927059409208596\n",
      "epoch: 28 step: 258, loss is 0.0011551447678357363\n",
      "epoch: 28 step: 259, loss is 0.000639449164737016\n",
      "epoch: 28 step: 260, loss is 0.00028650369495153427\n",
      "epoch: 28 step: 261, loss is 0.0011637713760137558\n",
      "epoch: 28 step: 262, loss is 0.0021326157730072737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 step: 263, loss is 0.000733032007701695\n",
      "epoch: 28 step: 264, loss is 0.00043768499745056033\n",
      "epoch: 28 step: 265, loss is 0.000391383160604164\n",
      "epoch: 28 step: 266, loss is 0.0006581998895853758\n",
      "epoch: 28 step: 267, loss is 0.0003615953028202057\n",
      "epoch: 28 step: 268, loss is 0.0012022331357002258\n",
      "epoch: 28 step: 269, loss is 0.0005753310979343951\n",
      "epoch: 28 step: 270, loss is 0.0002799035282805562\n",
      "epoch: 28 step: 271, loss is 0.0014387986157089472\n",
      "epoch: 28 step: 272, loss is 0.0007683243020437658\n",
      "epoch: 28 step: 273, loss is 0.0007628423045389354\n",
      "epoch: 28 step: 274, loss is 0.00032924057450145483\n",
      "epoch: 28 step: 275, loss is 0.0006473063258454204\n",
      "epoch: 28 step: 276, loss is 0.00022072115098126233\n",
      "epoch: 28 step: 277, loss is 0.001311324187554419\n",
      "epoch: 28 step: 278, loss is 0.00023743811470922083\n",
      "epoch: 28 step: 279, loss is 0.0008904982241801918\n",
      "epoch: 28 step: 280, loss is 0.00043747792369686067\n",
      "epoch: 28 step: 281, loss is 0.0015206930693238974\n",
      "epoch: 28 step: 282, loss is 0.0004341048770584166\n",
      "epoch: 28 step: 283, loss is 0.000828946998808533\n",
      "epoch: 28 step: 284, loss is 0.0005697761080227792\n",
      "epoch: 28 step: 285, loss is 0.00023098310339264572\n",
      "epoch: 28 step: 286, loss is 0.0008274636929854751\n",
      "epoch: 28 step: 287, loss is 0.0013635882642120123\n",
      "epoch: 28 step: 288, loss is 0.0014959246618673205\n",
      "epoch: 28 step: 289, loss is 0.0008330338750965893\n",
      "epoch: 28 step: 290, loss is 0.0009206344257108867\n",
      "epoch: 28 step: 291, loss is 0.0008321008644998074\n",
      "epoch: 28 step: 292, loss is 0.00020952324848622084\n",
      "epoch: 28 step: 293, loss is 0.0012378167593851686\n",
      "epoch: 28 step: 294, loss is 0.001069005811586976\n",
      "epoch: 28 step: 295, loss is 0.00046313932398334146\n",
      "epoch: 28 step: 296, loss is 0.00039090655627660453\n",
      "epoch: 28 step: 297, loss is 0.0009091756073758006\n",
      "epoch: 28 step: 298, loss is 0.0003300929383840412\n",
      "epoch: 28 step: 299, loss is 0.001524604856967926\n",
      "epoch: 28 step: 300, loss is 0.0013116589980199933\n",
      "epoch: 28 step: 301, loss is 0.00044992726179771125\n",
      "epoch: 28 step: 302, loss is 0.0014013305772095919\n",
      "epoch: 28 step: 303, loss is 0.0008058436797000468\n",
      "epoch: 28 step: 304, loss is 0.001722476677969098\n",
      "epoch: 28 step: 305, loss is 0.0003970586694777012\n",
      "epoch: 28 step: 306, loss is 0.000908474437892437\n",
      "epoch: 28 step: 307, loss is 0.0003414418315514922\n",
      "epoch: 28 step: 308, loss is 0.0010706433095037937\n",
      "epoch: 28 step: 309, loss is 0.0008033092017285526\n",
      "epoch: 28 step: 310, loss is 0.0006689421134069562\n",
      "epoch: 28 step: 311, loss is 0.0006946424255147576\n",
      "epoch: 28 step: 312, loss is 0.00016242911806330085\n",
      "epoch: 28 step: 313, loss is 0.0014134207740426064\n",
      "epoch: 28 step: 314, loss is 0.0008171789813786745\n",
      "epoch: 28 step: 315, loss is 0.000467501551611349\n",
      "epoch: 28 step: 316, loss is 0.0011707365047186613\n",
      "epoch: 28 step: 317, loss is 0.0007956970948725939\n",
      "epoch: 28 step: 318, loss is 0.0005998515407554805\n",
      "epoch: 28 step: 319, loss is 0.0006388920010067523\n",
      "epoch: 28 step: 320, loss is 0.0019082436338067055\n",
      "epoch: 28 step: 321, loss is 0.0005103017319925129\n",
      "epoch: 28 step: 322, loss is 0.0009418734698556364\n",
      "epoch: 28 step: 323, loss is 0.0008241977193392813\n",
      "epoch: 28 step: 324, loss is 0.00022948146215640008\n",
      "epoch: 28 step: 325, loss is 0.0003838213160634041\n",
      "epoch: 28 step: 326, loss is 0.00022955553140491247\n",
      "epoch: 28 step: 327, loss is 0.0006384443258866668\n",
      "epoch: 28 step: 328, loss is 0.0012538195587694645\n",
      "epoch: 28 step: 329, loss is 0.0008046784205362201\n",
      "epoch: 28 step: 330, loss is 0.000760336231905967\n",
      "epoch: 28 step: 331, loss is 0.0012288516154512763\n",
      "epoch: 28 step: 332, loss is 0.0004951828741468489\n",
      "epoch: 28 step: 333, loss is 0.00031982717337086797\n",
      "epoch: 28 step: 334, loss is 0.00045676392619498074\n",
      "epoch: 28 step: 335, loss is 0.0006365507724694908\n",
      "epoch: 28 step: 336, loss is 0.0004715448303613812\n",
      "epoch: 28 step: 337, loss is 0.0007259574485942721\n",
      "epoch: 28 step: 338, loss is 0.00034074598806910217\n",
      "epoch: 28 step: 339, loss is 0.000399990938603878\n",
      "epoch: 28 step: 340, loss is 0.0007082345546223223\n",
      "epoch: 28 step: 341, loss is 0.0010796969290822744\n",
      "epoch: 28 step: 342, loss is 0.0008009795565158129\n",
      "epoch: 28 step: 343, loss is 0.0005434915656223893\n",
      "epoch: 28 step: 344, loss is 0.0004370207025203854\n",
      "epoch: 28 step: 345, loss is 0.0006024457979947329\n",
      "epoch: 28 step: 346, loss is 0.0005313464789651334\n",
      "epoch: 28 step: 347, loss is 0.0005193790420889854\n",
      "epoch: 28 step: 348, loss is 0.0004922323860228062\n",
      "epoch: 28 step: 349, loss is 0.0008692917763255537\n",
      "epoch: 28 step: 350, loss is 0.0005034782807342708\n",
      "epoch: 28 step: 351, loss is 0.00038778327871114016\n",
      "epoch: 28 step: 352, loss is 0.0013260795967653394\n",
      "epoch: 28 step: 353, loss is 0.00035759733873419464\n",
      "epoch: 28 step: 354, loss is 0.00048598687862977386\n",
      "epoch: 28 step: 355, loss is 0.0006155843730084598\n",
      "epoch: 28 step: 356, loss is 0.0006535712163895369\n",
      "epoch: 28 step: 357, loss is 0.0004480006464291364\n",
      "epoch: 28 step: 358, loss is 0.001586005906574428\n",
      "epoch: 28 step: 359, loss is 0.00028719374677166343\n",
      "epoch: 28 step: 360, loss is 0.0004906545509584248\n",
      "epoch: 28 step: 361, loss is 0.0006907779606990516\n",
      "epoch: 28 step: 362, loss is 0.0011615254916250706\n",
      "epoch: 28 step: 363, loss is 0.0002496505039744079\n",
      "epoch: 28 step: 364, loss is 0.0005899430834688246\n",
      "epoch: 28 step: 365, loss is 0.0005654455162584782\n",
      "epoch: 28 step: 366, loss is 0.0009372528875246644\n",
      "epoch: 28 step: 367, loss is 0.0006399102276191115\n",
      "epoch: 28 step: 368, loss is 0.0004883837536908686\n",
      "epoch: 28 step: 369, loss is 0.00032551499316468835\n",
      "epoch: 28 step: 370, loss is 0.00108919118065387\n",
      "epoch: 28 step: 371, loss is 0.0006394484080374241\n",
      "epoch: 28 step: 372, loss is 0.0006398401455953717\n",
      "epoch: 28 step: 373, loss is 0.0003786407469306141\n",
      "epoch: 28 step: 374, loss is 0.0005791131989099085\n",
      "epoch: 28 step: 375, loss is 0.000646857195533812\n",
      "Train epoch time: 12075.438 ms, per step time: 32.201 ms\n",
      "epoch: 29 step: 1, loss is 0.0005041858530603349\n",
      "epoch: 29 step: 2, loss is 0.00047841048217378557\n",
      "epoch: 29 step: 3, loss is 0.0004990394809283316\n",
      "epoch: 29 step: 4, loss is 0.0008980025304481387\n",
      "epoch: 29 step: 5, loss is 0.0003900251176673919\n",
      "epoch: 29 step: 6, loss is 0.0005097815883345902\n",
      "epoch: 29 step: 7, loss is 0.0007367647485807538\n",
      "epoch: 29 step: 8, loss is 0.0006342469132505357\n",
      "epoch: 29 step: 9, loss is 0.0008146636537276208\n",
      "epoch: 29 step: 10, loss is 0.00039017110248096287\n",
      "epoch: 29 step: 11, loss is 0.0007076823385432363\n",
      "epoch: 29 step: 12, loss is 0.0005906512378714979\n",
      "epoch: 29 step: 13, loss is 0.0008988346671685576\n",
      "epoch: 29 step: 14, loss is 0.0005509629845619202\n",
      "epoch: 29 step: 15, loss is 0.0007464609225280583\n",
      "epoch: 29 step: 16, loss is 0.0005454312195070088\n",
      "epoch: 29 step: 17, loss is 0.0005866049905307591\n",
      "epoch: 29 step: 18, loss is 0.0005715072038583457\n",
      "epoch: 29 step: 19, loss is 0.0006308963638730347\n",
      "epoch: 29 step: 20, loss is 0.000326323788613081\n",
      "epoch: 29 step: 21, loss is 0.00037215277552604675\n",
      "epoch: 29 step: 22, loss is 0.0010379146551713347\n",
      "epoch: 29 step: 23, loss is 0.0005843424005433917\n",
      "epoch: 29 step: 24, loss is 0.0002671704569365829\n",
      "epoch: 29 step: 25, loss is 0.0003301105462014675\n",
      "epoch: 29 step: 26, loss is 0.0004698699340224266\n",
      "epoch: 29 step: 27, loss is 0.0002356741315452382\n",
      "epoch: 29 step: 28, loss is 0.00013473548460751772\n",
      "epoch: 29 step: 29, loss is 0.0014151082141324878\n",
      "epoch: 29 step: 30, loss is 0.0009393008076585829\n",
      "epoch: 29 step: 31, loss is 0.00033923069713637233\n",
      "epoch: 29 step: 32, loss is 0.00047714661923237145\n",
      "epoch: 29 step: 33, loss is 0.0007437060703523457\n",
      "epoch: 29 step: 34, loss is 0.00018136507424060255\n",
      "epoch: 29 step: 35, loss is 0.000644283602014184\n",
      "epoch: 29 step: 36, loss is 0.0002569431671872735\n",
      "epoch: 29 step: 37, loss is 0.0003034680266864598\n",
      "epoch: 29 step: 38, loss is 0.00032125000143423676\n",
      "epoch: 29 step: 39, loss is 0.0008815311011858284\n",
      "epoch: 29 step: 40, loss is 0.0010354615515097976\n",
      "epoch: 29 step: 41, loss is 0.000699531810823828\n",
      "epoch: 29 step: 42, loss is 0.00035712652606889606\n",
      "epoch: 29 step: 43, loss is 0.0009149552206508815\n",
      "epoch: 29 step: 44, loss is 0.0003869583015330136\n",
      "epoch: 29 step: 45, loss is 0.0005578330019488931\n",
      "epoch: 29 step: 46, loss is 0.0010333143873140216\n",
      "epoch: 29 step: 47, loss is 0.0005927719757892191\n",
      "epoch: 29 step: 48, loss is 0.0004746639751829207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 step: 49, loss is 0.00045535285607911646\n",
      "epoch: 29 step: 50, loss is 0.00042020820546895266\n",
      "epoch: 29 step: 51, loss is 0.0005436636856757104\n",
      "epoch: 29 step: 52, loss is 0.0005537628312595189\n",
      "epoch: 29 step: 53, loss is 0.0003975790459662676\n",
      "epoch: 29 step: 54, loss is 0.0011670291423797607\n",
      "epoch: 29 step: 55, loss is 0.0001125504495576024\n",
      "epoch: 29 step: 56, loss is 0.0009818891994655132\n",
      "epoch: 29 step: 57, loss is 0.00024253698938991874\n",
      "epoch: 29 step: 58, loss is 0.000345149717759341\n",
      "epoch: 29 step: 59, loss is 0.0007025048835203052\n",
      "epoch: 29 step: 60, loss is 0.0004018972103949636\n",
      "epoch: 29 step: 61, loss is 0.0009303796687163413\n",
      "epoch: 29 step: 62, loss is 0.0005481804255396128\n",
      "epoch: 29 step: 63, loss is 0.001079730223864317\n",
      "epoch: 29 step: 64, loss is 0.00046517193550243974\n",
      "epoch: 29 step: 65, loss is 0.00038988038431853056\n",
      "epoch: 29 step: 66, loss is 0.0005910973995923996\n",
      "epoch: 29 step: 67, loss is 0.0005506853340193629\n",
      "epoch: 29 step: 68, loss is 0.0005255520227365196\n",
      "epoch: 29 step: 69, loss is 0.00026873909519053996\n",
      "epoch: 29 step: 70, loss is 0.0008695171563886106\n",
      "epoch: 29 step: 71, loss is 0.0014412482269108295\n",
      "epoch: 29 step: 72, loss is 0.0004886222304776311\n",
      "epoch: 29 step: 73, loss is 0.0014151217183098197\n",
      "epoch: 29 step: 74, loss is 0.0006149811088107526\n",
      "epoch: 29 step: 75, loss is 0.0011000224621966481\n",
      "epoch: 29 step: 76, loss is 0.0018647529650479555\n",
      "epoch: 29 step: 77, loss is 0.0008245139615610242\n",
      "epoch: 29 step: 78, loss is 0.0003945901698898524\n",
      "epoch: 29 step: 79, loss is 0.0007048813859000802\n",
      "epoch: 29 step: 80, loss is 0.0009021013975143433\n",
      "epoch: 29 step: 81, loss is 0.0005089861224405468\n",
      "epoch: 29 step: 82, loss is 0.0005145064205862582\n",
      "epoch: 29 step: 83, loss is 0.0009659985080361366\n",
      "epoch: 29 step: 84, loss is 0.0008438213262706995\n",
      "epoch: 29 step: 85, loss is 0.0009853828232735395\n",
      "epoch: 29 step: 86, loss is 0.0005667223013006151\n",
      "epoch: 29 step: 87, loss is 0.0006122327176854014\n",
      "epoch: 29 step: 88, loss is 0.00019815030100289732\n",
      "epoch: 29 step: 89, loss is 0.000679849530570209\n",
      "epoch: 29 step: 90, loss is 0.00022149791766423732\n",
      "epoch: 29 step: 91, loss is 0.001149629824794829\n",
      "epoch: 29 step: 92, loss is 0.0006281915120780468\n",
      "epoch: 29 step: 93, loss is 0.00038256155676208436\n",
      "epoch: 29 step: 94, loss is 0.0004942792002111673\n",
      "epoch: 29 step: 95, loss is 0.0014851115411147475\n",
      "epoch: 29 step: 96, loss is 0.0010066209360957146\n",
      "epoch: 29 step: 97, loss is 0.000897353864274919\n",
      "epoch: 29 step: 98, loss is 0.0003492324030958116\n",
      "epoch: 29 step: 99, loss is 0.0011694806162267923\n",
      "epoch: 29 step: 100, loss is 0.0007007712265476584\n",
      "epoch: 29 step: 101, loss is 0.00043646254925988615\n",
      "epoch: 29 step: 102, loss is 0.000707259401679039\n",
      "epoch: 29 step: 103, loss is 0.00045744230737909675\n",
      "epoch: 29 step: 104, loss is 0.0008467617444694042\n",
      "epoch: 29 step: 105, loss is 0.0018780818209052086\n",
      "epoch: 29 step: 106, loss is 0.00016638885426800698\n",
      "epoch: 29 step: 107, loss is 0.0016524780075997114\n",
      "epoch: 29 step: 108, loss is 0.0008304116199724376\n",
      "epoch: 29 step: 109, loss is 0.0006459352443926036\n",
      "epoch: 29 step: 110, loss is 0.0009594823932275176\n",
      "epoch: 29 step: 111, loss is 0.0006994976429268718\n",
      "epoch: 29 step: 112, loss is 0.0002922630519606173\n",
      "epoch: 29 step: 113, loss is 0.0005180108128115535\n",
      "epoch: 29 step: 114, loss is 0.0012524969642981887\n",
      "epoch: 29 step: 115, loss is 0.0002445456921122968\n",
      "epoch: 29 step: 116, loss is 0.0007992394967004657\n",
      "epoch: 29 step: 117, loss is 0.0007547782151959836\n",
      "epoch: 29 step: 118, loss is 0.0007437234744429588\n",
      "epoch: 29 step: 119, loss is 0.0004162721452303231\n",
      "epoch: 29 step: 120, loss is 0.0009165165829472244\n",
      "epoch: 29 step: 121, loss is 0.0004128230211790651\n",
      "epoch: 29 step: 122, loss is 0.0006051362724974751\n",
      "epoch: 29 step: 123, loss is 0.0006343488930724561\n",
      "epoch: 29 step: 124, loss is 0.0004607487644534558\n",
      "epoch: 29 step: 125, loss is 0.0006526588113047183\n",
      "epoch: 29 step: 126, loss is 0.0007712742080911994\n",
      "epoch: 29 step: 127, loss is 0.00040252451435662806\n",
      "epoch: 29 step: 128, loss is 0.0005573412636294961\n",
      "epoch: 29 step: 129, loss is 0.0007770169177092612\n",
      "epoch: 29 step: 130, loss is 0.0012270925799384713\n",
      "epoch: 29 step: 131, loss is 0.000628847221378237\n",
      "epoch: 29 step: 132, loss is 0.00036022462882101536\n",
      "epoch: 29 step: 133, loss is 0.0006953598349355161\n",
      "epoch: 29 step: 134, loss is 0.0016957916086539626\n",
      "epoch: 29 step: 135, loss is 0.0004913666634820402\n",
      "epoch: 29 step: 136, loss is 0.0004864643851760775\n",
      "epoch: 29 step: 137, loss is 0.0007295956602320075\n",
      "epoch: 29 step: 138, loss is 0.0007522654486820102\n",
      "epoch: 29 step: 139, loss is 0.0005507916212081909\n",
      "epoch: 29 step: 140, loss is 0.000798292807303369\n",
      "epoch: 29 step: 141, loss is 0.0004520459333434701\n",
      "epoch: 29 step: 142, loss is 0.0009155583684332669\n",
      "epoch: 29 step: 143, loss is 0.0012301945826038718\n",
      "epoch: 29 step: 144, loss is 0.0005354577442631125\n",
      "epoch: 29 step: 145, loss is 0.00032746189390309155\n",
      "epoch: 29 step: 146, loss is 0.0006670263246633112\n",
      "epoch: 29 step: 147, loss is 0.0006377013633027673\n",
      "epoch: 29 step: 148, loss is 0.0007489710114896297\n",
      "epoch: 29 step: 149, loss is 0.0004059629573021084\n",
      "epoch: 29 step: 150, loss is 0.0003575025184545666\n",
      "epoch: 29 step: 151, loss is 0.00027118143043480814\n",
      "epoch: 29 step: 152, loss is 0.0006823043804615736\n",
      "epoch: 29 step: 153, loss is 0.0009654270834289491\n",
      "epoch: 29 step: 154, loss is 0.0007271214853972197\n",
      "epoch: 29 step: 155, loss is 0.0004629907780326903\n",
      "epoch: 29 step: 156, loss is 0.0015387643361464143\n",
      "epoch: 29 step: 157, loss is 0.0008090260089375079\n",
      "epoch: 29 step: 158, loss is 0.0005476144142448902\n",
      "epoch: 29 step: 159, loss is 0.0003692586615215987\n",
      "epoch: 29 step: 160, loss is 0.0011255367426201701\n",
      "epoch: 29 step: 161, loss is 0.00028930112603120506\n",
      "epoch: 29 step: 162, loss is 0.0011592088267207146\n",
      "epoch: 29 step: 163, loss is 0.0005071165505796671\n",
      "epoch: 29 step: 164, loss is 0.0014368824195116758\n",
      "epoch: 29 step: 165, loss is 0.0009243172826245427\n",
      "epoch: 29 step: 166, loss is 0.00035439874045550823\n",
      "epoch: 29 step: 167, loss is 0.0005638862494379282\n",
      "epoch: 29 step: 168, loss is 0.001172559568658471\n",
      "epoch: 29 step: 169, loss is 0.00043739876127801836\n",
      "epoch: 29 step: 170, loss is 0.0006142068887129426\n",
      "epoch: 29 step: 171, loss is 0.0005096795503050089\n",
      "epoch: 29 step: 172, loss is 0.0012122135376557708\n",
      "epoch: 29 step: 173, loss is 0.0008717048913240433\n",
      "epoch: 29 step: 174, loss is 0.0006655665929429233\n",
      "epoch: 29 step: 175, loss is 0.0003701411187648773\n",
      "epoch: 29 step: 176, loss is 9.210608550347388e-05\n",
      "epoch: 29 step: 177, loss is 0.0009274624171666801\n",
      "epoch: 29 step: 178, loss is 0.0006798917311243713\n",
      "epoch: 29 step: 179, loss is 0.0003814506053458899\n",
      "epoch: 29 step: 180, loss is 0.0006226723198778927\n",
      "epoch: 29 step: 181, loss is 0.0009527641232125461\n",
      "epoch: 29 step: 182, loss is 0.0003621695504989475\n",
      "epoch: 29 step: 183, loss is 0.000242181311477907\n",
      "epoch: 29 step: 184, loss is 0.00025535296299494803\n",
      "epoch: 29 step: 185, loss is 0.0005947385216131806\n",
      "epoch: 29 step: 186, loss is 0.0006175643065944314\n",
      "epoch: 29 step: 187, loss is 0.0003718928783200681\n",
      "epoch: 29 step: 188, loss is 0.0008140642894431949\n",
      "epoch: 29 step: 189, loss is 0.0005782526568509638\n",
      "epoch: 29 step: 190, loss is 0.0009899677243083715\n",
      "epoch: 29 step: 191, loss is 0.0003699531953316182\n",
      "epoch: 29 step: 192, loss is 0.0006106185610406101\n",
      "epoch: 29 step: 193, loss is 0.0018948563374578953\n",
      "epoch: 29 step: 194, loss is 0.00019573741883505136\n",
      "epoch: 29 step: 195, loss is 0.0007853148272261024\n",
      "epoch: 29 step: 196, loss is 0.0010090633295476437\n",
      "epoch: 29 step: 197, loss is 0.00014819193165749311\n",
      "epoch: 29 step: 198, loss is 0.000916238990612328\n",
      "epoch: 29 step: 199, loss is 0.00048501952551305294\n",
      "epoch: 29 step: 200, loss is 0.0008021464454941452\n",
      "epoch: 29 step: 201, loss is 0.0008811015286482871\n",
      "epoch: 29 step: 202, loss is 0.002015269361436367\n",
      "epoch: 29 step: 203, loss is 0.0002411025925539434\n",
      "epoch: 29 step: 204, loss is 0.0014449545415118337\n",
      "epoch: 29 step: 205, loss is 0.0013032343704253435\n",
      "epoch: 29 step: 206, loss is 0.0004517491615843028\n",
      "epoch: 29 step: 207, loss is 0.0009182195062749088\n",
      "epoch: 29 step: 208, loss is 0.0004108295252081007\n",
      "epoch: 29 step: 209, loss is 0.00011405079567339271\n",
      "epoch: 29 step: 210, loss is 0.000546302180737257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 step: 211, loss is 0.0004648478061426431\n",
      "epoch: 29 step: 212, loss is 0.0009805146837607026\n",
      "epoch: 29 step: 213, loss is 0.0014788986882194877\n",
      "epoch: 29 step: 214, loss is 0.0004075446049682796\n",
      "epoch: 29 step: 215, loss is 0.0004320903099142015\n",
      "epoch: 29 step: 216, loss is 0.0005271939444355667\n",
      "epoch: 29 step: 217, loss is 0.00021089366055093706\n",
      "epoch: 29 step: 218, loss is 0.0006572398124262691\n",
      "epoch: 29 step: 219, loss is 0.0002121854486176744\n",
      "epoch: 29 step: 220, loss is 0.0011444162810221314\n",
      "epoch: 29 step: 221, loss is 0.0006274722982198\n",
      "epoch: 29 step: 222, loss is 0.0004764047625940293\n",
      "epoch: 29 step: 223, loss is 0.0008300282061100006\n",
      "epoch: 29 step: 224, loss is 0.000648666056804359\n",
      "epoch: 29 step: 225, loss is 0.0005581389414146543\n",
      "epoch: 29 step: 226, loss is 0.000805585877969861\n",
      "epoch: 29 step: 227, loss is 0.0016262761782854795\n",
      "epoch: 29 step: 228, loss is 0.0006806423771195114\n",
      "epoch: 29 step: 229, loss is 0.0003101079782936722\n",
      "epoch: 29 step: 230, loss is 0.0008976844255812466\n",
      "epoch: 29 step: 231, loss is 0.0005824246909469366\n",
      "epoch: 29 step: 232, loss is 0.0020451885648071766\n",
      "epoch: 29 step: 233, loss is 0.0002696247538551688\n",
      "epoch: 29 step: 234, loss is 0.0006132570561021566\n",
      "epoch: 29 step: 235, loss is 0.0004437388270162046\n",
      "epoch: 29 step: 236, loss is 0.00039355704211629927\n",
      "epoch: 29 step: 237, loss is 0.00038436095928773284\n",
      "epoch: 29 step: 238, loss is 0.001119479420594871\n",
      "epoch: 29 step: 239, loss is 0.000264211354078725\n",
      "epoch: 29 step: 240, loss is 0.00039530129288323224\n",
      "epoch: 29 step: 241, loss is 0.0004780744493473321\n",
      "epoch: 29 step: 242, loss is 0.00014858614304102957\n",
      "epoch: 29 step: 243, loss is 0.000350460089975968\n",
      "epoch: 29 step: 244, loss is 0.00025197843206115067\n",
      "epoch: 29 step: 245, loss is 0.0008850547019392252\n",
      "epoch: 29 step: 246, loss is 0.002890313509851694\n",
      "epoch: 29 step: 247, loss is 0.0007424005889333785\n",
      "epoch: 29 step: 248, loss is 0.0009452595841139555\n",
      "epoch: 29 step: 249, loss is 0.0006532669067382812\n",
      "epoch: 29 step: 250, loss is 0.0008040106040425599\n",
      "epoch: 29 step: 251, loss is 0.0005796753684990108\n",
      "epoch: 29 step: 252, loss is 0.00040644104592502117\n",
      "epoch: 29 step: 253, loss is 0.000644186045974493\n",
      "epoch: 29 step: 254, loss is 0.0004510008147917688\n",
      "epoch: 29 step: 255, loss is 0.0004848645767197013\n",
      "epoch: 29 step: 256, loss is 0.0014008627040311694\n",
      "epoch: 29 step: 257, loss is 0.001234385184943676\n",
      "epoch: 29 step: 258, loss is 0.0003957230946980417\n",
      "epoch: 29 step: 259, loss is 0.0007208108436316252\n",
      "epoch: 29 step: 260, loss is 0.0006262762472033501\n",
      "epoch: 29 step: 261, loss is 0.00115383870434016\n",
      "epoch: 29 step: 262, loss is 0.0009339351672679186\n",
      "epoch: 29 step: 263, loss is 0.0008769381092861295\n",
      "epoch: 29 step: 264, loss is 0.0005934950313530862\n",
      "epoch: 29 step: 265, loss is 0.00023311248514801264\n",
      "epoch: 29 step: 266, loss is 0.0007152252946980298\n",
      "epoch: 29 step: 267, loss is 0.0010860440088436007\n",
      "epoch: 29 step: 268, loss is 0.0008483711280860007\n",
      "epoch: 29 step: 269, loss is 0.0010762846795842052\n",
      "epoch: 29 step: 270, loss is 0.0009270606678910553\n",
      "epoch: 29 step: 271, loss is 0.0008557278197258711\n",
      "epoch: 29 step: 272, loss is 0.0008396893972530961\n",
      "epoch: 29 step: 273, loss is 0.0007597488583996892\n",
      "epoch: 29 step: 274, loss is 0.0004320091975387186\n",
      "epoch: 29 step: 275, loss is 0.0009710901649668813\n",
      "epoch: 29 step: 276, loss is 0.0020560252014547586\n",
      "epoch: 29 step: 277, loss is 0.0012387278256937861\n",
      "epoch: 29 step: 278, loss is 0.00013212028716225177\n",
      "epoch: 29 step: 279, loss is 0.00023039072402752936\n",
      "epoch: 29 step: 280, loss is 0.00024464866146445274\n",
      "epoch: 29 step: 281, loss is 0.0005763014196418226\n",
      "epoch: 29 step: 282, loss is 0.0009974401909857988\n",
      "epoch: 29 step: 283, loss is 0.00031989594572223723\n",
      "epoch: 29 step: 284, loss is 0.00023565118317492306\n",
      "epoch: 29 step: 285, loss is 0.0010267337784171104\n",
      "epoch: 29 step: 286, loss is 0.00010901049245148897\n",
      "epoch: 29 step: 287, loss is 0.00039620031020604074\n",
      "epoch: 29 step: 288, loss is 0.0005657870788127184\n",
      "epoch: 29 step: 289, loss is 0.0005556463729590178\n",
      "epoch: 29 step: 290, loss is 0.0008812982705421746\n",
      "epoch: 29 step: 291, loss is 0.0007453918224200606\n",
      "epoch: 29 step: 292, loss is 0.0008199997246265411\n",
      "epoch: 29 step: 293, loss is 0.00018092626123689115\n",
      "epoch: 29 step: 294, loss is 0.0005177085404284298\n",
      "epoch: 29 step: 295, loss is 0.0003966364311054349\n",
      "epoch: 29 step: 296, loss is 0.0005849217413924634\n",
      "epoch: 29 step: 297, loss is 0.0007474871235899627\n",
      "epoch: 29 step: 298, loss is 0.00044640619307756424\n",
      "epoch: 29 step: 299, loss is 0.0007858250173740089\n",
      "epoch: 29 step: 300, loss is 0.0009043804602697492\n",
      "epoch: 29 step: 301, loss is 0.0007774931727908552\n",
      "epoch: 29 step: 302, loss is 0.000617674901150167\n",
      "epoch: 29 step: 303, loss is 0.0005974990199320018\n",
      "epoch: 29 step: 304, loss is 0.0003616456233430654\n",
      "epoch: 29 step: 305, loss is 0.0005623857141472399\n",
      "epoch: 29 step: 306, loss is 0.0010074572637677193\n",
      "epoch: 29 step: 307, loss is 0.0011569384951144457\n",
      "epoch: 29 step: 308, loss is 0.00027608315576799214\n",
      "epoch: 29 step: 309, loss is 0.0005545539897866547\n",
      "epoch: 29 step: 310, loss is 0.0005787238478660583\n",
      "epoch: 29 step: 311, loss is 0.0008353713783435524\n",
      "epoch: 29 step: 312, loss is 0.0002654613053891808\n",
      "epoch: 29 step: 313, loss is 0.0003996718442067504\n",
      "epoch: 29 step: 314, loss is 0.0012304299743846059\n",
      "epoch: 29 step: 315, loss is 0.001264017540961504\n",
      "epoch: 29 step: 316, loss is 0.0012984491186216474\n",
      "epoch: 29 step: 317, loss is 0.00020363663497846574\n",
      "epoch: 29 step: 318, loss is 0.0003424371825531125\n",
      "epoch: 29 step: 319, loss is 0.0008680566097609699\n",
      "epoch: 29 step: 320, loss is 0.0005297907046042383\n",
      "epoch: 29 step: 321, loss is 0.0006215488538146019\n",
      "epoch: 29 step: 322, loss is 0.0006602365174330771\n",
      "epoch: 29 step: 323, loss is 0.0005417924840003252\n",
      "epoch: 29 step: 324, loss is 0.000594798126257956\n",
      "epoch: 29 step: 325, loss is 0.0009187324321828783\n",
      "epoch: 29 step: 326, loss is 0.0009570628753863275\n",
      "epoch: 29 step: 327, loss is 0.0009370124898850918\n",
      "epoch: 29 step: 328, loss is 0.0004344405315350741\n",
      "epoch: 29 step: 329, loss is 0.0005846191197633743\n",
      "epoch: 29 step: 330, loss is 0.0013311791699379683\n",
      "epoch: 29 step: 331, loss is 0.0007509739371016622\n",
      "epoch: 29 step: 332, loss is 0.0010575512424111366\n",
      "epoch: 29 step: 333, loss is 0.00035387001116760075\n",
      "epoch: 29 step: 334, loss is 0.0002215589483967051\n",
      "epoch: 29 step: 335, loss is 0.0009913305984809995\n",
      "epoch: 29 step: 336, loss is 0.0011508752359077334\n",
      "epoch: 29 step: 337, loss is 0.0019414223497733474\n",
      "epoch: 29 step: 338, loss is 0.0008483605342917144\n",
      "epoch: 29 step: 339, loss is 0.00036750585422851145\n",
      "epoch: 29 step: 340, loss is 0.00040071632247418165\n",
      "epoch: 29 step: 341, loss is 0.00012168727698735893\n",
      "epoch: 29 step: 342, loss is 0.00043486719368956983\n",
      "epoch: 29 step: 343, loss is 0.0006496846908703446\n",
      "epoch: 29 step: 344, loss is 0.001179714105091989\n",
      "epoch: 29 step: 345, loss is 0.00042667699744924903\n",
      "epoch: 29 step: 346, loss is 0.00034881700412370265\n",
      "epoch: 29 step: 347, loss is 0.0011115773813799024\n",
      "epoch: 29 step: 348, loss is 0.0009401382994838059\n",
      "epoch: 29 step: 349, loss is 0.0006925941561348736\n",
      "epoch: 29 step: 350, loss is 0.0005985227762721479\n",
      "epoch: 29 step: 351, loss is 0.0004457168106455356\n",
      "epoch: 29 step: 352, loss is 0.00023264976334758103\n",
      "epoch: 29 step: 353, loss is 0.0006406694883480668\n",
      "epoch: 29 step: 354, loss is 0.0005624280893243849\n",
      "epoch: 29 step: 355, loss is 0.000990077038295567\n",
      "epoch: 29 step: 356, loss is 0.0006295584025792778\n",
      "epoch: 29 step: 357, loss is 0.00036758347414433956\n",
      "epoch: 29 step: 358, loss is 0.0006883920286782086\n",
      "epoch: 29 step: 359, loss is 0.0008419955847784877\n",
      "epoch: 29 step: 360, loss is 0.0006342486012727022\n",
      "epoch: 29 step: 361, loss is 0.0012021345319226384\n",
      "epoch: 29 step: 362, loss is 4.905924288323149e-05\n",
      "epoch: 29 step: 363, loss is 0.0007106103003025055\n",
      "epoch: 29 step: 364, loss is 0.0005759869236499071\n",
      "epoch: 29 step: 365, loss is 0.0006317174411378801\n",
      "epoch: 29 step: 366, loss is 0.00042183941695839167\n",
      "epoch: 29 step: 367, loss is 0.00044870536657981575\n",
      "epoch: 29 step: 368, loss is 0.00026114151114597917\n",
      "epoch: 29 step: 369, loss is 0.0004479427880141884\n",
      "epoch: 29 step: 370, loss is 0.0002486152807250619\n",
      "epoch: 29 step: 371, loss is 0.00040030849049799144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 step: 372, loss is 0.0008189075742848217\n",
      "epoch: 29 step: 373, loss is 0.001364000840112567\n",
      "epoch: 29 step: 374, loss is 0.000994124449789524\n",
      "epoch: 29 step: 375, loss is 0.0002484804135747254\n",
      "Train epoch time: 11889.411 ms, per step time: 31.705 ms\n",
      "epoch: 30 step: 1, loss is 0.0006954915588721633\n",
      "epoch: 30 step: 2, loss is 0.0004459065676201135\n",
      "epoch: 30 step: 3, loss is 0.0005752778961323202\n",
      "epoch: 30 step: 4, loss is 0.0010656294180080295\n",
      "epoch: 30 step: 5, loss is 0.0015752580948174\n",
      "epoch: 30 step: 6, loss is 0.0007313132518902421\n",
      "epoch: 30 step: 7, loss is 0.0009726040880195796\n",
      "epoch: 30 step: 8, loss is 0.000416979833971709\n",
      "epoch: 30 step: 9, loss is 0.00027024801238439977\n",
      "epoch: 30 step: 10, loss is 0.0011298516765236855\n",
      "epoch: 30 step: 11, loss is 0.0006209841812960804\n",
      "epoch: 30 step: 12, loss is 0.00038105083513073623\n",
      "epoch: 30 step: 13, loss is 0.0013002469204366207\n",
      "epoch: 30 step: 14, loss is 0.001301185810007155\n",
      "epoch: 30 step: 15, loss is 0.0002272853598697111\n",
      "epoch: 30 step: 16, loss is 0.00016317603876814246\n",
      "epoch: 30 step: 17, loss is 0.0004593744233716279\n",
      "epoch: 30 step: 18, loss is 0.00041314633563160896\n",
      "epoch: 30 step: 19, loss is 0.00021334487246349454\n",
      "epoch: 30 step: 20, loss is 0.0004020080668851733\n",
      "epoch: 30 step: 21, loss is 0.001570572261698544\n",
      "epoch: 30 step: 22, loss is 0.0006121858023107052\n",
      "epoch: 30 step: 23, loss is 0.00038830575067549944\n",
      "epoch: 30 step: 24, loss is 0.0004794409906025976\n",
      "epoch: 30 step: 25, loss is 0.0006691481685265899\n",
      "epoch: 30 step: 26, loss is 0.00048189080553129315\n",
      "epoch: 30 step: 27, loss is 0.0006210567662492394\n",
      "epoch: 30 step: 28, loss is 0.00035089251468889415\n",
      "epoch: 30 step: 29, loss is 0.0004357330035418272\n",
      "epoch: 30 step: 30, loss is 0.0005370618309825659\n",
      "epoch: 30 step: 31, loss is 0.00039236119482666254\n",
      "epoch: 30 step: 32, loss is 0.00015652472211513668\n",
      "epoch: 30 step: 33, loss is 0.0013062449870631099\n",
      "epoch: 30 step: 34, loss is 0.00037969424738548696\n",
      "epoch: 30 step: 35, loss is 0.0009819009574130177\n",
      "epoch: 30 step: 36, loss is 0.0007766205817461014\n",
      "epoch: 30 step: 37, loss is 0.0006027081399224699\n",
      "epoch: 30 step: 38, loss is 0.0020991642959415913\n",
      "epoch: 30 step: 39, loss is 0.0006667514098808169\n",
      "epoch: 30 step: 40, loss is 0.0005460226093418896\n",
      "epoch: 30 step: 41, loss is 0.0003396651882212609\n",
      "epoch: 30 step: 42, loss is 0.0008706807275302708\n",
      "epoch: 30 step: 43, loss is 0.0007137467036955059\n",
      "epoch: 30 step: 44, loss is 0.0008311800775118172\n",
      "epoch: 30 step: 45, loss is 0.0009019546560011804\n",
      "epoch: 30 step: 46, loss is 0.0008419006480835378\n",
      "epoch: 30 step: 47, loss is 0.0006485300255008042\n",
      "epoch: 30 step: 48, loss is 0.0012211906723678112\n",
      "epoch: 30 step: 49, loss is 0.0008014249615371227\n",
      "epoch: 30 step: 50, loss is 0.0005005554994568229\n",
      "epoch: 30 step: 51, loss is 0.0014310306869447231\n",
      "epoch: 30 step: 52, loss is 0.0004101133381482214\n",
      "epoch: 30 step: 53, loss is 0.0005836026975885034\n",
      "epoch: 30 step: 54, loss is 0.0011689862003549933\n",
      "epoch: 30 step: 55, loss is 0.0002506979799363762\n",
      "epoch: 30 step: 56, loss is 0.0003688014403451234\n",
      "epoch: 30 step: 57, loss is 0.0010885410010814667\n",
      "epoch: 30 step: 58, loss is 0.00025224359706044197\n",
      "epoch: 30 step: 59, loss is 0.0005089560872875154\n",
      "epoch: 30 step: 60, loss is 0.001132211065851152\n",
      "epoch: 30 step: 61, loss is 0.0008671856485307217\n",
      "epoch: 30 step: 62, loss is 0.0011090283514931798\n",
      "epoch: 30 step: 63, loss is 0.0016675328370183706\n",
      "epoch: 30 step: 64, loss is 0.0004641296109184623\n",
      "epoch: 30 step: 65, loss is 0.0008635075646452606\n",
      "epoch: 30 step: 66, loss is 0.0003072131657972932\n",
      "epoch: 30 step: 67, loss is 0.0007611570181325078\n",
      "epoch: 30 step: 68, loss is 0.0013146818382665515\n",
      "epoch: 30 step: 69, loss is 0.00013130553998053074\n",
      "epoch: 30 step: 70, loss is 0.0015389351174235344\n",
      "epoch: 30 step: 71, loss is 0.0006889318465255201\n",
      "epoch: 30 step: 72, loss is 0.0005126290488988161\n",
      "epoch: 30 step: 73, loss is 0.0008242054609581828\n",
      "epoch: 30 step: 74, loss is 0.0005650743842124939\n",
      "epoch: 30 step: 75, loss is 0.000395111070247367\n",
      "epoch: 30 step: 76, loss is 0.00022992436424829066\n",
      "epoch: 30 step: 77, loss is 0.00015091193199623376\n",
      "epoch: 30 step: 78, loss is 0.0004328117938712239\n",
      "epoch: 30 step: 79, loss is 0.0007080713985487819\n",
      "epoch: 30 step: 80, loss is 0.0003727237635757774\n",
      "epoch: 30 step: 81, loss is 0.0004544569237623364\n",
      "epoch: 30 step: 82, loss is 0.00048050947953015566\n",
      "epoch: 30 step: 83, loss is 0.0006819326663389802\n",
      "epoch: 30 step: 84, loss is 0.0007094571483321488\n",
      "epoch: 30 step: 85, loss is 0.0010362935718148947\n",
      "epoch: 30 step: 86, loss is 0.0003373317886143923\n",
      "epoch: 30 step: 87, loss is 0.0008506755693815649\n",
      "epoch: 30 step: 88, loss is 0.00091962656006217\n",
      "epoch: 30 step: 89, loss is 0.0007000997429713607\n",
      "epoch: 30 step: 90, loss is 0.0003639620845206082\n",
      "epoch: 30 step: 91, loss is 0.0017929491586983204\n",
      "epoch: 30 step: 92, loss is 0.001077311928384006\n",
      "epoch: 30 step: 93, loss is 0.00046831488725729287\n",
      "epoch: 30 step: 94, loss is 0.0007966113626025617\n",
      "epoch: 30 step: 95, loss is 0.0008566192118450999\n",
      "epoch: 30 step: 96, loss is 0.0007844919455237687\n",
      "epoch: 30 step: 97, loss is 0.00017827552801463753\n",
      "epoch: 30 step: 98, loss is 0.0010227287421002984\n",
      "epoch: 30 step: 99, loss is 0.0005179607542231679\n",
      "epoch: 30 step: 100, loss is 0.0006054870318621397\n",
      "epoch: 30 step: 101, loss is 0.0005314156296662986\n",
      "epoch: 30 step: 102, loss is 0.0003950831887777895\n",
      "epoch: 30 step: 103, loss is 0.0008087949245236814\n",
      "epoch: 30 step: 104, loss is 0.0006200997158885002\n",
      "epoch: 30 step: 105, loss is 0.0004897141479887068\n",
      "epoch: 30 step: 106, loss is 0.00022948892728891224\n",
      "epoch: 30 step: 107, loss is 0.00025206166901625693\n",
      "epoch: 30 step: 108, loss is 0.001706330687738955\n",
      "epoch: 30 step: 109, loss is 0.00018725999689195305\n",
      "epoch: 30 step: 110, loss is 0.0004688514454755932\n",
      "epoch: 30 step: 111, loss is 0.0006448843632824719\n",
      "epoch: 30 step: 112, loss is 0.0007292541558854282\n",
      "epoch: 30 step: 113, loss is 8.599138527642936e-05\n",
      "epoch: 30 step: 114, loss is 0.0008980815764516592\n",
      "epoch: 30 step: 115, loss is 0.0009423631126992404\n",
      "epoch: 30 step: 116, loss is 0.00020857559866271913\n",
      "epoch: 30 step: 117, loss is 0.0007938804337754846\n",
      "epoch: 30 step: 118, loss is 0.000486566626932472\n",
      "epoch: 30 step: 119, loss is 0.0006667231791652739\n",
      "epoch: 30 step: 120, loss is 0.0003281930403318256\n",
      "epoch: 30 step: 121, loss is 0.0003038884315174073\n",
      "epoch: 30 step: 122, loss is 0.0005320865311659873\n",
      "epoch: 30 step: 123, loss is 0.0003426566254347563\n",
      "epoch: 30 step: 124, loss is 0.0009168434771709144\n",
      "epoch: 30 step: 125, loss is 0.0010375394485890865\n",
      "epoch: 30 step: 126, loss is 0.0003949824895244092\n",
      "epoch: 30 step: 127, loss is 0.0006117707816883922\n",
      "epoch: 30 step: 128, loss is 0.0009070266969501972\n",
      "epoch: 30 step: 129, loss is 0.00024469810887239873\n",
      "epoch: 30 step: 130, loss is 0.00020419868815224618\n",
      "epoch: 30 step: 131, loss is 0.0005382936797104776\n",
      "epoch: 30 step: 132, loss is 0.0003198097401764244\n",
      "epoch: 30 step: 133, loss is 0.000851691176649183\n",
      "epoch: 30 step: 134, loss is 0.00047201907727867365\n",
      "epoch: 30 step: 135, loss is 0.0003413430240470916\n",
      "epoch: 30 step: 136, loss is 0.0005974629893898964\n",
      "epoch: 30 step: 137, loss is 0.0008877837099134922\n",
      "epoch: 30 step: 138, loss is 0.0008019626839086413\n",
      "epoch: 30 step: 139, loss is 0.0002889174793381244\n",
      "epoch: 30 step: 140, loss is 0.00046559629845432937\n",
      "epoch: 30 step: 141, loss is 0.002423910889774561\n",
      "epoch: 30 step: 142, loss is 0.0011876464122906327\n",
      "epoch: 30 step: 143, loss is 0.0007630824111402035\n",
      "epoch: 30 step: 144, loss is 0.0006319064414128661\n",
      "epoch: 30 step: 145, loss is 0.0006451826775446534\n",
      "epoch: 30 step: 146, loss is 0.0009562091436237097\n",
      "epoch: 30 step: 147, loss is 0.0004738840798381716\n",
      "epoch: 30 step: 148, loss is 0.0008136115502566099\n",
      "epoch: 30 step: 149, loss is 0.0011080146068707108\n",
      "epoch: 30 step: 150, loss is 0.001283917692489922\n",
      "epoch: 30 step: 151, loss is 0.00023414294992107898\n",
      "epoch: 30 step: 152, loss is 0.0003362708375789225\n",
      "epoch: 30 step: 153, loss is 0.0005878793890587986\n",
      "epoch: 30 step: 154, loss is 0.0011687937658280134\n",
      "epoch: 30 step: 155, loss is 0.0007550307782366872\n",
      "epoch: 30 step: 156, loss is 0.0007363342447206378\n",
      "epoch: 30 step: 157, loss is 0.0006687162676826119\n",
      "epoch: 30 step: 158, loss is 0.0014583826996386051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 step: 159, loss is 0.000699802185408771\n",
      "epoch: 30 step: 160, loss is 0.00026018975768238306\n",
      "epoch: 30 step: 161, loss is 0.00042814589687623084\n",
      "epoch: 30 step: 162, loss is 0.000402112869778648\n",
      "epoch: 30 step: 163, loss is 0.0004921435029245913\n",
      "epoch: 30 step: 164, loss is 0.0003410311182960868\n",
      "epoch: 30 step: 165, loss is 0.0009455457329750061\n",
      "epoch: 30 step: 166, loss is 0.0009827053872868419\n",
      "epoch: 30 step: 167, loss is 0.00044287584023550153\n",
      "epoch: 30 step: 168, loss is 0.0004751637461595237\n",
      "epoch: 30 step: 169, loss is 0.000954184855800122\n",
      "epoch: 30 step: 170, loss is 0.0004920415813103318\n",
      "epoch: 30 step: 171, loss is 0.00042997850687243044\n",
      "epoch: 30 step: 172, loss is 0.0017901377286762\n",
      "epoch: 30 step: 173, loss is 0.0003984274226240814\n",
      "epoch: 30 step: 174, loss is 0.0005180428270250559\n",
      "epoch: 30 step: 175, loss is 0.0011617214186117053\n",
      "epoch: 30 step: 176, loss is 0.000939520716201514\n",
      "epoch: 30 step: 177, loss is 0.0006869696662761271\n",
      "epoch: 30 step: 178, loss is 0.0006417248514480889\n",
      "epoch: 30 step: 179, loss is 0.0009755369974300265\n",
      "epoch: 30 step: 180, loss is 0.001328829675912857\n",
      "epoch: 30 step: 181, loss is 0.00028997345361858606\n",
      "epoch: 30 step: 182, loss is 0.0004541238595265895\n",
      "epoch: 30 step: 183, loss is 0.0009511054377071559\n",
      "epoch: 30 step: 184, loss is 0.0008306255331262946\n",
      "epoch: 30 step: 185, loss is 0.0003313427441753447\n",
      "epoch: 30 step: 186, loss is 0.001477370853535831\n",
      "epoch: 30 step: 187, loss is 0.00031042180489748716\n",
      "epoch: 30 step: 188, loss is 0.0005718783941119909\n",
      "epoch: 30 step: 189, loss is 0.0004978971555829048\n",
      "epoch: 30 step: 190, loss is 0.0008318919572047889\n",
      "epoch: 30 step: 191, loss is 0.0007819351740181446\n",
      "epoch: 30 step: 192, loss is 0.0007148168515414\n",
      "epoch: 30 step: 193, loss is 0.0005290804547257721\n",
      "epoch: 30 step: 194, loss is 0.001267811399884522\n",
      "epoch: 30 step: 195, loss is 0.0005417802021838725\n",
      "epoch: 30 step: 196, loss is 0.0007513802847824991\n",
      "epoch: 30 step: 197, loss is 0.0008585924515500665\n",
      "epoch: 30 step: 198, loss is 0.0007467787945643067\n",
      "epoch: 30 step: 199, loss is 0.0007313925307244062\n",
      "epoch: 30 step: 200, loss is 0.00034984052763320506\n",
      "epoch: 30 step: 201, loss is 0.0004102952079847455\n",
      "epoch: 30 step: 202, loss is 0.0018458960112184286\n",
      "epoch: 30 step: 203, loss is 0.001233554445207119\n",
      "epoch: 30 step: 204, loss is 0.0007850698893889785\n",
      "epoch: 30 step: 205, loss is 0.0010013481369242072\n",
      "epoch: 30 step: 206, loss is 0.00047879660269245505\n",
      "epoch: 30 step: 207, loss is 0.0009175327140837908\n",
      "epoch: 30 step: 208, loss is 0.000490393431391567\n",
      "epoch: 30 step: 209, loss is 0.0003726708819158375\n",
      "epoch: 30 step: 210, loss is 0.0008532963693141937\n",
      "epoch: 30 step: 211, loss is 0.00023447364219464362\n",
      "epoch: 30 step: 212, loss is 0.0002957434335257858\n",
      "epoch: 30 step: 213, loss is 0.001272369408980012\n",
      "epoch: 30 step: 214, loss is 0.0004427112580742687\n",
      "epoch: 30 step: 215, loss is 0.0013392207911238074\n",
      "epoch: 30 step: 216, loss is 0.000530440651345998\n",
      "epoch: 30 step: 217, loss is 0.00044142830302007496\n",
      "epoch: 30 step: 218, loss is 0.000849275616928935\n",
      "epoch: 30 step: 219, loss is 0.0006125667714513838\n",
      "epoch: 30 step: 220, loss is 0.0018861040007323027\n",
      "epoch: 30 step: 221, loss is 0.0003623332886490971\n",
      "epoch: 30 step: 222, loss is 0.0005545212188735604\n",
      "epoch: 30 step: 223, loss is 0.0005474923527799547\n",
      "epoch: 30 step: 224, loss is 0.0007475627353414893\n",
      "epoch: 30 step: 225, loss is 0.00011348663974786177\n",
      "epoch: 30 step: 226, loss is 0.0007038775365799665\n",
      "epoch: 30 step: 227, loss is 0.0007008211687207222\n",
      "epoch: 30 step: 228, loss is 0.00026103705749846995\n",
      "epoch: 30 step: 229, loss is 0.0005607592756859958\n",
      "epoch: 30 step: 230, loss is 0.0007704371237196028\n",
      "epoch: 30 step: 231, loss is 0.0006207430851645768\n",
      "epoch: 30 step: 232, loss is 0.0006234668544493616\n",
      "epoch: 30 step: 233, loss is 0.000864301051478833\n",
      "epoch: 30 step: 234, loss is 0.0004973033792339265\n",
      "epoch: 30 step: 235, loss is 0.000799968431238085\n",
      "epoch: 30 step: 236, loss is 0.00035429158015176654\n",
      "epoch: 30 step: 237, loss is 0.001321864896453917\n",
      "epoch: 30 step: 238, loss is 0.0006298103835433722\n",
      "epoch: 30 step: 239, loss is 0.0008471363107673824\n",
      "epoch: 30 step: 240, loss is 0.0005401280941441655\n",
      "epoch: 30 step: 241, loss is 0.0003818387631326914\n",
      "epoch: 30 step: 242, loss is 0.0009831000352278352\n",
      "epoch: 30 step: 243, loss is 0.00019176981004420668\n",
      "epoch: 30 step: 244, loss is 0.0009323787526227534\n",
      "epoch: 30 step: 245, loss is 0.0016306196339428425\n",
      "epoch: 30 step: 246, loss is 0.00047281678416766226\n",
      "epoch: 30 step: 247, loss is 0.0003926958015654236\n",
      "epoch: 30 step: 248, loss is 0.0004126899584662169\n",
      "epoch: 30 step: 249, loss is 0.0007885773084126413\n",
      "epoch: 30 step: 250, loss is 0.0009672589367255569\n",
      "epoch: 30 step: 251, loss is 0.0014621634036302567\n",
      "epoch: 30 step: 252, loss is 0.0006867200718261302\n",
      "epoch: 30 step: 253, loss is 0.0003338024253025651\n",
      "epoch: 30 step: 254, loss is 0.0006454898975789547\n",
      "epoch: 30 step: 255, loss is 0.00019170627638231963\n",
      "epoch: 30 step: 256, loss is 0.0007546475389972329\n",
      "epoch: 30 step: 257, loss is 0.0005093575455248356\n",
      "epoch: 30 step: 258, loss is 0.0008724694489501417\n",
      "epoch: 30 step: 259, loss is 0.000734338304027915\n",
      "epoch: 30 step: 260, loss is 0.0004345450142864138\n",
      "epoch: 30 step: 261, loss is 0.0003583125944714993\n",
      "epoch: 30 step: 262, loss is 0.0005984468152746558\n",
      "epoch: 30 step: 263, loss is 0.0003380058042239398\n",
      "epoch: 30 step: 264, loss is 0.00017093263159040362\n",
      "epoch: 30 step: 265, loss is 0.0011413467582315207\n",
      "epoch: 30 step: 266, loss is 0.0009829113259911537\n",
      "epoch: 30 step: 267, loss is 0.0005891889450140297\n",
      "epoch: 30 step: 268, loss is 0.0001990457676583901\n",
      "epoch: 30 step: 269, loss is 0.0010130946757271886\n",
      "epoch: 30 step: 270, loss is 4.510103462962434e-05\n",
      "epoch: 30 step: 271, loss is 0.0002921995474025607\n",
      "epoch: 30 step: 272, loss is 0.0004144349950365722\n",
      "epoch: 30 step: 273, loss is 0.0004686298780143261\n",
      "epoch: 30 step: 274, loss is 0.0011213431134819984\n",
      "epoch: 30 step: 275, loss is 0.0002356569020776078\n",
      "epoch: 30 step: 276, loss is 0.0006408790359273553\n",
      "epoch: 30 step: 277, loss is 0.0010701061692088842\n",
      "epoch: 30 step: 278, loss is 7.213627395685762e-05\n",
      "epoch: 30 step: 279, loss is 0.0010098974453285336\n",
      "epoch: 30 step: 280, loss is 0.0014389239950105548\n",
      "epoch: 30 step: 281, loss is 0.0002935898082796484\n",
      "epoch: 30 step: 282, loss is 0.0006341973203234375\n",
      "epoch: 30 step: 283, loss is 0.0004372438124846667\n",
      "epoch: 30 step: 284, loss is 7.854227442294359e-05\n",
      "epoch: 30 step: 285, loss is 0.0006045931368134916\n",
      "epoch: 30 step: 286, loss is 0.0007913687149994075\n",
      "epoch: 30 step: 287, loss is 0.0008766818209551275\n",
      "epoch: 30 step: 288, loss is 0.0014153269585222006\n",
      "epoch: 30 step: 289, loss is 0.00040470264502801\n",
      "epoch: 30 step: 290, loss is 0.0011082949349656701\n",
      "epoch: 30 step: 291, loss is 0.0003769074392039329\n",
      "epoch: 30 step: 292, loss is 0.0006078191217966378\n",
      "epoch: 30 step: 293, loss is 0.0006226710393093526\n",
      "epoch: 30 step: 294, loss is 0.0008682433981448412\n",
      "epoch: 30 step: 295, loss is 0.0008398773497901857\n",
      "epoch: 30 step: 296, loss is 0.0005455883801914752\n",
      "epoch: 30 step: 297, loss is 0.0009726542048156261\n",
      "epoch: 30 step: 298, loss is 0.00044900577631779015\n",
      "epoch: 30 step: 299, loss is 0.00032907628337852657\n",
      "epoch: 30 step: 300, loss is 0.0002869184245355427\n",
      "epoch: 30 step: 301, loss is 0.000419482501456514\n",
      "epoch: 30 step: 302, loss is 0.0007640091353096068\n",
      "epoch: 30 step: 303, loss is 0.002062851330265403\n",
      "epoch: 30 step: 304, loss is 0.0006097045843489468\n",
      "epoch: 30 step: 305, loss is 0.0009400512790307403\n",
      "epoch: 30 step: 306, loss is 0.0011065531289204955\n",
      "epoch: 30 step: 307, loss is 0.0022950030397623777\n",
      "epoch: 30 step: 308, loss is 0.0010499435011297464\n",
      "epoch: 30 step: 309, loss is 0.000781831971835345\n",
      "epoch: 30 step: 310, loss is 0.00031056220177561045\n",
      "epoch: 30 step: 311, loss is 0.0005258839810267091\n",
      "epoch: 30 step: 312, loss is 0.0004336181445978582\n",
      "epoch: 30 step: 313, loss is 0.0005473913042806089\n",
      "epoch: 30 step: 314, loss is 0.0007202853448688984\n",
      "epoch: 30 step: 315, loss is 0.0009257802157662809\n",
      "epoch: 30 step: 316, loss is 0.0007110588485375047\n",
      "epoch: 30 step: 317, loss is 0.0008971353527158499\n",
      "epoch: 30 step: 318, loss is 0.0003026693011634052\n",
      "epoch: 30 step: 319, loss is 0.000991487642750144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 step: 320, loss is 0.00043157636537216604\n",
      "epoch: 30 step: 321, loss is 0.0007278790581040084\n",
      "epoch: 30 step: 322, loss is 0.0005232402472756803\n",
      "epoch: 30 step: 323, loss is 0.0005978600820526481\n",
      "epoch: 30 step: 324, loss is 0.000371880509192124\n",
      "epoch: 30 step: 325, loss is 0.0014634227845817804\n",
      "epoch: 30 step: 326, loss is 0.000677526171784848\n",
      "epoch: 30 step: 327, loss is 0.00044099855585955083\n",
      "epoch: 30 step: 328, loss is 0.0009839487029239535\n",
      "epoch: 30 step: 329, loss is 0.0001233745861100033\n",
      "epoch: 30 step: 330, loss is 0.0004689257766585797\n",
      "epoch: 30 step: 331, loss is 0.000506302691064775\n",
      "epoch: 30 step: 332, loss is 0.00030168984085321426\n",
      "epoch: 30 step: 333, loss is 0.0006523221964016557\n",
      "epoch: 30 step: 334, loss is 0.0008300213958136737\n",
      "epoch: 30 step: 335, loss is 0.0008685785578563809\n",
      "epoch: 30 step: 336, loss is 0.00031590351136401296\n",
      "epoch: 30 step: 337, loss is 0.0004936079494655132\n",
      "epoch: 30 step: 338, loss is 0.0007335917907766998\n",
      "epoch: 30 step: 339, loss is 0.00023452100867871195\n",
      "epoch: 30 step: 340, loss is 0.0007220507250167429\n",
      "epoch: 30 step: 341, loss is 0.001032668398693204\n",
      "epoch: 30 step: 342, loss is 0.0007018096512183547\n",
      "epoch: 30 step: 343, loss is 0.0005527960602194071\n",
      "epoch: 30 step: 344, loss is 0.0004978742799721658\n",
      "epoch: 30 step: 345, loss is 0.0006947862566448748\n",
      "epoch: 30 step: 346, loss is 0.0003219104546587914\n",
      "epoch: 30 step: 347, loss is 0.0005960186826996505\n",
      "epoch: 30 step: 348, loss is 0.0016732874792069197\n",
      "epoch: 30 step: 349, loss is 0.0005640994058921933\n",
      "epoch: 30 step: 350, loss is 0.00037531365524046123\n",
      "epoch: 30 step: 351, loss is 0.0010114823235198855\n",
      "epoch: 30 step: 352, loss is 0.0006067570648156106\n",
      "epoch: 30 step: 353, loss is 0.0005563253071159124\n",
      "epoch: 30 step: 354, loss is 0.0007131727761588991\n",
      "epoch: 30 step: 355, loss is 0.0014308436075225472\n",
      "epoch: 30 step: 356, loss is 0.001148780807852745\n",
      "epoch: 30 step: 357, loss is 0.000729392864741385\n",
      "epoch: 30 step: 358, loss is 0.00047464706585742533\n",
      "epoch: 30 step: 359, loss is 0.0005110695492476225\n",
      "epoch: 30 step: 360, loss is 0.0007188263698481023\n",
      "epoch: 30 step: 361, loss is 0.0006491863750852644\n",
      "epoch: 30 step: 362, loss is 0.0011988587211817503\n",
      "epoch: 30 step: 363, loss is 0.000713987392373383\n",
      "epoch: 30 step: 364, loss is 0.0006545897340402007\n",
      "epoch: 30 step: 365, loss is 0.0006692818715237081\n",
      "epoch: 30 step: 366, loss is 0.0008869856246747077\n",
      "epoch: 30 step: 367, loss is 0.00041353507549501956\n",
      "epoch: 30 step: 368, loss is 0.00048805601545609534\n",
      "epoch: 30 step: 369, loss is 0.0008583800517953932\n",
      "epoch: 30 step: 370, loss is 0.00028583258972503245\n",
      "epoch: 30 step: 371, loss is 0.00028179760556668043\n",
      "epoch: 30 step: 372, loss is 0.00037793981027789414\n",
      "epoch: 30 step: 373, loss is 0.00044757197611033916\n",
      "epoch: 30 step: 374, loss is 0.00013298718840815127\n",
      "epoch: 30 step: 375, loss is 0.000744472723454237\n",
      "Train epoch time: 11930.540 ms, per step time: 31.815 ms\n",
      "epoch: 31 step: 1, loss is 0.0005885226419195533\n",
      "epoch: 31 step: 2, loss is 0.0003691539168357849\n",
      "epoch: 31 step: 3, loss is 0.0004131418536417186\n",
      "epoch: 31 step: 4, loss is 0.0008479607058688998\n",
      "epoch: 31 step: 5, loss is 0.00032080404344014823\n",
      "epoch: 31 step: 6, loss is 0.0004001737688668072\n",
      "epoch: 31 step: 7, loss is 0.00015652987349312752\n",
      "epoch: 31 step: 8, loss is 0.0007271431968547404\n",
      "epoch: 31 step: 9, loss is 0.0010231572668999434\n",
      "epoch: 31 step: 10, loss is 0.000552307115867734\n",
      "epoch: 31 step: 11, loss is 0.0005999120185151696\n",
      "epoch: 31 step: 12, loss is 0.0007459149928763509\n",
      "epoch: 31 step: 13, loss is 0.0006774424109607935\n",
      "epoch: 31 step: 14, loss is 0.00023425580002367496\n",
      "epoch: 31 step: 15, loss is 0.0002630784292705357\n",
      "epoch: 31 step: 16, loss is 0.0007136926869861782\n",
      "epoch: 31 step: 17, loss is 0.0011997853871434927\n",
      "epoch: 31 step: 18, loss is 0.0009309402666985989\n",
      "epoch: 31 step: 19, loss is 0.0011127707548439503\n",
      "epoch: 31 step: 20, loss is 0.0006433061207644641\n",
      "epoch: 31 step: 21, loss is 0.0007025724044069648\n",
      "epoch: 31 step: 22, loss is 0.0007525331457145512\n",
      "epoch: 31 step: 23, loss is 0.000966775172855705\n",
      "epoch: 31 step: 24, loss is 0.00038207133184187114\n",
      "epoch: 31 step: 25, loss is 0.0003164559311699122\n",
      "epoch: 31 step: 26, loss is 0.00030008243629708886\n",
      "epoch: 31 step: 27, loss is 0.0010760694276541471\n",
      "epoch: 31 step: 28, loss is 0.0014637359417974949\n",
      "epoch: 31 step: 29, loss is 0.0011466133873909712\n",
      "epoch: 31 step: 30, loss is 0.0008125870954245329\n",
      "epoch: 31 step: 31, loss is 0.0008611883386038244\n",
      "epoch: 31 step: 32, loss is 0.00044808865641243756\n",
      "epoch: 31 step: 33, loss is 0.0009401278221048415\n",
      "epoch: 31 step: 34, loss is 0.0006455480470322073\n",
      "epoch: 31 step: 35, loss is 0.0008391361334361136\n",
      "epoch: 31 step: 36, loss is 0.000986626255325973\n",
      "epoch: 31 step: 37, loss is 0.0005216273129917681\n",
      "epoch: 31 step: 38, loss is 0.00028814279357902706\n",
      "epoch: 31 step: 39, loss is 0.0005977227701805532\n",
      "epoch: 31 step: 40, loss is 0.00038800699985586107\n",
      "epoch: 31 step: 41, loss is 0.0006220058421604335\n",
      "epoch: 31 step: 42, loss is 0.00023169735504779965\n",
      "epoch: 31 step: 43, loss is 0.001877032220363617\n",
      "epoch: 31 step: 44, loss is 0.00024069291248451918\n",
      "epoch: 31 step: 45, loss is 0.000892766285687685\n",
      "epoch: 31 step: 46, loss is 0.0005316614406183362\n",
      "epoch: 31 step: 47, loss is 0.00045822697575204074\n",
      "epoch: 31 step: 48, loss is 0.0013536408077925444\n",
      "epoch: 31 step: 49, loss is 0.0002013328339671716\n",
      "epoch: 31 step: 50, loss is 0.0008695443975739181\n",
      "epoch: 31 step: 51, loss is 0.0004773397813551128\n",
      "epoch: 31 step: 52, loss is 0.0014496035873889923\n",
      "epoch: 31 step: 53, loss is 0.0011584644671529531\n",
      "epoch: 31 step: 54, loss is 0.0002753236622083932\n",
      "epoch: 31 step: 55, loss is 0.0013980901567265391\n",
      "epoch: 31 step: 56, loss is 0.00044339863234199584\n",
      "epoch: 31 step: 57, loss is 0.00046267517609521747\n",
      "epoch: 31 step: 58, loss is 0.000975190894678235\n",
      "epoch: 31 step: 59, loss is 0.001264675403945148\n",
      "epoch: 31 step: 60, loss is 0.00048398709623143077\n",
      "epoch: 31 step: 61, loss is 0.0007014055154286325\n",
      "epoch: 31 step: 62, loss is 0.0006015914841555059\n",
      "epoch: 31 step: 63, loss is 0.0006444985629059374\n",
      "epoch: 31 step: 64, loss is 0.0005748656112700701\n",
      "epoch: 31 step: 65, loss is 0.0007157700601965189\n",
      "epoch: 31 step: 66, loss is 0.0003413087106309831\n",
      "epoch: 31 step: 67, loss is 0.0008848913130350411\n",
      "epoch: 31 step: 68, loss is 0.0005968617624603212\n",
      "epoch: 31 step: 69, loss is 0.0012906306656077504\n",
      "epoch: 31 step: 70, loss is 0.0007070821011438966\n",
      "epoch: 31 step: 71, loss is 0.0004607200971804559\n",
      "epoch: 31 step: 72, loss is 0.001060807378962636\n",
      "epoch: 31 step: 73, loss is 0.0002361622464377433\n",
      "epoch: 31 step: 74, loss is 0.0007927449769340456\n",
      "epoch: 31 step: 75, loss is 0.000574059144128114\n",
      "epoch: 31 step: 76, loss is 0.0007686011376790702\n",
      "epoch: 31 step: 77, loss is 0.0008941293344832957\n",
      "epoch: 31 step: 78, loss is 0.0005908061284571886\n",
      "epoch: 31 step: 79, loss is 0.0005479612736962736\n",
      "epoch: 31 step: 80, loss is 0.0008847356657497585\n",
      "epoch: 31 step: 81, loss is 0.0002772131992969662\n",
      "epoch: 31 step: 82, loss is 0.0010895138839259744\n",
      "epoch: 31 step: 83, loss is 0.00023082405095919967\n",
      "epoch: 31 step: 84, loss is 0.0006563880015164614\n",
      "epoch: 31 step: 85, loss is 0.00046242718235589564\n",
      "epoch: 31 step: 86, loss is 0.00037499339669011533\n",
      "epoch: 31 step: 87, loss is 0.0008814670145511627\n",
      "epoch: 31 step: 88, loss is 0.0007620105752721429\n",
      "epoch: 31 step: 89, loss is 0.0006917417049407959\n",
      "epoch: 31 step: 90, loss is 0.0015355697833001614\n",
      "epoch: 31 step: 91, loss is 0.00021718762582167983\n",
      "epoch: 31 step: 92, loss is 0.0006205238751135767\n",
      "epoch: 31 step: 93, loss is 0.0002793454332277179\n",
      "epoch: 31 step: 94, loss is 0.0005375411710701883\n",
      "epoch: 31 step: 95, loss is 0.00015410265768878162\n",
      "epoch: 31 step: 96, loss is 0.0002791842562146485\n",
      "epoch: 31 step: 97, loss is 0.0004906863323412836\n",
      "epoch: 31 step: 98, loss is 0.00036624440690502524\n",
      "epoch: 31 step: 99, loss is 0.0006870918441563845\n",
      "epoch: 31 step: 100, loss is 0.0002983020676765591\n",
      "epoch: 31 step: 101, loss is 0.0002862506080418825\n",
      "epoch: 31 step: 102, loss is 0.0005099166301079094\n",
      "epoch: 31 step: 103, loss is 0.0007698531844653189\n",
      "epoch: 31 step: 104, loss is 0.0007611130131408572\n",
      "epoch: 31 step: 105, loss is 0.00038961568498052657\n",
      "epoch: 31 step: 106, loss is 0.0009441770962439477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 step: 107, loss is 0.0003921490570064634\n",
      "epoch: 31 step: 108, loss is 0.0003430164069868624\n",
      "epoch: 31 step: 109, loss is 0.00041214204975403845\n",
      "epoch: 31 step: 110, loss is 0.0010547323618084192\n",
      "epoch: 31 step: 111, loss is 0.0008134372183121741\n",
      "epoch: 31 step: 112, loss is 0.0004342432366684079\n",
      "epoch: 31 step: 113, loss is 0.0003483228792902082\n",
      "epoch: 31 step: 114, loss is 0.00017528372700326145\n",
      "epoch: 31 step: 115, loss is 0.0013357411371544003\n",
      "epoch: 31 step: 116, loss is 0.0003419849672354758\n",
      "epoch: 31 step: 117, loss is 0.0014411202864721417\n",
      "epoch: 31 step: 118, loss is 0.0006459540454670787\n",
      "epoch: 31 step: 119, loss is 0.001942087896168232\n",
      "epoch: 31 step: 120, loss is 7.791429379722103e-05\n",
      "epoch: 31 step: 121, loss is 0.0013167291181162\n",
      "epoch: 31 step: 122, loss is 0.00020128874166402966\n",
      "epoch: 31 step: 123, loss is 0.00012004649033769965\n",
      "epoch: 31 step: 124, loss is 0.0012663158122450113\n",
      "epoch: 31 step: 125, loss is 0.000453584740171209\n",
      "epoch: 31 step: 126, loss is 0.0004902409273199737\n",
      "epoch: 31 step: 127, loss is 0.0006320377578958869\n",
      "epoch: 31 step: 128, loss is 0.0003640388895291835\n",
      "epoch: 31 step: 129, loss is 0.001007139217108488\n",
      "epoch: 31 step: 130, loss is 0.0010253795189782977\n",
      "epoch: 31 step: 131, loss is 0.0005778202903456986\n",
      "epoch: 31 step: 132, loss is 0.0008347714901901782\n",
      "epoch: 31 step: 133, loss is 0.0002693998103495687\n",
      "epoch: 31 step: 134, loss is 0.0013093027519062161\n",
      "epoch: 31 step: 135, loss is 0.00035250760265626013\n",
      "epoch: 31 step: 136, loss is 0.00048072339268401265\n",
      "epoch: 31 step: 137, loss is 0.0005431075114756823\n",
      "epoch: 31 step: 138, loss is 0.0002099799894494936\n",
      "epoch: 31 step: 139, loss is 0.0005775579484179616\n",
      "epoch: 31 step: 140, loss is 0.0008151123183779418\n",
      "epoch: 31 step: 141, loss is 0.00037194695323705673\n",
      "epoch: 31 step: 142, loss is 0.0008504302822984755\n",
      "epoch: 31 step: 143, loss is 0.0004380690515972674\n",
      "epoch: 31 step: 144, loss is 0.0006125690415501595\n",
      "epoch: 31 step: 145, loss is 0.0014608644414693117\n",
      "epoch: 31 step: 146, loss is 0.0011406895937398076\n",
      "epoch: 31 step: 147, loss is 0.00041385277290828526\n",
      "epoch: 31 step: 148, loss is 0.0008954384247772396\n",
      "epoch: 31 step: 149, loss is 0.0006627627881243825\n",
      "epoch: 31 step: 150, loss is 0.0008303381036967039\n",
      "epoch: 31 step: 151, loss is 0.0012292562751099467\n",
      "epoch: 31 step: 152, loss is 0.0015340435784310102\n",
      "epoch: 31 step: 153, loss is 0.0007322154124267399\n",
      "epoch: 31 step: 154, loss is 0.0002962497528642416\n",
      "epoch: 31 step: 155, loss is 0.0004759844159707427\n",
      "epoch: 31 step: 156, loss is 0.00045111458166502416\n",
      "epoch: 31 step: 157, loss is 0.0006229517748579383\n",
      "epoch: 31 step: 158, loss is 0.00036647001979872584\n",
      "epoch: 31 step: 159, loss is 0.0005627745995298028\n",
      "epoch: 31 step: 160, loss is 0.0004350350354798138\n",
      "epoch: 31 step: 161, loss is 0.0006297084037214518\n",
      "epoch: 31 step: 162, loss is 0.00064800278050825\n",
      "epoch: 31 step: 163, loss is 0.0004672790819313377\n",
      "epoch: 31 step: 164, loss is 0.0002619504521135241\n",
      "epoch: 31 step: 165, loss is 0.0004006706876680255\n",
      "epoch: 31 step: 166, loss is 0.00020983423746656626\n",
      "epoch: 31 step: 167, loss is 0.000667326501570642\n",
      "epoch: 31 step: 168, loss is 0.0007900167838670313\n",
      "epoch: 31 step: 169, loss is 0.0005982663715258241\n",
      "epoch: 31 step: 170, loss is 0.0009849189082160592\n",
      "epoch: 31 step: 171, loss is 0.0008923144196160138\n",
      "epoch: 31 step: 172, loss is 0.00019197861547581851\n",
      "epoch: 31 step: 173, loss is 0.0009019912104122341\n",
      "epoch: 31 step: 174, loss is 0.0006162717472761869\n",
      "epoch: 31 step: 175, loss is 0.0003501403843984008\n",
      "epoch: 31 step: 176, loss is 0.0011405006516724825\n",
      "epoch: 31 step: 177, loss is 0.00038168361061252654\n",
      "epoch: 31 step: 178, loss is 0.001868327264674008\n",
      "epoch: 31 step: 179, loss is 0.000579143175855279\n",
      "epoch: 31 step: 180, loss is 0.0005379068315960467\n",
      "epoch: 31 step: 181, loss is 0.0016759870341047645\n",
      "epoch: 31 step: 182, loss is 0.001003043376840651\n",
      "epoch: 31 step: 183, loss is 0.0004477359470911324\n",
      "epoch: 31 step: 184, loss is 0.0004966986016370356\n",
      "epoch: 31 step: 185, loss is 0.0008671907125972211\n",
      "epoch: 31 step: 186, loss is 0.0012620678171515465\n",
      "epoch: 31 step: 187, loss is 0.00023889880685601383\n",
      "epoch: 31 step: 188, loss is 0.0005144334863871336\n",
      "epoch: 31 step: 189, loss is 0.0010367195354774594\n",
      "epoch: 31 step: 190, loss is 0.0003441317530814558\n",
      "epoch: 31 step: 191, loss is 0.0007335537229664624\n",
      "epoch: 31 step: 192, loss is 0.00021693685266654938\n",
      "epoch: 31 step: 193, loss is 0.0005241743056103587\n",
      "epoch: 31 step: 194, loss is 0.0007185591966845095\n",
      "epoch: 31 step: 195, loss is 0.0010113597381860018\n",
      "epoch: 31 step: 196, loss is 0.0011723689967766404\n",
      "epoch: 31 step: 197, loss is 0.0015734437620267272\n",
      "epoch: 31 step: 198, loss is 0.0006033549434505403\n",
      "epoch: 31 step: 199, loss is 0.00022633949993178248\n",
      "epoch: 31 step: 200, loss is 0.0015654964372515678\n",
      "epoch: 31 step: 201, loss is 0.0009102449985221028\n",
      "epoch: 31 step: 202, loss is 0.000866600894369185\n",
      "epoch: 31 step: 203, loss is 0.0007814130512997508\n",
      "epoch: 31 step: 204, loss is 7.97105094534345e-05\n",
      "epoch: 31 step: 205, loss is 0.000332955620251596\n",
      "epoch: 31 step: 206, loss is 0.0005196338752284646\n",
      "epoch: 31 step: 207, loss is 0.0007022973150014877\n",
      "epoch: 31 step: 208, loss is 0.0012210208224132657\n",
      "epoch: 31 step: 209, loss is 0.0008550190250389278\n",
      "epoch: 31 step: 210, loss is 0.0008443609694950283\n",
      "epoch: 31 step: 211, loss is 0.0009259121143259108\n",
      "epoch: 31 step: 212, loss is 0.0009859944693744183\n",
      "epoch: 31 step: 213, loss is 0.0006971140392124653\n",
      "epoch: 31 step: 214, loss is 0.0014621455920860171\n",
      "epoch: 31 step: 215, loss is 0.0009746793657541275\n",
      "epoch: 31 step: 216, loss is 0.0008521379204466939\n",
      "epoch: 31 step: 217, loss is 0.00032741311588324606\n",
      "epoch: 31 step: 218, loss is 0.0007273998926393688\n",
      "epoch: 31 step: 219, loss is 0.0003099221212323755\n",
      "epoch: 31 step: 220, loss is 0.0011463293340057135\n",
      "epoch: 31 step: 221, loss is 0.0015782996779307723\n",
      "epoch: 31 step: 222, loss is 0.0005005178391002119\n",
      "epoch: 31 step: 223, loss is 0.0011713290587067604\n",
      "epoch: 31 step: 224, loss is 0.0006470851949416101\n",
      "epoch: 31 step: 225, loss is 0.00047368419473059475\n",
      "epoch: 31 step: 226, loss is 0.00013952753215562552\n",
      "epoch: 31 step: 227, loss is 0.0005990102654322982\n",
      "epoch: 31 step: 228, loss is 0.0014892694307491183\n",
      "epoch: 31 step: 229, loss is 0.00017580928397364914\n",
      "epoch: 31 step: 230, loss is 0.0004128666769247502\n",
      "epoch: 31 step: 231, loss is 0.0008756227325648069\n",
      "epoch: 31 step: 232, loss is 0.0002783293020911515\n",
      "epoch: 31 step: 233, loss is 0.001170988311059773\n",
      "epoch: 31 step: 234, loss is 0.0005576239200308919\n",
      "epoch: 31 step: 235, loss is 0.0004875037702731788\n",
      "epoch: 31 step: 236, loss is 0.001199292135424912\n",
      "epoch: 31 step: 237, loss is 0.00040105124935507774\n",
      "epoch: 31 step: 238, loss is 0.0004263110749889165\n",
      "epoch: 31 step: 239, loss is 0.0005064332508482039\n",
      "epoch: 31 step: 240, loss is 0.0005595333059318364\n",
      "epoch: 31 step: 241, loss is 0.0013719259295612574\n",
      "epoch: 31 step: 242, loss is 0.0007878135656937957\n",
      "epoch: 31 step: 243, loss is 0.00046771945198997855\n",
      "epoch: 31 step: 244, loss is 0.0008033455233089626\n",
      "epoch: 31 step: 245, loss is 0.0009087487123906612\n",
      "epoch: 31 step: 246, loss is 0.0007826191140338778\n",
      "epoch: 31 step: 247, loss is 0.0004996884963475168\n",
      "epoch: 31 step: 248, loss is 0.0003727677103597671\n",
      "epoch: 31 step: 249, loss is 0.0005196431302465498\n",
      "epoch: 31 step: 250, loss is 0.000529601878952235\n",
      "epoch: 31 step: 251, loss is 0.0003803605795837939\n",
      "epoch: 31 step: 252, loss is 0.0003379882255103439\n",
      "epoch: 31 step: 253, loss is 0.0005641417228616774\n",
      "epoch: 31 step: 254, loss is 0.0005472054472193122\n",
      "epoch: 31 step: 255, loss is 0.0010216905502602458\n",
      "epoch: 31 step: 256, loss is 0.0005204177577979863\n",
      "epoch: 31 step: 257, loss is 0.0007308340864256024\n",
      "epoch: 31 step: 258, loss is 0.0004393502022139728\n",
      "epoch: 31 step: 259, loss is 0.0007283008890226483\n",
      "epoch: 31 step: 260, loss is 0.0007424482610076666\n",
      "epoch: 31 step: 261, loss is 0.0006308479350991547\n",
      "epoch: 31 step: 262, loss is 0.0005064640427008271\n",
      "epoch: 31 step: 263, loss is 0.0009440172580070794\n",
      "epoch: 31 step: 264, loss is 0.0001657743559917435\n",
      "epoch: 31 step: 265, loss is 0.0006844617892056704\n",
      "epoch: 31 step: 266, loss is 0.00036258669570088387\n",
      "epoch: 31 step: 267, loss is 0.00034620531369000673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 step: 268, loss is 0.0006892691599205136\n",
      "epoch: 31 step: 269, loss is 0.00016135428450070322\n",
      "epoch: 31 step: 270, loss is 0.0006613368750549853\n",
      "epoch: 31 step: 271, loss is 0.0005861583631485701\n",
      "epoch: 31 step: 272, loss is 0.0008546931203454733\n",
      "epoch: 31 step: 273, loss is 0.0006707654101774096\n",
      "epoch: 31 step: 274, loss is 0.0005229753442108631\n",
      "epoch: 31 step: 275, loss is 0.0008478366653434932\n",
      "epoch: 31 step: 276, loss is 0.000880255363881588\n",
      "epoch: 31 step: 277, loss is 0.00029980632825754583\n",
      "epoch: 31 step: 278, loss is 0.00111973041202873\n",
      "epoch: 31 step: 279, loss is 0.0014811827568337321\n",
      "epoch: 31 step: 280, loss is 0.0005204299814067781\n",
      "epoch: 31 step: 281, loss is 0.00024187378585338593\n",
      "epoch: 31 step: 282, loss is 0.0004929783754050732\n",
      "epoch: 31 step: 283, loss is 0.00041148130549117923\n",
      "epoch: 31 step: 284, loss is 0.00045772752491757274\n",
      "epoch: 31 step: 285, loss is 0.0009390519699081779\n",
      "epoch: 31 step: 286, loss is 0.00032660498982295394\n",
      "epoch: 31 step: 287, loss is 0.0006207798141986132\n",
      "epoch: 31 step: 288, loss is 0.00026494567282497883\n",
      "epoch: 31 step: 289, loss is 0.0008196390699595213\n",
      "epoch: 31 step: 290, loss is 0.0002777497284114361\n",
      "epoch: 31 step: 291, loss is 0.0016613153275102377\n",
      "epoch: 31 step: 292, loss is 0.00048277530004270375\n",
      "epoch: 31 step: 293, loss is 0.0004352836695034057\n",
      "epoch: 31 step: 294, loss is 0.0004046268295496702\n",
      "epoch: 31 step: 295, loss is 0.00022804159380029887\n",
      "epoch: 31 step: 296, loss is 0.002278102794662118\n",
      "epoch: 31 step: 297, loss is 0.0012740198289975524\n",
      "epoch: 31 step: 298, loss is 0.0007346589118242264\n",
      "epoch: 31 step: 299, loss is 0.00031611850135959685\n",
      "epoch: 31 step: 300, loss is 0.0008918012608774006\n",
      "epoch: 31 step: 301, loss is 0.00041816485463641584\n",
      "epoch: 31 step: 302, loss is 0.000777307664975524\n",
      "epoch: 31 step: 303, loss is 0.0010761161101981997\n",
      "epoch: 31 step: 304, loss is 0.0007737318519502878\n",
      "epoch: 31 step: 305, loss is 0.0005504487198777497\n",
      "epoch: 31 step: 306, loss is 0.0007227947353385389\n",
      "epoch: 31 step: 307, loss is 0.0006754286587238312\n",
      "epoch: 31 step: 308, loss is 0.0007204711437225342\n",
      "epoch: 31 step: 309, loss is 0.0004986755084246397\n",
      "epoch: 31 step: 310, loss is 0.0004407653759699315\n",
      "epoch: 31 step: 311, loss is 0.0005378720234148204\n",
      "epoch: 31 step: 312, loss is 0.00026429706485942006\n",
      "epoch: 31 step: 313, loss is 0.00042312650475651026\n",
      "epoch: 31 step: 314, loss is 0.0005384551477618515\n",
      "epoch: 31 step: 315, loss is 0.001027391874231398\n",
      "epoch: 31 step: 316, loss is 0.0006236938643269241\n",
      "epoch: 31 step: 317, loss is 0.000368756300304085\n",
      "epoch: 31 step: 318, loss is 0.0006608855910599232\n",
      "epoch: 31 step: 319, loss is 0.0003093247360084206\n",
      "epoch: 31 step: 320, loss is 0.00025114588788710535\n",
      "epoch: 31 step: 321, loss is 0.0012824120931327343\n",
      "epoch: 31 step: 322, loss is 0.0007384078344330192\n",
      "epoch: 31 step: 323, loss is 0.001312539097853005\n",
      "epoch: 31 step: 324, loss is 0.0010886549716815352\n",
      "epoch: 31 step: 325, loss is 0.0001077017150237225\n",
      "epoch: 31 step: 326, loss is 0.0005419430672191083\n",
      "epoch: 31 step: 327, loss is 0.0005978266126476228\n",
      "epoch: 31 step: 328, loss is 0.0013948050327599049\n",
      "epoch: 31 step: 329, loss is 0.0008935399819165468\n",
      "epoch: 31 step: 330, loss is 0.0002118039265042171\n",
      "epoch: 31 step: 331, loss is 0.0005684823263436556\n",
      "epoch: 31 step: 332, loss is 0.0006081443279981613\n",
      "epoch: 31 step: 333, loss is 0.0005409882869571447\n",
      "epoch: 31 step: 334, loss is 0.0005406420677900314\n",
      "epoch: 31 step: 335, loss is 0.00018087882199324667\n",
      "epoch: 31 step: 336, loss is 0.0010874581057578325\n",
      "epoch: 31 step: 337, loss is 0.00020099680114071816\n",
      "epoch: 31 step: 338, loss is 0.0004582242399919778\n",
      "epoch: 31 step: 339, loss is 0.00033070967765524983\n",
      "epoch: 31 step: 340, loss is 0.000330528971971944\n",
      "epoch: 31 step: 341, loss is 0.0002194917033193633\n",
      "epoch: 31 step: 342, loss is 0.0008323543588630855\n",
      "epoch: 31 step: 343, loss is 0.0009270946029573679\n",
      "epoch: 31 step: 344, loss is 0.0008584490860812366\n",
      "epoch: 31 step: 345, loss is 0.0003417631087359041\n",
      "epoch: 31 step: 346, loss is 0.0015599275939166546\n",
      "epoch: 31 step: 347, loss is 0.00017808548000175506\n",
      "epoch: 31 step: 348, loss is 0.00029489316511899233\n",
      "epoch: 31 step: 349, loss is 0.000638489902485162\n",
      "epoch: 31 step: 350, loss is 0.00029570056358352304\n",
      "epoch: 31 step: 351, loss is 0.0013722022995352745\n",
      "epoch: 31 step: 352, loss is 0.0007101574447005987\n",
      "epoch: 31 step: 353, loss is 0.0004452657012734562\n",
      "epoch: 31 step: 354, loss is 0.0011326110688969493\n",
      "epoch: 31 step: 355, loss is 0.0003055466222576797\n",
      "epoch: 31 step: 356, loss is 0.0001294328976655379\n",
      "epoch: 31 step: 357, loss is 0.0009449973003938794\n",
      "epoch: 31 step: 358, loss is 0.0007462850771844387\n",
      "epoch: 31 step: 359, loss is 0.00040130887646228075\n",
      "epoch: 31 step: 360, loss is 0.0003432428929954767\n",
      "epoch: 31 step: 361, loss is 0.001167314825579524\n",
      "epoch: 31 step: 362, loss is 0.0003253691829741001\n",
      "epoch: 31 step: 363, loss is 0.0007361056632362306\n",
      "epoch: 31 step: 364, loss is 0.000577583268750459\n",
      "epoch: 31 step: 365, loss is 0.0007055796450003982\n",
      "epoch: 31 step: 366, loss is 0.0006048856885172427\n",
      "epoch: 31 step: 367, loss is 0.0006869653007015586\n",
      "epoch: 31 step: 368, loss is 0.0002489163016434759\n",
      "epoch: 31 step: 369, loss is 0.0013720316346734762\n",
      "epoch: 31 step: 370, loss is 0.0006961970939300954\n",
      "epoch: 31 step: 371, loss is 0.0017873215256258845\n",
      "epoch: 31 step: 372, loss is 0.00041836066520772874\n",
      "epoch: 31 step: 373, loss is 0.000582312059123069\n",
      "epoch: 31 step: 374, loss is 0.0006493128021247685\n",
      "epoch: 31 step: 375, loss is 0.0004535218176897615\n",
      "Train epoch time: 11913.117 ms, per step time: 31.768 ms\n",
      "epoch: 32 step: 1, loss is 0.0009602236095815897\n",
      "epoch: 32 step: 2, loss is 0.0009260177612304688\n",
      "epoch: 32 step: 3, loss is 0.0012929668882861733\n",
      "epoch: 32 step: 4, loss is 0.00029872817685827613\n",
      "epoch: 32 step: 5, loss is 0.001243852311745286\n",
      "epoch: 32 step: 6, loss is 0.0005869398592039943\n",
      "epoch: 32 step: 7, loss is 0.0008183741592802107\n",
      "epoch: 32 step: 8, loss is 0.0014783453661948442\n",
      "epoch: 32 step: 9, loss is 0.0007225866429507732\n",
      "epoch: 32 step: 10, loss is 0.00046304118586704135\n",
      "epoch: 32 step: 11, loss is 0.00033273093868047\n",
      "epoch: 32 step: 12, loss is 0.0003967893135268241\n",
      "epoch: 32 step: 13, loss is 0.00045522075379267335\n",
      "epoch: 32 step: 14, loss is 0.000765567587222904\n",
      "epoch: 32 step: 15, loss is 0.000560694606974721\n",
      "epoch: 32 step: 16, loss is 0.0005653952830471098\n",
      "epoch: 32 step: 17, loss is 0.000688238360453397\n",
      "epoch: 32 step: 18, loss is 0.0005524907610379159\n",
      "epoch: 32 step: 19, loss is 0.0007741149165667593\n",
      "epoch: 32 step: 20, loss is 0.0009779665851965547\n",
      "epoch: 32 step: 21, loss is 0.00034344999585300684\n",
      "epoch: 32 step: 22, loss is 0.0002913355128839612\n",
      "epoch: 32 step: 23, loss is 0.0005918112583458424\n",
      "epoch: 32 step: 24, loss is 0.0002993433445226401\n",
      "epoch: 32 step: 25, loss is 0.0014853132888674736\n",
      "epoch: 32 step: 26, loss is 0.0003648416022770107\n",
      "epoch: 32 step: 27, loss is 0.0009018259588629007\n",
      "epoch: 32 step: 28, loss is 0.0003014765097759664\n",
      "epoch: 32 step: 29, loss is 0.0006341808475553989\n",
      "epoch: 32 step: 30, loss is 0.00016321572184097022\n",
      "epoch: 32 step: 31, loss is 0.00013248869800008833\n",
      "epoch: 32 step: 32, loss is 0.0005267465603537858\n",
      "epoch: 32 step: 33, loss is 0.0003108993114437908\n",
      "epoch: 32 step: 34, loss is 0.00045728127588517964\n",
      "epoch: 32 step: 35, loss is 0.0005153706297278404\n",
      "epoch: 32 step: 36, loss is 0.0012257718481123447\n",
      "epoch: 32 step: 37, loss is 0.0007395641296170652\n",
      "epoch: 32 step: 38, loss is 0.00035059283254668117\n",
      "epoch: 32 step: 39, loss is 0.0014199988218024373\n",
      "epoch: 32 step: 40, loss is 0.0010445999214425683\n",
      "epoch: 32 step: 41, loss is 0.0008698566816747189\n",
      "epoch: 32 step: 42, loss is 0.0014089841861277819\n",
      "epoch: 32 step: 43, loss is 0.001002774341031909\n",
      "epoch: 32 step: 44, loss is 0.0005652589607052505\n",
      "epoch: 32 step: 45, loss is 6.537020817631856e-05\n",
      "epoch: 32 step: 46, loss is 0.0004833094426430762\n",
      "epoch: 32 step: 47, loss is 0.00022837609867565334\n",
      "epoch: 32 step: 48, loss is 0.0005359508213587105\n",
      "epoch: 32 step: 49, loss is 0.00025320539134554565\n",
      "epoch: 32 step: 50, loss is 0.00042880335240624845\n",
      "epoch: 32 step: 51, loss is 0.0007102989475242794\n",
      "epoch: 32 step: 52, loss is 0.00021981877216603607\n",
      "epoch: 32 step: 53, loss is 0.0003902841708622873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 step: 54, loss is 0.0007195615908131003\n",
      "epoch: 32 step: 55, loss is 0.00025750850909389555\n",
      "epoch: 32 step: 56, loss is 0.0007814612472429872\n",
      "epoch: 32 step: 57, loss is 0.0001247549953404814\n",
      "epoch: 32 step: 58, loss is 0.0005507230525836349\n",
      "epoch: 32 step: 59, loss is 0.0006109838141128421\n",
      "epoch: 32 step: 60, loss is 0.001226075110025704\n",
      "epoch: 32 step: 61, loss is 0.00012077863357262686\n",
      "epoch: 32 step: 62, loss is 0.0005530784837901592\n",
      "epoch: 32 step: 63, loss is 0.0008601630106568336\n",
      "epoch: 32 step: 64, loss is 0.0015660711796954274\n",
      "epoch: 32 step: 65, loss is 0.0007569377776235342\n",
      "epoch: 32 step: 66, loss is 0.001546070328913629\n",
      "epoch: 32 step: 67, loss is 0.000727263861335814\n",
      "epoch: 32 step: 68, loss is 0.0005034381174482405\n",
      "epoch: 32 step: 69, loss is 0.00044530926970764995\n",
      "epoch: 32 step: 70, loss is 0.00027589613455347717\n",
      "epoch: 32 step: 71, loss is 0.00021398899843916297\n",
      "epoch: 32 step: 72, loss is 0.0012328235898166895\n",
      "epoch: 32 step: 73, loss is 0.0005842780810780823\n",
      "epoch: 32 step: 74, loss is 0.0006110366666689515\n",
      "epoch: 32 step: 75, loss is 0.0006975707365199924\n",
      "epoch: 32 step: 76, loss is 0.00024303917598444968\n",
      "epoch: 32 step: 77, loss is 0.0006889320793561637\n",
      "epoch: 32 step: 78, loss is 0.0012470714282244444\n",
      "epoch: 32 step: 79, loss is 0.0006339950487017632\n",
      "epoch: 32 step: 80, loss is 0.0006432973896153271\n",
      "epoch: 32 step: 81, loss is 0.0006230876897461712\n",
      "epoch: 32 step: 82, loss is 0.00039533135714009404\n",
      "epoch: 32 step: 83, loss is 0.00043280640966258943\n",
      "epoch: 32 step: 84, loss is 0.0006172339199110866\n",
      "epoch: 32 step: 85, loss is 0.00023930342285893857\n",
      "epoch: 32 step: 86, loss is 0.0010613895719870925\n",
      "epoch: 32 step: 87, loss is 0.0007275200332514942\n",
      "epoch: 32 step: 88, loss is 0.00048752143629826605\n",
      "epoch: 32 step: 89, loss is 0.00037239835364744067\n",
      "epoch: 32 step: 90, loss is 0.0007193688070401549\n",
      "epoch: 32 step: 91, loss is 0.00033818185329437256\n",
      "epoch: 32 step: 92, loss is 0.0009800911648198962\n",
      "epoch: 32 step: 93, loss is 0.00025770155480131507\n",
      "epoch: 32 step: 94, loss is 0.000520268629770726\n",
      "epoch: 32 step: 95, loss is 0.0006678795907646418\n",
      "epoch: 32 step: 96, loss is 0.00020161653810646385\n",
      "epoch: 32 step: 97, loss is 0.0004117230128031224\n",
      "epoch: 32 step: 98, loss is 0.0003739990061149001\n",
      "epoch: 32 step: 99, loss is 0.0007233418291434646\n",
      "epoch: 32 step: 100, loss is 0.00021916547848377377\n",
      "epoch: 32 step: 101, loss is 0.000442209595348686\n",
      "epoch: 32 step: 102, loss is 0.0003342860145494342\n",
      "epoch: 32 step: 103, loss is 0.00020502269035205245\n",
      "epoch: 32 step: 104, loss is 0.0008984492160379887\n",
      "epoch: 32 step: 105, loss is 0.0016193031333386898\n",
      "epoch: 32 step: 106, loss is 0.00046003921306692064\n",
      "epoch: 32 step: 107, loss is 0.0007081376388669014\n",
      "epoch: 32 step: 108, loss is 0.0007141737150959671\n",
      "epoch: 32 step: 109, loss is 0.0008339426130987704\n",
      "epoch: 32 step: 110, loss is 0.001129973097704351\n",
      "epoch: 32 step: 111, loss is 0.0007790083182044327\n",
      "epoch: 32 step: 112, loss is 0.0005078093963675201\n",
      "epoch: 32 step: 113, loss is 0.0005382326780818403\n",
      "epoch: 32 step: 114, loss is 0.0006225102115422487\n",
      "epoch: 32 step: 115, loss is 0.00033091611112467945\n",
      "epoch: 32 step: 116, loss is 0.0008895723731257021\n",
      "epoch: 32 step: 117, loss is 0.0009152992279268801\n",
      "epoch: 32 step: 118, loss is 0.00036785195698030293\n",
      "epoch: 32 step: 119, loss is 0.0016816469142213464\n",
      "epoch: 32 step: 120, loss is 0.0007180491811595857\n",
      "epoch: 32 step: 121, loss is 0.0011391775915399194\n",
      "epoch: 32 step: 122, loss is 0.0004662525898311287\n",
      "epoch: 32 step: 123, loss is 0.00024466426111757755\n",
      "epoch: 32 step: 124, loss is 0.0013800483429804444\n",
      "epoch: 32 step: 125, loss is 0.0007292333757504821\n",
      "epoch: 32 step: 126, loss is 0.00110923673491925\n",
      "epoch: 32 step: 127, loss is 0.0009608184336684644\n",
      "epoch: 32 step: 128, loss is 0.0004212261410430074\n",
      "epoch: 32 step: 129, loss is 0.0011819181963801384\n",
      "epoch: 32 step: 130, loss is 0.0003231596201658249\n",
      "epoch: 32 step: 131, loss is 0.0004936090554110706\n",
      "epoch: 32 step: 132, loss is 0.0005467343144118786\n",
      "epoch: 32 step: 133, loss is 0.0009594356524758041\n",
      "epoch: 32 step: 134, loss is 0.0009272215538658202\n",
      "epoch: 32 step: 135, loss is 0.00043335434747859836\n",
      "epoch: 32 step: 136, loss is 0.00034759085974656045\n",
      "epoch: 32 step: 137, loss is 0.000844344962388277\n",
      "epoch: 32 step: 138, loss is 0.001236422685906291\n",
      "epoch: 32 step: 139, loss is 0.0010611142497509718\n",
      "epoch: 32 step: 140, loss is 0.00038588594179600477\n",
      "epoch: 32 step: 141, loss is 0.0005180913140065968\n",
      "epoch: 32 step: 142, loss is 0.0007524713291786611\n",
      "epoch: 32 step: 143, loss is 0.0004975163610652089\n",
      "epoch: 32 step: 144, loss is 0.0006927283830009401\n",
      "epoch: 32 step: 145, loss is 0.0007073768647387624\n",
      "epoch: 32 step: 146, loss is 0.0006514225387945771\n",
      "epoch: 32 step: 147, loss is 0.0007655415683984756\n",
      "epoch: 32 step: 148, loss is 0.001060902257449925\n",
      "epoch: 32 step: 149, loss is 0.000907527341041714\n",
      "epoch: 32 step: 150, loss is 0.0003453042882028967\n",
      "epoch: 32 step: 151, loss is 0.0015232318546622992\n",
      "epoch: 32 step: 152, loss is 0.00026032933965325356\n",
      "epoch: 32 step: 153, loss is 0.0001890685234684497\n",
      "epoch: 32 step: 154, loss is 0.00019883294589817524\n",
      "epoch: 32 step: 155, loss is 0.0005606164340861142\n",
      "epoch: 32 step: 156, loss is 0.00039309082785621285\n",
      "epoch: 32 step: 157, loss is 0.0003156303719151765\n",
      "epoch: 32 step: 158, loss is 0.0009514584671705961\n",
      "epoch: 32 step: 159, loss is 0.0004635420918930322\n",
      "epoch: 32 step: 160, loss is 0.0003328887978568673\n",
      "epoch: 32 step: 161, loss is 0.0009183385409414768\n",
      "epoch: 32 step: 162, loss is 0.0007519815117120743\n",
      "epoch: 32 step: 163, loss is 0.0010665261652320623\n",
      "epoch: 32 step: 164, loss is 0.001362288254313171\n",
      "epoch: 32 step: 165, loss is 0.0008554073283448815\n",
      "epoch: 32 step: 166, loss is 0.0007819731836207211\n",
      "epoch: 32 step: 167, loss is 0.0006682373350486159\n",
      "epoch: 32 step: 168, loss is 0.001009845407679677\n",
      "epoch: 32 step: 169, loss is 0.0012323713162913918\n",
      "epoch: 32 step: 170, loss is 0.00147793791256845\n",
      "epoch: 32 step: 171, loss is 0.0007173071498982608\n",
      "epoch: 32 step: 172, loss is 0.001230563037097454\n",
      "epoch: 32 step: 173, loss is 0.0007630405598320067\n",
      "epoch: 32 step: 174, loss is 0.0008694991702213883\n",
      "epoch: 32 step: 175, loss is 0.0006228553829714656\n",
      "epoch: 32 step: 176, loss is 0.0006698037614114583\n",
      "epoch: 32 step: 177, loss is 0.000671965244691819\n",
      "epoch: 32 step: 178, loss is 0.0005348541308194399\n",
      "epoch: 32 step: 179, loss is 0.0012315692147240043\n",
      "epoch: 32 step: 180, loss is 0.00028369747451506555\n",
      "epoch: 32 step: 181, loss is 0.00022889894898980856\n",
      "epoch: 32 step: 182, loss is 0.0006985764484852552\n",
      "epoch: 32 step: 183, loss is 0.00023451937886420637\n",
      "epoch: 32 step: 184, loss is 0.0005508388276211917\n",
      "epoch: 32 step: 185, loss is 0.0015191249549388885\n",
      "epoch: 32 step: 186, loss is 0.00042020983528345823\n",
      "epoch: 32 step: 187, loss is 0.00030540581792593\n",
      "epoch: 32 step: 188, loss is 0.0007945839315652847\n",
      "epoch: 32 step: 189, loss is 0.0009494018158875406\n",
      "epoch: 32 step: 190, loss is 0.0013064858503639698\n",
      "epoch: 32 step: 191, loss is 0.0004304762987885624\n",
      "epoch: 32 step: 192, loss is 0.0006139804027043283\n",
      "epoch: 32 step: 193, loss is 0.0008969770278781652\n",
      "epoch: 32 step: 194, loss is 0.0004981317324563861\n",
      "epoch: 32 step: 195, loss is 0.00040483224438503385\n",
      "epoch: 32 step: 196, loss is 0.0006679450743831694\n",
      "epoch: 32 step: 197, loss is 0.0006716431234963238\n",
      "epoch: 32 step: 198, loss is 0.000491822196636349\n",
      "epoch: 32 step: 199, loss is 0.0005128831835463643\n",
      "epoch: 32 step: 200, loss is 0.0004994701012037694\n",
      "epoch: 32 step: 201, loss is 0.0002973250229842961\n",
      "epoch: 32 step: 202, loss is 0.0010465148370712996\n",
      "epoch: 32 step: 203, loss is 0.00013927467807661742\n",
      "epoch: 32 step: 204, loss is 0.0005946119199506938\n",
      "epoch: 32 step: 205, loss is 0.0007908390834927559\n",
      "epoch: 32 step: 206, loss is 0.0001331088860752061\n",
      "epoch: 32 step: 207, loss is 0.00031051476253196597\n",
      "epoch: 32 step: 208, loss is 0.0002012822951655835\n",
      "epoch: 32 step: 209, loss is 0.0008944468572735786\n",
      "epoch: 32 step: 210, loss is 0.0002334157907171175\n",
      "epoch: 32 step: 211, loss is 0.0010812114924192429\n",
      "epoch: 32 step: 212, loss is 0.0007041427888907492\n",
      "epoch: 32 step: 213, loss is 0.0004704247694462538\n",
      "epoch: 32 step: 214, loss is 0.0014158551348373294\n",
      "epoch: 32 step: 215, loss is 0.0005442763795144856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 step: 216, loss is 0.0006680069491267204\n",
      "epoch: 32 step: 217, loss is 0.0019108073320239782\n",
      "epoch: 32 step: 218, loss is 0.00020578448311425745\n",
      "epoch: 32 step: 219, loss is 0.0007855907897464931\n",
      "epoch: 32 step: 220, loss is 0.0006371449562720954\n",
      "epoch: 32 step: 221, loss is 0.0004920033388771117\n",
      "epoch: 32 step: 222, loss is 0.00046282788389362395\n",
      "epoch: 32 step: 223, loss is 0.00018127528892364353\n",
      "epoch: 32 step: 224, loss is 0.000665049534291029\n",
      "epoch: 32 step: 225, loss is 0.0003552746493369341\n",
      "epoch: 32 step: 226, loss is 0.0006598452455364168\n",
      "epoch: 32 step: 227, loss is 0.0006633010925725102\n",
      "epoch: 32 step: 228, loss is 0.000539169181138277\n",
      "epoch: 32 step: 229, loss is 0.0009762637782841921\n",
      "epoch: 32 step: 230, loss is 0.001321322051808238\n",
      "epoch: 32 step: 231, loss is 0.001567328698001802\n",
      "epoch: 32 step: 232, loss is 0.001677694614045322\n",
      "epoch: 32 step: 233, loss is 0.0003225381951779127\n",
      "epoch: 32 step: 234, loss is 0.0004896445898339152\n",
      "epoch: 32 step: 235, loss is 0.0006778949173167348\n",
      "epoch: 32 step: 236, loss is 0.0010973861208185554\n",
      "epoch: 32 step: 237, loss is 0.00043906172504648566\n",
      "epoch: 32 step: 238, loss is 0.0017902664840221405\n",
      "epoch: 32 step: 239, loss is 0.001312785199843347\n",
      "epoch: 32 step: 240, loss is 0.000804255367256701\n",
      "epoch: 32 step: 241, loss is 0.0008809475693851709\n",
      "epoch: 32 step: 242, loss is 0.0004188571183476597\n",
      "epoch: 32 step: 243, loss is 0.00024702263181097806\n",
      "epoch: 32 step: 244, loss is 0.0007467124960385263\n",
      "epoch: 32 step: 245, loss is 0.0005785867688246071\n",
      "epoch: 32 step: 246, loss is 0.00038616207893937826\n",
      "epoch: 32 step: 247, loss is 0.0003061284660361707\n",
      "epoch: 32 step: 248, loss is 0.0007181257824413478\n",
      "epoch: 32 step: 249, loss is 0.00047911008005030453\n",
      "epoch: 32 step: 250, loss is 0.0004695573588833213\n",
      "epoch: 32 step: 251, loss is 0.0006134762079454958\n",
      "epoch: 32 step: 252, loss is 0.0005863865371793509\n",
      "epoch: 32 step: 253, loss is 0.002171022817492485\n",
      "epoch: 32 step: 254, loss is 0.0005705580697394907\n",
      "epoch: 32 step: 255, loss is 0.0007058479823172092\n",
      "epoch: 32 step: 256, loss is 6.724137347191572e-05\n",
      "epoch: 32 step: 257, loss is 0.0007133428007364273\n",
      "epoch: 32 step: 258, loss is 0.0004891625139862299\n",
      "epoch: 32 step: 259, loss is 0.0005592851666733623\n",
      "epoch: 32 step: 260, loss is 0.00030254898592829704\n",
      "epoch: 32 step: 261, loss is 0.0007827983354218304\n",
      "epoch: 32 step: 262, loss is 0.00014846537669654936\n",
      "epoch: 32 step: 263, loss is 0.000740103074349463\n",
      "epoch: 32 step: 264, loss is 0.0006736706709489226\n",
      "epoch: 32 step: 265, loss is 0.0007484795060008764\n",
      "epoch: 32 step: 266, loss is 0.0007273565279319882\n",
      "epoch: 32 step: 267, loss is 0.0001602161501068622\n",
      "epoch: 32 step: 268, loss is 0.000606690242420882\n",
      "epoch: 32 step: 269, loss is 0.0002499035617802292\n",
      "epoch: 32 step: 270, loss is 0.0002866991562768817\n",
      "epoch: 32 step: 271, loss is 0.0004629794857464731\n",
      "epoch: 32 step: 272, loss is 0.0007078686030581594\n",
      "epoch: 32 step: 273, loss is 0.0004951126757077873\n",
      "epoch: 32 step: 274, loss is 0.0005985633470118046\n",
      "epoch: 32 step: 275, loss is 0.0012454299721866846\n",
      "epoch: 32 step: 276, loss is 0.0004402078047860414\n",
      "epoch: 32 step: 277, loss is 0.0013363370671868324\n",
      "epoch: 32 step: 278, loss is 0.0006479176809079945\n",
      "epoch: 32 step: 279, loss is 0.001034282729960978\n",
      "epoch: 32 step: 280, loss is 0.000570709933526814\n",
      "epoch: 32 step: 281, loss is 0.00044083414832130075\n",
      "epoch: 32 step: 282, loss is 0.00047332863323390484\n",
      "epoch: 32 step: 283, loss is 0.0007552206516265869\n",
      "epoch: 32 step: 284, loss is 0.00035475060576573014\n",
      "epoch: 32 step: 285, loss is 0.00032844714587554336\n",
      "epoch: 32 step: 286, loss is 0.00047438795445486903\n",
      "epoch: 32 step: 287, loss is 0.00029517439543269575\n",
      "epoch: 32 step: 288, loss is 0.00022173792240209877\n",
      "epoch: 32 step: 289, loss is 0.0007000394980423152\n",
      "epoch: 32 step: 290, loss is 0.0007438750471919775\n",
      "epoch: 32 step: 291, loss is 1.9240860638092272e-05\n",
      "epoch: 32 step: 292, loss is 0.0009750690660439432\n",
      "epoch: 32 step: 293, loss is 0.00020437415514606982\n",
      "epoch: 32 step: 294, loss is 0.0005928743630647659\n",
      "epoch: 32 step: 295, loss is 0.0005410162266343832\n",
      "epoch: 32 step: 296, loss is 0.0010388309601694345\n",
      "epoch: 32 step: 297, loss is 0.0006516720750369132\n",
      "epoch: 32 step: 298, loss is 0.00042454543290659785\n",
      "epoch: 32 step: 299, loss is 0.00033774282201193273\n",
      "epoch: 32 step: 300, loss is 0.0004947778070345521\n",
      "epoch: 32 step: 301, loss is 0.00022912058921065181\n",
      "epoch: 32 step: 302, loss is 0.0006966200890019536\n",
      "epoch: 32 step: 303, loss is 0.0005176865961402655\n",
      "epoch: 32 step: 304, loss is 0.0006130223046056926\n",
      "epoch: 32 step: 305, loss is 0.0002445958089083433\n",
      "epoch: 32 step: 306, loss is 0.0002671229303814471\n",
      "epoch: 32 step: 307, loss is 0.0008879976812750101\n",
      "epoch: 32 step: 308, loss is 0.0004228015895932913\n",
      "epoch: 32 step: 309, loss is 0.0005973631632514298\n",
      "epoch: 32 step: 310, loss is 0.0003744727582670748\n",
      "epoch: 32 step: 311, loss is 0.0018066874472424388\n",
      "epoch: 32 step: 312, loss is 0.001744697568938136\n",
      "epoch: 32 step: 313, loss is 0.0004080246144440025\n",
      "epoch: 32 step: 314, loss is 0.0007088815909810364\n",
      "epoch: 32 step: 315, loss is 0.0004639945109374821\n",
      "epoch: 32 step: 316, loss is 0.001234310562722385\n",
      "epoch: 32 step: 317, loss is 0.0007275944226421416\n",
      "epoch: 32 step: 318, loss is 0.0011763559887185693\n",
      "epoch: 32 step: 319, loss is 0.0009619310731068254\n",
      "epoch: 32 step: 320, loss is 0.001732718083076179\n",
      "epoch: 32 step: 321, loss is 0.0006503415061160922\n",
      "epoch: 32 step: 322, loss is 0.0010538969654589891\n",
      "epoch: 32 step: 323, loss is 0.00116814486682415\n",
      "epoch: 32 step: 324, loss is 0.0005408879369497299\n",
      "epoch: 32 step: 325, loss is 0.0001611936604604125\n",
      "epoch: 32 step: 326, loss is 0.0006798002286814153\n",
      "epoch: 32 step: 327, loss is 0.0009434096282348037\n",
      "epoch: 32 step: 328, loss is 0.0007772239623591304\n",
      "epoch: 32 step: 329, loss is 0.00036815492785535753\n",
      "epoch: 32 step: 330, loss is 0.0013028831453993917\n",
      "epoch: 32 step: 331, loss is 0.0005210794042795897\n",
      "epoch: 32 step: 332, loss is 0.00022500887280330062\n",
      "epoch: 32 step: 333, loss is 0.0008530322229489684\n",
      "epoch: 32 step: 334, loss is 0.0010455617448315024\n",
      "epoch: 32 step: 335, loss is 0.0007178829400800169\n",
      "epoch: 32 step: 336, loss is 0.00090456084581092\n",
      "epoch: 32 step: 337, loss is 0.0008675142889842391\n",
      "epoch: 32 step: 338, loss is 0.0013129775179550052\n",
      "epoch: 32 step: 339, loss is 0.0007614171481691301\n",
      "epoch: 32 step: 340, loss is 0.0006059764418751001\n",
      "epoch: 32 step: 341, loss is 0.0004843618953600526\n",
      "epoch: 32 step: 342, loss is 0.001186876092106104\n",
      "epoch: 32 step: 343, loss is 0.00036469250335358083\n",
      "epoch: 32 step: 344, loss is 0.00043203626410104334\n",
      "epoch: 32 step: 345, loss is 0.0005053638014942408\n",
      "epoch: 32 step: 346, loss is 0.0003539572353474796\n",
      "epoch: 32 step: 347, loss is 0.0009437346016056836\n",
      "epoch: 32 step: 348, loss is 0.00046795792877674103\n",
      "epoch: 32 step: 349, loss is 0.0005439543165266514\n",
      "epoch: 32 step: 350, loss is 0.00015491673548240215\n",
      "epoch: 32 step: 351, loss is 0.0005925921723246574\n",
      "epoch: 32 step: 352, loss is 0.0010425909422338009\n",
      "epoch: 32 step: 353, loss is 0.0005418189102783799\n",
      "epoch: 32 step: 354, loss is 0.0005740992492064834\n",
      "epoch: 32 step: 355, loss is 0.0006836277316324413\n",
      "epoch: 32 step: 356, loss is 0.0008839502697810531\n",
      "epoch: 32 step: 357, loss is 0.0003638043417595327\n",
      "epoch: 32 step: 358, loss is 0.0005357279442250729\n",
      "epoch: 32 step: 359, loss is 0.0007834508433006704\n",
      "epoch: 32 step: 360, loss is 0.00034271078766323626\n",
      "epoch: 32 step: 361, loss is 0.0005951375351287425\n",
      "epoch: 32 step: 362, loss is 0.0010626997100189328\n",
      "epoch: 32 step: 363, loss is 0.0008776069153100252\n",
      "epoch: 32 step: 364, loss is 0.0014219828881323338\n",
      "epoch: 32 step: 365, loss is 0.0008331914432346821\n",
      "epoch: 32 step: 366, loss is 0.0003822184808086604\n",
      "epoch: 32 step: 367, loss is 0.00032562590786255896\n",
      "epoch: 32 step: 368, loss is 0.0011077236849814653\n",
      "epoch: 32 step: 369, loss is 0.00037268895539455116\n",
      "epoch: 32 step: 370, loss is 0.000625914428383112\n",
      "epoch: 32 step: 371, loss is 0.0013618160737678409\n",
      "epoch: 32 step: 372, loss is 0.0005869399174116552\n",
      "epoch: 32 step: 373, loss is 0.0007077553309500217\n",
      "epoch: 32 step: 374, loss is 0.0006557453307323158\n",
      "epoch: 32 step: 375, loss is 0.0005538391997106373\n",
      "Train epoch time: 12047.855 ms, per step time: 32.128 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 step: 1, loss is 0.0011442684335634112\n",
      "epoch: 33 step: 2, loss is 0.00030646531376987696\n",
      "epoch: 33 step: 3, loss is 0.0006980933831073344\n",
      "epoch: 33 step: 4, loss is 0.00024340687377844006\n",
      "epoch: 33 step: 5, loss is 0.0009648761479184031\n",
      "epoch: 33 step: 6, loss is 0.0005806396366097033\n",
      "epoch: 33 step: 7, loss is 0.0009483536705374718\n",
      "epoch: 33 step: 8, loss is 0.0006760459509678185\n",
      "epoch: 33 step: 9, loss is 0.0005925893783569336\n",
      "epoch: 33 step: 10, loss is 0.0002635924320202321\n",
      "epoch: 33 step: 11, loss is 0.0012236842885613441\n",
      "epoch: 33 step: 12, loss is 0.0006054470431990921\n",
      "epoch: 33 step: 13, loss is 0.0005321603384800255\n",
      "epoch: 33 step: 14, loss is 0.0006726342835463583\n",
      "epoch: 33 step: 15, loss is 0.0009649503626860678\n",
      "epoch: 33 step: 16, loss is 0.0008854356128722429\n",
      "epoch: 33 step: 17, loss is 0.0004620051186066121\n",
      "epoch: 33 step: 18, loss is 0.001339373062364757\n",
      "epoch: 33 step: 19, loss is 0.00033137682476080954\n",
      "epoch: 33 step: 20, loss is 0.0010678879916667938\n",
      "epoch: 33 step: 21, loss is 0.0006108945817686617\n",
      "epoch: 33 step: 22, loss is 0.0001708928175503388\n",
      "epoch: 33 step: 23, loss is 0.0006517994916066527\n",
      "epoch: 33 step: 24, loss is 0.0006656124023720622\n",
      "epoch: 33 step: 25, loss is 0.0004489562415983528\n",
      "epoch: 33 step: 26, loss is 0.00029034010367468\n",
      "epoch: 33 step: 27, loss is 0.0008699672762304544\n",
      "epoch: 33 step: 28, loss is 0.00041657843394204974\n",
      "epoch: 33 step: 29, loss is 0.0011239036684855819\n",
      "epoch: 33 step: 30, loss is 0.001112873898819089\n",
      "epoch: 33 step: 31, loss is 0.0010711553040891886\n",
      "epoch: 33 step: 32, loss is 0.0016104289097711444\n",
      "epoch: 33 step: 33, loss is 0.0022392920218408108\n",
      "epoch: 33 step: 34, loss is 0.00028257560916244984\n",
      "epoch: 33 step: 35, loss is 0.0004752787936013192\n",
      "epoch: 33 step: 36, loss is 0.0008230991661548615\n",
      "epoch: 33 step: 37, loss is 0.000573811586946249\n",
      "epoch: 33 step: 38, loss is 0.00040651834569871426\n",
      "epoch: 33 step: 39, loss is 0.0005834512412548065\n",
      "epoch: 33 step: 40, loss is 0.0006712671602144837\n",
      "epoch: 33 step: 41, loss is 0.0016035602893680334\n",
      "epoch: 33 step: 42, loss is 0.0008404655964113772\n",
      "epoch: 33 step: 43, loss is 0.0011505053844302893\n",
      "epoch: 33 step: 44, loss is 0.0005571040092036128\n",
      "epoch: 33 step: 45, loss is 0.0010327042546123266\n",
      "epoch: 33 step: 46, loss is 0.00030709494603797793\n",
      "epoch: 33 step: 47, loss is 0.0006063014734536409\n",
      "epoch: 33 step: 48, loss is 0.00024305058468598872\n",
      "epoch: 33 step: 49, loss is 0.0005480967811308801\n",
      "epoch: 33 step: 50, loss is 0.0005918637616559863\n",
      "epoch: 33 step: 51, loss is 0.0010420329635962844\n",
      "epoch: 33 step: 52, loss is 0.00041263247840106487\n",
      "epoch: 33 step: 53, loss is 0.0005424367263913155\n",
      "epoch: 33 step: 54, loss is 0.002253147540614009\n",
      "epoch: 33 step: 55, loss is 0.00042666232911869884\n",
      "epoch: 33 step: 56, loss is 0.0006591240526176989\n",
      "epoch: 33 step: 57, loss is 0.0004003393987659365\n",
      "epoch: 33 step: 58, loss is 0.0008223438053391874\n",
      "epoch: 33 step: 59, loss is 0.00025958000333048403\n",
      "epoch: 33 step: 60, loss is 0.0007457564352080226\n",
      "epoch: 33 step: 61, loss is 0.0008012334583327174\n",
      "epoch: 33 step: 62, loss is 0.00040652070310898125\n",
      "epoch: 33 step: 63, loss is 0.00030658135074190795\n",
      "epoch: 33 step: 64, loss is 0.0007942333468236029\n",
      "epoch: 33 step: 65, loss is 0.0008960224804468453\n",
      "epoch: 33 step: 66, loss is 0.0005217533907853067\n",
      "epoch: 33 step: 67, loss is 0.001632278086617589\n",
      "epoch: 33 step: 68, loss is 0.00041563145350664854\n",
      "epoch: 33 step: 69, loss is 0.0003563478821888566\n",
      "epoch: 33 step: 70, loss is 0.00022702739806845784\n",
      "epoch: 33 step: 71, loss is 0.0003911480598617345\n",
      "epoch: 33 step: 72, loss is 0.0002825798583216965\n",
      "epoch: 33 step: 73, loss is 0.0008386261761188507\n",
      "epoch: 33 step: 74, loss is 0.001043529948219657\n",
      "epoch: 33 step: 75, loss is 0.0006723618716932833\n",
      "epoch: 33 step: 76, loss is 0.0009093592525459826\n",
      "epoch: 33 step: 77, loss is 0.0010911967838183045\n",
      "epoch: 33 step: 78, loss is 0.00038317914004437625\n",
      "epoch: 33 step: 79, loss is 0.0009600924677215517\n",
      "epoch: 33 step: 80, loss is 0.0006290408200584352\n",
      "epoch: 33 step: 81, loss is 0.0006744812708348036\n",
      "epoch: 33 step: 82, loss is 0.0014418689534068108\n",
      "epoch: 33 step: 83, loss is 0.00022428773809224367\n",
      "epoch: 33 step: 84, loss is 0.0009701426024548709\n",
      "epoch: 33 step: 85, loss is 0.0008722575730644166\n",
      "epoch: 33 step: 86, loss is 0.0007000378100201488\n",
      "epoch: 33 step: 87, loss is 0.0007959090871736407\n",
      "epoch: 33 step: 88, loss is 0.0007217864040285349\n",
      "epoch: 33 step: 89, loss is 0.0005500377737917006\n",
      "epoch: 33 step: 90, loss is 0.0002604714536573738\n",
      "epoch: 33 step: 91, loss is 0.0004438180476427078\n",
      "epoch: 33 step: 92, loss is 0.0005406068521551788\n",
      "epoch: 33 step: 93, loss is 0.0003984490758739412\n",
      "epoch: 33 step: 94, loss is 0.0004912862787023187\n",
      "epoch: 33 step: 95, loss is 0.00116436998359859\n",
      "epoch: 33 step: 96, loss is 0.0003806705353781581\n",
      "epoch: 33 step: 97, loss is 0.0009744665585458279\n",
      "epoch: 33 step: 98, loss is 0.0004030627605970949\n",
      "epoch: 33 step: 99, loss is 0.0008342292858287692\n",
      "epoch: 33 step: 100, loss is 0.000806467782240361\n",
      "epoch: 33 step: 101, loss is 0.0004105342668481171\n",
      "epoch: 33 step: 102, loss is 0.0007306690094992518\n",
      "epoch: 33 step: 103, loss is 0.0004538831708487123\n",
      "epoch: 33 step: 104, loss is 0.0007909359992481768\n",
      "epoch: 33 step: 105, loss is 0.0005577082629315555\n",
      "epoch: 33 step: 106, loss is 0.0006650646100752056\n",
      "epoch: 33 step: 107, loss is 0.00040860410081222653\n",
      "epoch: 33 step: 108, loss is 0.001517718774266541\n",
      "epoch: 33 step: 109, loss is 0.0008365449029952288\n",
      "epoch: 33 step: 110, loss is 0.0007632279302924871\n",
      "epoch: 33 step: 111, loss is 0.00057141826255247\n",
      "epoch: 33 step: 112, loss is 0.0011621337616816163\n",
      "epoch: 33 step: 113, loss is 0.00047138752415776253\n",
      "epoch: 33 step: 114, loss is 0.0006063593900762498\n",
      "epoch: 33 step: 115, loss is 0.00028482620837166905\n",
      "epoch: 33 step: 116, loss is 0.0005267770611681044\n",
      "epoch: 33 step: 117, loss is 0.0005567655898630619\n",
      "epoch: 33 step: 118, loss is 0.00040679567609913647\n",
      "epoch: 33 step: 119, loss is 0.000608230649959296\n",
      "epoch: 33 step: 120, loss is 0.0009479833533987403\n",
      "epoch: 33 step: 121, loss is 0.0005338230403140187\n",
      "epoch: 33 step: 122, loss is 0.0003771758929360658\n",
      "epoch: 33 step: 123, loss is 0.000840956112369895\n",
      "epoch: 33 step: 124, loss is 0.0017795693129301071\n",
      "epoch: 33 step: 125, loss is 0.0002727971295826137\n",
      "epoch: 33 step: 126, loss is 0.0007393447449430823\n",
      "epoch: 33 step: 127, loss is 0.00040235239430330694\n",
      "epoch: 33 step: 128, loss is 0.0004490998398978263\n",
      "epoch: 33 step: 129, loss is 0.00045958455302752554\n",
      "epoch: 33 step: 130, loss is 0.0010632803896442056\n",
      "epoch: 33 step: 131, loss is 0.0004556782660074532\n",
      "epoch: 33 step: 132, loss is 0.000601205974817276\n",
      "epoch: 33 step: 133, loss is 0.0005646385252475739\n",
      "epoch: 33 step: 134, loss is 0.00047125780838541687\n",
      "epoch: 33 step: 135, loss is 0.0008416006457991898\n",
      "epoch: 33 step: 136, loss is 0.00027948085335083306\n",
      "epoch: 33 step: 137, loss is 0.00044250659993849695\n",
      "epoch: 33 step: 138, loss is 0.00038585736183449626\n",
      "epoch: 33 step: 139, loss is 0.0003992729471065104\n",
      "epoch: 33 step: 140, loss is 0.00045355455949902534\n",
      "epoch: 33 step: 141, loss is 0.00011703930067596957\n",
      "epoch: 33 step: 142, loss is 0.00021030480274930596\n",
      "epoch: 33 step: 143, loss is 0.0009904906619340181\n",
      "epoch: 33 step: 144, loss is 0.0004080574435647577\n",
      "epoch: 33 step: 145, loss is 0.0004622915876097977\n",
      "epoch: 33 step: 146, loss is 0.0009323509875684977\n",
      "epoch: 33 step: 147, loss is 0.001088639604859054\n",
      "epoch: 33 step: 148, loss is 0.0003068643272854388\n",
      "epoch: 33 step: 149, loss is 0.00012400379637256265\n",
      "epoch: 33 step: 150, loss is 0.0008545781602151692\n",
      "epoch: 33 step: 151, loss is 0.0009082493488676846\n",
      "epoch: 33 step: 152, loss is 0.0010904495138674974\n",
      "epoch: 33 step: 153, loss is 0.0006356989615596831\n",
      "epoch: 33 step: 154, loss is 0.0006806644378229976\n",
      "epoch: 33 step: 155, loss is 0.0001020143972709775\n",
      "epoch: 33 step: 156, loss is 0.0004217779787722975\n",
      "epoch: 33 step: 157, loss is 0.00047674300731159747\n",
      "epoch: 33 step: 158, loss is 0.00045104368473403156\n",
      "epoch: 33 step: 159, loss is 0.000713993504177779\n",
      "epoch: 33 step: 160, loss is 0.000531186698935926\n",
      "epoch: 33 step: 161, loss is 0.00046308714081533253\n",
      "epoch: 33 step: 162, loss is 0.0012159246252849698\n",
      "epoch: 33 step: 163, loss is 0.00028556957840919495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 step: 164, loss is 0.0011319272452965379\n",
      "epoch: 33 step: 165, loss is 0.0004607764130923897\n",
      "epoch: 33 step: 166, loss is 0.0008541132556274533\n",
      "epoch: 33 step: 167, loss is 0.0004217298701405525\n",
      "epoch: 33 step: 168, loss is 0.0019193401094526052\n",
      "epoch: 33 step: 169, loss is 0.0004339884908404201\n",
      "epoch: 33 step: 170, loss is 0.0007481213542632759\n",
      "epoch: 33 step: 171, loss is 0.00015341145626734942\n",
      "epoch: 33 step: 172, loss is 0.000765172066166997\n",
      "epoch: 33 step: 173, loss is 0.00032921668025664985\n",
      "epoch: 33 step: 174, loss is 0.0004666356253437698\n",
      "epoch: 33 step: 175, loss is 0.0007230136543512344\n",
      "epoch: 33 step: 176, loss is 0.0011644854675978422\n",
      "epoch: 33 step: 177, loss is 8.114056254271418e-05\n",
      "epoch: 33 step: 178, loss is 0.0009509317460469902\n",
      "epoch: 33 step: 179, loss is 0.0008293905993923545\n",
      "epoch: 33 step: 180, loss is 0.0005096609820611775\n",
      "epoch: 33 step: 181, loss is 0.0008359079365618527\n",
      "epoch: 33 step: 182, loss is 0.001068641198799014\n",
      "epoch: 33 step: 183, loss is 0.0009747330914251506\n",
      "epoch: 33 step: 184, loss is 0.0008647607173770666\n",
      "epoch: 33 step: 185, loss is 0.0005903260898776352\n",
      "epoch: 33 step: 186, loss is 0.0002491760824341327\n",
      "epoch: 33 step: 187, loss is 0.0007242833962664008\n",
      "epoch: 33 step: 188, loss is 0.0008112738723866642\n",
      "epoch: 33 step: 189, loss is 0.00048472225898876786\n",
      "epoch: 33 step: 190, loss is 0.000978144584223628\n",
      "epoch: 33 step: 191, loss is 0.0005097584798932076\n",
      "epoch: 33 step: 192, loss is 0.00013818879961036146\n",
      "epoch: 33 step: 193, loss is 0.0011566438479349017\n",
      "epoch: 33 step: 194, loss is 0.0005447564763016999\n",
      "epoch: 33 step: 195, loss is 0.0012722592800855637\n",
      "epoch: 33 step: 196, loss is 0.0012155913282185793\n",
      "epoch: 33 step: 197, loss is 0.0015960752498358488\n",
      "epoch: 33 step: 198, loss is 0.0005961835267953575\n",
      "epoch: 33 step: 199, loss is 0.0003094579151365906\n",
      "epoch: 33 step: 200, loss is 0.0005127448821440339\n",
      "epoch: 33 step: 201, loss is 0.0005437814397737384\n",
      "epoch: 33 step: 202, loss is 0.0013195406645536423\n",
      "epoch: 33 step: 203, loss is 0.0004930414725095034\n",
      "epoch: 33 step: 204, loss is 0.0009166927775368094\n",
      "epoch: 33 step: 205, loss is 0.0006591065903194249\n",
      "epoch: 33 step: 206, loss is 0.00048656485159881413\n",
      "epoch: 33 step: 207, loss is 0.0010969961294904351\n",
      "epoch: 33 step: 208, loss is 0.0005536498501896858\n",
      "epoch: 33 step: 209, loss is 0.00038230937207117677\n",
      "epoch: 33 step: 210, loss is 0.0014811353757977486\n",
      "epoch: 33 step: 211, loss is 0.0011464646086096764\n",
      "epoch: 33 step: 212, loss is 0.000868426461238414\n",
      "epoch: 33 step: 213, loss is 0.0018834699876606464\n",
      "epoch: 33 step: 214, loss is 0.0006374100339598954\n",
      "epoch: 33 step: 215, loss is 0.001218075049109757\n",
      "epoch: 33 step: 216, loss is 0.00034328363835811615\n",
      "epoch: 33 step: 217, loss is 0.0005209880182519555\n",
      "epoch: 33 step: 218, loss is 0.0005340061616152525\n",
      "epoch: 33 step: 219, loss is 0.0002778362249955535\n",
      "epoch: 33 step: 220, loss is 0.0004278265405446291\n",
      "epoch: 33 step: 221, loss is 0.0006653171149082482\n",
      "epoch: 33 step: 222, loss is 0.0006745134596712887\n",
      "epoch: 33 step: 223, loss is 0.00017926380678545684\n",
      "epoch: 33 step: 224, loss is 0.00133289466612041\n",
      "epoch: 33 step: 225, loss is 0.0005700731417164207\n",
      "epoch: 33 step: 226, loss is 0.0006104219937697053\n",
      "epoch: 33 step: 227, loss is 0.0002510375634301454\n",
      "epoch: 33 step: 228, loss is 0.0008684889180585742\n",
      "epoch: 33 step: 229, loss is 0.0005902449483983219\n",
      "epoch: 33 step: 230, loss is 0.0010737116681411862\n",
      "epoch: 33 step: 231, loss is 0.0002937738609034568\n",
      "epoch: 33 step: 232, loss is 0.000910092843696475\n",
      "epoch: 33 step: 233, loss is 0.0006545823416672647\n",
      "epoch: 33 step: 234, loss is 0.0009063816978596151\n",
      "epoch: 33 step: 235, loss is 0.0012505988124758005\n",
      "epoch: 33 step: 236, loss is 0.00028711784398183227\n",
      "epoch: 33 step: 237, loss is 0.0004353388794697821\n",
      "epoch: 33 step: 238, loss is 0.000329434871673584\n",
      "epoch: 33 step: 239, loss is 0.0006648382404819131\n",
      "epoch: 33 step: 240, loss is 0.0012575301807373762\n",
      "epoch: 33 step: 241, loss is 0.00032467732671648264\n",
      "epoch: 33 step: 242, loss is 0.0014237487921491265\n",
      "epoch: 33 step: 243, loss is 0.0006441632867790759\n",
      "epoch: 33 step: 244, loss is 0.0004977971548214555\n",
      "epoch: 33 step: 245, loss is 0.0011715597938746214\n",
      "epoch: 33 step: 246, loss is 0.00033810833701863885\n",
      "epoch: 33 step: 247, loss is 0.0003451884549576789\n",
      "epoch: 33 step: 248, loss is 0.00018779955280479044\n",
      "epoch: 33 step: 249, loss is 0.001486601191572845\n",
      "epoch: 33 step: 250, loss is 0.00037878224975429475\n",
      "epoch: 33 step: 251, loss is 0.0009917711140587926\n",
      "epoch: 33 step: 252, loss is 0.0007104302640073001\n",
      "epoch: 33 step: 253, loss is 0.00015090638771653175\n",
      "epoch: 33 step: 254, loss is 0.0007237839745357633\n",
      "epoch: 33 step: 255, loss is 0.0004428640240803361\n",
      "epoch: 33 step: 256, loss is 0.00046480161836370826\n",
      "epoch: 33 step: 257, loss is 0.0004342193715274334\n",
      "epoch: 33 step: 258, loss is 0.0009515613783150911\n",
      "epoch: 33 step: 259, loss is 0.0004448779800441116\n",
      "epoch: 33 step: 260, loss is 0.0002791675506159663\n",
      "epoch: 33 step: 261, loss is 0.0001617042435100302\n",
      "epoch: 33 step: 262, loss is 0.0009808861650526524\n",
      "epoch: 33 step: 263, loss is 0.0015231985598802567\n",
      "epoch: 33 step: 264, loss is 0.0003492880205158144\n",
      "epoch: 33 step: 265, loss is 0.0007853119168430567\n",
      "epoch: 33 step: 266, loss is 0.0008784132078289986\n",
      "epoch: 33 step: 267, loss is 0.0012104177149012685\n",
      "epoch: 33 step: 268, loss is 0.00029935588827356696\n",
      "epoch: 33 step: 269, loss is 0.0002336572069907561\n",
      "epoch: 33 step: 270, loss is 0.0007367277867160738\n",
      "epoch: 33 step: 271, loss is 0.00038079271325841546\n",
      "epoch: 33 step: 272, loss is 0.0004424469079822302\n",
      "epoch: 33 step: 273, loss is 0.0003276084316894412\n",
      "epoch: 33 step: 274, loss is 0.00040377365075983107\n",
      "epoch: 33 step: 275, loss is 0.0006081437459215522\n",
      "epoch: 33 step: 276, loss is 0.00016025306831579655\n",
      "epoch: 33 step: 277, loss is 0.0009107891819439828\n",
      "epoch: 33 step: 278, loss is 0.00046764928265474737\n",
      "epoch: 33 step: 279, loss is 0.0008893343037925661\n",
      "epoch: 33 step: 280, loss is 0.0004643835127353668\n",
      "epoch: 33 step: 281, loss is 0.0018390684854239225\n",
      "epoch: 33 step: 282, loss is 0.00028928284882567823\n",
      "epoch: 33 step: 283, loss is 0.0009090396342799067\n",
      "epoch: 33 step: 284, loss is 0.0007421805057674646\n",
      "epoch: 33 step: 285, loss is 0.0010926041286438704\n",
      "epoch: 33 step: 286, loss is 0.0005795969627797604\n",
      "epoch: 33 step: 287, loss is 0.0012934819096699357\n",
      "epoch: 33 step: 288, loss is 0.0005728131509386003\n",
      "epoch: 33 step: 289, loss is 0.0007596169016323984\n",
      "epoch: 33 step: 290, loss is 0.0007046239334158599\n",
      "epoch: 33 step: 291, loss is 0.000662529026158154\n",
      "epoch: 33 step: 292, loss is 0.0005842577666044235\n",
      "epoch: 33 step: 293, loss is 0.0010434617288410664\n",
      "epoch: 33 step: 294, loss is 0.0006076459540054202\n",
      "epoch: 33 step: 295, loss is 0.0010573096806183457\n",
      "epoch: 33 step: 296, loss is 0.0006575825391337276\n",
      "epoch: 33 step: 297, loss is 0.001039543654769659\n",
      "epoch: 33 step: 298, loss is 0.0006134386057965457\n",
      "epoch: 33 step: 299, loss is 0.00019925825472455472\n",
      "epoch: 33 step: 300, loss is 0.0008873867918737233\n",
      "epoch: 33 step: 301, loss is 0.00022410588280763477\n",
      "epoch: 33 step: 302, loss is 0.0006515963468700647\n",
      "epoch: 33 step: 303, loss is 0.0006139484466984868\n",
      "epoch: 33 step: 304, loss is 0.0009668123093433678\n",
      "epoch: 33 step: 305, loss is 0.0007046873797662556\n",
      "epoch: 33 step: 306, loss is 0.0007093395106494427\n",
      "epoch: 33 step: 307, loss is 0.0005965358577668667\n",
      "epoch: 33 step: 308, loss is 0.0004737614654004574\n",
      "epoch: 33 step: 309, loss is 0.00013454054715111852\n",
      "epoch: 33 step: 310, loss is 0.0007563648396171629\n",
      "epoch: 33 step: 311, loss is 0.00043408642522990704\n",
      "epoch: 33 step: 312, loss is 0.0010063144145533442\n",
      "epoch: 33 step: 313, loss is 0.0005036492366343737\n",
      "epoch: 33 step: 314, loss is 0.0006573193240910769\n",
      "epoch: 33 step: 315, loss is 0.00034272612538188696\n",
      "epoch: 33 step: 316, loss is 0.00032848049886524677\n",
      "epoch: 33 step: 317, loss is 0.0009998249588534236\n",
      "epoch: 33 step: 318, loss is 0.0007650817278772593\n",
      "epoch: 33 step: 319, loss is 0.0005478271632455289\n",
      "epoch: 33 step: 320, loss is 0.0004444503574632108\n",
      "epoch: 33 step: 321, loss is 0.0005863935803063214\n",
      "epoch: 33 step: 322, loss is 0.0008587176562286913\n",
      "epoch: 33 step: 323, loss is 0.0004213533247821033\n",
      "epoch: 33 step: 324, loss is 0.00044792157132178545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 step: 325, loss is 0.000635832897387445\n",
      "epoch: 33 step: 326, loss is 0.0004772409738507122\n",
      "epoch: 33 step: 327, loss is 0.0007829275564290583\n",
      "epoch: 33 step: 328, loss is 0.00023608034825883806\n",
      "epoch: 33 step: 329, loss is 0.00032766666845418513\n",
      "epoch: 33 step: 330, loss is 0.0009559882455505431\n",
      "epoch: 33 step: 331, loss is 0.0005022158147767186\n",
      "epoch: 33 step: 332, loss is 0.0009474208927713335\n",
      "epoch: 33 step: 333, loss is 0.0006556835141964257\n",
      "epoch: 33 step: 334, loss is 0.0006524838390760124\n",
      "epoch: 33 step: 335, loss is 0.0013884006766602397\n",
      "epoch: 33 step: 336, loss is 0.0006704933475703001\n",
      "epoch: 33 step: 337, loss is 0.0002550541248638183\n",
      "epoch: 33 step: 338, loss is 0.0007691594073548913\n",
      "epoch: 33 step: 339, loss is 0.0007271438953466713\n",
      "epoch: 33 step: 340, loss is 0.00048176446580328047\n",
      "epoch: 33 step: 341, loss is 0.001024505472742021\n",
      "epoch: 33 step: 342, loss is 0.0004063749802298844\n",
      "epoch: 33 step: 343, loss is 0.0006857675034552813\n",
      "epoch: 33 step: 344, loss is 0.0006027668132446706\n",
      "epoch: 33 step: 345, loss is 0.00042574419057928026\n",
      "epoch: 33 step: 346, loss is 0.0008878086810000241\n",
      "epoch: 33 step: 347, loss is 0.0014433555770665407\n",
      "epoch: 33 step: 348, loss is 0.0009432592196390033\n",
      "epoch: 33 step: 349, loss is 0.0005308563122525811\n",
      "epoch: 33 step: 350, loss is 0.0006424225284717977\n",
      "epoch: 33 step: 351, loss is 0.0005175514961592853\n",
      "epoch: 33 step: 352, loss is 0.00029316326254047453\n",
      "epoch: 33 step: 353, loss is 0.0012495368719100952\n",
      "epoch: 33 step: 354, loss is 0.0002196176938014105\n",
      "epoch: 33 step: 355, loss is 0.000893516291398555\n",
      "epoch: 33 step: 356, loss is 0.0003522770421113819\n",
      "epoch: 33 step: 357, loss is 0.0008585794130340219\n",
      "epoch: 33 step: 358, loss is 0.0007237418903969228\n",
      "epoch: 33 step: 359, loss is 0.0010999632067978382\n",
      "epoch: 33 step: 360, loss is 0.0011512998025864363\n",
      "epoch: 33 step: 361, loss is 0.00027729233261197805\n",
      "epoch: 33 step: 362, loss is 0.0005962764844298363\n",
      "epoch: 33 step: 363, loss is 0.0002805654949042946\n",
      "epoch: 33 step: 364, loss is 0.0005525160813704133\n",
      "epoch: 33 step: 365, loss is 0.000615545257460326\n",
      "epoch: 33 step: 366, loss is 0.0007234979420900345\n",
      "epoch: 33 step: 367, loss is 0.000547983858268708\n",
      "epoch: 33 step: 368, loss is 0.00053984863916412\n",
      "epoch: 33 step: 369, loss is 0.001378644141368568\n",
      "epoch: 33 step: 370, loss is 0.0007276522810570896\n",
      "epoch: 33 step: 371, loss is 0.0004748047504108399\n",
      "epoch: 33 step: 372, loss is 0.00036756531335413456\n",
      "epoch: 33 step: 373, loss is 0.0004262114816810936\n",
      "epoch: 33 step: 374, loss is 0.0021461325231939554\n",
      "epoch: 33 step: 375, loss is 0.0010429270332679152\n",
      "Train epoch time: 11973.186 ms, per step time: 31.928 ms\n",
      "epoch: 34 step: 1, loss is 0.00030931225046515465\n",
      "epoch: 34 step: 2, loss is 0.0008426790009252727\n",
      "epoch: 34 step: 3, loss is 0.0004519644135143608\n",
      "epoch: 34 step: 4, loss is 0.0009279723162762821\n",
      "epoch: 34 step: 5, loss is 0.0003754597855731845\n",
      "epoch: 34 step: 6, loss is 0.0005696747684851289\n",
      "epoch: 34 step: 7, loss is 0.00020370529091451317\n",
      "epoch: 34 step: 8, loss is 0.0003989956167060882\n",
      "epoch: 34 step: 9, loss is 0.0006460660952143371\n",
      "epoch: 34 step: 10, loss is 0.00031947807292453945\n",
      "epoch: 34 step: 11, loss is 0.0009025592589750886\n",
      "epoch: 34 step: 12, loss is 0.0006912319804541767\n",
      "epoch: 34 step: 13, loss is 0.0006048393552191556\n",
      "epoch: 34 step: 14, loss is 0.00048355935723520815\n",
      "epoch: 34 step: 15, loss is 0.0001849968102760613\n",
      "epoch: 34 step: 16, loss is 0.00026092963526025414\n",
      "epoch: 34 step: 17, loss is 0.0006286989082582295\n",
      "epoch: 34 step: 18, loss is 0.00019979853823315352\n",
      "epoch: 34 step: 19, loss is 0.00012382229033391923\n",
      "epoch: 34 step: 20, loss is 0.0014307355741038918\n",
      "epoch: 34 step: 21, loss is 0.0008286697557196021\n",
      "epoch: 34 step: 22, loss is 0.0008032064652070403\n",
      "epoch: 34 step: 23, loss is 0.0007212452474050224\n",
      "epoch: 34 step: 24, loss is 0.0007362416363321245\n",
      "epoch: 34 step: 25, loss is 0.0003809565387200564\n",
      "epoch: 34 step: 26, loss is 0.001753471908159554\n",
      "epoch: 34 step: 27, loss is 0.00044160999823361635\n",
      "epoch: 34 step: 28, loss is 0.0002488485479261726\n",
      "epoch: 34 step: 29, loss is 0.0007659158436581492\n",
      "epoch: 34 step: 30, loss is 0.000624106964096427\n",
      "epoch: 34 step: 31, loss is 0.0012112754629924893\n",
      "epoch: 34 step: 32, loss is 0.0004738924908451736\n",
      "epoch: 34 step: 33, loss is 0.0003275389317423105\n",
      "epoch: 34 step: 34, loss is 0.0009045431506820023\n",
      "epoch: 34 step: 35, loss is 0.0004508401907514781\n",
      "epoch: 34 step: 36, loss is 0.0010262649739161134\n",
      "epoch: 34 step: 37, loss is 0.0017515169456601143\n",
      "epoch: 34 step: 38, loss is 0.0004364321066532284\n",
      "epoch: 34 step: 39, loss is 0.00030993815744295716\n",
      "epoch: 34 step: 40, loss is 0.0013801963068544865\n",
      "epoch: 34 step: 41, loss is 0.0015907182823866606\n",
      "epoch: 34 step: 42, loss is 0.00016758954734541476\n",
      "epoch: 34 step: 43, loss is 0.0006718561053276062\n",
      "epoch: 34 step: 44, loss is 0.0003553218557499349\n",
      "epoch: 34 step: 45, loss is 0.000430977699579671\n",
      "epoch: 34 step: 46, loss is 0.0005576281109824777\n",
      "epoch: 34 step: 47, loss is 0.0004169915628153831\n",
      "epoch: 34 step: 48, loss is 0.00039892829954624176\n",
      "epoch: 34 step: 49, loss is 0.0002621952153276652\n",
      "epoch: 34 step: 50, loss is 0.0006641808431595564\n",
      "epoch: 34 step: 51, loss is 0.0006685938569717109\n",
      "epoch: 34 step: 52, loss is 0.0009672729065641761\n",
      "epoch: 34 step: 53, loss is 0.0003939746238756925\n",
      "epoch: 34 step: 54, loss is 0.0006655870238319039\n",
      "epoch: 34 step: 55, loss is 0.0004723152960650623\n",
      "epoch: 34 step: 56, loss is 0.000323841639328748\n",
      "epoch: 34 step: 57, loss is 0.00041395812877453864\n",
      "epoch: 34 step: 58, loss is 0.0018572336994111538\n",
      "epoch: 34 step: 59, loss is 0.0003102466289419681\n",
      "epoch: 34 step: 60, loss is 0.0011169057106599212\n",
      "epoch: 34 step: 61, loss is 0.0013005336513742805\n",
      "epoch: 34 step: 62, loss is 0.0013387678191065788\n",
      "epoch: 34 step: 63, loss is 0.00033817646908573806\n",
      "epoch: 34 step: 64, loss is 0.00048516321112401783\n",
      "epoch: 34 step: 65, loss is 0.0003451565862633288\n",
      "epoch: 34 step: 66, loss is 0.00034604803659021854\n",
      "epoch: 34 step: 67, loss is 0.0006936881691217422\n",
      "epoch: 34 step: 68, loss is 0.00040991255082190037\n",
      "epoch: 34 step: 69, loss is 0.0005767851835116744\n",
      "epoch: 34 step: 70, loss is 0.000709115993231535\n",
      "epoch: 34 step: 71, loss is 0.0006547840312123299\n",
      "epoch: 34 step: 72, loss is 0.0006655727047473192\n",
      "epoch: 34 step: 73, loss is 0.00046810301137156785\n",
      "epoch: 34 step: 74, loss is 0.000949061824940145\n",
      "epoch: 34 step: 75, loss is 0.00017576944082975388\n",
      "epoch: 34 step: 76, loss is 0.0005061454139649868\n",
      "epoch: 34 step: 77, loss is 0.0005670252721756697\n",
      "epoch: 34 step: 78, loss is 0.00039704181835986674\n",
      "epoch: 34 step: 79, loss is 0.001032438944093883\n",
      "epoch: 34 step: 80, loss is 0.0005660760216414928\n",
      "epoch: 34 step: 81, loss is 0.0006114575662650168\n",
      "epoch: 34 step: 82, loss is 0.0005340066854842007\n",
      "epoch: 34 step: 83, loss is 0.00021391517657320946\n",
      "epoch: 34 step: 84, loss is 0.0002821313391905278\n",
      "epoch: 34 step: 85, loss is 0.0003495596465654671\n",
      "epoch: 34 step: 86, loss is 0.0002717339957598597\n",
      "epoch: 34 step: 87, loss is 0.0005869592423550785\n",
      "epoch: 34 step: 88, loss is 0.0009982238989323378\n",
      "epoch: 34 step: 89, loss is 0.00036434794310480356\n",
      "epoch: 34 step: 90, loss is 0.0009190273121930659\n",
      "epoch: 34 step: 91, loss is 0.0004682701837737113\n",
      "epoch: 34 step: 92, loss is 0.0009090086095966399\n",
      "epoch: 34 step: 93, loss is 0.0018485940527170897\n",
      "epoch: 34 step: 94, loss is 0.0011555477976799011\n",
      "epoch: 34 step: 95, loss is 0.0003517610894050449\n",
      "epoch: 34 step: 96, loss is 0.00038035737816244364\n",
      "epoch: 34 step: 97, loss is 0.00030005135340616107\n",
      "epoch: 34 step: 98, loss is 0.0004375696007627994\n",
      "epoch: 34 step: 99, loss is 0.0005027273437008262\n",
      "epoch: 34 step: 100, loss is 0.0007841886254027486\n",
      "epoch: 34 step: 101, loss is 0.0005669401143677533\n",
      "epoch: 34 step: 102, loss is 0.00026756100123748183\n",
      "epoch: 34 step: 103, loss is 0.0005715107545256615\n",
      "epoch: 34 step: 104, loss is 0.00031638098880648613\n",
      "epoch: 34 step: 105, loss is 0.0007950429571792483\n",
      "epoch: 34 step: 106, loss is 0.0010118907084688544\n",
      "epoch: 34 step: 107, loss is 0.0004648233880288899\n",
      "epoch: 34 step: 108, loss is 0.0007770095253363252\n",
      "epoch: 34 step: 109, loss is 0.0006542900810018182\n",
      "epoch: 34 step: 110, loss is 0.0007389739621430635\n",
      "epoch: 34 step: 111, loss is 0.0007420590263791382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 step: 112, loss is 0.000866394373588264\n",
      "epoch: 34 step: 113, loss is 0.000957155367359519\n",
      "epoch: 34 step: 114, loss is 0.0004049545095767826\n",
      "epoch: 34 step: 115, loss is 0.0002519802947062999\n",
      "epoch: 34 step: 116, loss is 0.0009367538150399923\n",
      "epoch: 34 step: 117, loss is 0.000720916548743844\n",
      "epoch: 34 step: 118, loss is 0.0006688867579214275\n",
      "epoch: 34 step: 119, loss is 0.0006060788291506469\n",
      "epoch: 34 step: 120, loss is 0.0015881509752944112\n",
      "epoch: 34 step: 121, loss is 0.0001254386588698253\n",
      "epoch: 34 step: 122, loss is 0.0012357098748907447\n",
      "epoch: 34 step: 123, loss is 0.00022948435798753053\n",
      "epoch: 34 step: 124, loss is 0.0007580907549709082\n",
      "epoch: 34 step: 125, loss is 0.0003311737673357129\n",
      "epoch: 34 step: 126, loss is 0.0005057359230704606\n",
      "epoch: 34 step: 127, loss is 0.0003437414125073701\n",
      "epoch: 34 step: 128, loss is 0.00018808928143698722\n",
      "epoch: 34 step: 129, loss is 0.0006529207457788289\n",
      "epoch: 34 step: 130, loss is 0.001241967431269586\n",
      "epoch: 34 step: 131, loss is 0.0004367060319054872\n",
      "epoch: 34 step: 132, loss is 0.0015975767746567726\n",
      "epoch: 34 step: 133, loss is 0.00035855438909493387\n",
      "epoch: 34 step: 134, loss is 0.0009835773380473256\n",
      "epoch: 34 step: 135, loss is 0.0006676645716652274\n",
      "epoch: 34 step: 136, loss is 0.0006060075829736888\n",
      "epoch: 34 step: 137, loss is 0.0008569534402340651\n",
      "epoch: 34 step: 138, loss is 0.0006479616276919842\n",
      "epoch: 34 step: 139, loss is 0.00024922675220295787\n",
      "epoch: 34 step: 140, loss is 0.001216507633216679\n",
      "epoch: 34 step: 141, loss is 8.382691157748923e-05\n",
      "epoch: 34 step: 142, loss is 0.0008195973350666463\n",
      "epoch: 34 step: 143, loss is 0.0010087151313200593\n",
      "epoch: 34 step: 144, loss is 0.0004406000080052763\n",
      "epoch: 34 step: 145, loss is 0.0005902471020817757\n",
      "epoch: 34 step: 146, loss is 0.001245068502612412\n",
      "epoch: 34 step: 147, loss is 0.0014004060067236423\n",
      "epoch: 34 step: 148, loss is 0.00014731098781339824\n",
      "epoch: 34 step: 149, loss is 0.0005170475342310965\n",
      "epoch: 34 step: 150, loss is 0.0009824972366914153\n",
      "epoch: 34 step: 151, loss is 0.0003948796074837446\n",
      "epoch: 34 step: 152, loss is 0.0010824325727298856\n",
      "epoch: 34 step: 153, loss is 0.0007368348888121545\n",
      "epoch: 34 step: 154, loss is 0.0013497751206159592\n",
      "epoch: 34 step: 155, loss is 0.0008207118953578174\n",
      "epoch: 34 step: 156, loss is 0.0005408957367762923\n",
      "epoch: 34 step: 157, loss is 0.00046309962635859847\n",
      "epoch: 34 step: 158, loss is 0.0008707272354513407\n",
      "epoch: 34 step: 159, loss is 0.0004782328614965081\n",
      "epoch: 34 step: 160, loss is 0.0004571972240228206\n",
      "epoch: 34 step: 161, loss is 0.0007779048173688352\n",
      "epoch: 34 step: 162, loss is 0.0003343517892062664\n",
      "epoch: 34 step: 163, loss is 0.0008867884753271937\n",
      "epoch: 34 step: 164, loss is 0.0005667894147336483\n",
      "epoch: 34 step: 165, loss is 0.0009583413484506309\n",
      "epoch: 34 step: 166, loss is 0.000719211355317384\n",
      "epoch: 34 step: 167, loss is 0.0009240098297595978\n",
      "epoch: 34 step: 168, loss is 0.000489331956487149\n",
      "epoch: 34 step: 169, loss is 0.0009711636230349541\n",
      "epoch: 34 step: 170, loss is 0.0004622630949597806\n",
      "epoch: 34 step: 171, loss is 0.0007041615317575634\n",
      "epoch: 34 step: 172, loss is 0.0004399219178594649\n",
      "epoch: 34 step: 173, loss is 0.0012132242554798722\n",
      "epoch: 34 step: 174, loss is 0.00026968648307956755\n",
      "epoch: 34 step: 175, loss is 0.0007638894603587687\n",
      "epoch: 34 step: 176, loss is 0.0005211132229305804\n",
      "epoch: 34 step: 177, loss is 0.0005851693567819893\n",
      "epoch: 34 step: 178, loss is 0.0003106643271166831\n",
      "epoch: 34 step: 179, loss is 0.0005052097840234637\n",
      "epoch: 34 step: 180, loss is 0.0006142730708234012\n",
      "epoch: 34 step: 181, loss is 0.0005889743333682418\n",
      "epoch: 34 step: 182, loss is 0.0025847693905234337\n",
      "epoch: 34 step: 183, loss is 0.00016989326104521751\n",
      "epoch: 34 step: 184, loss is 0.00034169896389357746\n",
      "epoch: 34 step: 185, loss is 0.000348331086570397\n",
      "epoch: 34 step: 186, loss is 0.0018225862877443433\n",
      "epoch: 34 step: 187, loss is 0.0008592880330979824\n",
      "epoch: 34 step: 188, loss is 0.0004954378237016499\n",
      "epoch: 34 step: 189, loss is 0.0003934112610295415\n",
      "epoch: 34 step: 190, loss is 0.00134480360429734\n",
      "epoch: 34 step: 191, loss is 0.0001554242189740762\n",
      "epoch: 34 step: 192, loss is 0.00045987594057805836\n",
      "epoch: 34 step: 193, loss is 0.0012821084819734097\n",
      "epoch: 34 step: 194, loss is 0.00044746475759893656\n",
      "epoch: 34 step: 195, loss is 0.0005654062260873616\n",
      "epoch: 34 step: 196, loss is 0.0007619019015692174\n",
      "epoch: 34 step: 197, loss is 0.0006972440169192851\n",
      "epoch: 34 step: 198, loss is 0.000960403005592525\n",
      "epoch: 34 step: 199, loss is 0.0013244645670056343\n",
      "epoch: 34 step: 200, loss is 0.0002995808026753366\n",
      "epoch: 34 step: 201, loss is 0.00039730750722810626\n",
      "epoch: 34 step: 202, loss is 0.0007146382122300565\n",
      "epoch: 34 step: 203, loss is 0.0004056109464727342\n",
      "epoch: 34 step: 204, loss is 0.00043576574535109103\n",
      "epoch: 34 step: 205, loss is 0.0006618353654630482\n",
      "epoch: 34 step: 206, loss is 0.0006036613485775888\n",
      "epoch: 34 step: 207, loss is 0.0007637643720954657\n",
      "epoch: 34 step: 208, loss is 0.0005690951948054135\n",
      "epoch: 34 step: 209, loss is 0.0008010591263882816\n",
      "epoch: 34 step: 210, loss is 0.0003290612658020109\n",
      "epoch: 34 step: 211, loss is 0.0003425540344323963\n",
      "epoch: 34 step: 212, loss is 0.000357415818143636\n",
      "epoch: 34 step: 213, loss is 0.0011369327548891306\n",
      "epoch: 34 step: 214, loss is 0.001311899395659566\n",
      "epoch: 34 step: 215, loss is 0.0007928991108201444\n",
      "epoch: 34 step: 216, loss is 0.00039375488995574415\n",
      "epoch: 34 step: 217, loss is 0.001172583899460733\n",
      "epoch: 34 step: 218, loss is 0.0006565159419551492\n",
      "epoch: 34 step: 219, loss is 0.0008464768179692328\n",
      "epoch: 34 step: 220, loss is 0.0007973127067089081\n",
      "epoch: 34 step: 221, loss is 0.001145148416981101\n",
      "epoch: 34 step: 222, loss is 0.0008831832674331963\n",
      "epoch: 34 step: 223, loss is 0.0006587494281120598\n",
      "epoch: 34 step: 224, loss is 0.0010411767289042473\n",
      "epoch: 34 step: 225, loss is 0.0003596282913349569\n",
      "epoch: 34 step: 226, loss is 0.0005902803386561573\n",
      "epoch: 34 step: 227, loss is 0.0004054791934322566\n",
      "epoch: 34 step: 228, loss is 0.0007673320360481739\n",
      "epoch: 34 step: 229, loss is 0.0005083490977995098\n",
      "epoch: 34 step: 230, loss is 0.0007184661226347089\n",
      "epoch: 34 step: 231, loss is 0.0008634434198029339\n",
      "epoch: 34 step: 232, loss is 0.00109073705971241\n",
      "epoch: 34 step: 233, loss is 0.0004914294113405049\n",
      "epoch: 34 step: 234, loss is 0.000154913475853391\n",
      "epoch: 34 step: 235, loss is 0.0012596333399415016\n",
      "epoch: 34 step: 236, loss is 0.0004067799891345203\n",
      "epoch: 34 step: 237, loss is 0.0001895404129754752\n",
      "epoch: 34 step: 238, loss is 0.0008983556763269007\n",
      "epoch: 34 step: 239, loss is 0.0005865827552042902\n",
      "epoch: 34 step: 240, loss is 0.0015231462894007564\n",
      "epoch: 34 step: 241, loss is 0.0003806676249951124\n",
      "epoch: 34 step: 242, loss is 0.0007216503727249801\n",
      "epoch: 34 step: 243, loss is 0.0004072340962011367\n",
      "epoch: 34 step: 244, loss is 0.0007616525981575251\n",
      "epoch: 34 step: 245, loss is 0.001568474224768579\n",
      "epoch: 34 step: 246, loss is 0.000994297326542437\n",
      "epoch: 34 step: 247, loss is 0.0007390175596810877\n",
      "epoch: 34 step: 248, loss is 0.00032579945400357246\n",
      "epoch: 34 step: 249, loss is 0.0003660506918095052\n",
      "epoch: 34 step: 250, loss is 0.001477874000556767\n",
      "epoch: 34 step: 251, loss is 0.0006285237614065409\n",
      "epoch: 34 step: 252, loss is 0.00022329662169795483\n",
      "epoch: 34 step: 253, loss is 0.0005084476433694363\n",
      "epoch: 34 step: 254, loss is 0.00025459169410169125\n",
      "epoch: 34 step: 255, loss is 0.0009905491024255753\n",
      "epoch: 34 step: 256, loss is 0.00029323561466299\n",
      "epoch: 34 step: 257, loss is 0.0007953292806632817\n",
      "epoch: 34 step: 258, loss is 0.0005945242592133582\n",
      "epoch: 34 step: 259, loss is 0.000916672928724438\n",
      "epoch: 34 step: 260, loss is 0.0013171073514968157\n",
      "epoch: 34 step: 261, loss is 0.0010062853107228875\n",
      "epoch: 34 step: 262, loss is 0.00036838321830146015\n",
      "epoch: 34 step: 263, loss is 0.000588830909691751\n",
      "epoch: 34 step: 264, loss is 0.0005458533996716142\n",
      "epoch: 34 step: 265, loss is 0.000655314011964947\n",
      "epoch: 34 step: 266, loss is 0.0018025008030235767\n",
      "epoch: 34 step: 267, loss is 0.0009942647302523255\n",
      "epoch: 34 step: 268, loss is 0.0007996502099558711\n",
      "epoch: 34 step: 269, loss is 0.0006775430520065129\n",
      "epoch: 34 step: 270, loss is 0.001836976152844727\n",
      "epoch: 34 step: 271, loss is 0.0010599083034321666\n",
      "epoch: 34 step: 272, loss is 0.0005314130685292184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 step: 273, loss is 0.0006029106443747878\n",
      "epoch: 34 step: 274, loss is 0.0006940514431335032\n",
      "epoch: 34 step: 275, loss is 0.0007036486640572548\n",
      "epoch: 34 step: 276, loss is 0.0005292400601319969\n",
      "epoch: 34 step: 277, loss is 0.0006859240238554776\n",
      "epoch: 34 step: 278, loss is 0.0005944849108345807\n",
      "epoch: 34 step: 279, loss is 0.0004027823160868138\n",
      "epoch: 34 step: 280, loss is 0.0006855785031802952\n",
      "epoch: 34 step: 281, loss is 0.0005069102044217288\n",
      "epoch: 34 step: 282, loss is 0.0012723022373393178\n",
      "epoch: 34 step: 283, loss is 0.0002745978708844632\n",
      "epoch: 34 step: 284, loss is 0.0005620077718049288\n",
      "epoch: 34 step: 285, loss is 0.00029978100792504847\n",
      "epoch: 34 step: 286, loss is 0.0006574825965799391\n",
      "epoch: 34 step: 287, loss is 0.0005482375854626298\n",
      "epoch: 34 step: 288, loss is 0.0017663529142737389\n",
      "epoch: 34 step: 289, loss is 0.00032717385329306126\n",
      "epoch: 34 step: 290, loss is 0.00026404380332678556\n",
      "epoch: 34 step: 291, loss is 0.000551694305613637\n",
      "epoch: 34 step: 292, loss is 0.0004146163701079786\n",
      "epoch: 34 step: 293, loss is 0.0009485697955824435\n",
      "epoch: 34 step: 294, loss is 0.0006549027748405933\n",
      "epoch: 34 step: 295, loss is 0.0005703959614038467\n",
      "epoch: 34 step: 296, loss is 0.00023459184740204364\n",
      "epoch: 34 step: 297, loss is 0.0003277487412560731\n",
      "epoch: 34 step: 298, loss is 0.0006510617095045745\n",
      "epoch: 34 step: 299, loss is 0.00042515722452662885\n",
      "epoch: 34 step: 300, loss is 0.0007129355799406767\n",
      "epoch: 34 step: 301, loss is 0.0004833972197957337\n",
      "epoch: 34 step: 302, loss is 0.00019697126117534935\n",
      "epoch: 34 step: 303, loss is 0.000673412811011076\n",
      "epoch: 34 step: 304, loss is 0.0012002463918179274\n",
      "epoch: 34 step: 305, loss is 0.0003529138339217752\n",
      "epoch: 34 step: 306, loss is 0.00037012211396358907\n",
      "epoch: 34 step: 307, loss is 0.000941548787523061\n",
      "epoch: 34 step: 308, loss is 0.0006330399191938341\n",
      "epoch: 34 step: 309, loss is 0.0006659193313680589\n",
      "epoch: 34 step: 310, loss is 0.0004502864903770387\n",
      "epoch: 34 step: 311, loss is 0.0002241987531306222\n",
      "epoch: 34 step: 312, loss is 0.0009070129599422216\n",
      "epoch: 34 step: 313, loss is 0.0004354668199084699\n",
      "epoch: 34 step: 314, loss is 0.0005971845821477473\n",
      "epoch: 34 step: 315, loss is 0.0005236577126197517\n",
      "epoch: 34 step: 316, loss is 0.0003877775452565402\n",
      "epoch: 34 step: 317, loss is 0.0007323917234316468\n",
      "epoch: 34 step: 318, loss is 0.0011932484339922667\n",
      "epoch: 34 step: 319, loss is 0.00038116986979730427\n",
      "epoch: 34 step: 320, loss is 0.0007479469641111791\n",
      "epoch: 34 step: 321, loss is 0.0016316736582666636\n",
      "epoch: 34 step: 322, loss is 0.0007337628630921245\n",
      "epoch: 34 step: 323, loss is 0.00048796465853229165\n",
      "epoch: 34 step: 324, loss is 0.000684205733705312\n",
      "epoch: 34 step: 325, loss is 0.0010138563811779022\n",
      "epoch: 34 step: 326, loss is 0.0004894424928352237\n",
      "epoch: 34 step: 327, loss is 0.00041128724114969373\n",
      "epoch: 34 step: 328, loss is 0.0009997982997447252\n",
      "epoch: 34 step: 329, loss is 0.00025432088295929134\n",
      "epoch: 34 step: 330, loss is 0.0006520739989355206\n",
      "epoch: 34 step: 331, loss is 0.00017523411952424794\n",
      "epoch: 34 step: 332, loss is 0.0006710376474075019\n",
      "epoch: 34 step: 333, loss is 0.0013521615182980895\n",
      "epoch: 34 step: 334, loss is 0.00026406990946270525\n",
      "epoch: 34 step: 335, loss is 0.0009297293145209551\n",
      "epoch: 34 step: 336, loss is 0.0005305677186697721\n",
      "epoch: 34 step: 337, loss is 0.000842371373437345\n",
      "epoch: 34 step: 338, loss is 0.0005830502486787736\n",
      "epoch: 34 step: 339, loss is 0.0005709973629564047\n",
      "epoch: 34 step: 340, loss is 0.0007853289716877043\n",
      "epoch: 34 step: 341, loss is 0.0009626343962736428\n",
      "epoch: 34 step: 342, loss is 0.00039890417247079313\n",
      "epoch: 34 step: 343, loss is 0.00024393810599576682\n",
      "epoch: 34 step: 344, loss is 0.0003655156178865582\n",
      "epoch: 34 step: 345, loss is 0.0006178136682137847\n",
      "epoch: 34 step: 346, loss is 0.000351839407812804\n",
      "epoch: 34 step: 347, loss is 0.0010244976729154587\n",
      "epoch: 34 step: 348, loss is 0.00045587829663418233\n",
      "epoch: 34 step: 349, loss is 0.0009296971838921309\n",
      "epoch: 34 step: 350, loss is 0.0011579071870073676\n",
      "epoch: 34 step: 351, loss is 0.0005936312372796237\n",
      "epoch: 34 step: 352, loss is 0.0010253024520352483\n",
      "epoch: 34 step: 353, loss is 0.0006885759648866951\n",
      "epoch: 34 step: 354, loss is 0.0005427013384178281\n",
      "epoch: 34 step: 355, loss is 0.0005425678682513535\n",
      "epoch: 34 step: 356, loss is 0.0006267864955589175\n",
      "epoch: 34 step: 357, loss is 0.0005151765653863549\n",
      "epoch: 34 step: 358, loss is 0.0005836739437654614\n",
      "epoch: 34 step: 359, loss is 0.00038114580092951655\n",
      "epoch: 34 step: 360, loss is 0.001741047133691609\n",
      "epoch: 34 step: 361, loss is 0.00040809018537402153\n",
      "epoch: 34 step: 362, loss is 0.00019944591622333974\n",
      "epoch: 34 step: 363, loss is 0.0009466492920182645\n",
      "epoch: 34 step: 364, loss is 0.0010276873363181949\n",
      "epoch: 34 step: 365, loss is 0.0005464568384923041\n",
      "epoch: 34 step: 366, loss is 0.0004834157298319042\n",
      "epoch: 34 step: 367, loss is 0.0009653107263147831\n",
      "epoch: 34 step: 368, loss is 0.0007486567483283579\n",
      "epoch: 34 step: 369, loss is 0.0004775557608809322\n",
      "epoch: 34 step: 370, loss is 0.0007138229557313025\n",
      "epoch: 34 step: 371, loss is 0.0008266521617770195\n",
      "epoch: 34 step: 372, loss is 0.0009314673370681703\n",
      "epoch: 34 step: 373, loss is 0.00013586791465058923\n",
      "epoch: 34 step: 374, loss is 0.0003969706885982305\n",
      "epoch: 34 step: 375, loss is 0.001040145754814148\n",
      "Train epoch time: 12026.139 ms, per step time: 32.070 ms\n",
      "epoch: 35 step: 1, loss is 0.000922386534512043\n",
      "epoch: 35 step: 2, loss is 0.0006616096361540258\n",
      "epoch: 35 step: 3, loss is 0.0006051287637092173\n",
      "epoch: 35 step: 4, loss is 0.0013857822632417083\n",
      "epoch: 35 step: 5, loss is 0.00028389584622345865\n",
      "epoch: 35 step: 6, loss is 0.0004660284030251205\n",
      "epoch: 35 step: 7, loss is 0.00040541976341046393\n",
      "epoch: 35 step: 8, loss is 0.00022355096007231623\n",
      "epoch: 35 step: 9, loss is 0.0007082588854245842\n",
      "epoch: 35 step: 10, loss is 0.0006032702513039112\n",
      "epoch: 35 step: 11, loss is 0.0005945762968622148\n",
      "epoch: 35 step: 12, loss is 0.0007458049803972244\n",
      "epoch: 35 step: 13, loss is 0.0005707854288630188\n",
      "epoch: 35 step: 14, loss is 0.00041718699503690004\n",
      "epoch: 35 step: 15, loss is 0.0008325413800776005\n",
      "epoch: 35 step: 16, loss is 0.0010496689938008785\n",
      "epoch: 35 step: 17, loss is 0.0006432856898754835\n",
      "epoch: 35 step: 18, loss is 0.00010284909512847662\n",
      "epoch: 35 step: 19, loss is 0.0023405207321047783\n",
      "epoch: 35 step: 20, loss is 0.0011524832807481289\n",
      "epoch: 35 step: 21, loss is 0.00030122394673526287\n",
      "epoch: 35 step: 22, loss is 0.0013318369165062904\n",
      "epoch: 35 step: 23, loss is 0.00038251542719081044\n",
      "epoch: 35 step: 24, loss is 0.00044605188304558396\n",
      "epoch: 35 step: 25, loss is 0.000627902161795646\n",
      "epoch: 35 step: 26, loss is 0.0008835975895635784\n",
      "epoch: 35 step: 27, loss is 0.00038530578603968024\n",
      "epoch: 35 step: 28, loss is 0.0006775037036277354\n",
      "epoch: 35 step: 29, loss is 0.0012692122254520655\n",
      "epoch: 35 step: 30, loss is 0.0005509128095582128\n",
      "epoch: 35 step: 31, loss is 0.001371975988149643\n",
      "epoch: 35 step: 32, loss is 0.0013513782760128379\n",
      "epoch: 35 step: 33, loss is 0.0003172325377818197\n",
      "epoch: 35 step: 34, loss is 0.00022769825591240078\n",
      "epoch: 35 step: 35, loss is 0.001959190471097827\n",
      "epoch: 35 step: 36, loss is 0.0005266608204692602\n",
      "epoch: 35 step: 37, loss is 0.00048396913916803896\n",
      "epoch: 35 step: 38, loss is 0.00042512977961450815\n",
      "epoch: 35 step: 39, loss is 0.0006529579404741526\n",
      "epoch: 35 step: 40, loss is 0.0008761556819081306\n",
      "epoch: 35 step: 41, loss is 0.0007216658559627831\n",
      "epoch: 35 step: 42, loss is 0.00046009913785383105\n",
      "epoch: 35 step: 43, loss is 0.001202470506541431\n",
      "epoch: 35 step: 44, loss is 0.0004364131891634315\n",
      "epoch: 35 step: 45, loss is 0.00031479093013331294\n",
      "epoch: 35 step: 46, loss is 0.00019241667177993804\n",
      "epoch: 35 step: 47, loss is 0.0006478779832832515\n",
      "epoch: 35 step: 48, loss is 0.000899616745300591\n",
      "epoch: 35 step: 49, loss is 0.00042446309817023575\n",
      "epoch: 35 step: 50, loss is 0.0012349184835329652\n",
      "epoch: 35 step: 51, loss is 0.0007667365716770291\n",
      "epoch: 35 step: 52, loss is 0.0003149101685266942\n",
      "epoch: 35 step: 53, loss is 0.00030698502087034285\n",
      "epoch: 35 step: 54, loss is 0.0007984497933648527\n",
      "epoch: 35 step: 55, loss is 0.0007450837874785066\n",
      "epoch: 35 step: 56, loss is 0.0010020035551860929\n",
      "epoch: 35 step: 57, loss is 0.0010593149345368147\n",
      "epoch: 35 step: 58, loss is 0.0012822994031012058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 step: 59, loss is 0.0013171788305044174\n",
      "epoch: 35 step: 60, loss is 0.0007218723185360432\n",
      "epoch: 35 step: 61, loss is 0.0005549014313146472\n",
      "epoch: 35 step: 62, loss is 0.001557856798171997\n",
      "epoch: 35 step: 63, loss is 0.0008641669410280883\n",
      "epoch: 35 step: 64, loss is 0.0005986375035718083\n",
      "epoch: 35 step: 65, loss is 0.0004955466138198972\n",
      "epoch: 35 step: 66, loss is 0.00039841909892857075\n",
      "epoch: 35 step: 67, loss is 0.0003507496148813516\n",
      "epoch: 35 step: 68, loss is 0.0005125160096213222\n",
      "epoch: 35 step: 69, loss is 0.0006520455935969949\n",
      "epoch: 35 step: 70, loss is 0.0010764204198494554\n",
      "epoch: 35 step: 71, loss is 0.0006406299653463066\n",
      "epoch: 35 step: 72, loss is 0.00028738423134200275\n",
      "epoch: 35 step: 73, loss is 0.00042213621782138944\n",
      "epoch: 35 step: 74, loss is 0.00031070600380189717\n",
      "epoch: 35 step: 75, loss is 0.0003354298823978752\n",
      "epoch: 35 step: 76, loss is 0.00047883749357424676\n",
      "epoch: 35 step: 77, loss is 0.0007269745110534132\n",
      "epoch: 35 step: 78, loss is 0.0003212936862837523\n",
      "epoch: 35 step: 79, loss is 0.0004550036392174661\n",
      "epoch: 35 step: 80, loss is 0.0012255782494321465\n",
      "epoch: 35 step: 81, loss is 0.0006012836238369346\n",
      "epoch: 35 step: 82, loss is 0.0011111253406852484\n",
      "epoch: 35 step: 83, loss is 0.0006459428113885224\n",
      "epoch: 35 step: 84, loss is 0.0007421977934427559\n",
      "epoch: 35 step: 85, loss is 0.00044623628491535783\n",
      "epoch: 35 step: 86, loss is 0.0003523138875607401\n",
      "epoch: 35 step: 87, loss is 0.000354298681486398\n",
      "epoch: 35 step: 88, loss is 0.0005088333855383098\n",
      "epoch: 35 step: 89, loss is 0.0006348071619868279\n",
      "epoch: 35 step: 90, loss is 0.0005764040979556739\n",
      "epoch: 35 step: 91, loss is 0.0004279321292415261\n",
      "epoch: 35 step: 92, loss is 0.0008068965398706496\n",
      "epoch: 35 step: 93, loss is 0.000740446790587157\n",
      "epoch: 35 step: 94, loss is 0.00048409804003313184\n",
      "epoch: 35 step: 95, loss is 0.0006973292329348624\n",
      "epoch: 35 step: 96, loss is 0.0006272533792071044\n",
      "epoch: 35 step: 97, loss is 0.0013088715495541692\n",
      "epoch: 35 step: 98, loss is 0.00034668526495806873\n",
      "epoch: 35 step: 99, loss is 0.000391047855373472\n",
      "epoch: 35 step: 100, loss is 0.0015680420910939574\n",
      "epoch: 35 step: 101, loss is 0.00039954535895958543\n",
      "epoch: 35 step: 102, loss is 0.001183881307952106\n",
      "epoch: 35 step: 103, loss is 0.0006669606664218009\n",
      "epoch: 35 step: 104, loss is 0.0006610563141293824\n",
      "epoch: 35 step: 105, loss is 0.0005685274372808635\n",
      "epoch: 35 step: 106, loss is 0.00032579191611148417\n",
      "epoch: 35 step: 107, loss is 0.0006055909325368702\n",
      "epoch: 35 step: 108, loss is 0.00044768635416403413\n",
      "epoch: 35 step: 109, loss is 0.000634730386082083\n",
      "epoch: 35 step: 110, loss is 0.0002542842412367463\n",
      "epoch: 35 step: 111, loss is 0.0002979845448862761\n",
      "epoch: 35 step: 112, loss is 0.0006414102972485125\n",
      "epoch: 35 step: 113, loss is 0.0004061578365508467\n",
      "epoch: 35 step: 114, loss is 0.0008396924240514636\n",
      "epoch: 35 step: 115, loss is 0.0005260603502392769\n",
      "epoch: 35 step: 116, loss is 0.000775161839555949\n",
      "epoch: 35 step: 117, loss is 0.0006954059936106205\n",
      "epoch: 35 step: 118, loss is 0.0003118432068731636\n",
      "epoch: 35 step: 119, loss is 0.000661179656162858\n",
      "epoch: 35 step: 120, loss is 0.0011720363982021809\n",
      "epoch: 35 step: 121, loss is 0.0011813524179160595\n",
      "epoch: 35 step: 122, loss is 0.0007612128974869847\n",
      "epoch: 35 step: 123, loss is 0.0005866563296876848\n",
      "epoch: 35 step: 124, loss is 0.0004975359188392758\n",
      "epoch: 35 step: 125, loss is 0.0006837105029262602\n",
      "epoch: 35 step: 126, loss is 0.00025505555095151067\n",
      "epoch: 35 step: 127, loss is 0.0002973855007439852\n",
      "epoch: 35 step: 128, loss is 0.00018696323968470097\n",
      "epoch: 35 step: 129, loss is 0.0008854484767653048\n",
      "epoch: 35 step: 130, loss is 0.001490494585596025\n",
      "epoch: 35 step: 131, loss is 0.000777740147896111\n",
      "epoch: 35 step: 132, loss is 0.00016917695757001638\n",
      "epoch: 35 step: 133, loss is 0.0006881392910145223\n",
      "epoch: 35 step: 134, loss is 0.0005912011838518083\n",
      "epoch: 35 step: 135, loss is 0.0003940860042348504\n",
      "epoch: 35 step: 136, loss is 0.00023766382946632802\n",
      "epoch: 35 step: 137, loss is 0.0013377961004152894\n",
      "epoch: 35 step: 138, loss is 0.0001552382600493729\n",
      "epoch: 35 step: 139, loss is 0.0012790613109245896\n",
      "epoch: 35 step: 140, loss is 0.00040598196210339665\n",
      "epoch: 35 step: 141, loss is 0.0006905734189786017\n",
      "epoch: 35 step: 142, loss is 0.0002535445964895189\n",
      "epoch: 35 step: 143, loss is 0.00026745194918476045\n",
      "epoch: 35 step: 144, loss is 0.0008168030763044953\n",
      "epoch: 35 step: 145, loss is 0.0015849523479118943\n",
      "epoch: 35 step: 146, loss is 0.00034547795075923204\n",
      "epoch: 35 step: 147, loss is 0.0004244270676281303\n",
      "epoch: 35 step: 148, loss is 0.0006652825395576656\n",
      "epoch: 35 step: 149, loss is 0.0006489244988188148\n",
      "epoch: 35 step: 150, loss is 0.0007653914508409798\n",
      "epoch: 35 step: 151, loss is 0.0006833545048721135\n",
      "epoch: 35 step: 152, loss is 0.0006257502245716751\n",
      "epoch: 35 step: 153, loss is 0.0006788176251575351\n",
      "epoch: 35 step: 154, loss is 0.0011408563004806638\n",
      "epoch: 35 step: 155, loss is 0.00015227892436087132\n",
      "epoch: 35 step: 156, loss is 0.0004267972253728658\n",
      "epoch: 35 step: 157, loss is 0.00010165577259613201\n",
      "epoch: 35 step: 158, loss is 0.0003410685167182237\n",
      "epoch: 35 step: 159, loss is 0.0008126202737912536\n",
      "epoch: 35 step: 160, loss is 0.0006644061068072915\n",
      "epoch: 35 step: 161, loss is 0.0006523077609017491\n",
      "epoch: 35 step: 162, loss is 0.0005960356793366373\n",
      "epoch: 35 step: 163, loss is 0.0006269512814469635\n",
      "epoch: 35 step: 164, loss is 0.0005464109126478434\n",
      "epoch: 35 step: 165, loss is 0.0015740173403173685\n",
      "epoch: 35 step: 166, loss is 0.00044087349670007825\n",
      "epoch: 35 step: 167, loss is 0.0007664382574148476\n",
      "epoch: 35 step: 168, loss is 0.000839811924379319\n",
      "epoch: 35 step: 169, loss is 0.00039427028968930244\n",
      "epoch: 35 step: 170, loss is 0.0006289825541898608\n",
      "epoch: 35 step: 171, loss is 0.0005774836172349751\n",
      "epoch: 35 step: 172, loss is 0.00019280760898254812\n",
      "epoch: 35 step: 173, loss is 0.000319532846333459\n",
      "epoch: 35 step: 174, loss is 0.0008929787436500192\n",
      "epoch: 35 step: 175, loss is 0.0006082049803808331\n",
      "epoch: 35 step: 176, loss is 0.0008960792911238968\n",
      "epoch: 35 step: 177, loss is 0.0004287955816835165\n",
      "epoch: 35 step: 178, loss is 0.0007281287107616663\n",
      "epoch: 35 step: 179, loss is 0.0005264123319648206\n",
      "epoch: 35 step: 180, loss is 0.0008648840594105422\n",
      "epoch: 35 step: 181, loss is 0.000587455986533314\n",
      "epoch: 35 step: 182, loss is 0.0004983254475519061\n",
      "epoch: 35 step: 183, loss is 0.001305148471146822\n",
      "epoch: 35 step: 184, loss is 0.0011858891230076551\n",
      "epoch: 35 step: 185, loss is 0.0004046624235343188\n",
      "epoch: 35 step: 186, loss is 0.0009783596033230424\n",
      "epoch: 35 step: 187, loss is 0.0007630435284227133\n",
      "epoch: 35 step: 188, loss is 0.000527873111423105\n",
      "epoch: 35 step: 189, loss is 0.0006699025398120284\n",
      "epoch: 35 step: 190, loss is 0.0009651858126744628\n",
      "epoch: 35 step: 191, loss is 0.0008630746160633862\n",
      "epoch: 35 step: 192, loss is 0.00033186786458827555\n",
      "epoch: 35 step: 193, loss is 0.0011525904992595315\n",
      "epoch: 35 step: 194, loss is 0.0005831180606037378\n",
      "epoch: 35 step: 195, loss is 0.0012160895857959986\n",
      "epoch: 35 step: 196, loss is 0.0005076965899206698\n",
      "epoch: 35 step: 197, loss is 0.0006251538870856166\n",
      "epoch: 35 step: 198, loss is 0.0004172115004621446\n",
      "epoch: 35 step: 199, loss is 0.000411411834647879\n",
      "epoch: 35 step: 200, loss is 0.0008019691449590027\n",
      "epoch: 35 step: 201, loss is 0.00018410176562611014\n",
      "epoch: 35 step: 202, loss is 0.0012931983219459653\n",
      "epoch: 35 step: 203, loss is 0.0004741860902868211\n",
      "epoch: 35 step: 204, loss is 0.0004634434008039534\n",
      "epoch: 35 step: 205, loss is 0.0006355042569339275\n",
      "epoch: 35 step: 206, loss is 0.000890316441655159\n",
      "epoch: 35 step: 207, loss is 0.0006566587835550308\n",
      "epoch: 35 step: 208, loss is 0.00030310856527648866\n",
      "epoch: 35 step: 209, loss is 0.0002567603369243443\n",
      "epoch: 35 step: 210, loss is 0.0005966240423731506\n",
      "epoch: 35 step: 211, loss is 0.0006806367891840637\n",
      "epoch: 35 step: 212, loss is 0.0007489400450140238\n",
      "epoch: 35 step: 213, loss is 0.0017122426070272923\n",
      "epoch: 35 step: 214, loss is 0.0016713174991309643\n",
      "epoch: 35 step: 215, loss is 0.0009643291705287993\n",
      "epoch: 35 step: 216, loss is 0.0009381245472468436\n",
      "epoch: 35 step: 217, loss is 0.0010182561818510294\n",
      "epoch: 35 step: 218, loss is 0.00044770518434233963\n",
      "epoch: 35 step: 219, loss is 0.0009703090763650835\n",
      "epoch: 35 step: 220, loss is 0.0008685810025781393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 step: 221, loss is 0.0005451154429465532\n",
      "epoch: 35 step: 222, loss is 0.0008960698032751679\n",
      "epoch: 35 step: 223, loss is 0.0010197242954745889\n",
      "epoch: 35 step: 224, loss is 0.00035673147067427635\n",
      "epoch: 35 step: 225, loss is 0.0004001358465757221\n",
      "epoch: 35 step: 226, loss is 0.0005899263196624815\n",
      "epoch: 35 step: 227, loss is 0.0010533093009144068\n",
      "epoch: 35 step: 228, loss is 0.0008203604957088828\n",
      "epoch: 35 step: 229, loss is 0.0010527415433898568\n",
      "epoch: 35 step: 230, loss is 0.0006395276286639273\n",
      "epoch: 35 step: 231, loss is 0.0008929269388318062\n",
      "epoch: 35 step: 232, loss is 0.0006478903815150261\n",
      "epoch: 35 step: 233, loss is 0.0009936998831108212\n",
      "epoch: 35 step: 234, loss is 0.00026717083528637886\n",
      "epoch: 35 step: 235, loss is 0.0002150646469090134\n",
      "epoch: 35 step: 236, loss is 0.000326008623233065\n",
      "epoch: 35 step: 237, loss is 0.00038292756653390825\n",
      "epoch: 35 step: 238, loss is 0.0007485034293495119\n",
      "epoch: 35 step: 239, loss is 0.0006991666741669178\n",
      "epoch: 35 step: 240, loss is 0.000427425344241783\n",
      "epoch: 35 step: 241, loss is 0.0010897389147430658\n",
      "epoch: 35 step: 242, loss is 0.0007222455460578203\n",
      "epoch: 35 step: 243, loss is 0.00028315841336734593\n",
      "epoch: 35 step: 244, loss is 0.0009326125727966428\n",
      "epoch: 35 step: 245, loss is 0.0010658615501597524\n",
      "epoch: 35 step: 246, loss is 0.00040401334990747273\n",
      "epoch: 35 step: 247, loss is 0.0003591104468796402\n",
      "epoch: 35 step: 248, loss is 0.0007355251000262797\n",
      "epoch: 35 step: 249, loss is 0.0010522675001993775\n",
      "epoch: 35 step: 250, loss is 0.00022317362891044468\n",
      "epoch: 35 step: 251, loss is 0.000710638880264014\n",
      "epoch: 35 step: 252, loss is 0.00047460681525990367\n",
      "epoch: 35 step: 253, loss is 0.0001747862552292645\n",
      "epoch: 35 step: 254, loss is 0.0005798964411951602\n",
      "epoch: 35 step: 255, loss is 0.00042942544678226113\n",
      "epoch: 35 step: 256, loss is 0.0007729939534328878\n",
      "epoch: 35 step: 257, loss is 0.0002774318854790181\n",
      "epoch: 35 step: 258, loss is 0.0006351218326017261\n",
      "epoch: 35 step: 259, loss is 0.00024476239923387766\n",
      "epoch: 35 step: 260, loss is 0.00027619267348200083\n",
      "epoch: 35 step: 261, loss is 0.0012413980439305305\n",
      "epoch: 35 step: 262, loss is 0.0007449981058016419\n",
      "epoch: 35 step: 263, loss is 0.00045817470527254045\n",
      "epoch: 35 step: 264, loss is 0.0004031339194625616\n",
      "epoch: 35 step: 265, loss is 0.000636776618193835\n",
      "epoch: 35 step: 266, loss is 0.00047801886103115976\n",
      "epoch: 35 step: 267, loss is 0.0016421327600255609\n",
      "epoch: 35 step: 268, loss is 0.0005372007144615054\n",
      "epoch: 35 step: 269, loss is 0.0005494612269103527\n",
      "epoch: 35 step: 270, loss is 0.0003329955507069826\n",
      "epoch: 35 step: 271, loss is 0.0004531606682576239\n",
      "epoch: 35 step: 272, loss is 0.0006047498318366706\n",
      "epoch: 35 step: 273, loss is 0.0007033179281279445\n",
      "epoch: 35 step: 274, loss is 0.0004156107606831938\n",
      "epoch: 35 step: 275, loss is 0.00030307640554383397\n",
      "epoch: 35 step: 276, loss is 0.00025107699912041426\n",
      "epoch: 35 step: 277, loss is 0.00024880014825612307\n",
      "epoch: 35 step: 278, loss is 0.0005804283428005874\n",
      "epoch: 35 step: 279, loss is 0.0010054274462163448\n",
      "epoch: 35 step: 280, loss is 0.0003821631835307926\n",
      "epoch: 35 step: 281, loss is 0.0006244035321287811\n",
      "epoch: 35 step: 282, loss is 0.0008566145552322268\n",
      "epoch: 35 step: 283, loss is 0.0009161559864878654\n",
      "epoch: 35 step: 284, loss is 0.0005992540973238647\n",
      "epoch: 35 step: 285, loss is 0.001080344314686954\n",
      "epoch: 35 step: 286, loss is 0.0009248916758224368\n",
      "epoch: 35 step: 287, loss is 0.0008997935801744461\n",
      "epoch: 35 step: 288, loss is 0.0007828893722034991\n",
      "epoch: 35 step: 289, loss is 0.0004124818660784513\n",
      "epoch: 35 step: 290, loss is 0.0012225013924762607\n",
      "epoch: 35 step: 291, loss is 0.0005534302326850593\n",
      "epoch: 35 step: 292, loss is 0.001000049291178584\n",
      "epoch: 35 step: 293, loss is 0.0010267597390338778\n",
      "epoch: 35 step: 294, loss is 0.0012073098914697766\n",
      "epoch: 35 step: 295, loss is 0.001122153364121914\n",
      "epoch: 35 step: 296, loss is 0.0004897446488030255\n",
      "epoch: 35 step: 297, loss is 0.00025959886261262\n",
      "epoch: 35 step: 298, loss is 0.00037139406776987016\n",
      "epoch: 35 step: 299, loss is 0.0004492129373829812\n",
      "epoch: 35 step: 300, loss is 0.0009993016719818115\n",
      "epoch: 35 step: 301, loss is 0.0005711360718123615\n",
      "epoch: 35 step: 302, loss is 0.000582180276978761\n",
      "epoch: 35 step: 303, loss is 0.00045301791396923363\n",
      "epoch: 35 step: 304, loss is 0.0006731599569320679\n",
      "epoch: 35 step: 305, loss is 0.0015948307700455189\n",
      "epoch: 35 step: 306, loss is 0.0010373922996222973\n",
      "epoch: 35 step: 307, loss is 0.0003787606838159263\n",
      "epoch: 35 step: 308, loss is 0.0011722955387085676\n",
      "epoch: 35 step: 309, loss is 0.00021923540043644607\n",
      "epoch: 35 step: 310, loss is 0.0005350594292394817\n",
      "epoch: 35 step: 311, loss is 0.0010883149225264788\n",
      "epoch: 35 step: 312, loss is 0.0005376979243010283\n",
      "epoch: 35 step: 313, loss is 0.00035916754859499633\n",
      "epoch: 35 step: 314, loss is 0.0004776878922712058\n",
      "epoch: 35 step: 315, loss is 0.0009525442728772759\n",
      "epoch: 35 step: 316, loss is 0.0002737437607720494\n",
      "epoch: 35 step: 317, loss is 0.0009413384832441807\n",
      "epoch: 35 step: 318, loss is 0.0011881854152306914\n",
      "epoch: 35 step: 319, loss is 0.00023536052322015166\n",
      "epoch: 35 step: 320, loss is 0.0005625020712614059\n",
      "epoch: 35 step: 321, loss is 0.0012981948675587773\n",
      "epoch: 35 step: 322, loss is 0.0005880281678400934\n",
      "epoch: 35 step: 323, loss is 0.00028948919498361647\n",
      "epoch: 35 step: 324, loss is 0.00040608804556541145\n",
      "epoch: 35 step: 325, loss is 0.000569826050195843\n",
      "epoch: 35 step: 326, loss is 0.0002082922583213076\n",
      "epoch: 35 step: 327, loss is 0.00041519838850945234\n",
      "epoch: 35 step: 328, loss is 0.0010706810280680656\n",
      "epoch: 35 step: 329, loss is 0.0007667546160519123\n",
      "epoch: 35 step: 330, loss is 0.0012287942226976156\n",
      "epoch: 35 step: 331, loss is 0.0002208978112321347\n",
      "epoch: 35 step: 332, loss is 0.0010073918383568525\n",
      "epoch: 35 step: 333, loss is 0.00035523882252164185\n",
      "epoch: 35 step: 334, loss is 0.00036678597098216414\n",
      "epoch: 35 step: 335, loss is 0.0005776130128651857\n",
      "epoch: 35 step: 336, loss is 0.0005883385892957449\n",
      "epoch: 35 step: 337, loss is 0.0004947022534906864\n",
      "epoch: 35 step: 338, loss is 0.00039864963036961854\n",
      "epoch: 35 step: 339, loss is 0.0002603759930934757\n",
      "epoch: 35 step: 340, loss is 0.0004924503737129271\n",
      "epoch: 35 step: 341, loss is 0.0002743607619777322\n",
      "epoch: 35 step: 342, loss is 0.00033228902611881495\n",
      "epoch: 35 step: 343, loss is 0.001118642627261579\n",
      "epoch: 35 step: 344, loss is 0.0008768730913288891\n",
      "epoch: 35 step: 345, loss is 0.0007150610908865929\n",
      "epoch: 35 step: 346, loss is 0.00034497948945499957\n",
      "epoch: 35 step: 347, loss is 0.0009702763636596501\n",
      "epoch: 35 step: 348, loss is 0.0002292543649673462\n",
      "epoch: 35 step: 349, loss is 0.0003466880298219621\n",
      "epoch: 35 step: 350, loss is 0.00042149535147473216\n",
      "epoch: 35 step: 351, loss is 0.0007487068651244044\n",
      "epoch: 35 step: 352, loss is 0.0006752174813300371\n",
      "epoch: 35 step: 353, loss is 0.0002682662452571094\n",
      "epoch: 35 step: 354, loss is 0.0010351575911045074\n",
      "epoch: 35 step: 355, loss is 0.0011258668964728713\n",
      "epoch: 35 step: 356, loss is 0.0023042589891701937\n",
      "epoch: 35 step: 357, loss is 0.0005968498880974948\n",
      "epoch: 35 step: 358, loss is 0.0009693668107502162\n",
      "epoch: 35 step: 359, loss is 0.0007745824987068772\n",
      "epoch: 35 step: 360, loss is 0.0010448414832353592\n",
      "epoch: 35 step: 361, loss is 0.00033170232200063765\n",
      "epoch: 35 step: 362, loss is 0.00016554097237531096\n",
      "epoch: 35 step: 363, loss is 0.00040104196523316205\n",
      "epoch: 35 step: 364, loss is 0.00022523506777361035\n",
      "epoch: 35 step: 365, loss is 0.0010615591891109943\n",
      "epoch: 35 step: 366, loss is 0.00040484071359969676\n",
      "epoch: 35 step: 367, loss is 0.0004255668609403074\n",
      "epoch: 35 step: 368, loss is 0.0001170611722045578\n",
      "epoch: 35 step: 369, loss is 0.0011499233078211546\n",
      "epoch: 35 step: 370, loss is 0.0005012669716961682\n",
      "epoch: 35 step: 371, loss is 0.0005148474592715502\n",
      "epoch: 35 step: 372, loss is 0.00035855264286510646\n",
      "epoch: 35 step: 373, loss is 0.00139492261223495\n",
      "epoch: 35 step: 374, loss is 0.00030277023324742913\n",
      "epoch: 35 step: 375, loss is 0.0008378305356018245\n",
      "Train epoch time: 12447.581 ms, per step time: 33.194 ms\n",
      "epoch: 36 step: 1, loss is 0.0007535199983976781\n",
      "epoch: 36 step: 2, loss is 0.0006512971594929695\n",
      "epoch: 36 step: 3, loss is 0.0016445345245301723\n",
      "epoch: 36 step: 4, loss is 0.0006075042765587568\n",
      "epoch: 36 step: 5, loss is 0.0007939368952065706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 step: 6, loss is 0.0008207643986679614\n",
      "epoch: 36 step: 7, loss is 0.0005738039035350084\n",
      "epoch: 36 step: 8, loss is 0.0007886629900895059\n",
      "epoch: 36 step: 9, loss is 0.0005649213562719524\n",
      "epoch: 36 step: 10, loss is 0.0010256117675453424\n",
      "epoch: 36 step: 11, loss is 0.0009574211435392499\n",
      "epoch: 36 step: 12, loss is 0.00022812029055785388\n",
      "epoch: 36 step: 13, loss is 0.0007704436429776251\n",
      "epoch: 36 step: 14, loss is 0.000689063046593219\n",
      "epoch: 36 step: 15, loss is 0.0008292418788187206\n",
      "epoch: 36 step: 16, loss is 0.000348918663803488\n",
      "epoch: 36 step: 17, loss is 0.0006644783425144851\n",
      "epoch: 36 step: 18, loss is 0.0006287338910624385\n",
      "epoch: 36 step: 19, loss is 0.001274944981560111\n",
      "epoch: 36 step: 20, loss is 0.0001436681195627898\n",
      "epoch: 36 step: 21, loss is 0.0012573220301419497\n",
      "epoch: 36 step: 22, loss is 0.00044992935727350414\n",
      "epoch: 36 step: 23, loss is 0.0005672370316460729\n",
      "epoch: 36 step: 24, loss is 0.0004345320339780301\n",
      "epoch: 36 step: 25, loss is 0.0006749494932591915\n",
      "epoch: 36 step: 26, loss is 7.687633478781208e-05\n",
      "epoch: 36 step: 27, loss is 0.00033272188738919795\n",
      "epoch: 36 step: 28, loss is 0.0004773321561515331\n",
      "epoch: 36 step: 29, loss is 0.00026186765171587467\n",
      "epoch: 36 step: 30, loss is 0.0004855880397371948\n",
      "epoch: 36 step: 31, loss is 0.000995719339698553\n",
      "epoch: 36 step: 32, loss is 0.000804833194706589\n",
      "epoch: 36 step: 33, loss is 0.000565849244594574\n",
      "epoch: 36 step: 34, loss is 0.0005954415537416935\n",
      "epoch: 36 step: 35, loss is 0.0003536165750119835\n",
      "epoch: 36 step: 36, loss is 0.00044823691132478416\n",
      "epoch: 36 step: 37, loss is 0.0013112813467159867\n",
      "epoch: 36 step: 38, loss is 0.0004271685902494937\n",
      "epoch: 36 step: 39, loss is 0.0006292137550190091\n",
      "epoch: 36 step: 40, loss is 0.0006632213480770588\n",
      "epoch: 36 step: 41, loss is 0.0008345324895344675\n",
      "epoch: 36 step: 42, loss is 0.00031731053604744375\n",
      "epoch: 36 step: 43, loss is 0.00034245080314576626\n",
      "epoch: 36 step: 44, loss is 0.0008167809573933482\n",
      "epoch: 36 step: 45, loss is 0.0005785304820165038\n",
      "epoch: 36 step: 46, loss is 0.001276840572245419\n",
      "epoch: 36 step: 47, loss is 0.0009664921090006828\n",
      "epoch: 36 step: 48, loss is 0.002291209762915969\n",
      "epoch: 36 step: 49, loss is 0.0007669275510124862\n",
      "epoch: 36 step: 50, loss is 0.0011379689676687121\n",
      "epoch: 36 step: 51, loss is 0.0008905036957003176\n",
      "epoch: 36 step: 52, loss is 0.00030504565802402794\n",
      "epoch: 36 step: 53, loss is 0.0008842253009788692\n",
      "epoch: 36 step: 54, loss is 0.0004984033294022083\n",
      "epoch: 36 step: 55, loss is 0.0009249548311345279\n",
      "epoch: 36 step: 56, loss is 0.0015332077164202929\n",
      "epoch: 36 step: 57, loss is 0.0008722636266611516\n",
      "epoch: 36 step: 58, loss is 0.0005811989540234208\n",
      "epoch: 36 step: 59, loss is 0.0007768647046759725\n",
      "epoch: 36 step: 60, loss is 0.0010848287492990494\n",
      "epoch: 36 step: 61, loss is 0.0009159471374005079\n",
      "epoch: 36 step: 62, loss is 0.00016936965403147042\n",
      "epoch: 36 step: 63, loss is 0.0004875840968452394\n",
      "epoch: 36 step: 64, loss is 0.0007461120840162039\n",
      "epoch: 36 step: 65, loss is 0.0006365363951772451\n",
      "epoch: 36 step: 66, loss is 0.0003770537441596389\n",
      "epoch: 36 step: 67, loss is 0.0005604376783594489\n",
      "epoch: 36 step: 68, loss is 0.0006359928520396352\n",
      "epoch: 36 step: 69, loss is 8.120357961161062e-05\n",
      "epoch: 36 step: 70, loss is 0.0003337759990245104\n",
      "epoch: 36 step: 71, loss is 0.0008687084191478789\n",
      "epoch: 36 step: 72, loss is 0.001214521937072277\n",
      "epoch: 36 step: 73, loss is 0.0007600922253914177\n",
      "epoch: 36 step: 74, loss is 0.00048014760250225663\n",
      "epoch: 36 step: 75, loss is 0.00021110338275320828\n",
      "epoch: 36 step: 76, loss is 0.00033588570659048855\n",
      "epoch: 36 step: 77, loss is 0.0003356076776981354\n",
      "epoch: 36 step: 78, loss is 0.00013076644972898066\n",
      "epoch: 36 step: 79, loss is 0.00019811860693152994\n",
      "epoch: 36 step: 80, loss is 0.0007384049822576344\n",
      "epoch: 36 step: 81, loss is 0.000527850934304297\n",
      "epoch: 36 step: 82, loss is 0.0005981387221254408\n",
      "epoch: 36 step: 83, loss is 0.0010293448576703668\n",
      "epoch: 36 step: 84, loss is 0.0006242258823476732\n",
      "epoch: 36 step: 85, loss is 0.000606232846621424\n",
      "epoch: 36 step: 86, loss is 0.0009950652020052075\n",
      "epoch: 36 step: 87, loss is 0.0013684829464182258\n",
      "epoch: 36 step: 88, loss is 0.00040878658182919025\n",
      "epoch: 36 step: 89, loss is 0.000982228317297995\n",
      "epoch: 36 step: 90, loss is 0.0006068243528716266\n",
      "epoch: 36 step: 91, loss is 0.0006913996185176075\n",
      "epoch: 36 step: 92, loss is 0.0004153534828219563\n",
      "epoch: 36 step: 93, loss is 0.0006837403052486479\n",
      "epoch: 36 step: 94, loss is 0.0002634490083437413\n",
      "epoch: 36 step: 95, loss is 0.0005918199894949794\n",
      "epoch: 36 step: 96, loss is 0.0010253933724015951\n",
      "epoch: 36 step: 97, loss is 0.0001761154708219692\n",
      "epoch: 36 step: 98, loss is 0.0005144295282661915\n",
      "epoch: 36 step: 99, loss is 0.0016347308410331607\n",
      "epoch: 36 step: 100, loss is 0.00048710781265981495\n",
      "epoch: 36 step: 101, loss is 0.00014162342995405197\n",
      "epoch: 36 step: 102, loss is 0.0004300038854125887\n",
      "epoch: 36 step: 103, loss is 0.0008369333227165043\n",
      "epoch: 36 step: 104, loss is 0.00020420299551915377\n",
      "epoch: 36 step: 105, loss is 0.00015415834786836058\n",
      "epoch: 36 step: 106, loss is 0.0002603824541438371\n",
      "epoch: 36 step: 107, loss is 0.000903456995729357\n",
      "epoch: 36 step: 108, loss is 0.00011977092071902007\n",
      "epoch: 36 step: 109, loss is 0.00047391728730872273\n",
      "epoch: 36 step: 110, loss is 0.0011075669899582863\n",
      "epoch: 36 step: 111, loss is 0.0004560645029414445\n",
      "epoch: 36 step: 112, loss is 0.0004554070474114269\n",
      "epoch: 36 step: 113, loss is 0.0003934691776521504\n",
      "epoch: 36 step: 114, loss is 0.0004691983631346375\n",
      "epoch: 36 step: 115, loss is 0.0010136454366147518\n",
      "epoch: 36 step: 116, loss is 0.0005038641975261271\n",
      "epoch: 36 step: 117, loss is 0.0005602278397418559\n",
      "epoch: 36 step: 118, loss is 0.0006251996383070946\n",
      "epoch: 36 step: 119, loss is 0.0008818560163490474\n",
      "epoch: 36 step: 120, loss is 0.0005341332289390266\n",
      "epoch: 36 step: 121, loss is 0.0012839031405746937\n",
      "epoch: 36 step: 122, loss is 0.0005015761125832796\n",
      "epoch: 36 step: 123, loss is 0.0006355035002343357\n",
      "epoch: 36 step: 124, loss is 0.000978172873146832\n",
      "epoch: 36 step: 125, loss is 0.00020031740132253617\n",
      "epoch: 36 step: 126, loss is 0.0008684351341798902\n",
      "epoch: 36 step: 127, loss is 0.0007003252394497395\n",
      "epoch: 36 step: 128, loss is 0.001155035919509828\n",
      "epoch: 36 step: 129, loss is 0.0003081288596149534\n",
      "epoch: 36 step: 130, loss is 0.0004208047466818243\n",
      "epoch: 36 step: 131, loss is 0.000956083124037832\n",
      "epoch: 36 step: 132, loss is 0.0009244969114661217\n",
      "epoch: 36 step: 133, loss is 0.0008244063355959952\n",
      "epoch: 36 step: 134, loss is 0.000351808441337198\n",
      "epoch: 36 step: 135, loss is 0.0008730473346076906\n",
      "epoch: 36 step: 136, loss is 0.0007581075769849122\n",
      "epoch: 36 step: 137, loss is 0.0006000536377541721\n",
      "epoch: 36 step: 138, loss is 0.00028168142307549715\n",
      "epoch: 36 step: 139, loss is 0.0005324840894900262\n",
      "epoch: 36 step: 140, loss is 0.00040507043013349175\n",
      "epoch: 36 step: 141, loss is 0.0003820581769105047\n",
      "epoch: 36 step: 142, loss is 0.0012440010905265808\n",
      "epoch: 36 step: 143, loss is 0.0008548616315238178\n",
      "epoch: 36 step: 144, loss is 0.0010983874090015888\n",
      "epoch: 36 step: 145, loss is 0.0006800530245527625\n",
      "epoch: 36 step: 146, loss is 0.0008287517121061683\n",
      "epoch: 36 step: 147, loss is 0.0005885931896045804\n",
      "epoch: 36 step: 148, loss is 0.0007515514153055847\n",
      "epoch: 36 step: 149, loss is 0.0003347343299537897\n",
      "epoch: 36 step: 150, loss is 0.0008277641027234495\n",
      "epoch: 36 step: 151, loss is 0.0014732099371030927\n",
      "epoch: 36 step: 152, loss is 0.0003925701603293419\n",
      "epoch: 36 step: 153, loss is 0.00014827576524112374\n",
      "epoch: 36 step: 154, loss is 0.0014494721544906497\n",
      "epoch: 36 step: 155, loss is 0.0011660805903375149\n",
      "epoch: 36 step: 156, loss is 0.000468068610643968\n",
      "epoch: 36 step: 157, loss is 0.0004928127746097744\n",
      "epoch: 36 step: 158, loss is 0.0004986124113202095\n",
      "epoch: 36 step: 159, loss is 0.0013328315690159798\n",
      "epoch: 36 step: 160, loss is 0.000985386548563838\n",
      "epoch: 36 step: 161, loss is 0.0006629683775827289\n",
      "epoch: 36 step: 162, loss is 0.000343598541803658\n",
      "epoch: 36 step: 163, loss is 0.001699171494692564\n",
      "epoch: 36 step: 164, loss is 0.00043428654316812754\n",
      "epoch: 36 step: 165, loss is 0.0005362554220482707\n",
      "epoch: 36 step: 166, loss is 0.00039058353286236525\n",
      "epoch: 36 step: 167, loss is 0.0003522248298395425\n",
      "epoch: 36 step: 168, loss is 0.00048258661990985274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 step: 169, loss is 0.000514024228323251\n",
      "epoch: 36 step: 170, loss is 0.000545741873793304\n",
      "epoch: 36 step: 171, loss is 0.00029130943585187197\n",
      "epoch: 36 step: 172, loss is 0.0002818575012497604\n",
      "epoch: 36 step: 173, loss is 0.0009007594780996442\n",
      "epoch: 36 step: 174, loss is 0.001496756449341774\n",
      "epoch: 36 step: 175, loss is 0.0018198052421212196\n",
      "epoch: 36 step: 176, loss is 0.0009476396371610463\n",
      "epoch: 36 step: 177, loss is 0.00025212205946445465\n",
      "epoch: 36 step: 178, loss is 0.0012710265582427382\n",
      "epoch: 36 step: 179, loss is 0.0006769566680304706\n",
      "epoch: 36 step: 180, loss is 0.0007989351870492101\n",
      "epoch: 36 step: 181, loss is 0.0009230184950865805\n",
      "epoch: 36 step: 182, loss is 0.0010329043725505471\n",
      "epoch: 36 step: 183, loss is 0.0013022116618230939\n",
      "epoch: 36 step: 184, loss is 0.000604374217800796\n",
      "epoch: 36 step: 185, loss is 0.0005283535574562848\n",
      "epoch: 36 step: 186, loss is 0.0005007237778045237\n",
      "epoch: 36 step: 187, loss is 0.00027728587156161666\n",
      "epoch: 36 step: 188, loss is 0.0003013536334037781\n",
      "epoch: 36 step: 189, loss is 0.0007217996171675622\n",
      "epoch: 36 step: 190, loss is 0.0012408284237608314\n",
      "epoch: 36 step: 191, loss is 0.0006023606983944774\n",
      "epoch: 36 step: 192, loss is 0.0004661910352297127\n",
      "epoch: 36 step: 193, loss is 6.439700518967584e-05\n",
      "epoch: 36 step: 194, loss is 0.00025300486595369875\n",
      "epoch: 36 step: 195, loss is 0.00045636878348886967\n",
      "epoch: 36 step: 196, loss is 0.00047555487253703177\n",
      "epoch: 36 step: 197, loss is 0.0017136993119493127\n",
      "epoch: 36 step: 198, loss is 0.0007046724203974009\n",
      "epoch: 36 step: 199, loss is 0.00042681273771449924\n",
      "epoch: 36 step: 200, loss is 0.0006187554099597037\n",
      "epoch: 36 step: 201, loss is 0.0008509820327162743\n",
      "epoch: 36 step: 202, loss is 0.0003459662839304656\n",
      "epoch: 36 step: 203, loss is 0.00027976807905361056\n",
      "epoch: 36 step: 204, loss is 0.0011262320913374424\n",
      "epoch: 36 step: 205, loss is 0.00036863627610728145\n",
      "epoch: 36 step: 206, loss is 0.0012204037047922611\n",
      "epoch: 36 step: 207, loss is 0.0006975411088205874\n",
      "epoch: 36 step: 208, loss is 0.00031504849903285503\n",
      "epoch: 36 step: 209, loss is 0.001731749391183257\n",
      "epoch: 36 step: 210, loss is 0.0005494134966284037\n",
      "epoch: 36 step: 211, loss is 0.000596927828155458\n",
      "epoch: 36 step: 212, loss is 0.0003136417653877288\n",
      "epoch: 36 step: 213, loss is 0.00011353639274602756\n",
      "epoch: 36 step: 214, loss is 0.0003337886882945895\n",
      "epoch: 36 step: 215, loss is 0.0006884516915306449\n",
      "epoch: 36 step: 216, loss is 0.00025612994795665145\n",
      "epoch: 36 step: 217, loss is 0.0006559376488439739\n",
      "epoch: 36 step: 218, loss is 0.0017861069645732641\n",
      "epoch: 36 step: 219, loss is 0.0011900942772626877\n",
      "epoch: 36 step: 220, loss is 0.0005616960697807372\n",
      "epoch: 36 step: 221, loss is 0.0007024342776276171\n",
      "epoch: 36 step: 222, loss is 0.0007644426659680903\n",
      "epoch: 36 step: 223, loss is 0.0004814111744053662\n",
      "epoch: 36 step: 224, loss is 0.0006133508286438882\n",
      "epoch: 36 step: 225, loss is 0.0008193943067453802\n",
      "epoch: 36 step: 226, loss is 0.0006535303546115756\n",
      "epoch: 36 step: 227, loss is 0.0007429772522300482\n",
      "epoch: 36 step: 228, loss is 0.0004178267263341695\n",
      "epoch: 36 step: 229, loss is 0.0004872592107858509\n",
      "epoch: 36 step: 230, loss is 0.00116105773486197\n",
      "epoch: 36 step: 231, loss is 0.00044184524449519813\n",
      "epoch: 36 step: 232, loss is 0.000381143152480945\n",
      "epoch: 36 step: 233, loss is 0.0019045313820242882\n",
      "epoch: 36 step: 234, loss is 0.001256315503269434\n",
      "epoch: 36 step: 235, loss is 0.0005918938550166786\n",
      "epoch: 36 step: 236, loss is 0.00048252372653223574\n",
      "epoch: 36 step: 237, loss is 0.0011888020671904087\n",
      "epoch: 36 step: 238, loss is 0.000502888869959861\n",
      "epoch: 36 step: 239, loss is 0.0003574427973944694\n",
      "epoch: 36 step: 240, loss is 0.0006773335044272244\n",
      "epoch: 36 step: 241, loss is 0.0006575208390131593\n",
      "epoch: 36 step: 242, loss is 0.0006820442504249513\n",
      "epoch: 36 step: 243, loss is 0.00039637251757085323\n",
      "epoch: 36 step: 244, loss is 0.0005534946103580296\n",
      "epoch: 36 step: 245, loss is 0.0003923468175344169\n",
      "epoch: 36 step: 246, loss is 0.0008137926924973726\n",
      "epoch: 36 step: 247, loss is 0.00035491527523845434\n",
      "epoch: 36 step: 248, loss is 0.0009134870488196611\n",
      "epoch: 36 step: 249, loss is 0.0006254225736483932\n",
      "epoch: 36 step: 250, loss is 0.00046222060336731374\n",
      "epoch: 36 step: 251, loss is 0.0005674936692230403\n",
      "epoch: 36 step: 252, loss is 0.0005909741157665849\n",
      "epoch: 36 step: 253, loss is 0.0006652661832049489\n",
      "epoch: 36 step: 254, loss is 0.0008815781329758465\n",
      "epoch: 36 step: 255, loss is 0.0007759040454402566\n",
      "epoch: 36 step: 256, loss is 0.0010898609180003405\n",
      "epoch: 36 step: 257, loss is 0.0014239766169339418\n",
      "epoch: 36 step: 258, loss is 0.0005777708720415831\n",
      "epoch: 36 step: 259, loss is 0.00131421338301152\n",
      "epoch: 36 step: 260, loss is 0.001016408670693636\n",
      "epoch: 36 step: 261, loss is 0.000509846955537796\n",
      "epoch: 36 step: 262, loss is 0.0006011624354869127\n",
      "epoch: 36 step: 263, loss is 0.0009309441084042192\n",
      "epoch: 36 step: 264, loss is 0.0009052114910446107\n",
      "epoch: 36 step: 265, loss is 0.00038785807555541396\n",
      "epoch: 36 step: 266, loss is 0.0011212717508897185\n",
      "epoch: 36 step: 267, loss is 0.0005806419067084789\n",
      "epoch: 36 step: 268, loss is 0.00017421845404896885\n",
      "epoch: 36 step: 269, loss is 0.00037375936517491937\n",
      "epoch: 36 step: 270, loss is 0.0007650409825146198\n",
      "epoch: 36 step: 271, loss is 0.0005889781750738621\n",
      "epoch: 36 step: 272, loss is 0.0004739459836855531\n",
      "epoch: 36 step: 273, loss is 0.001630077138543129\n",
      "epoch: 36 step: 274, loss is 0.0006562856142409146\n",
      "epoch: 36 step: 275, loss is 0.0009088648948818445\n",
      "epoch: 36 step: 276, loss is 0.0004801252798642963\n",
      "epoch: 36 step: 277, loss is 0.0003637210465967655\n",
      "epoch: 36 step: 278, loss is 0.0010315857362002134\n",
      "epoch: 36 step: 279, loss is 0.0006727381842210889\n",
      "epoch: 36 step: 280, loss is 0.00016409381350968033\n",
      "epoch: 36 step: 281, loss is 0.0010812768014147878\n",
      "epoch: 36 step: 282, loss is 0.0007738432032056153\n",
      "epoch: 36 step: 283, loss is 0.00045763864181935787\n",
      "epoch: 36 step: 284, loss is 0.00029512326000258327\n",
      "epoch: 36 step: 285, loss is 0.00042338191997259855\n",
      "epoch: 36 step: 286, loss is 0.0007385349599644542\n",
      "epoch: 36 step: 287, loss is 0.00066229363437742\n",
      "epoch: 36 step: 288, loss is 0.0020232144743204117\n",
      "epoch: 36 step: 289, loss is 0.0006106417858973145\n",
      "epoch: 36 step: 290, loss is 0.00044154265196993947\n",
      "epoch: 36 step: 291, loss is 0.000771057850215584\n",
      "epoch: 36 step: 292, loss is 0.0011510498588904738\n",
      "epoch: 36 step: 293, loss is 0.000671688059810549\n",
      "epoch: 36 step: 294, loss is 0.001008792663924396\n",
      "epoch: 36 step: 295, loss is 0.0009057644638232887\n",
      "epoch: 36 step: 296, loss is 0.00038633504300378263\n",
      "epoch: 36 step: 297, loss is 9.846581087913364e-05\n",
      "epoch: 36 step: 298, loss is 0.0005409805453382432\n",
      "epoch: 36 step: 299, loss is 0.0007151432801038027\n",
      "epoch: 36 step: 300, loss is 0.0006987018859945238\n",
      "epoch: 36 step: 301, loss is 0.0004229215264786035\n",
      "epoch: 36 step: 302, loss is 0.00029553426429629326\n",
      "epoch: 36 step: 303, loss is 0.0011723556090146303\n",
      "epoch: 36 step: 304, loss is 0.00021194780129007995\n",
      "epoch: 36 step: 305, loss is 0.0003773962671402842\n",
      "epoch: 36 step: 306, loss is 0.00045341707300394773\n",
      "epoch: 36 step: 307, loss is 0.0007687390316277742\n",
      "epoch: 36 step: 308, loss is 0.001198675949126482\n",
      "epoch: 36 step: 309, loss is 0.0006559324683621526\n",
      "epoch: 36 step: 310, loss is 0.0004512360319495201\n",
      "epoch: 36 step: 311, loss is 0.0003523235791362822\n",
      "epoch: 36 step: 312, loss is 0.00020867878629360348\n",
      "epoch: 36 step: 313, loss is 0.0002200027520302683\n",
      "epoch: 36 step: 314, loss is 0.0006530213286168873\n",
      "epoch: 36 step: 315, loss is 0.0004658066900447011\n",
      "epoch: 36 step: 316, loss is 0.0010116363409906626\n",
      "epoch: 36 step: 317, loss is 0.0005650506354868412\n",
      "epoch: 36 step: 318, loss is 0.000706768361851573\n",
      "epoch: 36 step: 319, loss is 0.0008228576043620706\n",
      "epoch: 36 step: 320, loss is 0.0005701801856048405\n",
      "epoch: 36 step: 321, loss is 0.0007102810777723789\n",
      "epoch: 36 step: 322, loss is 0.0006505635101348162\n",
      "epoch: 36 step: 323, loss is 0.0004328243085183203\n",
      "epoch: 36 step: 324, loss is 0.0007346460479311645\n",
      "epoch: 36 step: 325, loss is 0.0006723645492456853\n",
      "epoch: 36 step: 326, loss is 0.0002746385580394417\n",
      "epoch: 36 step: 327, loss is 0.0005944541189819574\n",
      "epoch: 36 step: 328, loss is 0.001192009774968028\n",
      "epoch: 36 step: 329, loss is 0.0004214232903905213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 step: 330, loss is 0.00034104171209037304\n",
      "epoch: 36 step: 331, loss is 0.0005420625675469637\n",
      "epoch: 36 step: 332, loss is 0.0008494708454236388\n",
      "epoch: 36 step: 333, loss is 0.0008405621629208326\n",
      "epoch: 36 step: 334, loss is 0.0005780577776022255\n",
      "epoch: 36 step: 335, loss is 0.0007841718615964055\n",
      "epoch: 36 step: 336, loss is 0.0006822398863732815\n",
      "epoch: 36 step: 337, loss is 0.0009610382257960737\n",
      "epoch: 36 step: 338, loss is 0.000857954437378794\n",
      "epoch: 36 step: 339, loss is 0.0006245119730010629\n",
      "epoch: 36 step: 340, loss is 0.0005271537229418755\n",
      "epoch: 36 step: 341, loss is 0.000401286844862625\n",
      "epoch: 36 step: 342, loss is 0.00020602677250280976\n",
      "epoch: 36 step: 343, loss is 0.0005968387704342604\n",
      "epoch: 36 step: 344, loss is 0.0005450528115034103\n",
      "epoch: 36 step: 345, loss is 0.0004622740380000323\n",
      "epoch: 36 step: 346, loss is 0.0007261961582116783\n",
      "epoch: 36 step: 347, loss is 0.0009005676256492734\n",
      "epoch: 36 step: 348, loss is 0.0008326779352501035\n",
      "epoch: 36 step: 349, loss is 0.00047883097431622446\n",
      "epoch: 36 step: 350, loss is 0.0007736887782812119\n",
      "epoch: 36 step: 351, loss is 0.0005892007029615343\n",
      "epoch: 36 step: 352, loss is 0.0002736357564572245\n",
      "epoch: 36 step: 353, loss is 0.000451055821031332\n",
      "epoch: 36 step: 354, loss is 0.001371859572827816\n",
      "epoch: 36 step: 355, loss is 0.0003987364179920405\n",
      "epoch: 36 step: 356, loss is 0.0004961040685884655\n",
      "epoch: 36 step: 357, loss is 0.0007136455387808383\n",
      "epoch: 36 step: 358, loss is 0.0002539061533752829\n",
      "epoch: 36 step: 359, loss is 0.0009163302602246404\n",
      "epoch: 36 step: 360, loss is 0.00040996004827320576\n",
      "epoch: 36 step: 361, loss is 0.0007198425591923296\n",
      "epoch: 36 step: 362, loss is 0.00037358724512159824\n",
      "epoch: 36 step: 363, loss is 0.0010080402716994286\n",
      "epoch: 36 step: 364, loss is 0.0006549549289047718\n",
      "epoch: 36 step: 365, loss is 0.00042789752478711307\n",
      "epoch: 36 step: 366, loss is 0.0005816233460791409\n",
      "epoch: 36 step: 367, loss is 0.0005429328302852809\n",
      "epoch: 36 step: 368, loss is 0.0005227571236900985\n",
      "epoch: 36 step: 369, loss is 0.0010453404393047094\n",
      "epoch: 36 step: 370, loss is 0.000841451867017895\n",
      "epoch: 36 step: 371, loss is 0.0001290061481995508\n",
      "epoch: 36 step: 372, loss is 0.00017960673721972853\n",
      "epoch: 36 step: 373, loss is 0.0005005763377994299\n",
      "epoch: 36 step: 374, loss is 0.00040935177821666\n",
      "epoch: 36 step: 375, loss is 0.0004052152798976749\n",
      "Train epoch time: 11531.021 ms, per step time: 30.749 ms\n",
      "epoch: 37 step: 1, loss is 0.0005709448596462607\n",
      "epoch: 37 step: 2, loss is 0.0008462824043817818\n",
      "epoch: 37 step: 3, loss is 0.0004858785541728139\n",
      "epoch: 37 step: 4, loss is 0.0007977691711857915\n",
      "epoch: 37 step: 5, loss is 0.0008728056563995779\n",
      "epoch: 37 step: 6, loss is 0.0007471247226931155\n",
      "epoch: 37 step: 7, loss is 0.0005536243552342057\n",
      "epoch: 37 step: 8, loss is 0.0005095068481750786\n",
      "epoch: 37 step: 9, loss is 0.00035923614632338285\n",
      "epoch: 37 step: 10, loss is 9.928096551448107e-05\n",
      "epoch: 37 step: 11, loss is 0.0003743261331692338\n",
      "epoch: 37 step: 12, loss is 0.00015647169493604451\n",
      "epoch: 37 step: 13, loss is 0.000436897185863927\n",
      "epoch: 37 step: 14, loss is 0.0016335878754034638\n",
      "epoch: 37 step: 15, loss is 0.0005358728230930865\n",
      "epoch: 37 step: 16, loss is 0.00045280682388693094\n",
      "epoch: 37 step: 17, loss is 0.0005846880376338959\n",
      "epoch: 37 step: 18, loss is 0.00027458282420411706\n",
      "epoch: 37 step: 19, loss is 0.0002230875543318689\n",
      "epoch: 37 step: 20, loss is 0.0011238136794418097\n",
      "epoch: 37 step: 21, loss is 0.0006973646231926978\n",
      "epoch: 37 step: 22, loss is 0.0008002326940186322\n",
      "epoch: 37 step: 23, loss is 0.0020452088210731745\n",
      "epoch: 37 step: 24, loss is 0.0008804859244264662\n",
      "epoch: 37 step: 25, loss is 0.0005512515199370682\n",
      "epoch: 37 step: 26, loss is 0.00035836405004374683\n",
      "epoch: 37 step: 27, loss is 0.0006095903809182346\n",
      "epoch: 37 step: 28, loss is 0.0003311827022116631\n",
      "epoch: 37 step: 29, loss is 0.00024455730454064906\n",
      "epoch: 37 step: 30, loss is 0.0003924235061276704\n",
      "epoch: 37 step: 31, loss is 0.0004246049211360514\n",
      "epoch: 37 step: 32, loss is 0.00041136937215924263\n",
      "epoch: 37 step: 33, loss is 0.0010849249083548784\n",
      "epoch: 37 step: 34, loss is 0.0008682622574269772\n",
      "epoch: 37 step: 35, loss is 0.0005040713003836572\n",
      "epoch: 37 step: 36, loss is 0.00038574845530092716\n",
      "epoch: 37 step: 37, loss is 0.0008685753564350307\n",
      "epoch: 37 step: 38, loss is 0.0003495558921713382\n",
      "epoch: 37 step: 39, loss is 0.0007146515999920666\n",
      "epoch: 37 step: 40, loss is 0.0006950561073608696\n",
      "epoch: 37 step: 41, loss is 0.0002252365811727941\n",
      "epoch: 37 step: 42, loss is 0.00029243328026495874\n",
      "epoch: 37 step: 43, loss is 0.0004253911611158401\n",
      "epoch: 37 step: 44, loss is 0.0007079908973537385\n",
      "epoch: 37 step: 45, loss is 0.00031200432567857206\n",
      "epoch: 37 step: 46, loss is 0.0004428754618857056\n",
      "epoch: 37 step: 47, loss is 0.000582519918680191\n",
      "epoch: 37 step: 48, loss is 0.00031464017229154706\n",
      "epoch: 37 step: 49, loss is 0.00107350863981992\n",
      "epoch: 37 step: 50, loss is 0.0007154707564041018\n",
      "epoch: 37 step: 51, loss is 0.0004464272642508149\n",
      "epoch: 37 step: 52, loss is 0.00038059550570324063\n",
      "epoch: 37 step: 53, loss is 0.0007797793950885534\n",
      "epoch: 37 step: 54, loss is 0.0003125322691630572\n",
      "epoch: 37 step: 55, loss is 0.0012472437229007483\n",
      "epoch: 37 step: 56, loss is 0.0010817046277225018\n",
      "epoch: 37 step: 57, loss is 0.0004090739239472896\n",
      "epoch: 37 step: 58, loss is 0.00030497449915856123\n",
      "epoch: 37 step: 59, loss is 0.0008852269384078681\n",
      "epoch: 37 step: 60, loss is 0.0003948141820728779\n",
      "epoch: 37 step: 61, loss is 0.000813072023447603\n",
      "epoch: 37 step: 62, loss is 0.0006227374542504549\n",
      "epoch: 37 step: 63, loss is 0.00037188103306107223\n",
      "epoch: 37 step: 64, loss is 0.0003311559557914734\n",
      "epoch: 37 step: 65, loss is 0.0008399063954129815\n",
      "epoch: 37 step: 66, loss is 0.0005888044834136963\n",
      "epoch: 37 step: 67, loss is 0.0007851580739952624\n",
      "epoch: 37 step: 68, loss is 0.0005361876683309674\n",
      "epoch: 37 step: 69, loss is 0.00045885203871876\n",
      "epoch: 37 step: 70, loss is 0.00045777345076203346\n",
      "epoch: 37 step: 71, loss is 0.0010563584510236979\n",
      "epoch: 37 step: 72, loss is 0.000539077038411051\n",
      "epoch: 37 step: 73, loss is 0.0005267159431241453\n",
      "epoch: 37 step: 74, loss is 0.000457477115560323\n",
      "epoch: 37 step: 75, loss is 0.0008726419764570892\n",
      "epoch: 37 step: 76, loss is 0.00016543517995160073\n",
      "epoch: 37 step: 77, loss is 0.00013456950546242297\n",
      "epoch: 37 step: 78, loss is 0.0011203170288354158\n",
      "epoch: 37 step: 79, loss is 0.00028712686616927385\n",
      "epoch: 37 step: 80, loss is 0.00025672497577033937\n",
      "epoch: 37 step: 81, loss is 0.0008325010421685874\n",
      "epoch: 37 step: 82, loss is 0.0003766943409573287\n",
      "epoch: 37 step: 83, loss is 0.0009673233726061881\n",
      "epoch: 37 step: 84, loss is 0.0004619940009433776\n",
      "epoch: 37 step: 85, loss is 0.0005010647582821548\n",
      "epoch: 37 step: 86, loss is 0.00046615759492851794\n",
      "epoch: 37 step: 87, loss is 0.0006927879876457155\n",
      "epoch: 37 step: 88, loss is 0.0006764972931705415\n",
      "epoch: 37 step: 89, loss is 0.0011747777462005615\n",
      "epoch: 37 step: 90, loss is 0.0006766843725927174\n",
      "epoch: 37 step: 91, loss is 0.0009167648968286812\n",
      "epoch: 37 step: 92, loss is 0.00015423723380081356\n",
      "epoch: 37 step: 93, loss is 0.0010499961208552122\n",
      "epoch: 37 step: 94, loss is 0.00042184305493719876\n",
      "epoch: 37 step: 95, loss is 0.0004986579879187047\n",
      "epoch: 37 step: 96, loss is 0.0009274653275497258\n",
      "epoch: 37 step: 97, loss is 0.00033125304616987705\n",
      "epoch: 37 step: 98, loss is 0.0020441801752895117\n",
      "epoch: 37 step: 99, loss is 0.0006173377623781562\n",
      "epoch: 37 step: 100, loss is 0.0003262127283960581\n",
      "epoch: 37 step: 101, loss is 0.0012788093881681561\n",
      "epoch: 37 step: 102, loss is 0.0005538454279303551\n",
      "epoch: 37 step: 103, loss is 0.0005422761896625161\n",
      "epoch: 37 step: 104, loss is 0.0011536009842529893\n",
      "epoch: 37 step: 105, loss is 0.0004538322682492435\n",
      "epoch: 37 step: 106, loss is 0.0011140587739646435\n",
      "epoch: 37 step: 107, loss is 0.0006276467465795577\n",
      "epoch: 37 step: 108, loss is 0.00029520728276111186\n",
      "epoch: 37 step: 109, loss is 0.0007643584976904094\n",
      "epoch: 37 step: 110, loss is 0.0009145531803369522\n",
      "epoch: 37 step: 111, loss is 0.00035972020123153925\n",
      "epoch: 37 step: 112, loss is 0.0007509913993999362\n",
      "epoch: 37 step: 113, loss is 0.00037344658630900085\n",
      "epoch: 37 step: 114, loss is 0.0003584650985430926\n",
      "epoch: 37 step: 115, loss is 0.0006151280249468982\n",
      "epoch: 37 step: 116, loss is 0.001464340602979064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 step: 117, loss is 0.0012827642494812608\n",
      "epoch: 37 step: 118, loss is 0.0005576418479904532\n",
      "epoch: 37 step: 119, loss is 0.0006914215628057718\n",
      "epoch: 37 step: 120, loss is 0.0007002372294664383\n",
      "epoch: 37 step: 121, loss is 0.0014034878695383668\n",
      "epoch: 37 step: 122, loss is 0.0005684506031684577\n",
      "epoch: 37 step: 123, loss is 0.00047714984975755215\n",
      "epoch: 37 step: 124, loss is 0.000443201104644686\n",
      "epoch: 37 step: 125, loss is 0.00023716466967016459\n",
      "epoch: 37 step: 126, loss is 0.0011144978925585747\n",
      "epoch: 37 step: 127, loss is 0.0006339994724839926\n",
      "epoch: 37 step: 128, loss is 0.0004492184962145984\n",
      "epoch: 37 step: 129, loss is 0.0010451574344187975\n",
      "epoch: 37 step: 130, loss is 0.0003985654329881072\n",
      "epoch: 37 step: 131, loss is 0.00047818906023167074\n",
      "epoch: 37 step: 132, loss is 0.0014129499904811382\n",
      "epoch: 37 step: 133, loss is 0.0009233099990524352\n",
      "epoch: 37 step: 134, loss is 0.0008341638022102416\n",
      "epoch: 37 step: 135, loss is 0.000685333157889545\n",
      "epoch: 37 step: 136, loss is 0.0006598436739295721\n",
      "epoch: 37 step: 137, loss is 0.0003929346858058125\n",
      "epoch: 37 step: 138, loss is 0.0005395811167545617\n",
      "epoch: 37 step: 139, loss is 0.00048592707025818527\n",
      "epoch: 37 step: 140, loss is 0.00027544275508262217\n",
      "epoch: 37 step: 141, loss is 0.0007779983570799232\n",
      "epoch: 37 step: 142, loss is 0.0010118805803358555\n",
      "epoch: 37 step: 143, loss is 0.0005830849404446781\n",
      "epoch: 37 step: 144, loss is 0.0006281813839450479\n",
      "epoch: 37 step: 145, loss is 0.001458216574974358\n",
      "epoch: 37 step: 146, loss is 0.0004476206377148628\n",
      "epoch: 37 step: 147, loss is 0.0011294204741716385\n",
      "epoch: 37 step: 148, loss is 0.0003054542758036405\n",
      "epoch: 37 step: 149, loss is 0.0004638594400603324\n",
      "epoch: 37 step: 150, loss is 0.001073041814379394\n",
      "epoch: 37 step: 151, loss is 0.0011945931473746896\n",
      "epoch: 37 step: 152, loss is 0.00032773855491541326\n",
      "epoch: 37 step: 153, loss is 0.0005887874867767096\n",
      "epoch: 37 step: 154, loss is 0.0016826415667310357\n",
      "epoch: 37 step: 155, loss is 0.0004996564821340144\n",
      "epoch: 37 step: 156, loss is 0.0003547688538674265\n",
      "epoch: 37 step: 157, loss is 0.0013788947835564613\n",
      "epoch: 37 step: 158, loss is 0.0008777455659583211\n",
      "epoch: 37 step: 159, loss is 0.0005326459067873657\n",
      "epoch: 37 step: 160, loss is 0.00035786008811555803\n",
      "epoch: 37 step: 161, loss is 0.0007787779322825372\n",
      "epoch: 37 step: 162, loss is 0.00043214389006607234\n",
      "epoch: 37 step: 163, loss is 0.0002198334113927558\n",
      "epoch: 37 step: 164, loss is 0.00027363590197637677\n",
      "epoch: 37 step: 165, loss is 0.0008051030454225838\n",
      "epoch: 37 step: 166, loss is 0.0007381500327028334\n",
      "epoch: 37 step: 167, loss is 0.0004611638141795993\n",
      "epoch: 37 step: 168, loss is 0.0006517325527966022\n",
      "epoch: 37 step: 169, loss is 0.0007812004187144339\n",
      "epoch: 37 step: 170, loss is 0.0016935524763539433\n",
      "epoch: 37 step: 171, loss is 0.0010203117271885276\n",
      "epoch: 37 step: 172, loss is 0.00038820935878902674\n",
      "epoch: 37 step: 173, loss is 0.00048825645353645086\n",
      "epoch: 37 step: 174, loss is 0.0005037484806962311\n",
      "epoch: 37 step: 175, loss is 0.0003276570059824735\n",
      "epoch: 37 step: 176, loss is 0.0007616806542500854\n",
      "epoch: 37 step: 177, loss is 0.0012049498036503792\n",
      "epoch: 37 step: 178, loss is 0.00042311951983720064\n",
      "epoch: 37 step: 179, loss is 0.000539239845238626\n",
      "epoch: 37 step: 180, loss is 0.0005435903440229595\n",
      "epoch: 37 step: 181, loss is 0.0006312112673185766\n",
      "epoch: 37 step: 182, loss is 0.0004915025783702731\n",
      "epoch: 37 step: 183, loss is 0.00047455247840844095\n",
      "epoch: 37 step: 184, loss is 0.000701620418112725\n",
      "epoch: 37 step: 185, loss is 0.0005728087271563709\n",
      "epoch: 37 step: 186, loss is 8.882161637302488e-05\n",
      "epoch: 37 step: 187, loss is 0.0008547558099962771\n",
      "epoch: 37 step: 188, loss is 0.0005114974919706583\n",
      "epoch: 37 step: 189, loss is 0.0013697812100872397\n",
      "epoch: 37 step: 190, loss is 0.0005789399147033691\n",
      "epoch: 37 step: 191, loss is 0.0018494148971512914\n",
      "epoch: 37 step: 192, loss is 0.0004524675605352968\n",
      "epoch: 37 step: 193, loss is 0.0002564718306530267\n",
      "epoch: 37 step: 194, loss is 0.0006891096709296107\n",
      "epoch: 37 step: 195, loss is 0.000575876038055867\n",
      "epoch: 37 step: 196, loss is 0.0005769082345068455\n",
      "epoch: 37 step: 197, loss is 0.00046440123696811497\n",
      "epoch: 37 step: 198, loss is 0.0007492980221286416\n",
      "epoch: 37 step: 199, loss is 0.001123424619436264\n",
      "epoch: 37 step: 200, loss is 0.0005524360458366573\n",
      "epoch: 37 step: 201, loss is 0.00044169495231471956\n",
      "epoch: 37 step: 202, loss is 0.0009245815454050899\n",
      "epoch: 37 step: 203, loss is 0.000412243272876367\n",
      "epoch: 37 step: 204, loss is 0.0008602018351666629\n",
      "epoch: 37 step: 205, loss is 0.000261763168964535\n",
      "epoch: 37 step: 206, loss is 0.0011386638507246971\n",
      "epoch: 37 step: 207, loss is 0.0008628751384094357\n",
      "epoch: 37 step: 208, loss is 0.00045855712960474193\n",
      "epoch: 37 step: 209, loss is 0.00033313894527964294\n",
      "epoch: 37 step: 210, loss is 0.00024806876899674535\n",
      "epoch: 37 step: 211, loss is 0.0004943627282045782\n",
      "epoch: 37 step: 212, loss is 0.0007786115165799856\n",
      "epoch: 37 step: 213, loss is 0.0004113868053536862\n",
      "epoch: 37 step: 214, loss is 0.0012580640614032745\n",
      "epoch: 37 step: 215, loss is 0.0006202336517162621\n",
      "epoch: 37 step: 216, loss is 0.00183094572275877\n",
      "epoch: 37 step: 217, loss is 0.0002282457862747833\n",
      "epoch: 37 step: 218, loss is 0.0004297101986594498\n",
      "epoch: 37 step: 219, loss is 0.00045407042489387095\n",
      "epoch: 37 step: 220, loss is 0.0009607761749066412\n",
      "epoch: 37 step: 221, loss is 0.0002797989873215556\n",
      "epoch: 37 step: 222, loss is 0.0011279461905360222\n",
      "epoch: 37 step: 223, loss is 0.0006109635578468442\n",
      "epoch: 37 step: 224, loss is 0.0001986923161894083\n",
      "epoch: 37 step: 225, loss is 0.0007500359788537025\n",
      "epoch: 37 step: 226, loss is 0.0006087207002565265\n",
      "epoch: 37 step: 227, loss is 0.0002459821989759803\n",
      "epoch: 37 step: 228, loss is 0.0007555863121524453\n",
      "epoch: 37 step: 229, loss is 0.0008407781715504825\n",
      "epoch: 37 step: 230, loss is 0.0004752643289975822\n",
      "epoch: 37 step: 231, loss is 0.0011942340061068535\n",
      "epoch: 37 step: 232, loss is 0.0006576735177077353\n",
      "epoch: 37 step: 233, loss is 0.00020131305791437626\n",
      "epoch: 37 step: 234, loss is 0.0004169345193076879\n",
      "epoch: 37 step: 235, loss is 0.0004603378474712372\n",
      "epoch: 37 step: 236, loss is 0.0010329399956390262\n",
      "epoch: 37 step: 237, loss is 0.0005163254681974649\n",
      "epoch: 37 step: 238, loss is 0.0009906911291182041\n",
      "epoch: 37 step: 239, loss is 0.0001664532464928925\n",
      "epoch: 37 step: 240, loss is 0.0005003344267606735\n",
      "epoch: 37 step: 241, loss is 0.0012994644930586219\n",
      "epoch: 37 step: 242, loss is 0.0006485484191216528\n",
      "epoch: 37 step: 243, loss is 0.0007101842784322798\n",
      "epoch: 37 step: 244, loss is 0.0006295386119745672\n",
      "epoch: 37 step: 245, loss is 0.0007157704094424844\n",
      "epoch: 37 step: 246, loss is 0.0008123210864141583\n",
      "epoch: 37 step: 247, loss is 0.000660283665638417\n",
      "epoch: 37 step: 248, loss is 0.0012779614189639688\n",
      "epoch: 37 step: 249, loss is 0.0008430778398178518\n",
      "epoch: 37 step: 250, loss is 0.0006407277542166412\n",
      "epoch: 37 step: 251, loss is 0.0018255308968946338\n",
      "epoch: 37 step: 252, loss is 0.0008804577519185841\n",
      "epoch: 37 step: 253, loss is 0.00018876871035899967\n",
      "epoch: 37 step: 254, loss is 0.0007570436573587358\n",
      "epoch: 37 step: 255, loss is 0.00041917068301700056\n",
      "epoch: 37 step: 256, loss is 0.0007800303283147514\n",
      "epoch: 37 step: 257, loss is 0.0004327752976678312\n",
      "epoch: 37 step: 258, loss is 0.0013277526013553143\n",
      "epoch: 37 step: 259, loss is 0.0006665076361969113\n",
      "epoch: 37 step: 260, loss is 0.0006524408236145973\n",
      "epoch: 37 step: 261, loss is 0.0005776604521088302\n",
      "epoch: 37 step: 262, loss is 0.0010545975528657436\n",
      "epoch: 37 step: 263, loss is 0.00035735260462388396\n",
      "epoch: 37 step: 264, loss is 0.0011970638297498226\n",
      "epoch: 37 step: 265, loss is 0.0006616123719140887\n",
      "epoch: 37 step: 266, loss is 0.0005605568876489997\n",
      "epoch: 37 step: 267, loss is 0.0009216805920004845\n",
      "epoch: 37 step: 268, loss is 0.0005924238939769566\n",
      "epoch: 37 step: 269, loss is 0.0003313635243102908\n",
      "epoch: 37 step: 270, loss is 0.00125414808280766\n",
      "epoch: 37 step: 271, loss is 0.0006821333081461489\n",
      "epoch: 37 step: 272, loss is 0.0008877891232259572\n",
      "epoch: 37 step: 273, loss is 0.0003390892525203526\n",
      "epoch: 37 step: 274, loss is 0.00032633100636303425\n",
      "epoch: 37 step: 275, loss is 0.0007228779140859842\n",
      "epoch: 37 step: 276, loss is 6.475133704952896e-05\n",
      "epoch: 37 step: 277, loss is 0.0006052221287973225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 step: 278, loss is 0.0011867699213325977\n",
      "epoch: 37 step: 279, loss is 0.0010679474798962474\n",
      "epoch: 37 step: 280, loss is 0.000877615821082145\n",
      "epoch: 37 step: 281, loss is 0.0016326898476108909\n",
      "epoch: 37 step: 282, loss is 0.0005525433225557208\n",
      "epoch: 37 step: 283, loss is 0.0002291569544468075\n",
      "epoch: 37 step: 284, loss is 0.000757651636376977\n",
      "epoch: 37 step: 285, loss is 0.000479538575746119\n",
      "epoch: 37 step: 286, loss is 0.0005315836751833558\n",
      "epoch: 37 step: 287, loss is 0.0008358206250704825\n",
      "epoch: 37 step: 288, loss is 0.0004964348045177758\n",
      "epoch: 37 step: 289, loss is 0.0006616022437810898\n",
      "epoch: 37 step: 290, loss is 0.0006065792986191809\n",
      "epoch: 37 step: 291, loss is 0.0007259398116730154\n",
      "epoch: 37 step: 292, loss is 0.0007981132948771119\n",
      "epoch: 37 step: 293, loss is 0.0006466508493758738\n",
      "epoch: 37 step: 294, loss is 0.0006237042834982276\n",
      "epoch: 37 step: 295, loss is 0.0004664033476728946\n",
      "epoch: 37 step: 296, loss is 0.0007565229898318648\n",
      "epoch: 37 step: 297, loss is 0.0005139025743119419\n",
      "epoch: 37 step: 298, loss is 0.0016402985202148557\n",
      "epoch: 37 step: 299, loss is 0.0004984030965715647\n",
      "epoch: 37 step: 300, loss is 0.0001559524389449507\n",
      "epoch: 37 step: 301, loss is 0.0009650758001953363\n",
      "epoch: 37 step: 302, loss is 0.0018664132803678513\n",
      "epoch: 37 step: 303, loss is 0.0013880889164283872\n",
      "epoch: 37 step: 304, loss is 0.0004545395786408335\n",
      "epoch: 37 step: 305, loss is 0.0012615728192031384\n",
      "epoch: 37 step: 306, loss is 0.00011313991853967309\n",
      "epoch: 37 step: 307, loss is 0.0005317179020494223\n",
      "epoch: 37 step: 308, loss is 0.0012133062118664384\n",
      "epoch: 37 step: 309, loss is 0.0018506348133087158\n",
      "epoch: 37 step: 310, loss is 0.0008344080997630954\n",
      "epoch: 37 step: 311, loss is 0.00032374728471040726\n",
      "epoch: 37 step: 312, loss is 0.0006968419183976948\n",
      "epoch: 37 step: 313, loss is 0.0003283521218691021\n",
      "epoch: 37 step: 314, loss is 0.0005663812626153231\n",
      "epoch: 37 step: 315, loss is 0.0005520234699361026\n",
      "epoch: 37 step: 316, loss is 0.0007330531952902675\n",
      "epoch: 37 step: 317, loss is 0.0008484377176500857\n",
      "epoch: 37 step: 318, loss is 0.0005594160757027566\n",
      "epoch: 37 step: 319, loss is 0.0003949249512515962\n",
      "epoch: 37 step: 320, loss is 0.0006329836905933917\n",
      "epoch: 37 step: 321, loss is 0.0004718861309811473\n",
      "epoch: 37 step: 322, loss is 0.0005008758162148297\n",
      "epoch: 37 step: 323, loss is 0.0003996945742983371\n",
      "epoch: 37 step: 324, loss is 0.0014751206617802382\n",
      "epoch: 37 step: 325, loss is 0.000570945325307548\n",
      "epoch: 37 step: 326, loss is 0.0009237718186341226\n",
      "epoch: 37 step: 327, loss is 0.0003714374324772507\n",
      "epoch: 37 step: 328, loss is 0.00040864551556296647\n",
      "epoch: 37 step: 329, loss is 0.0004418838652782142\n",
      "epoch: 37 step: 330, loss is 0.0005312279681675136\n",
      "epoch: 37 step: 331, loss is 0.00034172923187725246\n",
      "epoch: 37 step: 332, loss is 0.0009196586324833333\n",
      "epoch: 37 step: 333, loss is 0.00025407076464034617\n",
      "epoch: 37 step: 334, loss is 0.002172885462641716\n",
      "epoch: 37 step: 335, loss is 0.0006538875750266016\n",
      "epoch: 37 step: 336, loss is 0.0013818248407915235\n",
      "epoch: 37 step: 337, loss is 0.0008121925638988614\n",
      "epoch: 37 step: 338, loss is 0.001077721593901515\n",
      "epoch: 37 step: 339, loss is 0.0007148120203055441\n",
      "epoch: 37 step: 340, loss is 0.0005756862228736281\n",
      "epoch: 37 step: 341, loss is 0.001228900975547731\n",
      "epoch: 37 step: 342, loss is 0.000462960044387728\n",
      "epoch: 37 step: 343, loss is 0.0006129542598500848\n",
      "epoch: 37 step: 344, loss is 0.001229745801538229\n",
      "epoch: 37 step: 345, loss is 0.0003125444636680186\n",
      "epoch: 37 step: 346, loss is 0.0002970770001411438\n",
      "epoch: 37 step: 347, loss is 0.0005869803135283291\n",
      "epoch: 37 step: 348, loss is 0.00018126869690604508\n",
      "epoch: 37 step: 349, loss is 0.00047697234549559653\n",
      "epoch: 37 step: 350, loss is 0.0009027797495946288\n",
      "epoch: 37 step: 351, loss is 0.0014366974355652928\n",
      "epoch: 37 step: 352, loss is 0.0005422048852778971\n",
      "epoch: 37 step: 353, loss is 0.0006475343834608793\n",
      "epoch: 37 step: 354, loss is 0.00115651311352849\n",
      "epoch: 37 step: 355, loss is 0.0013839089078828692\n",
      "epoch: 37 step: 356, loss is 0.0004915880272164941\n",
      "epoch: 37 step: 357, loss is 0.0009818042162805796\n",
      "epoch: 37 step: 358, loss is 0.00018835128867067397\n",
      "epoch: 37 step: 359, loss is 0.0015646613901481032\n",
      "epoch: 37 step: 360, loss is 0.0003507751098368317\n",
      "epoch: 37 step: 361, loss is 0.0011957378592342138\n",
      "epoch: 37 step: 362, loss is 0.0003735899517778307\n",
      "epoch: 37 step: 363, loss is 0.0005323129589669406\n",
      "epoch: 37 step: 364, loss is 0.00047928988351486623\n",
      "epoch: 37 step: 365, loss is 0.0004740231088362634\n",
      "epoch: 37 step: 366, loss is 0.0005668969824910164\n",
      "epoch: 37 step: 367, loss is 0.0006698990473523736\n",
      "epoch: 37 step: 368, loss is 0.0005611471133306623\n",
      "epoch: 37 step: 369, loss is 0.0006999463075771928\n",
      "epoch: 37 step: 370, loss is 0.0002477574162185192\n",
      "epoch: 37 step: 371, loss is 0.0003060439194086939\n",
      "epoch: 37 step: 372, loss is 0.00015018839621916413\n",
      "epoch: 37 step: 373, loss is 0.0006657513440586627\n",
      "epoch: 37 step: 374, loss is 0.0010680899722501636\n",
      "epoch: 37 step: 375, loss is 0.000627770321443677\n",
      "Train epoch time: 11581.807 ms, per step time: 30.885 ms\n",
      "epoch: 38 step: 1, loss is 0.0002858458610717207\n",
      "epoch: 38 step: 2, loss is 0.0011072310153394938\n",
      "epoch: 38 step: 3, loss is 0.00038017757469788194\n",
      "epoch: 38 step: 4, loss is 0.0015747810248285532\n",
      "epoch: 38 step: 5, loss is 0.0007008176762610674\n",
      "epoch: 38 step: 6, loss is 0.0015497362473979592\n",
      "epoch: 38 step: 7, loss is 0.0005290108383633196\n",
      "epoch: 38 step: 8, loss is 0.0010301966685801744\n",
      "epoch: 38 step: 9, loss is 0.001433469820767641\n",
      "epoch: 38 step: 10, loss is 0.0010954405879601836\n",
      "epoch: 38 step: 11, loss is 0.0003388608747627586\n",
      "epoch: 38 step: 12, loss is 0.0004739909782074392\n",
      "epoch: 38 step: 13, loss is 0.0008718832395970821\n",
      "epoch: 38 step: 14, loss is 0.0003365086449775845\n",
      "epoch: 38 step: 15, loss is 0.0002902537817135453\n",
      "epoch: 38 step: 16, loss is 0.00020700467575807124\n",
      "epoch: 38 step: 17, loss is 0.00017190609651152045\n",
      "epoch: 38 step: 18, loss is 0.0014218256110325456\n",
      "epoch: 38 step: 19, loss is 0.0005112202488817275\n",
      "epoch: 38 step: 20, loss is 0.00032953458139672875\n",
      "epoch: 38 step: 21, loss is 0.00033061642898246646\n",
      "epoch: 38 step: 22, loss is 0.0004397151351440698\n",
      "epoch: 38 step: 23, loss is 0.00038357125595211983\n",
      "epoch: 38 step: 24, loss is 0.00018607899255584925\n",
      "epoch: 38 step: 25, loss is 0.0005985845346003771\n",
      "epoch: 38 step: 26, loss is 0.0005977722466923296\n",
      "epoch: 38 step: 27, loss is 0.0007149184821173549\n",
      "epoch: 38 step: 28, loss is 0.0006609753472730517\n",
      "epoch: 38 step: 29, loss is 0.0007311422377824783\n",
      "epoch: 38 step: 30, loss is 0.0008067053859122097\n",
      "epoch: 38 step: 31, loss is 0.0005527650355361402\n",
      "epoch: 38 step: 32, loss is 0.0006737976218573749\n",
      "epoch: 38 step: 33, loss is 0.0004431392590049654\n",
      "epoch: 38 step: 34, loss is 0.000369443092495203\n",
      "epoch: 38 step: 35, loss is 0.00047335834824480116\n",
      "epoch: 38 step: 36, loss is 0.0005699097528122365\n",
      "epoch: 38 step: 37, loss is 0.0004809664096683264\n",
      "epoch: 38 step: 38, loss is 0.0008706051739864051\n",
      "epoch: 38 step: 39, loss is 0.0002485528530087322\n",
      "epoch: 38 step: 40, loss is 0.0005583103629760444\n",
      "epoch: 38 step: 41, loss is 0.0004374393029138446\n",
      "epoch: 38 step: 42, loss is 0.0006226074765436351\n",
      "epoch: 38 step: 43, loss is 0.0007243335130624473\n",
      "epoch: 38 step: 44, loss is 0.00031403417233377695\n",
      "epoch: 38 step: 45, loss is 0.0006659970968030393\n",
      "epoch: 38 step: 46, loss is 0.0011498278472572565\n",
      "epoch: 38 step: 47, loss is 0.00083546043606475\n",
      "epoch: 38 step: 48, loss is 0.0004452329594641924\n",
      "epoch: 38 step: 49, loss is 0.0004065633984282613\n",
      "epoch: 38 step: 50, loss is 0.0006104927742853761\n",
      "epoch: 38 step: 51, loss is 0.000984201324172318\n",
      "epoch: 38 step: 52, loss is 0.00048307146062143147\n",
      "epoch: 38 step: 53, loss is 0.0006449056090787053\n",
      "epoch: 38 step: 54, loss is 0.0006700116209685802\n",
      "epoch: 38 step: 55, loss is 0.001092017744667828\n",
      "epoch: 38 step: 56, loss is 0.0009097171132452786\n",
      "epoch: 38 step: 57, loss is 0.0003439171996433288\n",
      "epoch: 38 step: 58, loss is 0.0015329127199947834\n",
      "epoch: 38 step: 59, loss is 0.00012062174209859222\n",
      "epoch: 38 step: 60, loss is 0.0006124963401816785\n",
      "epoch: 38 step: 61, loss is 0.00036623311461880803\n",
      "epoch: 38 step: 62, loss is 0.0009788612369447947\n",
      "epoch: 38 step: 63, loss is 0.0006472872337326407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 step: 64, loss is 0.000783993280492723\n",
      "epoch: 38 step: 65, loss is 0.0006224652752280235\n",
      "epoch: 38 step: 66, loss is 0.0004967347485944629\n",
      "epoch: 38 step: 67, loss is 0.0008107122266665101\n",
      "epoch: 38 step: 68, loss is 0.0003914255939889699\n",
      "epoch: 38 step: 69, loss is 0.0005425139679573476\n",
      "epoch: 38 step: 70, loss is 0.000957452692091465\n",
      "epoch: 38 step: 71, loss is 0.0004777504364028573\n",
      "epoch: 38 step: 72, loss is 0.0007176782237365842\n",
      "epoch: 38 step: 73, loss is 0.0004366139182820916\n",
      "epoch: 38 step: 74, loss is 0.0009819791885092854\n",
      "epoch: 38 step: 75, loss is 0.0003700560482684523\n",
      "epoch: 38 step: 76, loss is 0.0010359452571719885\n",
      "epoch: 38 step: 77, loss is 0.0004957758355885744\n",
      "epoch: 38 step: 78, loss is 0.0017047727014869452\n",
      "epoch: 38 step: 79, loss is 0.0007977298810146749\n",
      "epoch: 38 step: 80, loss is 0.0005128817865625024\n",
      "epoch: 38 step: 81, loss is 0.0011094975052401423\n",
      "epoch: 38 step: 82, loss is 0.0002458662202116102\n",
      "epoch: 38 step: 83, loss is 0.0008930767071433365\n",
      "epoch: 38 step: 84, loss is 0.001181495375931263\n",
      "epoch: 38 step: 85, loss is 0.0017108834581449628\n",
      "epoch: 38 step: 86, loss is 0.0008148711640387774\n",
      "epoch: 38 step: 87, loss is 0.0003938378649763763\n",
      "epoch: 38 step: 88, loss is 0.00042078850674442947\n",
      "epoch: 38 step: 89, loss is 0.00043387574260123074\n",
      "epoch: 38 step: 90, loss is 0.0008382581290788949\n",
      "epoch: 38 step: 91, loss is 0.0005085999146103859\n",
      "epoch: 38 step: 92, loss is 0.0001596345828147605\n",
      "epoch: 38 step: 93, loss is 0.001037847949191928\n",
      "epoch: 38 step: 94, loss is 0.0005346756661310792\n",
      "epoch: 38 step: 95, loss is 0.0015051052905619144\n",
      "epoch: 38 step: 96, loss is 0.0007081191288307309\n",
      "epoch: 38 step: 97, loss is 0.0005895915674045682\n",
      "epoch: 38 step: 98, loss is 0.0005037093069404364\n",
      "epoch: 38 step: 99, loss is 0.0009071634849533439\n",
      "epoch: 38 step: 100, loss is 0.00020840606885030866\n",
      "epoch: 38 step: 101, loss is 0.0003479070437606424\n",
      "epoch: 38 step: 102, loss is 0.0002374480536673218\n",
      "epoch: 38 step: 103, loss is 0.0004562855465337634\n",
      "epoch: 38 step: 104, loss is 0.0004405684885568917\n",
      "epoch: 38 step: 105, loss is 0.0005896845832467079\n",
      "epoch: 38 step: 106, loss is 0.0010494355810806155\n",
      "epoch: 38 step: 107, loss is 0.0009195296443067491\n",
      "epoch: 38 step: 108, loss is 0.0008564232266508043\n",
      "epoch: 38 step: 109, loss is 0.0008693404379300773\n",
      "epoch: 38 step: 110, loss is 0.00039106447366066277\n",
      "epoch: 38 step: 111, loss is 0.00030208862153813243\n",
      "epoch: 38 step: 112, loss is 0.0003538695746101439\n",
      "epoch: 38 step: 113, loss is 0.0006120716570876539\n",
      "epoch: 38 step: 114, loss is 0.0009670075960457325\n",
      "epoch: 38 step: 115, loss is 0.0011876783100888133\n",
      "epoch: 38 step: 116, loss is 0.0006916268612258136\n",
      "epoch: 38 step: 117, loss is 8.615273691248149e-05\n",
      "epoch: 38 step: 118, loss is 0.0011561791179701686\n",
      "epoch: 38 step: 119, loss is 0.0008843644172884524\n",
      "epoch: 38 step: 120, loss is 0.00031932993442751467\n",
      "epoch: 38 step: 121, loss is 0.0005031770560890436\n",
      "epoch: 38 step: 122, loss is 0.0006132210837677121\n",
      "epoch: 38 step: 123, loss is 0.001146251568570733\n",
      "epoch: 38 step: 124, loss is 0.0010938856285065413\n",
      "epoch: 38 step: 125, loss is 0.0006063022883608937\n",
      "epoch: 38 step: 126, loss is 0.0003437947598285973\n",
      "epoch: 38 step: 127, loss is 0.0008026225259527564\n",
      "epoch: 38 step: 128, loss is 0.0008272111299447715\n",
      "epoch: 38 step: 129, loss is 0.0007612326880916953\n",
      "epoch: 38 step: 130, loss is 0.0011430054437369108\n",
      "epoch: 38 step: 131, loss is 0.0011307295644655824\n",
      "epoch: 38 step: 132, loss is 0.0004957341006956995\n",
      "epoch: 38 step: 133, loss is 0.000201729271793738\n",
      "epoch: 38 step: 134, loss is 0.0007048232364468277\n",
      "epoch: 38 step: 135, loss is 0.0005766301765106618\n",
      "epoch: 38 step: 136, loss is 0.0003721822868101299\n",
      "epoch: 38 step: 137, loss is 0.0004778355942107737\n",
      "epoch: 38 step: 138, loss is 0.0008446837309747934\n",
      "epoch: 38 step: 139, loss is 0.0005233468837104738\n",
      "epoch: 38 step: 140, loss is 0.0008220341405831277\n",
      "epoch: 38 step: 141, loss is 0.00047352290130220354\n",
      "epoch: 38 step: 142, loss is 0.0002564852184150368\n",
      "epoch: 38 step: 143, loss is 0.00011710439139278606\n",
      "epoch: 38 step: 144, loss is 0.0006127499509602785\n",
      "epoch: 38 step: 145, loss is 0.0007627902086824179\n",
      "epoch: 38 step: 146, loss is 0.0009827843168750405\n",
      "epoch: 38 step: 147, loss is 0.0006285991403274238\n",
      "epoch: 38 step: 148, loss is 0.0003033063549082726\n",
      "epoch: 38 step: 149, loss is 0.000540267035830766\n",
      "epoch: 38 step: 150, loss is 0.0013300502905622125\n",
      "epoch: 38 step: 151, loss is 0.0006883429014123976\n",
      "epoch: 38 step: 152, loss is 0.00083421595627442\n",
      "epoch: 38 step: 153, loss is 0.000598092854488641\n",
      "epoch: 38 step: 154, loss is 0.0005467425798997283\n",
      "epoch: 38 step: 155, loss is 0.00032261214801110327\n",
      "epoch: 38 step: 156, loss is 0.00010068926349049434\n",
      "epoch: 38 step: 157, loss is 0.00102434610016644\n",
      "epoch: 38 step: 158, loss is 0.0006284514674916863\n",
      "epoch: 38 step: 159, loss is 0.0007900751661509275\n",
      "epoch: 38 step: 160, loss is 0.00028626833227463067\n",
      "epoch: 38 step: 161, loss is 0.0018049956997856498\n",
      "epoch: 38 step: 162, loss is 0.00048870436148718\n",
      "epoch: 38 step: 163, loss is 0.0007426476222462952\n",
      "epoch: 38 step: 164, loss is 0.0005511411582119763\n",
      "epoch: 38 step: 165, loss is 0.0003074304840993136\n",
      "epoch: 38 step: 166, loss is 0.00020068555022589862\n",
      "epoch: 38 step: 167, loss is 0.0005331551074050367\n",
      "epoch: 38 step: 168, loss is 0.0007214776123873889\n",
      "epoch: 38 step: 169, loss is 0.0002394090552115813\n",
      "epoch: 38 step: 170, loss is 0.00012702321691904217\n",
      "epoch: 38 step: 171, loss is 0.00036490740603767335\n",
      "epoch: 38 step: 172, loss is 0.000712063629180193\n",
      "epoch: 38 step: 173, loss is 0.000415372516727075\n",
      "epoch: 38 step: 174, loss is 0.0004614887584466487\n",
      "epoch: 38 step: 175, loss is 0.0003161816275678575\n",
      "epoch: 38 step: 176, loss is 0.0006942842737771571\n",
      "epoch: 38 step: 177, loss is 0.001374419778585434\n",
      "epoch: 38 step: 178, loss is 0.0007551283924840391\n",
      "epoch: 38 step: 179, loss is 0.0017423795070499182\n",
      "epoch: 38 step: 180, loss is 0.0006022184970788658\n",
      "epoch: 38 step: 181, loss is 0.0007820543251000345\n",
      "epoch: 38 step: 182, loss is 0.0007042170036584139\n",
      "epoch: 38 step: 183, loss is 0.00044244391028769314\n",
      "epoch: 38 step: 184, loss is 0.0013846495421603322\n",
      "epoch: 38 step: 185, loss is 0.0004674311785493046\n",
      "epoch: 38 step: 186, loss is 0.0004937317571602762\n",
      "epoch: 38 step: 187, loss is 0.000548577809240669\n",
      "epoch: 38 step: 188, loss is 0.0013363452162593603\n",
      "epoch: 38 step: 189, loss is 0.0008816566551104188\n",
      "epoch: 38 step: 190, loss is 0.000413285568356514\n",
      "epoch: 38 step: 191, loss is 0.0013820941094309092\n",
      "epoch: 38 step: 192, loss is 0.0003630427527241409\n",
      "epoch: 38 step: 193, loss is 0.0005185817135497928\n",
      "epoch: 38 step: 194, loss is 0.000218909204704687\n",
      "epoch: 38 step: 195, loss is 0.00042479552212171257\n",
      "epoch: 38 step: 196, loss is 0.00017586632748134434\n",
      "epoch: 38 step: 197, loss is 0.00025798226124607027\n",
      "epoch: 38 step: 198, loss is 0.00043400379945524037\n",
      "epoch: 38 step: 199, loss is 0.0006929461378604174\n",
      "epoch: 38 step: 200, loss is 0.0005343952216207981\n",
      "epoch: 38 step: 201, loss is 0.0004339333681855351\n",
      "epoch: 38 step: 202, loss is 0.0002604954643175006\n",
      "epoch: 38 step: 203, loss is 0.0005880819517187774\n",
      "epoch: 38 step: 204, loss is 0.00040494793211109936\n",
      "epoch: 38 step: 205, loss is 0.0009056444396264851\n",
      "epoch: 38 step: 206, loss is 0.0005522166611626744\n",
      "epoch: 38 step: 207, loss is 0.00044102492392994463\n",
      "epoch: 38 step: 208, loss is 0.0004613742639776319\n",
      "epoch: 38 step: 209, loss is 0.0003925870405510068\n",
      "epoch: 38 step: 210, loss is 0.0013625564752146602\n",
      "epoch: 38 step: 211, loss is 0.0005914485664106905\n",
      "epoch: 38 step: 212, loss is 0.0018206114182248712\n",
      "epoch: 38 step: 213, loss is 0.0007396368309855461\n",
      "epoch: 38 step: 214, loss is 0.0005436131614260375\n",
      "epoch: 38 step: 215, loss is 0.0009580664336681366\n",
      "epoch: 38 step: 216, loss is 0.00031686192960478365\n",
      "epoch: 38 step: 217, loss is 0.0005736089660786092\n",
      "epoch: 38 step: 218, loss is 0.0009052696404978633\n",
      "epoch: 38 step: 219, loss is 0.0004911667783744633\n",
      "epoch: 38 step: 220, loss is 0.0005857025389559567\n",
      "epoch: 38 step: 221, loss is 0.0009161177440546453\n",
      "epoch: 38 step: 222, loss is 0.000783381110522896\n",
      "epoch: 38 step: 223, loss is 0.0004214443906676024\n",
      "epoch: 38 step: 224, loss is 0.0009441719739697874\n",
      "epoch: 38 step: 225, loss is 0.0008600867004133761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 step: 226, loss is 0.00020943168783560395\n",
      "epoch: 38 step: 227, loss is 0.0007804549532011151\n",
      "epoch: 38 step: 228, loss is 0.00024771326570771635\n",
      "epoch: 38 step: 229, loss is 0.0006599798216484487\n",
      "epoch: 38 step: 230, loss is 0.0010607435833662748\n",
      "epoch: 38 step: 231, loss is 0.0004985640407539904\n",
      "epoch: 38 step: 232, loss is 0.00055021169828251\n",
      "epoch: 38 step: 233, loss is 0.000652757182251662\n",
      "epoch: 38 step: 234, loss is 0.0012164809741079807\n",
      "epoch: 38 step: 235, loss is 0.00012570559920277447\n",
      "epoch: 38 step: 236, loss is 0.0007300356519408524\n",
      "epoch: 38 step: 237, loss is 0.0007412791601382196\n",
      "epoch: 38 step: 238, loss is 0.0015642150538042188\n",
      "epoch: 38 step: 239, loss is 0.00036704109515994787\n",
      "epoch: 38 step: 240, loss is 0.0005130672361701727\n",
      "epoch: 38 step: 241, loss is 0.0012006931938230991\n",
      "epoch: 38 step: 242, loss is 0.0005680454778485\n",
      "epoch: 38 step: 243, loss is 0.0004528235294856131\n",
      "epoch: 38 step: 244, loss is 0.0007157978834584355\n",
      "epoch: 38 step: 245, loss is 0.0005654612323269248\n",
      "epoch: 38 step: 246, loss is 0.0007335047703236341\n",
      "epoch: 38 step: 247, loss is 0.001000758958980441\n",
      "epoch: 38 step: 248, loss is 0.0005399802466854453\n",
      "epoch: 38 step: 249, loss is 0.0006099758320488036\n",
      "epoch: 38 step: 250, loss is 0.0007893635774962604\n",
      "epoch: 38 step: 251, loss is 5.725830851588398e-05\n",
      "epoch: 38 step: 252, loss is 0.0002725384256336838\n",
      "epoch: 38 step: 253, loss is 0.0015929751098155975\n",
      "epoch: 38 step: 254, loss is 0.000861351378262043\n",
      "epoch: 38 step: 255, loss is 0.0016074792947620153\n",
      "epoch: 38 step: 256, loss is 0.0012717951321974397\n",
      "epoch: 38 step: 257, loss is 0.00012556368892546743\n",
      "epoch: 38 step: 258, loss is 0.0006139978067949414\n",
      "epoch: 38 step: 259, loss is 0.00046002378803677857\n",
      "epoch: 38 step: 260, loss is 0.0007615303038619459\n",
      "epoch: 38 step: 261, loss is 0.0004294220998417586\n",
      "epoch: 38 step: 262, loss is 0.0005561952712014318\n",
      "epoch: 38 step: 263, loss is 0.0004026802780572325\n",
      "epoch: 38 step: 264, loss is 0.0004508362035267055\n",
      "epoch: 38 step: 265, loss is 0.0005591126973740757\n",
      "epoch: 38 step: 266, loss is 0.000851136224810034\n",
      "epoch: 38 step: 267, loss is 0.0005759946652688086\n",
      "epoch: 38 step: 268, loss is 0.000973026268184185\n",
      "epoch: 38 step: 269, loss is 0.0005790329887531698\n",
      "epoch: 38 step: 270, loss is 0.00033648230601102114\n",
      "epoch: 38 step: 271, loss is 0.0008586604963056743\n",
      "epoch: 38 step: 272, loss is 0.00037355298991315067\n",
      "epoch: 38 step: 273, loss is 0.0005672668339684606\n",
      "epoch: 38 step: 274, loss is 0.0005312438006512821\n",
      "epoch: 38 step: 275, loss is 0.0004529592115432024\n",
      "epoch: 38 step: 276, loss is 0.00042837002547457814\n",
      "epoch: 38 step: 277, loss is 0.0005034585483372211\n",
      "epoch: 38 step: 278, loss is 0.0005650662933476269\n",
      "epoch: 38 step: 279, loss is 0.00016459100879728794\n",
      "epoch: 38 step: 280, loss is 0.0006402883445844054\n",
      "epoch: 38 step: 281, loss is 0.001389287761412561\n",
      "epoch: 38 step: 282, loss is 0.0012501014862209558\n",
      "epoch: 38 step: 283, loss is 0.0011749975383281708\n",
      "epoch: 38 step: 284, loss is 0.0004758388677146286\n",
      "epoch: 38 step: 285, loss is 0.00043118474422954023\n",
      "epoch: 38 step: 286, loss is 0.0004360769526101649\n",
      "epoch: 38 step: 287, loss is 0.0005639757146127522\n",
      "epoch: 38 step: 288, loss is 0.0018356505315750837\n",
      "epoch: 38 step: 289, loss is 0.0011426950804889202\n",
      "epoch: 38 step: 290, loss is 0.0006488016224466264\n",
      "epoch: 38 step: 291, loss is 0.000780415371991694\n",
      "epoch: 38 step: 292, loss is 0.00027508550556376576\n",
      "epoch: 38 step: 293, loss is 0.0006394044612534344\n",
      "epoch: 38 step: 294, loss is 0.0007752056117169559\n",
      "epoch: 38 step: 295, loss is 0.000451253610663116\n",
      "epoch: 38 step: 296, loss is 0.000239416811382398\n",
      "epoch: 38 step: 297, loss is 0.0008633004035800695\n",
      "epoch: 38 step: 298, loss is 0.00029577972600236535\n",
      "epoch: 38 step: 299, loss is 0.00038500374648720026\n",
      "epoch: 38 step: 300, loss is 0.00040725740836933255\n",
      "epoch: 38 step: 301, loss is 0.0009698698413558304\n",
      "epoch: 38 step: 302, loss is 0.0006622071377933025\n",
      "epoch: 38 step: 303, loss is 0.0009667624835856259\n",
      "epoch: 38 step: 304, loss is 0.00034333980875089765\n",
      "epoch: 38 step: 305, loss is 0.0001470991555834189\n",
      "epoch: 38 step: 306, loss is 0.0004712446534540504\n",
      "epoch: 38 step: 307, loss is 0.0003867457853630185\n",
      "epoch: 38 step: 308, loss is 0.0008576101972721517\n",
      "epoch: 38 step: 309, loss is 0.0006214098539203405\n",
      "epoch: 38 step: 310, loss is 0.0006316652870737016\n",
      "epoch: 38 step: 311, loss is 0.0009907757630571723\n",
      "epoch: 38 step: 312, loss is 0.0004437096940819174\n",
      "epoch: 38 step: 313, loss is 0.0008164406754076481\n",
      "epoch: 38 step: 314, loss is 0.0006495311390608549\n",
      "epoch: 38 step: 315, loss is 0.0005275247385725379\n",
      "epoch: 38 step: 316, loss is 0.0008885957067832351\n",
      "epoch: 38 step: 317, loss is 0.0012862825533375144\n",
      "epoch: 38 step: 318, loss is 0.0004422352649271488\n",
      "epoch: 38 step: 319, loss is 0.000191907151020132\n",
      "epoch: 38 step: 320, loss is 0.0002940943231806159\n",
      "epoch: 38 step: 321, loss is 0.0005766722606495023\n",
      "epoch: 38 step: 322, loss is 0.0006936856079846621\n",
      "epoch: 38 step: 323, loss is 0.0014050144236534834\n",
      "epoch: 38 step: 324, loss is 0.00033149149385280907\n",
      "epoch: 38 step: 325, loss is 0.001848452491685748\n",
      "epoch: 38 step: 326, loss is 0.0002129740605596453\n",
      "epoch: 38 step: 327, loss is 0.0006472026580013335\n",
      "epoch: 38 step: 328, loss is 0.00029889497091062367\n",
      "epoch: 38 step: 329, loss is 0.0005288337706588209\n",
      "epoch: 38 step: 330, loss is 0.0007347909267991781\n",
      "epoch: 38 step: 331, loss is 0.0006416984251700342\n",
      "epoch: 38 step: 332, loss is 0.0007077499758452177\n",
      "epoch: 38 step: 333, loss is 0.0006880389992147684\n",
      "epoch: 38 step: 334, loss is 0.00027165227220393717\n",
      "epoch: 38 step: 335, loss is 0.001426190952770412\n",
      "epoch: 38 step: 336, loss is 0.00044408722897060215\n",
      "epoch: 38 step: 337, loss is 0.0009100871975533664\n",
      "epoch: 38 step: 338, loss is 0.0005050251493230462\n",
      "epoch: 38 step: 339, loss is 0.0006083958433009684\n",
      "epoch: 38 step: 340, loss is 0.0005168035277165473\n",
      "epoch: 38 step: 341, loss is 0.0006886339979246259\n",
      "epoch: 38 step: 342, loss is 0.00033213282586075366\n",
      "epoch: 38 step: 343, loss is 0.00039835195639170706\n",
      "epoch: 38 step: 344, loss is 0.0013828714145347476\n",
      "epoch: 38 step: 345, loss is 0.00015585195797029883\n",
      "epoch: 38 step: 346, loss is 0.00040255184285342693\n",
      "epoch: 38 step: 347, loss is 0.00020407185365911573\n",
      "epoch: 38 step: 348, loss is 0.003149277064949274\n",
      "epoch: 38 step: 349, loss is 0.0003532731207087636\n",
      "epoch: 38 step: 350, loss is 0.0003618801129050553\n",
      "epoch: 38 step: 351, loss is 0.0007572831818833947\n",
      "epoch: 38 step: 352, loss is 0.0005046169389970601\n",
      "epoch: 38 step: 353, loss is 0.0003163150104228407\n",
      "epoch: 38 step: 354, loss is 0.0006934106349945068\n",
      "epoch: 38 step: 355, loss is 0.0004966626293025911\n",
      "epoch: 38 step: 356, loss is 0.0008619028958491981\n",
      "epoch: 38 step: 357, loss is 0.00046304211718961596\n",
      "epoch: 38 step: 358, loss is 0.0007297834963537753\n",
      "epoch: 38 step: 359, loss is 0.0012370951008051634\n",
      "epoch: 38 step: 360, loss is 0.0011268560774624348\n",
      "epoch: 38 step: 361, loss is 0.0004360306775197387\n",
      "epoch: 38 step: 362, loss is 0.0018659846391528845\n",
      "epoch: 38 step: 363, loss is 0.0003583625366445631\n",
      "epoch: 38 step: 364, loss is 0.0006680329679511487\n",
      "epoch: 38 step: 365, loss is 0.000740206683985889\n",
      "epoch: 38 step: 366, loss is 0.0011929712491109967\n",
      "epoch: 38 step: 367, loss is 0.00062509102281183\n",
      "epoch: 38 step: 368, loss is 0.000247737392783165\n",
      "epoch: 38 step: 369, loss is 0.000848362862598151\n",
      "epoch: 38 step: 370, loss is 0.0003471909440122545\n",
      "epoch: 38 step: 371, loss is 0.0004893287550657988\n",
      "epoch: 38 step: 372, loss is 0.0006030331715010107\n",
      "epoch: 38 step: 373, loss is 0.0005379877984523773\n",
      "epoch: 38 step: 374, loss is 0.0007070823921822011\n",
      "epoch: 38 step: 375, loss is 0.0007121796370483935\n",
      "Train epoch time: 11709.204 ms, per step time: 31.225 ms\n",
      "epoch: 39 step: 1, loss is 0.0003354084037709981\n",
      "epoch: 39 step: 2, loss is 0.0006956502329558134\n",
      "epoch: 39 step: 3, loss is 0.0014725615037605166\n",
      "epoch: 39 step: 4, loss is 0.0007184520363807678\n",
      "epoch: 39 step: 5, loss is 0.0005850804736837745\n",
      "epoch: 39 step: 6, loss is 0.00036772090243175626\n",
      "epoch: 39 step: 7, loss is 0.0005410024896264076\n",
      "epoch: 39 step: 8, loss is 0.0013185094576328993\n",
      "epoch: 39 step: 9, loss is 0.00036567854112945497\n",
      "epoch: 39 step: 10, loss is 0.0012984711211174726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 step: 11, loss is 0.0009777171071618795\n",
      "epoch: 39 step: 12, loss is 0.0005298706819303334\n",
      "epoch: 39 step: 13, loss is 0.000705576385371387\n",
      "epoch: 39 step: 14, loss is 0.0010161349782720208\n",
      "epoch: 39 step: 15, loss is 0.0005179695435799658\n",
      "epoch: 39 step: 16, loss is 0.001776419230736792\n",
      "epoch: 39 step: 17, loss is 0.00028986658435314894\n",
      "epoch: 39 step: 18, loss is 0.00047427459503524005\n",
      "epoch: 39 step: 19, loss is 0.0007862251368351281\n",
      "epoch: 39 step: 20, loss is 0.0012601593043655157\n",
      "epoch: 39 step: 21, loss is 0.000287965580355376\n",
      "epoch: 39 step: 22, loss is 0.0003997463791165501\n",
      "epoch: 39 step: 23, loss is 0.0005011296598240733\n",
      "epoch: 39 step: 24, loss is 0.0007346021011471748\n",
      "epoch: 39 step: 25, loss is 0.0001716547558316961\n",
      "epoch: 39 step: 26, loss is 0.00039240613114088774\n",
      "epoch: 39 step: 27, loss is 0.0009746482828631997\n",
      "epoch: 39 step: 28, loss is 0.0002424360136501491\n",
      "epoch: 39 step: 29, loss is 0.0006136837182566524\n",
      "epoch: 39 step: 30, loss is 0.00066309206886217\n",
      "epoch: 39 step: 31, loss is 0.00038678833516314626\n",
      "epoch: 39 step: 32, loss is 0.0008240080787800252\n",
      "epoch: 39 step: 33, loss is 0.0013005066430196166\n",
      "epoch: 39 step: 34, loss is 0.0013994850451126695\n",
      "epoch: 39 step: 35, loss is 0.0001891453139251098\n",
      "epoch: 39 step: 36, loss is 0.0003838549891952425\n",
      "epoch: 39 step: 37, loss is 0.0005551871145144105\n",
      "epoch: 39 step: 38, loss is 0.00016276589303743094\n",
      "epoch: 39 step: 39, loss is 0.0007648809114471078\n",
      "epoch: 39 step: 40, loss is 0.00045452150516211987\n",
      "epoch: 39 step: 41, loss is 0.0010486482642591\n",
      "epoch: 39 step: 42, loss is 0.0005159558495506644\n",
      "epoch: 39 step: 43, loss is 0.00015682383673265576\n",
      "epoch: 39 step: 44, loss is 0.00035889868740923703\n",
      "epoch: 39 step: 45, loss is 0.0006323123234324157\n",
      "epoch: 39 step: 46, loss is 0.0011731134727597237\n",
      "epoch: 39 step: 47, loss is 0.00017052970360964537\n",
      "epoch: 39 step: 48, loss is 0.001154451398178935\n",
      "epoch: 39 step: 49, loss is 0.0005100042326375842\n",
      "epoch: 39 step: 50, loss is 0.0007509833667427301\n",
      "epoch: 39 step: 51, loss is 0.00016932110884226859\n",
      "epoch: 39 step: 52, loss is 0.0005376884946599603\n",
      "epoch: 39 step: 53, loss is 0.00021023041335865855\n",
      "epoch: 39 step: 54, loss is 0.000827333889901638\n",
      "epoch: 39 step: 55, loss is 0.0002784367825370282\n",
      "epoch: 39 step: 56, loss is 0.000369620363926515\n",
      "epoch: 39 step: 57, loss is 0.00016678789688739926\n",
      "epoch: 39 step: 58, loss is 0.0006828050245530903\n",
      "epoch: 39 step: 59, loss is 0.0006188314873725176\n",
      "epoch: 39 step: 60, loss is 0.0005329814157448709\n",
      "epoch: 39 step: 61, loss is 0.0010116545017808676\n",
      "epoch: 39 step: 62, loss is 0.0005807107081636786\n",
      "epoch: 39 step: 63, loss is 0.0003950533864554018\n",
      "epoch: 39 step: 64, loss is 0.0014524735743179917\n",
      "epoch: 39 step: 65, loss is 0.0014159780694171786\n",
      "epoch: 39 step: 66, loss is 0.0009752234909683466\n",
      "epoch: 39 step: 67, loss is 0.001457694685086608\n",
      "epoch: 39 step: 68, loss is 0.00159111013635993\n",
      "epoch: 39 step: 69, loss is 0.000454967375844717\n",
      "epoch: 39 step: 70, loss is 0.0006761429831385612\n",
      "epoch: 39 step: 71, loss is 0.00044516249909065664\n",
      "epoch: 39 step: 72, loss is 0.0006876628613099456\n",
      "epoch: 39 step: 73, loss is 0.00031304301228374243\n",
      "epoch: 39 step: 74, loss is 0.00033841817639768124\n",
      "epoch: 39 step: 75, loss is 0.00061992829432711\n",
      "epoch: 39 step: 76, loss is 0.0004059720376972109\n",
      "epoch: 39 step: 77, loss is 0.00074834527913481\n",
      "epoch: 39 step: 78, loss is 0.000955955358222127\n",
      "epoch: 39 step: 79, loss is 0.0003871780354529619\n",
      "epoch: 39 step: 80, loss is 0.0007322209421545267\n",
      "epoch: 39 step: 81, loss is 0.0005887128063477576\n",
      "epoch: 39 step: 82, loss is 0.0019910812843590975\n",
      "epoch: 39 step: 83, loss is 0.0013728865887969732\n",
      "epoch: 39 step: 84, loss is 0.0002878599043469876\n",
      "epoch: 39 step: 85, loss is 0.0006904262700118124\n",
      "epoch: 39 step: 86, loss is 0.0017181453295052052\n",
      "epoch: 39 step: 87, loss is 0.0008250270038843155\n",
      "epoch: 39 step: 88, loss is 0.001463377266190946\n",
      "epoch: 39 step: 89, loss is 0.0001359220768790692\n",
      "epoch: 39 step: 90, loss is 0.0007248591864481568\n",
      "epoch: 39 step: 91, loss is 0.00026838091434910893\n",
      "epoch: 39 step: 92, loss is 0.0005795603501610458\n",
      "epoch: 39 step: 93, loss is 0.0012500318698585033\n",
      "epoch: 39 step: 94, loss is 0.0004278437700122595\n",
      "epoch: 39 step: 95, loss is 0.0010146532440558076\n",
      "epoch: 39 step: 96, loss is 0.0007908853003755212\n",
      "epoch: 39 step: 97, loss is 0.0002473121858201921\n",
      "epoch: 39 step: 98, loss is 0.0005806335830129683\n",
      "epoch: 39 step: 99, loss is 0.000730598927475512\n",
      "epoch: 39 step: 100, loss is 0.0012638921616598964\n",
      "epoch: 39 step: 101, loss is 0.0003007042978424579\n",
      "epoch: 39 step: 102, loss is 0.0005178767023608088\n",
      "epoch: 39 step: 103, loss is 0.0008989201160147786\n",
      "epoch: 39 step: 104, loss is 0.0002757124602794647\n",
      "epoch: 39 step: 105, loss is 0.0005131465732119977\n",
      "epoch: 39 step: 106, loss is 0.0011101154377683997\n",
      "epoch: 39 step: 107, loss is 0.0008093843352980912\n",
      "epoch: 39 step: 108, loss is 0.0011488235322758555\n",
      "epoch: 39 step: 109, loss is 0.0004564225091598928\n",
      "epoch: 39 step: 110, loss is 0.0009796968661248684\n",
      "epoch: 39 step: 111, loss is 0.0007832761039026082\n",
      "epoch: 39 step: 112, loss is 0.0007560685626231134\n",
      "epoch: 39 step: 113, loss is 0.0001576200156705454\n",
      "epoch: 39 step: 114, loss is 0.0007787952781654894\n",
      "epoch: 39 step: 115, loss is 0.0008546988829039037\n",
      "epoch: 39 step: 116, loss is 0.000681418867316097\n",
      "epoch: 39 step: 117, loss is 0.001138196443207562\n",
      "epoch: 39 step: 118, loss is 0.0009011329966597259\n",
      "epoch: 39 step: 119, loss is 0.0004718457057606429\n",
      "epoch: 39 step: 120, loss is 0.0007736152620054781\n",
      "epoch: 39 step: 121, loss is 0.0015748417936265469\n",
      "epoch: 39 step: 122, loss is 0.0005450796452350914\n",
      "epoch: 39 step: 123, loss is 0.0009947895305231214\n",
      "epoch: 39 step: 124, loss is 0.0008042245171964169\n",
      "epoch: 39 step: 125, loss is 0.0003600367344915867\n",
      "epoch: 39 step: 126, loss is 0.0005509115871973336\n",
      "epoch: 39 step: 127, loss is 0.0003434107347857207\n",
      "epoch: 39 step: 128, loss is 0.00013709311315324157\n",
      "epoch: 39 step: 129, loss is 0.000316984805976972\n",
      "epoch: 39 step: 130, loss is 0.0008015758940018713\n",
      "epoch: 39 step: 131, loss is 6.392340583261102e-05\n",
      "epoch: 39 step: 132, loss is 0.00058736716164276\n",
      "epoch: 39 step: 133, loss is 0.00034387430059723556\n",
      "epoch: 39 step: 134, loss is 0.00047561369137838483\n",
      "epoch: 39 step: 135, loss is 0.0004506148979999125\n",
      "epoch: 39 step: 136, loss is 0.0005316255264915526\n",
      "epoch: 39 step: 137, loss is 0.000278178951703012\n",
      "epoch: 39 step: 138, loss is 0.00042494514491409063\n",
      "epoch: 39 step: 139, loss is 0.0006288127042353153\n",
      "epoch: 39 step: 140, loss is 0.000761260453145951\n",
      "epoch: 39 step: 141, loss is 0.0005059331306256354\n",
      "epoch: 39 step: 142, loss is 0.0008450302411802113\n",
      "epoch: 39 step: 143, loss is 0.0006594866863451898\n",
      "epoch: 39 step: 144, loss is 0.000767558696679771\n",
      "epoch: 39 step: 145, loss is 0.000664160237647593\n",
      "epoch: 39 step: 146, loss is 0.0006658185739070177\n",
      "epoch: 39 step: 147, loss is 0.00047764432383701205\n",
      "epoch: 39 step: 148, loss is 0.00034611826413311064\n",
      "epoch: 39 step: 149, loss is 0.00018759227532427758\n",
      "epoch: 39 step: 150, loss is 0.000545461371075362\n",
      "epoch: 39 step: 151, loss is 0.0015366433653980494\n",
      "epoch: 39 step: 152, loss is 0.0006000876892358065\n",
      "epoch: 39 step: 153, loss is 0.00023169335327111185\n",
      "epoch: 39 step: 154, loss is 0.00043756511877290905\n",
      "epoch: 39 step: 155, loss is 0.0003223250387236476\n",
      "epoch: 39 step: 156, loss is 0.00030755740590393543\n",
      "epoch: 39 step: 157, loss is 0.0002892499614972621\n",
      "epoch: 39 step: 158, loss is 0.0009810890769585967\n",
      "epoch: 39 step: 159, loss is 0.0018609844846650958\n",
      "epoch: 39 step: 160, loss is 0.0005458631203509867\n",
      "epoch: 39 step: 161, loss is 0.0005292993737384677\n",
      "epoch: 39 step: 162, loss is 0.0008760340861044824\n",
      "epoch: 39 step: 163, loss is 0.0007823448977433145\n",
      "epoch: 39 step: 164, loss is 0.0012456397525966167\n",
      "epoch: 39 step: 165, loss is 0.00177956058178097\n",
      "epoch: 39 step: 166, loss is 0.0006198183982633054\n",
      "epoch: 39 step: 167, loss is 0.0008349874406121671\n",
      "epoch: 39 step: 168, loss is 0.0007524464745074511\n",
      "epoch: 39 step: 169, loss is 0.0010873451828956604\n",
      "epoch: 39 step: 170, loss is 0.0006302314577624202\n",
      "epoch: 39 step: 171, loss is 0.0010658090468496084\n",
      "epoch: 39 step: 172, loss is 0.0006560057518072426\n",
      "epoch: 39 step: 173, loss is 0.0010679418919607997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 step: 174, loss is 0.00043647675192914903\n",
      "epoch: 39 step: 175, loss is 0.0003392854705452919\n",
      "epoch: 39 step: 176, loss is 0.0004933039890602231\n",
      "epoch: 39 step: 177, loss is 0.0007268933695740998\n",
      "epoch: 39 step: 178, loss is 0.00087397126480937\n",
      "epoch: 39 step: 179, loss is 0.0006442226585932076\n",
      "epoch: 39 step: 180, loss is 0.001988364616408944\n",
      "epoch: 39 step: 181, loss is 0.00011947137682000175\n",
      "epoch: 39 step: 182, loss is 0.0006235427572391927\n",
      "epoch: 39 step: 183, loss is 0.0001372279948554933\n",
      "epoch: 39 step: 184, loss is 0.0004956359043717384\n",
      "epoch: 39 step: 185, loss is 0.0002987765474244952\n",
      "epoch: 39 step: 186, loss is 0.0010293324012309313\n",
      "epoch: 39 step: 187, loss is 0.0010734967654570937\n",
      "epoch: 39 step: 188, loss is 0.000594506913330406\n",
      "epoch: 39 step: 189, loss is 0.00029987958259880543\n",
      "epoch: 39 step: 190, loss is 0.00022453466954175383\n",
      "epoch: 39 step: 191, loss is 0.001449767267331481\n",
      "epoch: 39 step: 192, loss is 0.0008248287485912442\n",
      "epoch: 39 step: 193, loss is 0.00071912253042683\n",
      "epoch: 39 step: 194, loss is 0.0008097385289147496\n",
      "epoch: 39 step: 195, loss is 0.0007344300393015146\n",
      "epoch: 39 step: 196, loss is 0.0003848493506666273\n",
      "epoch: 39 step: 197, loss is 0.0006971403490751982\n",
      "epoch: 39 step: 198, loss is 0.00017522144480608404\n",
      "epoch: 39 step: 199, loss is 0.0002913104253821075\n",
      "epoch: 39 step: 200, loss is 0.0004750500083900988\n",
      "epoch: 39 step: 201, loss is 0.0006915939156897366\n",
      "epoch: 39 step: 202, loss is 0.0006123236380517483\n",
      "epoch: 39 step: 203, loss is 0.0006911471136845648\n",
      "epoch: 39 step: 204, loss is 0.000171861654962413\n",
      "epoch: 39 step: 205, loss is 0.0001972996542463079\n",
      "epoch: 39 step: 206, loss is 0.0004558655491564423\n",
      "epoch: 39 step: 207, loss is 0.00049667211715132\n",
      "epoch: 39 step: 208, loss is 0.000358239485649392\n",
      "epoch: 39 step: 209, loss is 0.0006782881100662053\n",
      "epoch: 39 step: 210, loss is 0.00047485894174315035\n",
      "epoch: 39 step: 211, loss is 0.0008542159921489656\n",
      "epoch: 39 step: 212, loss is 0.00027336872881278396\n",
      "epoch: 39 step: 213, loss is 0.00032657544943504035\n",
      "epoch: 39 step: 214, loss is 0.0006660809158347547\n",
      "epoch: 39 step: 215, loss is 0.0006270887679420412\n",
      "epoch: 39 step: 216, loss is 0.0005188503419049084\n",
      "epoch: 39 step: 217, loss is 0.0020086560398340225\n",
      "epoch: 39 step: 218, loss is 0.0006917364662513137\n",
      "epoch: 39 step: 219, loss is 0.00048732577124610543\n",
      "epoch: 39 step: 220, loss is 0.00022350106155499816\n",
      "epoch: 39 step: 221, loss is 0.00034082765341736376\n",
      "epoch: 39 step: 222, loss is 0.0002920458500739187\n",
      "epoch: 39 step: 223, loss is 0.0005069382023066282\n",
      "epoch: 39 step: 224, loss is 0.00032684762845747173\n",
      "epoch: 39 step: 225, loss is 0.0009563977364450693\n",
      "epoch: 39 step: 226, loss is 0.0004917586338706315\n",
      "epoch: 39 step: 227, loss is 0.00030588917434215546\n",
      "epoch: 39 step: 228, loss is 0.0007190479664131999\n",
      "epoch: 39 step: 229, loss is 0.0007210917538031936\n",
      "epoch: 39 step: 230, loss is 0.0005847499705851078\n",
      "epoch: 39 step: 231, loss is 0.0008390651200897992\n",
      "epoch: 39 step: 232, loss is 0.0008250397513620555\n",
      "epoch: 39 step: 233, loss is 0.0006470264052040875\n",
      "epoch: 39 step: 234, loss is 0.0013525377726182342\n",
      "epoch: 39 step: 235, loss is 0.0002731000422500074\n",
      "epoch: 39 step: 236, loss is 0.0009429986821487546\n",
      "epoch: 39 step: 237, loss is 0.0005275086732581258\n",
      "epoch: 39 step: 238, loss is 0.0003426455077715218\n",
      "epoch: 39 step: 239, loss is 0.0006251347367651761\n",
      "epoch: 39 step: 240, loss is 0.0017988490872085094\n",
      "epoch: 39 step: 241, loss is 0.001649733167141676\n",
      "epoch: 39 step: 242, loss is 0.0012290322920307517\n",
      "epoch: 39 step: 243, loss is 0.0007913896697573364\n",
      "epoch: 39 step: 244, loss is 0.0004408035892993212\n",
      "epoch: 39 step: 245, loss is 0.001260962337255478\n",
      "epoch: 39 step: 246, loss is 0.0005049582687206566\n",
      "epoch: 39 step: 247, loss is 0.00024309297441504896\n",
      "epoch: 39 step: 248, loss is 0.0005926404846832156\n",
      "epoch: 39 step: 249, loss is 0.000794795632828027\n",
      "epoch: 39 step: 250, loss is 0.0011430007871240377\n",
      "epoch: 39 step: 251, loss is 0.0004500788345467299\n",
      "epoch: 39 step: 252, loss is 0.0006258580251596868\n",
      "epoch: 39 step: 253, loss is 0.00019682770653162152\n",
      "epoch: 39 step: 254, loss is 0.0011288266396149993\n",
      "epoch: 39 step: 255, loss is 0.0003625306417234242\n",
      "epoch: 39 step: 256, loss is 0.0002589461801107973\n",
      "epoch: 39 step: 257, loss is 0.0002669495006557554\n",
      "epoch: 39 step: 258, loss is 0.0004704291350208223\n",
      "epoch: 39 step: 259, loss is 0.0008100534323602915\n",
      "epoch: 39 step: 260, loss is 0.0008488124003633857\n",
      "epoch: 39 step: 261, loss is 0.0007750366348773241\n",
      "epoch: 39 step: 262, loss is 0.0006484874174930155\n",
      "epoch: 39 step: 263, loss is 0.00139607151504606\n",
      "epoch: 39 step: 264, loss is 0.0004730584332719445\n",
      "epoch: 39 step: 265, loss is 0.0008929334580898285\n",
      "epoch: 39 step: 266, loss is 0.0015100655145943165\n",
      "epoch: 39 step: 267, loss is 0.0003751564654521644\n",
      "epoch: 39 step: 268, loss is 0.0006343098939396441\n",
      "epoch: 39 step: 269, loss is 0.0005184711772017181\n",
      "epoch: 39 step: 270, loss is 0.0008870406891219318\n",
      "epoch: 39 step: 271, loss is 0.0006412736838683486\n",
      "epoch: 39 step: 272, loss is 0.0003719438100233674\n",
      "epoch: 39 step: 273, loss is 0.0007750955410301685\n",
      "epoch: 39 step: 274, loss is 0.00017522585403639823\n",
      "epoch: 39 step: 275, loss is 0.0009873472154140472\n",
      "epoch: 39 step: 276, loss is 0.0005478017847053707\n",
      "epoch: 39 step: 277, loss is 0.0005312649300321937\n",
      "epoch: 39 step: 278, loss is 0.000547940784599632\n",
      "epoch: 39 step: 279, loss is 0.0005363667150959373\n",
      "epoch: 39 step: 280, loss is 0.0004097144119441509\n",
      "epoch: 39 step: 281, loss is 0.0003801993152592331\n",
      "epoch: 39 step: 282, loss is 0.0005136438412591815\n",
      "epoch: 39 step: 283, loss is 0.0009627444087527692\n",
      "epoch: 39 step: 284, loss is 0.0005365971010178328\n",
      "epoch: 39 step: 285, loss is 0.0008948091417551041\n",
      "epoch: 39 step: 286, loss is 0.00020717352163046598\n",
      "epoch: 39 step: 287, loss is 0.001226364285685122\n",
      "epoch: 39 step: 288, loss is 0.0001181630213977769\n",
      "epoch: 39 step: 289, loss is 0.0007363055483438075\n",
      "epoch: 39 step: 290, loss is 0.0012694449396803975\n",
      "epoch: 39 step: 291, loss is 0.0007968238787725568\n",
      "epoch: 39 step: 292, loss is 0.0006995830917730927\n",
      "epoch: 39 step: 293, loss is 0.0008001144742593169\n",
      "epoch: 39 step: 294, loss is 0.0008666765643283725\n",
      "epoch: 39 step: 295, loss is 0.0011963570723310113\n",
      "epoch: 39 step: 296, loss is 0.0002770764986053109\n",
      "epoch: 39 step: 297, loss is 0.0002699612232390791\n",
      "epoch: 39 step: 298, loss is 0.0004163755220361054\n",
      "epoch: 39 step: 299, loss is 0.00043280015233904123\n",
      "epoch: 39 step: 300, loss is 0.0005134043167345226\n",
      "epoch: 39 step: 301, loss is 0.0014635708648711443\n",
      "epoch: 39 step: 302, loss is 0.0005246457876637578\n",
      "epoch: 39 step: 303, loss is 0.00036540720611810684\n",
      "epoch: 39 step: 304, loss is 0.0002979999699164182\n",
      "epoch: 39 step: 305, loss is 0.0011151684448122978\n",
      "epoch: 39 step: 306, loss is 0.0008859391091391444\n",
      "epoch: 39 step: 307, loss is 0.000619998318143189\n",
      "epoch: 39 step: 308, loss is 0.0005595320835709572\n",
      "epoch: 39 step: 309, loss is 0.0005228917580097914\n",
      "epoch: 39 step: 310, loss is 0.0002772326406557113\n",
      "epoch: 39 step: 311, loss is 0.00031143828528001904\n",
      "epoch: 39 step: 312, loss is 0.00141773815266788\n",
      "epoch: 39 step: 313, loss is 0.0009373860084451735\n",
      "epoch: 39 step: 314, loss is 0.0007940899231471121\n",
      "epoch: 39 step: 315, loss is 0.0004189343599136919\n",
      "epoch: 39 step: 316, loss is 0.00048665289068594575\n",
      "epoch: 39 step: 317, loss is 0.0002763063821475953\n",
      "epoch: 39 step: 318, loss is 0.00033291339059360325\n",
      "epoch: 39 step: 319, loss is 0.0007585772546008229\n",
      "epoch: 39 step: 320, loss is 0.0010714761447161436\n",
      "epoch: 39 step: 321, loss is 0.0018549017840996385\n",
      "epoch: 39 step: 322, loss is 0.0004740574804600328\n",
      "epoch: 39 step: 323, loss is 0.0006388143519870937\n",
      "epoch: 39 step: 324, loss is 0.0009343190467916429\n",
      "epoch: 39 step: 325, loss is 0.00026415332104079425\n",
      "epoch: 39 step: 326, loss is 0.0007858264725655317\n",
      "epoch: 39 step: 327, loss is 0.00024312324239872396\n",
      "epoch: 39 step: 328, loss is 0.00036018635728396475\n",
      "epoch: 39 step: 329, loss is 0.0007415886502712965\n",
      "epoch: 39 step: 330, loss is 0.00024402092094533145\n",
      "epoch: 39 step: 331, loss is 0.0007190676406025887\n",
      "epoch: 39 step: 332, loss is 0.00048554441309534013\n",
      "epoch: 39 step: 333, loss is 0.0005977705004625022\n",
      "epoch: 39 step: 334, loss is 0.0007266324828378856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 step: 335, loss is 0.0006362419226206839\n",
      "epoch: 39 step: 336, loss is 0.0014085170114412904\n",
      "epoch: 39 step: 337, loss is 0.0011733720311895013\n",
      "epoch: 39 step: 338, loss is 0.00024533073883503675\n",
      "epoch: 39 step: 339, loss is 0.0004909445415250957\n",
      "epoch: 39 step: 340, loss is 0.0007626772276125848\n",
      "epoch: 39 step: 341, loss is 0.0009564577485434711\n",
      "epoch: 39 step: 342, loss is 0.0005950136692263186\n",
      "epoch: 39 step: 343, loss is 0.00048611024976707995\n",
      "epoch: 39 step: 344, loss is 0.0003772411437239498\n",
      "epoch: 39 step: 345, loss is 0.0005149916396476328\n",
      "epoch: 39 step: 346, loss is 0.0007559137884527445\n",
      "epoch: 39 step: 347, loss is 0.0003116715815849602\n",
      "epoch: 39 step: 348, loss is 0.00041198235703632236\n",
      "epoch: 39 step: 349, loss is 0.00041377567686140537\n",
      "epoch: 39 step: 350, loss is 0.0006058310973457992\n",
      "epoch: 39 step: 351, loss is 0.0004016759339720011\n",
      "epoch: 39 step: 352, loss is 0.0004176636866759509\n",
      "epoch: 39 step: 353, loss is 0.0005648788646794856\n",
      "epoch: 39 step: 354, loss is 0.0006580204935744405\n",
      "epoch: 39 step: 355, loss is 0.0007049083360470831\n",
      "epoch: 39 step: 356, loss is 0.0002157805283786729\n",
      "epoch: 39 step: 357, loss is 0.000752133084461093\n",
      "epoch: 39 step: 358, loss is 0.002020204206928611\n",
      "epoch: 39 step: 359, loss is 0.0006062467000447214\n",
      "epoch: 39 step: 360, loss is 0.0007360124727711082\n",
      "epoch: 39 step: 361, loss is 0.0006310560856945813\n",
      "epoch: 39 step: 362, loss is 0.0006905706832185388\n",
      "epoch: 39 step: 363, loss is 0.0001806240907171741\n",
      "epoch: 39 step: 364, loss is 0.0008043288253247738\n",
      "epoch: 39 step: 365, loss is 0.0003517305594868958\n",
      "epoch: 39 step: 366, loss is 0.0005631319363601506\n",
      "epoch: 39 step: 367, loss is 0.0006164285005070269\n",
      "epoch: 39 step: 368, loss is 0.00042632955592125654\n",
      "epoch: 39 step: 369, loss is 0.000332090217852965\n",
      "epoch: 39 step: 370, loss is 0.00042650807881727815\n",
      "epoch: 39 step: 371, loss is 0.00020114885410293937\n",
      "epoch: 39 step: 372, loss is 0.0005928476457484066\n",
      "epoch: 39 step: 373, loss is 0.00039244937943294644\n",
      "epoch: 39 step: 374, loss is 0.0006968987872824073\n",
      "epoch: 39 step: 375, loss is 4.643399370252155e-05\n",
      "Train epoch time: 11869.975 ms, per step time: 31.653 ms\n",
      "epoch: 40 step: 1, loss is 0.0009818085236474872\n",
      "epoch: 40 step: 2, loss is 0.0013013113057240844\n",
      "epoch: 40 step: 3, loss is 0.0003760065883398056\n",
      "epoch: 40 step: 4, loss is 0.001084627234376967\n",
      "epoch: 40 step: 5, loss is 0.0003848456544801593\n",
      "epoch: 40 step: 6, loss is 0.0003365968295838684\n",
      "epoch: 40 step: 7, loss is 0.0008623247849754989\n",
      "epoch: 40 step: 8, loss is 0.0004807989171240479\n",
      "epoch: 40 step: 9, loss is 0.00040073864511214197\n",
      "epoch: 40 step: 10, loss is 0.0004888075636699796\n",
      "epoch: 40 step: 11, loss is 0.0005511667113751173\n",
      "epoch: 40 step: 12, loss is 0.000617124664131552\n",
      "epoch: 40 step: 13, loss is 0.0011326955864205956\n",
      "epoch: 40 step: 14, loss is 0.0004807688819710165\n",
      "epoch: 40 step: 15, loss is 0.0006378841935656965\n",
      "epoch: 40 step: 16, loss is 0.0004851253761444241\n",
      "epoch: 40 step: 17, loss is 0.0002911494520958513\n",
      "epoch: 40 step: 18, loss is 0.0006471474189311266\n",
      "epoch: 40 step: 19, loss is 0.0004978076322004199\n",
      "epoch: 40 step: 20, loss is 0.00031935208244249225\n",
      "epoch: 40 step: 21, loss is 0.0007695643580518663\n",
      "epoch: 40 step: 22, loss is 0.0001836215378716588\n",
      "epoch: 40 step: 23, loss is 0.0006107969093136489\n",
      "epoch: 40 step: 24, loss is 0.00035158474929630756\n",
      "epoch: 40 step: 25, loss is 0.0004897630424238741\n",
      "epoch: 40 step: 26, loss is 0.0004305694892536849\n",
      "epoch: 40 step: 27, loss is 0.0005640429444611073\n",
      "epoch: 40 step: 28, loss is 0.0001564294216223061\n",
      "epoch: 40 step: 29, loss is 0.0009313073242083192\n",
      "epoch: 40 step: 30, loss is 0.0006426776526495814\n",
      "epoch: 40 step: 31, loss is 0.0005777842598035932\n",
      "epoch: 40 step: 32, loss is 0.0003219068457838148\n",
      "epoch: 40 step: 33, loss is 0.00016824404883664101\n",
      "epoch: 40 step: 34, loss is 0.0006166796665638685\n",
      "epoch: 40 step: 35, loss is 0.00022118532797321677\n",
      "epoch: 40 step: 36, loss is 0.0008301056222990155\n",
      "epoch: 40 step: 37, loss is 0.0011057768715545535\n",
      "epoch: 40 step: 38, loss is 0.0005219343584030867\n",
      "epoch: 40 step: 39, loss is 0.0011439110385254025\n",
      "epoch: 40 step: 40, loss is 0.0008963093277998269\n",
      "epoch: 40 step: 41, loss is 0.0006237624911591411\n",
      "epoch: 40 step: 42, loss is 0.0002937691460829228\n",
      "epoch: 40 step: 43, loss is 0.0006142717902548611\n",
      "epoch: 40 step: 44, loss is 0.0010089018614962697\n",
      "epoch: 40 step: 45, loss is 0.00030711881117895246\n",
      "epoch: 40 step: 46, loss is 0.0009751911275088787\n",
      "epoch: 40 step: 47, loss is 0.0011897560907527804\n",
      "epoch: 40 step: 48, loss is 0.0007799522718414664\n",
      "epoch: 40 step: 49, loss is 0.0005493787466548383\n",
      "epoch: 40 step: 50, loss is 0.0008512858184985816\n",
      "epoch: 40 step: 51, loss is 0.0009949259692803025\n",
      "epoch: 40 step: 52, loss is 0.00041471474105492234\n",
      "epoch: 40 step: 53, loss is 0.0006778286769986153\n",
      "epoch: 40 step: 54, loss is 0.0010370311792939901\n",
      "epoch: 40 step: 55, loss is 0.0007215506630018353\n",
      "epoch: 40 step: 56, loss is 0.0010605972493067384\n",
      "epoch: 40 step: 57, loss is 0.0012963624903932214\n",
      "epoch: 40 step: 58, loss is 0.0005100828129798174\n",
      "epoch: 40 step: 59, loss is 0.00029146255110390484\n",
      "epoch: 40 step: 60, loss is 0.0003068966616410762\n",
      "epoch: 40 step: 61, loss is 0.0002854903577826917\n",
      "epoch: 40 step: 62, loss is 0.0004471995052881539\n",
      "epoch: 40 step: 63, loss is 0.0006133199785836041\n",
      "epoch: 40 step: 64, loss is 0.0010380124440416694\n",
      "epoch: 40 step: 65, loss is 0.00039223494241014123\n",
      "epoch: 40 step: 66, loss is 0.00038355894503183663\n",
      "epoch: 40 step: 67, loss is 0.000751720042899251\n",
      "epoch: 40 step: 68, loss is 0.0005888636806048453\n",
      "epoch: 40 step: 69, loss is 0.0009114968706853688\n",
      "epoch: 40 step: 70, loss is 0.0005337342154234648\n",
      "epoch: 40 step: 71, loss is 0.000704979698639363\n",
      "epoch: 40 step: 72, loss is 0.0003708431904669851\n",
      "epoch: 40 step: 73, loss is 0.0001998861989704892\n",
      "epoch: 40 step: 74, loss is 0.0006327863084152341\n",
      "epoch: 40 step: 75, loss is 0.0002716293092817068\n",
      "epoch: 40 step: 76, loss is 0.0009828389156609774\n",
      "epoch: 40 step: 77, loss is 0.000540279143024236\n",
      "epoch: 40 step: 78, loss is 0.0005997281987220049\n",
      "epoch: 40 step: 79, loss is 0.001096063875593245\n",
      "epoch: 40 step: 80, loss is 0.0004641929699573666\n",
      "epoch: 40 step: 81, loss is 0.0006494103581644595\n",
      "epoch: 40 step: 82, loss is 0.0008598290733061731\n",
      "epoch: 40 step: 83, loss is 0.0004722387238871306\n",
      "epoch: 40 step: 84, loss is 0.0007358213770203292\n",
      "epoch: 40 step: 85, loss is 0.00034271873300895095\n",
      "epoch: 40 step: 86, loss is 0.0017585217719897628\n",
      "epoch: 40 step: 87, loss is 0.0011674152920022607\n",
      "epoch: 40 step: 88, loss is 0.0005814310279674828\n",
      "epoch: 40 step: 89, loss is 0.000947166932746768\n",
      "epoch: 40 step: 90, loss is 0.0005669394740834832\n",
      "epoch: 40 step: 91, loss is 0.0005942574352957308\n",
      "epoch: 40 step: 92, loss is 0.0005952506326138973\n",
      "epoch: 40 step: 93, loss is 0.0005084325675852597\n",
      "epoch: 40 step: 94, loss is 0.0004951133159920573\n",
      "epoch: 40 step: 95, loss is 0.0002916404919233173\n",
      "epoch: 40 step: 96, loss is 0.0007765755872242153\n",
      "epoch: 40 step: 97, loss is 0.00039675194420851767\n",
      "epoch: 40 step: 98, loss is 0.0007711818325333297\n",
      "epoch: 40 step: 99, loss is 0.0007409406825900078\n",
      "epoch: 40 step: 100, loss is 0.0005791141884401441\n",
      "epoch: 40 step: 101, loss is 0.0002831755264196545\n",
      "epoch: 40 step: 102, loss is 0.00034235851489938796\n",
      "epoch: 40 step: 103, loss is 0.0006278986693359911\n",
      "epoch: 40 step: 104, loss is 0.0015614633448421955\n",
      "epoch: 40 step: 105, loss is 0.0009887667838484049\n",
      "epoch: 40 step: 106, loss is 0.000498573062941432\n",
      "epoch: 40 step: 107, loss is 0.00026111528859473765\n",
      "epoch: 40 step: 108, loss is 0.0020697268191725016\n",
      "epoch: 40 step: 109, loss is 0.001564854639582336\n",
      "epoch: 40 step: 110, loss is 0.0002898767124861479\n",
      "epoch: 40 step: 111, loss is 0.0007559456280432642\n",
      "epoch: 40 step: 112, loss is 0.0005810307338833809\n",
      "epoch: 40 step: 113, loss is 0.0006863409653306007\n",
      "epoch: 40 step: 114, loss is 0.00038201341521926224\n",
      "epoch: 40 step: 115, loss is 0.0005866674473509192\n",
      "epoch: 40 step: 116, loss is 0.000864582892972976\n",
      "epoch: 40 step: 117, loss is 0.0005239977035671473\n",
      "epoch: 40 step: 118, loss is 0.0013212121557444334\n",
      "epoch: 40 step: 119, loss is 0.00015278748469427228\n",
      "epoch: 40 step: 120, loss is 0.0007249750196933746\n",
      "epoch: 40 step: 121, loss is 0.00022625361452810466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 step: 122, loss is 0.0010575447231531143\n",
      "epoch: 40 step: 123, loss is 0.0006525187636725605\n",
      "epoch: 40 step: 124, loss is 0.0012336832005530596\n",
      "epoch: 40 step: 125, loss is 0.0011622821912169456\n",
      "epoch: 40 step: 126, loss is 0.0012394771911203861\n",
      "epoch: 40 step: 127, loss is 0.0014913321938365698\n",
      "epoch: 40 step: 128, loss is 0.0008429442532360554\n",
      "epoch: 40 step: 129, loss is 0.0005997297121211886\n",
      "epoch: 40 step: 130, loss is 0.0007755306432954967\n",
      "epoch: 40 step: 131, loss is 0.0013261476997286081\n",
      "epoch: 40 step: 132, loss is 0.0007262879516929388\n",
      "epoch: 40 step: 133, loss is 0.00047773943515494466\n",
      "epoch: 40 step: 134, loss is 0.000564312853384763\n",
      "epoch: 40 step: 135, loss is 0.0005122387665323913\n",
      "epoch: 40 step: 136, loss is 0.001319135189987719\n",
      "epoch: 40 step: 137, loss is 0.000541942601557821\n",
      "epoch: 40 step: 138, loss is 0.0006543431081809103\n",
      "epoch: 40 step: 139, loss is 0.0006592058343812823\n",
      "epoch: 40 step: 140, loss is 0.0003629135899245739\n",
      "epoch: 40 step: 141, loss is 0.0011288594687357545\n",
      "epoch: 40 step: 142, loss is 0.00033536116825416684\n",
      "epoch: 40 step: 143, loss is 0.0003109223034698516\n",
      "epoch: 40 step: 144, loss is 0.0004648839239962399\n",
      "epoch: 40 step: 145, loss is 0.0009335960494354367\n",
      "epoch: 40 step: 146, loss is 0.000745311495848\n",
      "epoch: 40 step: 147, loss is 0.0007355451816692948\n",
      "epoch: 40 step: 148, loss is 0.00017160273273475468\n",
      "epoch: 40 step: 149, loss is 0.00026351393898949027\n",
      "epoch: 40 step: 150, loss is 0.0006430151406675577\n",
      "epoch: 40 step: 151, loss is 0.0006197255570441484\n",
      "epoch: 40 step: 152, loss is 0.0004564227710943669\n",
      "epoch: 40 step: 153, loss is 0.00018550873210188001\n",
      "epoch: 40 step: 154, loss is 0.0008973220246843994\n",
      "epoch: 40 step: 155, loss is 0.0006839396082796156\n",
      "epoch: 40 step: 156, loss is 0.0008601859444752336\n",
      "epoch: 40 step: 157, loss is 0.0011187285417690873\n",
      "epoch: 40 step: 158, loss is 0.0010228486498817801\n",
      "epoch: 40 step: 159, loss is 0.0002774031017906964\n",
      "epoch: 40 step: 160, loss is 0.0011744484072551131\n",
      "epoch: 40 step: 161, loss is 0.0007664409931749105\n",
      "epoch: 40 step: 162, loss is 0.0005713078426197171\n",
      "epoch: 40 step: 163, loss is 0.0007406529039144516\n",
      "epoch: 40 step: 164, loss is 0.0010170635068789124\n",
      "epoch: 40 step: 165, loss is 0.0008782244403846562\n",
      "epoch: 40 step: 166, loss is 0.0009984449716284871\n",
      "epoch: 40 step: 167, loss is 0.0006068212096579373\n",
      "epoch: 40 step: 168, loss is 0.000728106067981571\n",
      "epoch: 40 step: 169, loss is 0.000735158275347203\n",
      "epoch: 40 step: 170, loss is 0.0005061532137915492\n",
      "epoch: 40 step: 171, loss is 0.0003590882697608322\n",
      "epoch: 40 step: 172, loss is 0.0004524843825493008\n",
      "epoch: 40 step: 173, loss is 0.000328096590237692\n",
      "epoch: 40 step: 174, loss is 0.0007704701274633408\n",
      "epoch: 40 step: 175, loss is 0.0005035897484049201\n",
      "epoch: 40 step: 176, loss is 0.0005582619342021644\n",
      "epoch: 40 step: 177, loss is 0.0008138346020132303\n",
      "epoch: 40 step: 178, loss is 0.0006928023067303002\n",
      "epoch: 40 step: 179, loss is 0.00031039348687045276\n",
      "epoch: 40 step: 180, loss is 0.0003501008031889796\n",
      "epoch: 40 step: 181, loss is 0.000439689785707742\n",
      "epoch: 40 step: 182, loss is 0.0006372731295414269\n",
      "epoch: 40 step: 183, loss is 0.0006492102984338999\n",
      "epoch: 40 step: 184, loss is 0.00039766577538102865\n",
      "epoch: 40 step: 185, loss is 0.0005733412690460682\n",
      "epoch: 40 step: 186, loss is 0.00046707107685506344\n",
      "epoch: 40 step: 187, loss is 0.00036643576459027827\n",
      "epoch: 40 step: 188, loss is 0.0018129543168470263\n",
      "epoch: 40 step: 189, loss is 0.000345316861057654\n",
      "epoch: 40 step: 190, loss is 0.0004138317017350346\n",
      "epoch: 40 step: 191, loss is 0.00048452173359692097\n",
      "epoch: 40 step: 192, loss is 0.0005664083291776478\n",
      "epoch: 40 step: 193, loss is 0.0010676748352125287\n",
      "epoch: 40 step: 194, loss is 0.00043208678835071623\n",
      "epoch: 40 step: 195, loss is 0.00026580688427202404\n",
      "epoch: 40 step: 196, loss is 0.00035497709177434444\n",
      "epoch: 40 step: 197, loss is 0.0014128015609458089\n",
      "epoch: 40 step: 198, loss is 0.0009443718590773642\n",
      "epoch: 40 step: 199, loss is 0.0006297340732999146\n",
      "epoch: 40 step: 200, loss is 0.0007098282803781331\n",
      "epoch: 40 step: 201, loss is 0.0006509688100777566\n",
      "epoch: 40 step: 202, loss is 0.0013351524248719215\n",
      "epoch: 40 step: 203, loss is 0.0006686885026283562\n",
      "epoch: 40 step: 204, loss is 0.0017930332105606794\n",
      "epoch: 40 step: 205, loss is 0.000463176955236122\n",
      "epoch: 40 step: 206, loss is 0.0008113705553114414\n",
      "epoch: 40 step: 207, loss is 0.0005987855838611722\n",
      "epoch: 40 step: 208, loss is 0.001087202108465135\n",
      "epoch: 40 step: 209, loss is 0.0006089173257350922\n",
      "epoch: 40 step: 210, loss is 0.0006920227315276861\n",
      "epoch: 40 step: 211, loss is 0.00042347845737822354\n",
      "epoch: 40 step: 212, loss is 0.000410808774176985\n",
      "epoch: 40 step: 213, loss is 0.0007036452880129218\n",
      "epoch: 40 step: 214, loss is 0.0004592501209117472\n",
      "epoch: 40 step: 215, loss is 0.0014144639717414975\n",
      "epoch: 40 step: 216, loss is 0.0002475024666637182\n",
      "epoch: 40 step: 217, loss is 0.0002378226927248761\n",
      "epoch: 40 step: 218, loss is 0.0013088913401588798\n",
      "epoch: 40 step: 219, loss is 0.0017514957580715418\n",
      "epoch: 40 step: 220, loss is 0.0006915322155691683\n",
      "epoch: 40 step: 221, loss is 0.00022313468798529357\n",
      "epoch: 40 step: 222, loss is 0.0006145501392893493\n",
      "epoch: 40 step: 223, loss is 0.000665250001475215\n",
      "epoch: 40 step: 224, loss is 0.0005095428787171841\n",
      "epoch: 40 step: 225, loss is 0.00033822361729107797\n",
      "epoch: 40 step: 226, loss is 0.0005100612179376185\n",
      "epoch: 40 step: 227, loss is 0.0005260946345515549\n",
      "epoch: 40 step: 228, loss is 0.0008476325892843306\n",
      "epoch: 40 step: 229, loss is 0.00022662275296170264\n",
      "epoch: 40 step: 230, loss is 0.0005496100056916475\n",
      "epoch: 40 step: 231, loss is 0.00037498315214179456\n",
      "epoch: 40 step: 232, loss is 0.0005370608996599913\n",
      "epoch: 40 step: 233, loss is 0.0013388270745053887\n",
      "epoch: 40 step: 234, loss is 0.0007909788400866091\n",
      "epoch: 40 step: 235, loss is 0.0011802514782175422\n",
      "epoch: 40 step: 236, loss is 0.0009221243672072887\n",
      "epoch: 40 step: 237, loss is 0.00020772399147972465\n",
      "epoch: 40 step: 238, loss is 0.0005103180301375687\n",
      "epoch: 40 step: 239, loss is 0.0006963573396205902\n",
      "epoch: 40 step: 240, loss is 0.00036622871994040906\n",
      "epoch: 40 step: 241, loss is 0.0006302854744717479\n",
      "epoch: 40 step: 242, loss is 0.0002879745152313262\n",
      "epoch: 40 step: 243, loss is 0.0003713314072228968\n",
      "epoch: 40 step: 244, loss is 0.0006685286061838269\n",
      "epoch: 40 step: 245, loss is 0.0009297769865952432\n",
      "epoch: 40 step: 246, loss is 0.0007080397917889059\n",
      "epoch: 40 step: 247, loss is 0.000862128334119916\n",
      "epoch: 40 step: 248, loss is 0.00033626717049628496\n",
      "epoch: 40 step: 249, loss is 0.0001732664677547291\n",
      "epoch: 40 step: 250, loss is 0.000987803447060287\n",
      "epoch: 40 step: 251, loss is 0.0006268237484619021\n",
      "epoch: 40 step: 252, loss is 0.00029815506422892213\n",
      "epoch: 40 step: 253, loss is 0.0005080265109427273\n",
      "epoch: 40 step: 254, loss is 0.0009286875720135868\n",
      "epoch: 40 step: 255, loss is 0.0005010114400647581\n",
      "epoch: 40 step: 256, loss is 0.0006876842235215008\n",
      "epoch: 40 step: 257, loss is 0.0007331003434956074\n",
      "epoch: 40 step: 258, loss is 0.000622011604718864\n",
      "epoch: 40 step: 259, loss is 0.001434501027688384\n",
      "epoch: 40 step: 260, loss is 0.0009028424974530935\n",
      "epoch: 40 step: 261, loss is 0.00039507573819719255\n",
      "epoch: 40 step: 262, loss is 0.0006073866970837116\n",
      "epoch: 40 step: 263, loss is 0.000390373170375824\n",
      "epoch: 40 step: 264, loss is 4.937066478305496e-05\n",
      "epoch: 40 step: 265, loss is 0.0005365260876715183\n",
      "epoch: 40 step: 266, loss is 0.0004412364505697042\n",
      "epoch: 40 step: 267, loss is 0.00018895050743594766\n",
      "epoch: 40 step: 268, loss is 0.0006481360760517418\n",
      "epoch: 40 step: 269, loss is 0.0011655031703412533\n",
      "epoch: 40 step: 270, loss is 0.0020100665278732777\n",
      "epoch: 40 step: 271, loss is 0.0012441679136827588\n",
      "epoch: 40 step: 272, loss is 0.0009835083037614822\n",
      "epoch: 40 step: 273, loss is 0.0016369648510590196\n",
      "epoch: 40 step: 274, loss is 0.0003751633921638131\n",
      "epoch: 40 step: 275, loss is 0.0014054402709007263\n",
      "epoch: 40 step: 276, loss is 0.0004640693368855864\n",
      "epoch: 40 step: 277, loss is 0.0005026464350521564\n",
      "epoch: 40 step: 278, loss is 0.0008888345910236239\n",
      "epoch: 40 step: 279, loss is 0.00045909773325547576\n",
      "epoch: 40 step: 280, loss is 0.0002820532245095819\n",
      "epoch: 40 step: 281, loss is 0.0003878439893014729\n",
      "epoch: 40 step: 282, loss is 0.0008543907315470278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 step: 283, loss is 0.0008198383147828281\n",
      "epoch: 40 step: 284, loss is 0.001320548471994698\n",
      "epoch: 40 step: 285, loss is 0.0003405412717256695\n",
      "epoch: 40 step: 286, loss is 0.0002591308730188757\n",
      "epoch: 40 step: 287, loss is 0.0009371421183459461\n",
      "epoch: 40 step: 288, loss is 0.0008898705709725618\n",
      "epoch: 40 step: 289, loss is 0.0007663614233024418\n",
      "epoch: 40 step: 290, loss is 0.0002824093389790505\n",
      "epoch: 40 step: 291, loss is 0.0004151395696680993\n",
      "epoch: 40 step: 292, loss is 0.0008400582009926438\n",
      "epoch: 40 step: 293, loss is 0.00041232569492422044\n",
      "epoch: 40 step: 294, loss is 0.00028259167447686195\n",
      "epoch: 40 step: 295, loss is 0.0015431276988238096\n",
      "epoch: 40 step: 296, loss is 0.0003662792732939124\n",
      "epoch: 40 step: 297, loss is 0.0004712776280939579\n",
      "epoch: 40 step: 298, loss is 0.000884348526597023\n",
      "epoch: 40 step: 299, loss is 0.0007622975390404463\n",
      "epoch: 40 step: 300, loss is 0.0012349358294159174\n",
      "epoch: 40 step: 301, loss is 0.00030859961407259107\n",
      "epoch: 40 step: 302, loss is 0.00044005687232129276\n",
      "epoch: 40 step: 303, loss is 0.0004572837788145989\n",
      "epoch: 40 step: 304, loss is 0.0010298340348526835\n",
      "epoch: 40 step: 305, loss is 0.00030740065267309546\n",
      "epoch: 40 step: 306, loss is 0.00017128865874838084\n",
      "epoch: 40 step: 307, loss is 0.0007962289964780211\n",
      "epoch: 40 step: 308, loss is 0.0003655297332443297\n",
      "epoch: 40 step: 309, loss is 0.0009795600781217217\n",
      "epoch: 40 step: 310, loss is 0.0007453500875271857\n",
      "epoch: 40 step: 311, loss is 0.0007864737417548895\n",
      "epoch: 40 step: 312, loss is 0.0006202324875630438\n",
      "epoch: 40 step: 313, loss is 0.0008161208825185895\n",
      "epoch: 40 step: 314, loss is 0.0006294057238847017\n",
      "epoch: 40 step: 315, loss is 0.0006333985948003829\n",
      "epoch: 40 step: 316, loss is 0.0004626082954928279\n",
      "epoch: 40 step: 317, loss is 0.0011912418995052576\n",
      "epoch: 40 step: 318, loss is 0.0008189583895727992\n",
      "epoch: 40 step: 319, loss is 0.0008434287738054991\n",
      "epoch: 40 step: 320, loss is 0.00038741371827200055\n",
      "epoch: 40 step: 321, loss is 0.0003407339099794626\n",
      "epoch: 40 step: 322, loss is 0.0005436069332063198\n",
      "epoch: 40 step: 323, loss is 0.0001939657813636586\n",
      "epoch: 40 step: 324, loss is 0.0001455216552130878\n",
      "epoch: 40 step: 325, loss is 0.0013646177249029279\n",
      "epoch: 40 step: 326, loss is 0.0005471445620059967\n",
      "epoch: 40 step: 327, loss is 0.000374405033653602\n",
      "epoch: 40 step: 328, loss is 1.628103018447291e-05\n",
      "epoch: 40 step: 329, loss is 0.00030993964173831046\n",
      "epoch: 40 step: 330, loss is 0.0004420314508024603\n",
      "epoch: 40 step: 331, loss is 0.000880271487403661\n",
      "epoch: 40 step: 332, loss is 0.00027930192300118506\n",
      "epoch: 40 step: 333, loss is 0.0004466227546799928\n",
      "epoch: 40 step: 334, loss is 0.0007409210666082799\n",
      "epoch: 40 step: 335, loss is 0.0004807951918337494\n",
      "epoch: 40 step: 336, loss is 0.00025978716439567506\n",
      "epoch: 40 step: 337, loss is 0.0002943006984423846\n",
      "epoch: 40 step: 338, loss is 0.0008098399848677218\n",
      "epoch: 40 step: 339, loss is 0.0004679135454352945\n",
      "epoch: 40 step: 340, loss is 0.00027603452326729894\n",
      "epoch: 40 step: 341, loss is 0.0006148171960376203\n",
      "epoch: 40 step: 342, loss is 0.0011027308646589518\n",
      "epoch: 40 step: 343, loss is 0.0005550310597755015\n",
      "epoch: 40 step: 344, loss is 0.0007458451436832547\n",
      "epoch: 40 step: 345, loss is 0.00042728520929813385\n",
      "epoch: 40 step: 346, loss is 0.0006347220041789114\n",
      "epoch: 40 step: 347, loss is 0.0004524289397522807\n",
      "epoch: 40 step: 348, loss is 0.0002312957076355815\n",
      "epoch: 40 step: 349, loss is 0.0004486987309064716\n",
      "epoch: 40 step: 350, loss is 0.0008005709969438612\n",
      "epoch: 40 step: 351, loss is 0.00023994213552214205\n",
      "epoch: 40 step: 352, loss is 0.0005006262799724936\n",
      "epoch: 40 step: 353, loss is 0.0001495924370829016\n",
      "epoch: 40 step: 354, loss is 0.000501959933899343\n",
      "epoch: 40 step: 355, loss is 0.0016340380534529686\n",
      "epoch: 40 step: 356, loss is 0.0008881582180038095\n",
      "epoch: 40 step: 357, loss is 0.001185883767902851\n",
      "epoch: 40 step: 358, loss is 0.001902357442304492\n",
      "epoch: 40 step: 359, loss is 0.0005936568486504257\n",
      "epoch: 40 step: 360, loss is 0.0010149201843887568\n",
      "epoch: 40 step: 361, loss is 0.0002728814724832773\n",
      "epoch: 40 step: 362, loss is 0.0008177882409654558\n",
      "epoch: 40 step: 363, loss is 0.000606512650847435\n",
      "epoch: 40 step: 364, loss is 0.0004361888859421015\n",
      "epoch: 40 step: 365, loss is 0.0006465719197876751\n",
      "epoch: 40 step: 366, loss is 0.0007202585111372173\n",
      "epoch: 40 step: 367, loss is 0.0004682868311647326\n",
      "epoch: 40 step: 368, loss is 0.0007402406772598624\n",
      "epoch: 40 step: 369, loss is 0.0005409916047938168\n",
      "epoch: 40 step: 370, loss is 0.0004786202043760568\n",
      "epoch: 40 step: 371, loss is 0.000536678999196738\n",
      "epoch: 40 step: 372, loss is 0.00034403757308609784\n",
      "epoch: 40 step: 373, loss is 0.0005726742674596608\n",
      "epoch: 40 step: 374, loss is 0.0013297590194270015\n",
      "epoch: 40 step: 375, loss is 0.000676139141432941\n",
      "Train epoch time: 11787.937 ms, per step time: 31.434 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context, Tensor\n",
    "from mindspore.common import set_seed\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.train.callback import TimeMonitor, LossMonitor, CheckpointConfig, ModelCheckpoint\n",
    "from mindspore.communication.management import init, get_rank, get_group_size\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from dataset import create_train_dataset\n",
    "from srcnn import SRCNN\n",
    "from model_utils.config import config\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "def filter_checkpoint_parameter_by_list(origin_dict, param_filter):\n",
    "    \"\"\"remove useless parameters according to filter_list\"\"\"\n",
    "    for key in list(origin_dict.keys()):\n",
    "        for name in param_filter:\n",
    "            if name in key:\n",
    "                print(\"Delete parameter from checkpoint: \", key)\n",
    "                del origin_dict[key]\n",
    "                break\n",
    "\n",
    "\n",
    "def run_train():\n",
    "    cfg = config\n",
    "    data_path = cfg.data_path\n",
    "    pretrained_ckpt_path = cfg.pre_trained_path\n",
    "    data_path += \"/srcnn.mindrecord00\"\n",
    "    output_path = cfg.output_path\n",
    "    if cfg.device_target == \"CPU\":\n",
    "        print(\"Running on CPU\")\n",
    "        if cfg.run_distribute:\n",
    "            init()\n",
    "        context.set_context(mode=context.GRAPH_MODE,\n",
    "                            device_target=cfg.device_target,\n",
    "                            save_graphs=False)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported device target.\")\n",
    "\n",
    "    rank = 0\n",
    "    device_num = 1\n",
    "    train_dataset = create_train_dataset(data_path, batch_size=cfg.batch_size,\n",
    "                                         shard_id=rank, num_shard=device_num)\n",
    "    step_size = train_dataset.get_dataset_size()\n",
    "\n",
    "    # define net\n",
    "    net = SRCNN()\n",
    "\n",
    "    # init weight\n",
    "    if cfg.pre_trained_path:\n",
    "        param_dict = load_checkpoint(pretrained_ckpt_path)\n",
    "        if cfg.filter_weight:\n",
    "            filter_list = [x.name for x in net.end_point.get_parameters()]\n",
    "            filter_checkpoint_parameter_by_list(param_dict, filter_list)\n",
    "        load_param_into_net(net, param_dict)\n",
    "\n",
    "    lr = Tensor(float(cfg.lr), ms.float32)\n",
    "\n",
    "    opt = nn.Adam(params=net.trainable_params(), learning_rate=lr, eps=1e-07)\n",
    "    loss = nn.MSELoss(reduction='mean')\n",
    "    model = Model(net, loss_fn=loss, optimizer=opt)\n",
    "\n",
    "    # define callbacks\n",
    "    callbacks = [LossMonitor(), TimeMonitor(data_size=step_size)]\n",
    "    if cfg.save_checkpoint and rank == 0:\n",
    "        config_ck = CheckpointConfig(save_checkpoint_steps=step_size,\n",
    "                                     keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "        save_ckpt_path = os.path.join(output_path, 'ckpt_' + str(rank) + '/')\n",
    "        ckpt_cb = ModelCheckpoint(prefix=\"srcnn\", directory=save_ckpt_path, config=config_ck)\n",
    "        callbacks.append(ckpt_cb)\n",
    "\n",
    "    model.train(cfg.epoch_size, train_dataset, callbacks=callbacks, dataset_sink_mode=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27c7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ms]",
   "language": "python",
   "name": "conda-env-ms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
